{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1c53e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b00dc989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\scholar-aI\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0fd423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffccbbd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\scholar-aI'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c67f8dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0c95a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Data From the PDF File\n",
    "def load_pdf_file(data):\n",
    "    loader= DirectoryLoader(data,\n",
    "                            glob=\"*.pdf\",\n",
    "                            loader_cls=PyPDFLoader)\n",
    "\n",
    "    documents=loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b952dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\Anil Kumar\\AppData\\Local\\Temp\\ipykernel_11908\\3415809438.py:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  extracted_data=load_pdf_file(data='D:\\scholar-aI\\Data')\n"
     ]
    }
   ],
   "source": [
    "extracted_data=load_pdf_file(data='D:\\scholar-aI\\Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b12f5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 0}, page_content=', Intelligence \\nRoadmap \\n~ lhe Complete \\nProject Lifecycle for \\nDecision-Support \\nApplications \\nLarissa T. Moss ¢ Shaku Atre \\nForeword by Edward Yourdon \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 1}, page_content='Digitized by the Internet Archive \\nin 2022 with funding from \\nKahle/Austin Foundation \\nhttps://archive.org/details/businessintelligo00Omoss \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 2}, page_content='Business Intelligence Roadmap \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 3}, page_content=\"Addison-Wesley Information Technology Series \\nCapers Jones and David S. Linthicum, Consulting Editors \\nThe information technology (IT) industry is in the public eye now more than ever before because of a number of \\nmajor issues in which software technology and national policies are closely related. As the use of software expands, \\nthere is a continuing need for business and software professionals to stay current with the state of the art in soft- \\nware methodologies and technologies. The goal of the Addison-Wesley Information Technology Series is to \\ncover any and all topics that affect the IT community. These books illustrate and explore how information technology \\ncan be aligned with business practices to achieve business goals and support business imperatives. Addison-Wesley \\nhas created this innovative series to empower you with the benefits of the industry experts’ experience. \\nFor more information point your browser to www.awprofessional.com/itseries \\nSid Adelman, Larissa Terpeluk Moss, Data Warehouse \\nProject Management. ISBN: 0-201-61635-1 \\nSid Adelman et al., Impossible Data Warehouse \\nSituations: Solutions from the Experts. ISBN: 0-201- \\n76033-9 \\nWayne Applehans, Alden Globe, and Greg Laugero, \\nManaging Knowledge: A Practical Web-Based \\nApproach. ISBN: 0-201-43315-X \\nDavid Leon Clark, Enterprise Security: The Manager's \\nDefense Guide. ISBN: 0-201-71972-X \\nFrank P. Coyle, XML, Web Services, and the Data \\nRevolution. ISBN: 0-201-77641-3 \\nKevin Dick, XML, Second Edition: A Manager’s Guide. \\nISBN: 0-201-77006-7 \\nJill Dyché, e-Data: Turning Data into Information with \\nData Warehousing. ISBN: 0-201-65780-5 \\nJill Dyché, The CRM Handbook: A Business Guide \\nto Customer Relationship Management. ISBN: 0-201- \\n73062-6 \\nPatricia L. Ferdinandi, A Requirements Pattern: \\nSucceeding in the Internet Economy. ISBN: 0-201- \\n73826-0 \\nDavid Garmus and David Herron, Function Point \\nAnalysis: Measurement Practices for Successful \\nSoftware Projects. ISBN: 0-201-69944-3 \\nJohn Harney, Application Service Providers (ASPs): A \\nManager's Guide. ISBN: 0-201-72659-9 \\nInternational Function Point Users Group, /T \\nMeasurement: Practical Advice from the Experts. \\nISBN: 0-201-74158-X \\nCapers Jones, Software Assessments, Benchmarks, and \\nBest Practices. ISBN: 0-201-48542-7 \\nRavi Kalakota and Marcia Robinson, e-Business 2.0: \\nRoadmap for Success. ISBN: 0-201-72165-1 \\nRavi Kalakota and Marcia Robinson, Services Blueprint: \\nRoadmap for Execution. ISBN: 0-321-15039-2 \\nGreg Laugero and Alden Globe, Enterprise Content \\nServices: Connecting Information and Profitability. \\nISBN: 0-201-73016-2 \\nDavid S. Linthicum, B2B Application Integration: e- \\nBusiness-Enable Your Enterprise. ISBN: 0-201-70936-8 \\nDavid S. Linthicum, Enterprise Application Integration. \\nISBN: 0-201-61583-5 \\nDavid S. Linthicum, Next Generation Application \\nIntegration: From Simple Information to Web Services. \\nISBN: 0-201-84456-7 \\nSergio Lozinsky, Enterprise-Wide Software Solutions: \\nIntegration Strategies and Practices. ISBN: 0-201- \\n30971-8 \\nAnne Thomas Manes, Web Services: A Manager’s \\nGuide. ISBN: 0-321-18577-3 \\nLarissa T. Moss and Shaku Atre, Business Intelligence \\nRoadmap: The Complete Project Lifecycle for Decision- \\nSupport Applications. ISBN: 0-201-78420-3 \\nBud Porter-Roth, Request for Proposal: A Guide to \\nEffective RFP Development. ISBN: 0-201-77575-1 \\nRonald G. Ross, Principles of the Business Rule \\nApproach. ISBN: 0-201-78893-4 \\nDan Sullivan, Proven Portals: Best Practices for \\nPlanning, Designing, and Developing Enterprise \\nPortals. ISBN: 0-321-12520-7 \\nKarl E. Wiegers, Peer Reviews in Software: A Practical \\nGuide. ISBN: 0-201-73485-0 \\nRalph R. Young, Effective Requirements Practices. \\nISBN: 0-201-70912-0 \\nBill Zoellick, CyberRegs: A Business Guide to Web \\nProperty, Privacy, and Patents. ISBN: 0-201-72230-5 \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 4}, page_content='Business Intelligence \\nRoadmap \\nThe Complete Project Lifecycle for \\nDecision-Support Applications \\nLarissa T. Moss, Shaku Atre \\nvv Addison-Wesley \\nBoston « San Francisco * New York * Toronto * Montreal \\nLondon * Munich ° Paris * Madrid \\nCapetown * Sydney * Tokyo * Singapore * Mexico City \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 5}, page_content=\"Many of the designations used by manufacturers and sellers to distinguish their products are \\nclaimed as trademarks. Where those designations appear in this book, and Addison-Wesley was \\naware of a trademark claim, the designations have been printed with initial capital letters or in all \\ncapitals. \\nThe authors and publisher have taken care in the preparation of this book, but make no expressed \\nor implied warranty of any kind and assume no responsibility for errors or omissions. No liability \\nis assumed for incidental or consequential damages in connection with or arising out of the use of \\nthe information or programs contained herein. \\nThe publisher offers discounts on this book when ordered in quantity for bulk purchases and spe- \\ncial sales. For more information, please contact: \\nU.S. Corporate and Government Sales \\n(800) 382-3419 \\ncorpsales@pearsontechgroup.com \\nFor sales outside of the U.S., please contact: \\nInternational Sales \\n(317) 581-3793 \\ninternational@pearsontechgroup.com \\nVisit Addison-Wesley on the Web: www.awprofessional.com \\nLibrary of Congress Cataloging-in-Publication Data \\nMoss, Larissa Terpeluk. \\nBusiness intelligence roadmap : the complete project lifecycle for decision-support \\napplications / Larissa T. Moss, Shaku Atre. \\np. cm. \\nIncludes bibliographical references and index. \\nISBN 0-201-78420-3 (pbk. : alk. paper) \\n1. Business intelligence 2. Decision support systems. I. Atre, S., 1940— II. Title. \\nHD38.7 .M67 2003 \\n658.4'03—dc21 \\n2002026196 \\nCopyright © 2003 by Pearson Education, Inc., Larissa T. Moss, and Shaku Atre \\nAll rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or \\ntransmitted, in any form, or by any means, electronic, mechanical, photocopying, recording, or \\notherwise, without the prior consent of the publisher. Printed in the United States of America. \\nPublished simultaneously in Canada. \\nFor information on obtaining permission for use of material from this work, please submit a writ- \\nten request to: \\nPearson Education, Inc. \\nRights and Contracts Department \\n75 Arlington Street, Suite 300 \\nBoston, MA 02116 \\nFax: (617) 848-7047 \\nISBN 0-201-78420-3 \\nText printed on recycled paper \\n6789 10 11—DOC—09080706 \\nSixth printing, February 2006 \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 6}, page_content='DEDICATION \\nTo my soul mate, Donald P. Sherman, \\nwhose love and support have encouraged me to \\nachieve goals that once seemed unreachable and \\nto face life’s events that at times seemed unbearable. \\n—Larissa T. Moss \\nTo Tante Lisel, and to my mother. \\n—Shaku Atre \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 7}, page_content='Meme? @ xa eats. tem gc Lovie ’ : \\nOO U senses: in ty Agee Vet 7 \\naeag”** ‘ ’ a \\nGeom od (nd . Sat oe hb baw a \\nDt enter pre Me oar ecttitaee = Spend ts fielded 3 + comma) age 9 ap” ths @ aoBy a \\n© mre pais: ap est ig aoe eet \\nfer p@ite: bei beasties aK» ab pennevt ein & \\naot te. Rr aie Si ee a ae a if oe \\nChopats © 1 oruenirtadsa thane nati Tencd en OF : joni mguny oro Lggny burs eoudl hegenec tan san] mow : — \\nDed oes cay? os Neila raced tie ‘evaitlon a : \\nraat ei : mee tym indents an es is Sant us 7 \\nWF) ter t? sai . ; = \\nWe qeasr - ae sear _——_— - ae - \\nae Ore et ee oll : 7 : \\nNapee “ares Pg Vik a - \\n—— eee Gate OS — es wl Pee @ow 4 ~- © \\nSyeee tne © leaeleraewie of but dos.) Snel of = Le - a => —— : \\na eT a ‘ a. \\nSe 23710 ° OR. | Seo \\nee en ore ® coals a me © —_ \\n126% ake ans \\nCBA 411i \\na > -_ \\n—_ \\nOF \\n= Yr Hie” \\n| (patig) O 7s @ hearer, 7 sbhne O.. oa FV \\nCh tighty sass + 1) pt 1d Gh oe me wey \\nteenie’ A} ow bem 0 te ns Qe ad ; \\nathiy um wide ad Ocan eons = 6! *s @ = a \\nPu hte) Stringer rah yp Cates <= \\nBer Se idne « laering pe cepaty oy Came e \\nOo tenet & \\nAcar Oie oon, ip \\nae co Coton ts Cnpeertns Ge rf \\n24 ire: writ Jee OH \\nGeer 1 7 is 7 T) Vas ji 7 = ry \\nVe Sco clas i oF \\noe rag! ~« @ehioye * as \\nwm 4) IU 1d ee ey \\nMo 4G) \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 8}, page_content='Contents \\nAbout the Authors xvii \\nForeword xix \\nPreface xxi \\nThe Purpose of This Book xxii \\nComplexity xxii \\nStep-by-Step Guide xxii \\nHow This Book Is Organized xxiii \\nPart I: Stages and Steps xxiv \\nPart II: Ata Glance xxv \\nHow to Use This Book  xxvi \\nWho Should Read This Book xxvi \\nBusiness Representatives xxvi \\nBusiness Sponsors xxvi \\nProject Managers xxviii \\nTechnicians xxvix \\nComments xxx \\nAcknowlegments xxxi \\nPARTI STAGES AND STEPS 1 \\nChapter Zero Guide to the Development Steps 3 \\nBusiness Intelligence Definition 4 \\nBI Decision-Support Initiatives 5 \\nDevelopment Approaches 5 \\nThe Traditional Development Approach 6 \\nThe Cross-Organizational Development Approach 8 \\nEngineering Stages and the Development Steps 11 \\nParallel Development Tracks 17 \\nBI Project Team Structure 20 \\nThe Core Team 20 \\nThe Extended Team 23 \\nThe BI Arbitration Board 26 \\nvii \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 9}, page_content='Viii Contents \\nJustification for Using This Project Lifecycle Guide 26 \\nBibliography and Additional Reading 27 \\nChapter One Step 1: Business Case Assessment 29 \\nBusiness Justification 31 \\nBusiness Drivers 33 \\nBusiness Analysis Issues 35 \\nInformation Needs 35 \\nTypes of Data Sources 35 \\nSource Data Quality 37 \\nCost-Benefit Analysis 37 \\nRisk Assessment 40 \\nBusiness Case Assessment Activities 45 \\nDeliverable Resulting from These Activities 48 \\nRoles Involved in These Activities 49 \\nRisks of Not Performing Step 1 49 \\nBibliography and Additional Reading 50 \\nChapter Two Step 2: Enterprise Infrastructure Evaluation \\nStep 2, Section A: Technical Infrastructure Evaluation 53 \\nThe Hardware Platform 54 \\nControlled Chaos 54 \\nHardware Platform Requirements 55 \\nThe Middleware Platform 57 \\nDBMS Gateways 58 \\nThe DBMS Platform 58 \\nCriteria for Selecting a DBMS 59 \\nTechnical Infrastructure Evaluation Activities 61 \\nDeliverables Resulting from These Activities 62 \\nRoles Involved in These Activities 63 \\nRisks of Not Performing Step 2, Section A 63 \\nStep 2, Section B: Nontechnical Infrastructure Evaluation 64 \\nThe Effects of Stovepipe Development 65 \\nThe Need for Nontechnical Infrastructure 66 \\nEnterprise Architecture 68 \\nEnterprise Standards 71 \\nNontechnical Infrastructure Evaluation Activities 75 \\nDeliverable Resulting from These Activities 76 \\nRoles Involved in These Activities 77 \\na) | \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 10}, page_content='Contents ix \\nRisks of Not Performing Step 2, Section B 78 \\nBibliography and Additional Reading 78 \\nTechnical Infrastructure Evaluation 78 \\nNontechnical Infrastructure Evaluation 79 \\nChapter Three Step 3: Project Planning 81 \\nManaging the BI Project 83 \\nDefining the BI Project 84 \\nProject Goals and Objectives 85 \\nProject Scope 85 \\nProject Risks 85 \\nProject Constraints 86 \\nAssumptions 87 \\nChange-Control Procedures 88 \\nIssues Management Procedures 90 \\nPlanning the BI Project 90 \\nActivities and Tasks 90 \\nEstimating Techniques 92 \\nResource Assignment 93 \\nTask Dependencies 94 \\nResource Dependencies 95 \\nCritical Path Method 95 \\nProject Schedules 96 \\nProject Planning Activities 98 \\nDeliverables Resulting from These Activities 100 \\nRoles Involved in These Activities 101 \\nRisks of Not Performing Step 3 103 \\nBibliography and Additional Reading 103 \\nChapter Four Step 4: Project Requirements Definition 105 \\nGeneral Business Requirements 108 \\nInterviewees for General Business Requirements 109 \\nData Quality Requirements 110 \\nBusiness Requirements Report 111 \\nProject-Specific Requirements 112 \\nInterviewees for Project-Specific Requirements 113 \\nApplication Requirements Document 114 \\nThe Interviewing Process 116 \\nInterviewing Considerations 116 \\nInterviewing Tips 117 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 11}, page_content='x Contents \\nProject Requirements Definition Activities 118 \\nDeliverable Resulting from These Activities 121 \\nRoles Involved in These Activities 121 \\nRisks of Not Performing Step 4 122 \\nBibliography and Additional Reading 123 \\nChapter Five Step 5: Data Analysis 125 \\nBusiness-Focused Data Analysis 127 \\nTop-Down Logical Data Modeling 128 \\nProject-Specific Logical Data Model 128 \\nEnterprise Logical Data Model 129 \\nLogical Data Modeling Participants 131 \\nStandardized Business Meta Data 131 \\nBottom-Up Source Data Analysis 133 \\nTechnical Data Conversion Rules 134 \\nBusiness Data Domain Rules 134 \\nBusiness Data Integrity Rules 135 \\nData Cleansing 136 \\nData Quality Responsibility 137 \\nSource Data Selection Process 137 \\nKey Points of Data Selection 139 \\nTo Cleanse or Not to Cleanse 140 \\nCleansing Operational Systems 141 \\nData Analysis Activities 141 \\nDeliverables Resulting from These Activities 143 \\nRoles Involved in These Activities 144 \\nRisks of Not Performing Step5 145 \\nBibliography and Additional Reading 146 \\nChapter Six Step 6: Application Prototyping 149 \\nPurposes of Prototyping 151 \\nTime-Boxing 152 \\nBest Practices for Prototyping 153 \\nConsiderations for Prototyping 154 \\nTypes of Prototypes 156 \\nShow-and-Tell Prototype 156 \\nMock-Up Prototype 156 \\nProof-of-Concept Prototype 157 \\nVisual-Design Prototype 157 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 12}, page_content='Contents \\nDemo Prototype 158 \\nOperational Prototype 159 \\nBuilding Successful Prototypes 159 \\nPrototype Charter 160 \\nGuidelines for Prototyping 161 \\nSkills Survey 162 \\nApplication Prototyping Activities 163 \\nDeliverables Resulting from These Activities 165 \\nRoles Involved in These Activities 165 \\nRisks of Not Performing Step 6 166 \\nBibliography and Additional Reading 167 \\nChapter Seven Step 7: Meta Data Repository Analysis 169 \\nThe Importance of Meta Data 172 \\nMeta Data Categories 173 \\nMeta Data Repository as Navigation Tool 174 \\nData Standardization 175 \\nMeta Data Classifications 176 \\nGroupings of Meta DataComponents 176 \\nPrioritization of Meta Data Components 179 \\nMeta Data Repository Challenges 182 \\nTechnical Challenges 182 \\nStaffing Challenges 183 \\nBudget Challenges 183 \\nUsability Challenges 183 \\nPolitical Challenges 184 \\nThe Logical Meta Model 184 \\nThe Entity-Relationship Meta Model 185 \\nMeta-Meta Data 186 \\nMeta Data Repository Analysis Activities 186 \\nDeliverables Resulting from These Activities 188 \\nRoles Involved in These Activities 188 \\nRisks of Not Performing Step 7 189 \\nBibliography and Additional Reading 190 \\nChapter Eight Step 8: Database Design 191 \\nDifferences in Database Design Philosophies 193 \\nOperational Databases 193 \\nBI Target Databases 196 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 13}, page_content='xii Contents \\n| ER APSE SESE STEGER TEP TBE SOE TERE ESSA RE TEA OSE IBS TEL ETE DE REE EPRI ELIE CELE OEE LEE LEE IE OE A II IEE ELE \\nLogical Database Design 197 \\nThe Star Schema 197 \\nThe Snowflake Schema 200 \\nPhysical Database Design 201 \\nImplementation Options 201 \\nPhysical Dataset Placement 201 \\nPartitioning 202 \\nClustering 202 \\nIndexing 202 \\nReorganizations 203 \\nBackup and Recovery 203 \\nParallel Query Execution 204 \\nDatabase Design Activities 204 \\nDeliverables Resulting from These Activities 207 \\nRoles Involved in These Activities 208 \\nRisks of Not Performing Step 8 209 \\nBibliography and Additional Reading 209 \\nChapter Nine Step 9: Extract/Transform/Load Design 211 \\nImplementation Strategies 213 \\nPreparing for the ETL Process 215 \\nThe Initial Load 216 \\nThe Historical Load 217 \\nThe Incremental Load 217 \\nDesigning the Extract Programs 219 \\nDesigning the Transformation Programs 221 \\nSource Data Problems 221 \\nData Transformations 222 \\nDesigning the Load Programs 223 \\nReferential Integrity 224 \\nIndexing 224 \\nDesigning the ETL Process Flow 225 \\nThe Source-to-Target Mapping Document 225 \\nThe ETL Process Flow Diagram 225 \\nThe Staging Area 228 \\nEvaluating ETL Tools 229 \\nETL Design Activities 231 \\nDeliverables Resulting from These Activities 233 \\nRoles Involved in These Activities 233 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 14}, page_content='Contents xiii \\nRisks of Not Performing Step9 234 \\nBibliography and Additional Reading 234 \\nChapter Ten Step 10: Meta Data Repository Design 237 \\nMeta Data Silos 239 \\nSources of Meta Data 240 \\nMeta Data Repository Solutions 242 \\nCentralized Meta Data Repository 242 \\nDecentralized Meta Data Repository 244 \\nDistributed XML-Enabled Meta Data Solution 245 \\nDesigning a Meta Data Repository 247 \\nEntity-Relationship Design 247 \\nObject-Oriented Design 248 \\nLicensing (Buying) a Meta Data Repository 250 \\nProduct Evaluation 251 \\nVendor Evaluation 252 \\nMeta Data Repository Design Activities 254 \\nDeliverables Resulting from These Activities 255 \\nRoles Involved in These Activities 256 \\nRisks of Not Performing Step 10 257 \\nBibliography and Additional Reading 257 \\nChapter Eleven Step 11: Extract/Transform/Load Development 259 \\nSource Data Transformation 261 \\nData Transformation Activities 261 \\nUnderestimating Data Transformation Efforts 262 \\nReconciliation 263 \\nCalculating Reconciliation Totals 264 \\nStoring Reconciliation Statistics 266 \\nPeer Reviews 267 \\nETL Testing 268 \\nUnit Testing 269 \\nIntegration Testing 270 \\nRegression Testing 271 \\nPerformance Testing 271 \\nQuality Assurance Testing 272 \\nAcceptance Testing 272 \\nFormal Test Plan 273 \\nETL Development Activities 276 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 15}, page_content='Xiv Contents \\nDeliverables Resulting from These Activities 277 \\nRoles Involved in These Activities 278 \\nRisks of Not Performing Step 11 279 \\nBibliography and Additional Reading 279 \\nChapter Twelve Step 12: Application Development 281 \\nOnline Analytical Processing Tools 283 \\nAdvantages of OLAP Tools 284 \\nOLAP Tool Features 285 \\nMultidimensional Analysis Factors 287 \\nMultivariate Analysis 289 \\nOnline Analytical Processing Architecture 289 \\nPresentation Services 290 \\nOLAP Services 291 \\nDatabase Services 292 \\nDevelopment Environments 292 \\nApplication Development Activities 295 \\nDeliverables Resulting from These Activities 297 \\nRoles Involved in These Activities 298 \\nRisks of Not Performing Step 12 299 \\nBibliography and Additional Reading 299 \\nChapter Thirteen Step 13: Data Mining 301 \\nDefining Data Mining 303 \\nThe Importance of Data Mining 305 \\nData Sources for Data Mining 306 \\nData Mining Techniques 307 \\nAssociations Discovery 307 \\nSequential Pattern Discovery 308 \\nClassification 309 \\nClustering 309 \\nForecasting 309 \\nData Mining Operations 310 \\nPredictive and Classification Modeling 310 \\nLink Analysis 311 \\nDatabase Segmentation 311 \\nDeviation Detection 311 \\nApplications of Data Mining 311 \\nData Mining Activities 313 \\nDeliverables Resulting from These Activities 315 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 16}, page_content='Contents XV \\nRoles Involved in These Activities 316 \\nRisks of Not Performing Step 13 316 \\nBibliography and Additional Reading 317 \\nChapter Fourteen Step 14: Meta Data Repository Development 319 \\nPopulating the Meta Data Repository 321 \\nMeta Data Repository Interface Processes 324 \\nThe Tool Interface Process 324 \\nThe Access Interface Process 325 \\nMeta Data Repository Testing 326 \\nPreparing for the Meta Data Repository Rollout 327 \\nMeta Data Repository Directory 330 \\nMeta Data Repository Development Activities 331 \\nDeliverables Resulting from These Activities 332 \\nRoles Involved in These Activities 333 \\nRisks of Not Performing Step 14 334 \\nBibliography and Additional Reading 335 \\nChapter Fifteen Step 15:Implementation 337 \\nIncremental Rollout 339 \\nSecurity Management 340 \\nSecurity Measures for BI Applications 340 \\nSecurity in a Multi-Tier Environment 341 \\nSecurity for Internet Access 344 \\nData Backup and Recovery 345 \\nMonitoring the Utilization of Resources 347 \\nComputer Utilization 347 \\nNetwork Utilization 347 \\nPersonnel Utilization 348 \\nGrowth Management 349 \\nGrowth in Data 349 \\nGrowth in Usage 350 \\nGrowth in Hardware 351 \\nImplementation Activities 352 \\nDeliverables Resulting from These Activities 354 \\nRoles Involved in These Activities 355 \\nRisks of Not Performing Step 15 356 \\nBibliography and Additional Reading 356 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 17}, page_content='xvi Contents \\nChapter Sixteen Step 16: Release Evaluation 359 \\nThe Application Release Concept 361 \\nGuidelines for Using the Release Concept 362 \\nPost-Implementation Reviews 364 \\nOrganizing a Post-Implementation Review 366 \\nPost-Implementation Review Session Flow 368 \\nRelease Evaluation Activities 369 \\nDeliverables Resulting from These Activities 371 \\nRoles Involved in These Activities 371 \\nRisks of Not Performing Step 16 374 \\nBibliography and Additional Reading 375 \\nPARTIIT ATAGLANCE 377 \\nChapter Seventeen Human Resource Allocation Matrix 379 \\nChapter Eighteen Entry & Exit Criteria and Deliverables Matrix 387 \\nChapter Nineteen Activity Dependency Matrix 405 \\nChapter Twenty ‘Task/Subtask Matrix 411 \\nChapter Twenty-one Practical Guidelines Matrix 455 \\nAppendix Work Breakdown Structure 491 \\nIndex 525 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 18}, page_content='About the Authors \\nLarissa T. Moss \\nMs. Moss is president of Method Focus, Inc. She consults, lectures, and \\nspeaks at conferences worldwide on the topics of business intelligence, \\ndata warehousing, customer relationship management, information \\nquality, data integration, and cross-organizational application develop- \\nment. She has coauthored the books Data Warehouse Project Management \\n(Addison-Wesley, 2000) and Impossible Data Warehouse Situations (Addison- \\nWesley, 2002). She publishes white papers through the Cutter Consortium \\nand articles in TDWI Journal of Data Warehousing, DM Review, Cutter IT \\nJournal, The Navigator, and Analytic Edge. She is a member of the IBM \\nGold Group and a senior consultant of the Cutter Consortium. She is a \\ncontributing member to the “Ask the Experts” forum of DM Review. She \\nwas a part-time faculty member at the Extended University of California \\nPolytechnic University, Pomona, and an associate of the Codd & Date \\nConsulting Group. Ms. Moss can be reached at Imoss@methodfocus.com. \\nShaku Atre \\nMs. Atre is president of Atre Group, Inc., specializing in business intelli- \\ngence, data warehousing, and DBMS. She is on the board of AtreNet, \\nInc., a Web agency in Santa Cruz, CA. Ms. Atre was a partner with Price- \\nWaterhouseCoopers. She held a wide variety of management and techni- \\ncal positions at IBM. She is a renowned expert, consultant, and a speaker \\nin business intelligence, data warehousing, end-user computing, and “Politics \\nand IT.” She has taught graduate-level courses in databases at New York \\nUniversity. Ms. Atre lectures on these topics worldwide. She is a columnist \\nwith Computerworld. Her articles are available at http://www.atre.com. \\nMs. Atre is the author of five books, including Data Base: Structured Tech- \\nniques for Design, Performance and Management, and Distributed Data- \\nbases, Cooperative Processing & Networking. Ms. Atre holds a master’s \\ndegree in statistics and has done research at the University of Heidelberg, \\nGermany, in mathematics. She can be reached at shaku@atre.com. \\nxvii \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 19}, page_content='= 7 7 * : 7 ; ; \\nbat cole Mien SA Ti ED thie oe \\n(ie 2? Qo Se — =e EES (US Cages \\nPaspie ti se ah rredh - i Oe on eee | > \\nfear meat bel) 1 7 é : a \\n= n \\na a Pam hee 7 i \\ndl \\n(Pyicinesg 0 t--? beter a 2 e ams 3 ene \\n(oh MaehT TY Higa! ML o> Sem ltire aot je aa — \\nBae oe “tin A ae tHhiby fh hist Sueno aw Peay) al \\nE Wetto ath ay ean hs notivicld vial: 5¢! Mg | \\nrd , Way Seis ys ae st iduod oat bg vung edd ae tear \\n) wala a2 ig oe AAT il fit eegael hers (WO, ede eae \\nimathairnena) vie!) och: dew? (rng wlitw conti. we let \\naed sere Pile Soho co) 5 vp Marcie. Vortt ai esiige bow : ; \\nA) aii Xa ¥ebrrars s aj Maple siF2 Wh st ae sotecrenets wht veal, —_ \\noe eee ee ee Sale beuwNA TAG Lo cma? “eeseega! ‘att tad? alt <2 Sere game Onna 4 \\nPuayplly Je, cteg tw\\\\y belyrrey, ea pe ebony 2 ar aw ¢ ope . \\naalt & Sbold adi hu “ri PE OE. Aw) qurerirtk airy! maa \\n(ears alaee Serta alae 0: ceil eet en \\nPants Teeyny imines “em? 61 * i \\nCRApits Tipit ce | eee) Coins De 4 \\n, eee. \\nCpr ie aT] fits Saha AIBA Fare rmneeey a Gath al \\nspies 1g Giel sift np ai ote ORME Bowe greg eagy ater pot \\nSee io te gage SA oh’, > care) pane i etd ant Gre ste sor ai WA, russ str G. Sige &.- \\nAsutvas bite trarasgsoect te ciece shiw s Glut al? cope eae \\nTElosg? © brs.tosiusny) Jreqe Lenwoiees § 0 ae MGT te = , : \\nciti * bean anit sorte yseur-betes \\\\arleaoctoriet s nual eg eet 7 \\ndl walt je eradanb ni ooo ivesk easly tga el SHES Bn 4 \\nwurtuiler « sit idwuhow suyor seed? mouse Wah a4 Ergot ie \\nneh Ota wren an ‘ w oidalcvs oye — nih Pamrrgeone? ce \\neet tqpenwené a5 wie sbalsni gine \\nwil Weivted” fom Apsineyere hy Meee \\napie » éblad oA 2h ane = \\ngnedisbick to viieiovi) oft ty does \\naw AiG ats & baths eine \\nWve \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 20}, page_content=\"Foreword \\nIn today’s highly competitive and increasingly uncertain world, the quality and \\ntimeliness of an organization’s “business intelligence” (BI) can mean not only the \\ndifference between profit and loss but even the difference between survival and \\nbankruptcy. \\nIn helping senior executives and information technology (IT) managers, \\nMoss and Atre’s greatest contribution, I believe, is the comprehensive nature of \\ntheir “roadmap”; as the subtitle of their book promises, they have provided a \\ncomplete project lifecycle for the development of such systems. Because BI and \\ndecision-support systems ultimately rely on a rich treasure trove of data, there is a \\nsignificant emphasis in Business Intelligence Roadmap on various technical \\naspects of data: meta data, data mining, data warehousing, multidimensional \\ndata analysis (online analytical processing [OLAP]), data security, and so on. But \\nthere is also significant emphasis on the business justification, project planning, \\nanalysis, implementation, and deployment details of BI systems. In addition to \\nthe more traditional details of systems analysis, Moss and Atre also provide prac- \\ntical advice on the structure and organization of the project team, as well as the \\nskills and talents of the human resource roles required for such project teams. \\nAnd, because of the importance of building enterprise-wide BI systems, the \\nauthors also describe the lifecycle activities that must be carried out in a cross- \\norganizational fashion. \\nAnyone planning to lead a BI project initiative, as well as the data analysts, \\nsystems architects, and other senior IT professionals involved in such an initia- \\ntive, should definitely read Business Intelligence Roadmap from cover to cover. It \\nwouldn't hurt senior executives to read the entire book, too, for then they might \\nhave a better appreciation for the careful planning and disciplined project organi- \\nzation required to make a BI project succeed. But Moss and Atre have wisely rec- \\nognized that many senior executives are too busy, or too technophobic, to read \\nthe entire book; for such people, they have provided an “at a glance” section of \\nthe book that concludes with a final chapter summarizing dos, don'ts, and tips \\nxix \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 21}, page_content='xXx Foreword \\nfor each of the project lifecycle steps that they discuss in detail. For example, the \\npenultimate tip, in the final chapter of the book, advises the reader to \\nImplement your BI applications using the release concept. It is much better to \\ndeliver high-quality, partially functioning application releases over time than to \\ndeliver a low-quality, completed application that is fraught with many defects \\nand with dirty data. If the first release is successful, new requirements will \\nemerge as the business people get used to the iterative development process. \\nEdward Yourdon \\nNew York City \\nSeptember 2002 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 22}, page_content='Preface \\nMany organizations are already well equipped to implement successful \\nbusiness intelligence (BI) decision-support applications, such as data \\nwarehouses, data marts, and other business analytics applications. How- \\never, during our consulting and teaching engagements, we have encoun- \\ntered many ill-equipped organizations as well. We observed some common \\nfactors among them, which we address in this book: \\n* Lack of understanding of the complexity of BI decision-support \\nprojects \\n* Lack of recognizing BI decision-support projects as cross-organizational \\nbusiness initiatives and not understanding that cross-organizational ini- \\ntiatives are different from stand-alone solutions \\n* Unavailable or unwilling business representatives \\n* Unengaged business sponsors or business sponsors who have little or \\nno authority due to their low-level positions within the organization \\n* Lack of skilled and available staff as well as suboptimum staff utilization \\n* Inappropriate project team structure and dynamics \\n* No software release concept (no iterative development method) \\n* No work breakdown structure (no methodology) \\n* Ineffective project management (only project administration) \\n* No business analysis and no standardization activities \\n* No appreciation of the impact of dirty data on business profitability \\n* No understanding of the necessity for and the usage of meta data \\n* Too much reliance on disparate methods and tools (the “silver bullet” \\nsyndrome) \\nBI project managers and project teams can use this book to improve \\ntheir project life cycles. They can also use it to obtain the appropriate rec- \\nognition for their BI projects from the business community and to solicit \\nXxi \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 23}, page_content='xxii Preface \\nSP SF RET EA AT EE TT IE I IT TD IE \\nthe required support from their executive management. BI project team \\nmembers and the business representatives assigned to them can use this \\nbook to gain a better understanding of the development effort required \\nto build and deploy successful BI decision-support applications. \\nTHE PURPOSE OF THIS BOOK \\nBusiness Intelligence Roadmap is a guide for developing BI decision-support \\napplications. The two main purposes of this book are to \\n1. Explain the complexity of BI decision-support projects \\n2. Present a step-by-step guide for the entire BI project lifecycle \\nComplexity \\nIn order to give you an appreciation of the complexity of BI decision-support \\nprojects, we describe all of the components that go into a BI decision- \\nsupport development effort. For example: \\n* You should know what makes a BI decision-support application dif- \\nferent from a traditional decision-support system so that you can \\navoid costly mistakes. \\n* You should understand the infrastructure components of your new \\nBI decision-support application, such as the tools available (for \\ndevelopment and for access and analysis). \\n* You should be able to recognize items that could impair the success of \\nyour new BI decision-support application. \\n* You should determine how many resources you need and what type \\nof resources, both technical and human. \\n* You should decide on the design or architecture of your BI decision- \\nsupport application, such as designing for multidimensional report- \\ning or ad hoc querying. \\nStep-by-Step Guide \\nOur step-by-step guide across the breadth of a complete development \\nlifecycle includes activities, deliverables, roles and responsibilities, dos and \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 24}, page_content=\"How This Book Is Organized xxiii \\ndon'ts, and entry and exit criteria, plus tips and rules of thumb to lead \\nyou to a successful BI decision-support implementation. For example: \\n* You should choose which steps you ought to perform on your BI \\nproject because no two BI decision-support projects are exactly alike. \\n* You should know whether to start with a cross-organizational deci- \\nsion-support solution or a tailored departmental solution with the \\nbasis for expansion. \\n* You should understand the sequence in which to perform develop- \\nment activities, that is, which ones can be performed in parallel \\ntracks and which ones have a strong dependency on one another. \\nIn contrast to topic-specific materials available on BI, this book is a \\nsingle-source development guide written specifically for BI decision-sup- \\nport applications. The guidelines presented in this book are based not \\nonly on our personal experiences but also on some of the best practices \\ncovered in topic-specific books, articles, and Web sites. \\nHow THIS BOOK IS ORGANIZED \\nAll software development projects are complicated engineering projects, \\nas demonstrated by the breadth of topics covered in this book. Chapter 0, \\nGuide to the Development Steps, explains the general organization of the \\ndevelopment guidelines in Business Intelligence Roadmap, which is as follows: \\nEngineering stages \\nily Parallel development tracks \\nau Development steps \\nkes) Major activities \\nii> Tasks and subtasks \\nThis book is organized into two major parts. Part I, Stages and Steps, \\ndescribes the 16 development steps, which are introduced in Chapter 0. \\nPart I gives you a broad understanding of the development effort involved \\nin BI decision-support projects. Part H, At a Glance, supplements the text \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 25}, page_content='Xxiv Preface \\ncontained in the first part of the book with several matrices that should \\nbe used together as a reference guide for all BI decision-support projects. \\nPart I: Stages and Steps \\nPart I begins with Chapter 0, Guide to the Development Steps, and is fol- \\nlowed by 16 development chapters. Each of the 16 development chapters \\nis dedicated to one unique development step and describes the effort \\nrequired to perform the activities of that step. \\nGuide to the Development Steps (Chapter 0) describes the general \\nlayout of the development guidelines presented in this book, contrasting \\nthose guidelines with a traditional development methodology. It dis- \\ncusses the six engineering stages as well as the three parallel development \\ntracks, and it groups the applicable development steps under both. Chap- \\nter 0 explains the application release concept and shows how to organize \\na BI project with the appropriate roles and responsibilities for the core \\nteam and the extended team. \\nEach of the development steps (Chapters 1-16) begins with an individ- \\nual chapter overview followed by a section called Things to Consider. \\nThese are general questions BI project teams usually contemplate when \\ndeciding which activities need to be performed under each development \\nstep. These questions are merely presented as “food for thought” and are \\nnot necessarily explored in the chapters; nor are they all-inclusive. Each \\nchapter discusses the main topics applicable to the development step cov- \\nered by that chapter. Some topics apply to more than one development \\nstep, such as testing or product evaluation. However, to avoid redun- \\ndancy these common topics are covered in only one chapter and are only \\nbriefly referenced in the other chapters. \\nEach of the 16 chapters contains a list of major activities for that \\ndevelopment step, accompanied by a figure showing what activities could \\nbe performed concurrently. The list of activities is followed by descrip- \\ntions of the deliverables resulting from these activities and the roles \\ninvolved in performing these activities. Each chapter concludes with a \\nbrief discussion of risks to weigh in case you decide not to perform that \\nstep on your project. Do not interpret the risks of not performing the step \\nto mean that every BI project team must perform every development step \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 26}, page_content=\"How This Book Is Organized XXV \\nexactly as suggested. Instead, use the risk section to determine whether \\nthe activities in that development step are—or should be—mandatory on \\nyour project. If they are not, you may decide not to perform some or all \\nof those activities after discussing the risks with the business sponsor. \\nPart II: At a Glance \\nPart II contains the following matrices. \\nThe Human Resource Allocation Matrix (Chapter 17) lists all the vital \\nroles involved in performing the step activities, tasks, and subtasks. \\nThe roles listed in this matrix need to be assigned to project team \\nmembers. In order to help you discover and avoid potential resource \\nallocation problems, the steps that can be performed in parallel and \\ntheir appropriate roles are listed together. \\nThe Entry & Exit Criteria and Deliverables Matrix (Chapter 18) indi- \\ncates the prerequisites, results, and deliverables for each development \\nstep. Not every BI project team will need to perform all activities for \\nall development steps. This matrix should help you determine whether \\nyou can skip a step or incorporate some of its activities into other steps. \\nThe Activity Dependency Matrix (Chapter 19) is a collection of activ- \\nity dependency charts for the development steps. This matrix shows \\nat a glance which activities in each step can be performed concur- \\nrently. It should be used to determine workflow and task assignments \\nfor project team members. \\nThe Task/Subtask Matrix (Chapter 20) itemizes all pertinent tasks, \\nand in some cases subtasks, for all the major activities under each \\nstep. This matrix should be used to prepare the work breakdown \\nstructure for the project plan. You can customize (expand or reduce) \\nthe tasks and subtasks on an as-needed basis for individual projects. \\nThe Practical Guidelines Matrix (Chapter 21) presents three subsec- \\ntions for each development step: Dos, Don'ts, and Tips and Rules of \\nThumb. Dos point out best practices for the development steps, and \\nDon'ts instruct you how to avoid traps and pitfalls. Tips and Rules of \\nThumb are our personal collection of experiences over several decades \\nof developing cross-organizational decision-support applications. \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 27}, page_content='Xxvi Preface \\nHow TO USE THIS BOOK \\nWe suggest that all core members of the BI project team make use of this \\nbook as follows. \\nIe First, read all the chapters in Part I to gain an overall understanding \\nof all the components of BI decision-support development. \\n. Next, compare your own BI project scope and requirements to the \\ntopics in the book. Use the discussions in the chapters to decide \\nwhich specific development steps apply to your project. \\n. Go to Chapter 18 and look up the entry and exit criteria for the steps \\nyou selected. Be sure that you have the prerequisites to implement \\nyour development approach and that you have a clear understanding \\nof what it takes to move forward. \\n. Put your project plan together for the steps you have chosen by con- \\nsulting the activity dependency flow charts in Chapter 19 and by using \\nthe tasks and subtasks listed in Chapter 20. To kick-start your project, \\nyou may want to copy and customize the work breakdown structure \\nprovided on the CD included with this book to fit your needs. The \\nwork breakdown structure on the CD is a Microsoft Project file that \\nalready includes the step dependencies (shown in Figure 0.6 in Chap- \\nter 0) and the activity dependencies (shown in the flow charts in \\nChapter 19). In addition, the work breakdown structure contains \\nsome basic mandatory task dependencies. \\n. Use the matrices in Part II as a quick reference to help guide your \\ndevelopment work throughout the project. \\nWHO SHOULD READ THIS BOOK \\nSegments of this book should be read and referenced by every mem- \\nber of the BI project team, including business representatives. It is impor- \\ntant that all project participants understand “the big picture” and how \\nthey and their roles fit into it. This also applies to third-party consultants, \\nwho can fill any technical role on the project team. Understanding this \\nlarger view of the project and its development effort is essential in main- \\ntaining a level of enthusiasm and cooperation necessary for the team. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 28}, page_content='Who Should Read This Book Xxvii \\nBelow we spotlight team members’ roles and provide lists of the most \\nuseful and applicable chapters for each specific role. \\nBusiness Representatives \\nAlthough the development steps are technical in nature, business repre- \\nsentatives involved in BI projects must understand what activities need to \\noccur during the development effort. Business representatives are \\nexpected to participate as full-time members of the project core teams, \\nand some of the activities described in this book will be assigned to them. \\nTable P.1 lists chapters of particular interest to business representatives. \\nTable P.1: Chapters for Business Representatives \\nChapter Title \\n0 Guide to the Development Steps \\n1 Step 1: Business Case Assessment \\n2 Step 2: Enterprise Infrastructure Evaluation \\n(especially Section B, Nontechnical Infrastructure Evaluation) \\nStep 3: Project Planning \\nStep 4: Project Requirements Definition \\nStep 5: Data Analysis \\nStep 7: Meta Data Repository Analysis \\n3 \\n4 \\n5 \\n6 Step 6: Application Prototyping \\n7 \\n9 Step 9: Extract/Transform/Load Design \\n13 Step 13: Data Mining \\n16 Step 16: Release Evaluation \\nBusiness Sponsors \\nAlthough business sponsors are not directly involved in the daily devel- \\nopment effort, they should make frequent checks on the health of the \\nproject as well as the project team. In order to do this, business sponsors \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 29}, page_content='Xxviii Preface \\nTable P.2: Chapters for Business Sponsors \\nChapter Title \\n0 Guide to the Development Steps \\n1 Step 1: Business Case Assessment \\n2 Step 2: Enterprise Infrastructure Evaluation \\n(especially Section B, Nontechnical Infrastructure Evaluation) \\n3 Step 3: Project Planning \\n4 Step 4: Project Requirements Definition \\n5 Step 5: Data Analysis \\n13 Step 13: Data Mining \\n16 Step 16: Release Evaluation \\nmust have a comprehensive, high-level understanding of the effort. Table \\nP.2 lists the chapters recommended for business sponsors. \\nProject Managers \\nThe project manager is responsible for the entire development effort and \\nmust therefore be intimately familiar with all development steps. He or \\nshe must read all chapters in the book and use the matrices in Part II as \\nan ongoing reference guide, as shown in Table P.3. \\nBI projects are not for inexperienced project managers. A thorough under- \\nstanding of project management principles is required. \\nTable P.3: Chapters for Project Managers \\nChapter Title \\n0 Guide to the Development Steps \\nT=16 Part I: Stages and Steps \\nT7=2Z1 Part Il: At a Glance \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 30}, page_content='Who Should Read This Book xxix \\nTechnicians \\nVarious types of technicians work on BI projects. Some technicians are \\nassigned to the core team on a full-time basis, such as a lead developer; \\nothers are on the extended team supporting the development activities on \\nan as-needed basis, such as a security officer. (For an itemized list of roles \\nassigned to the core team and to the extended team, refer to Chapter 0.) \\n* Core team technicians should read all the chapters in the book and \\nuse the matrices as an ongoing reference guide, as shown in Table P.4. \\n* Extended team technicians should read, at a minimum, the chapters \\nlisted in Table P.5. However, these technicians would gain a greater \\nunderstanding of the BI decision-support development process if \\nthey read all the chapters in the book. \\nTable P.4: Chapters for Core Team Technicians \\nChapter Title \\n(6) Guide to the Development Steps \\n116 Part I: Stages and Steps \\nWe Part Il: At a Glance \\nTable P.5: Chapters for Extended Team Technicians \\nChapter Title \\n0 Guide to the Development Steps \\n2 Step 2: Enterprise Infrastructure Evaluation \\n(especially Section A, Technical Infrastructure Evaluation) \\n3 Step 3: Project Planning \\n4 Step 4: Project Requirements Definition \\n16 Step 16: Release Evaluation \\nAdditional chapters on an as-needed basis \\n(For example, an ETL developer should read Step 9: Extract/ \\nTransform/Load Design, Step 11: Extract/Transform/Load \\nDevelopment, and Step 15: Implementation.) \\nrT a 0S ES SRT FE SS I SS ES ES ES \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 31}, page_content='XXX Preface \\nCOMMENTS \\nDespite the large collection of topic-specific BI material, we observed a \\nstrong need by project teams for a unified plan or method to follow. \\nTherefore, we started this book with the notion of writing a complete \\ndevelopment methodology for BI decision-support projects. We quickly \\nrealized that to meet such a goal we would have to produce a multivolume \\nwork—something not feasible for most project managers and project \\nteam members to read. Our original plan quickly gave way to a general \\nroadmap that would serve as an umbrella for all the major development \\nsteps, topics, considerations, and activities of a BI project. In addition, at \\nthe end of each chapter we provide a list of references that are most appli- \\ncable to the topics of the chapter. \\nWe also wanted to share with project managers, project teams, and \\nbusiness representatives our personal discoveries about what works and \\nwhat doesn’t work on BI projects. Therefore, the information we present \\nin the matrices in Part II is an accumulation of our own personal obser- \\nvations, experiences, and judgments. \\nFinally, to enhance the readability of this complex technical material, \\nwe broke up the text with as many tables, graphs, pictures, and other \\nvisuals as possible. We hope these visual aids make this book easier to \\nread in addition to clarifying the topics presented. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 32}, page_content='Acknowledgments \\nWriting this all-encompassing development guide for BI decision-support \\napplications required extensive knowledge of traditional as well as current \\ninformation technology (IT) development disciplines. While we have over \\n50 years of combined IT experience, many colleagues and friends con- \\ntributed their expertise and time to this book. \\nOur special appreciation goes to Melvin Rusakoff, who came out of \\nretirement to help us jump-start the book. We want to thank him for all \\nof his contributions, in particular on testing and peer reviews. His exten- \\nsive knowledge of methodologies provided a benchmark for quality \\nassurance of our book. \\nWe thank Sid Adelman and Florence Alcorn for their extensive and \\nmerciless critiques of our first draft. Their input profoundly changed the \\nscope and content of this book. \\nWe are grateful to David Marco for his early contribution on meta \\ndata repositories. Our appreciation also goes to Mike Schmitz for his \\ndatabase suggestions, to Joyce Bischoff for her ETL comments, and to \\nHerb Edelstein and Arun Swami for their data mining remarks. \\nThe extensive critiques provided by two IT journalists, Paul Gillin \\nand Peter Krass, made our technical jargon more comprehensible. We are \\nindebted to John Tiglias who, based on his high-level management expe- \\nrience, provided us valuable insights into the needs of CIOs and gave us \\nsuggestions for addressing them. \\nWe are also very thankful for the real-life comments from the \\n“trenches” provided by Tom McCullough, Ross Armstrong, Bill Tillman, \\nMajid Abai, Pat Higgs, and Jane Aubol. \\nOur special thanks go to Ed Yourdon for taking time out of his very \\nbusy schedule and for giving us encouragement from the very beginning \\nof this long project to the very end. We are also very thankful to Bill \\nInmon for reviewing our manuscript on very short notice. \\nXXxi \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 33}, page_content='XXxii Acknowledgments \\nWe are indebted to Info-Edge Inc. for working with us on this \\nproject. We also want to thank Anthony Ianniciello and Tushar Atre of \\nAtreNet, Inc. for helping us with the cover design. \\nOur sincere appreciation goes to our executive editor, Mary O’Brien, \\nat Addison-Wesley, who displayed extraordinary patience while accom- \\nmodating our every out-of-the-ordinary book-formatting request. In \\naddition, we thank the many Addison-Wesley team members for their \\nindividual contributions to making our book a success, in particular \\nBrenda Mulligan for coordinating all aspects of the editorial process, \\nSimone Payment and Jacquelyn Doucette for managing the production \\nprocess, Chrysta Meadowbrooke for copyediting, and Curt Johnson and \\nChanda Leary-Coutu for their tireless efforts in marketing. \\nOur special gratitude goes to Donald P. Sherman, who spent an \\nextraordinary amount of his time editing and cross-checking the book \\nmultiple times to ensure consistency and readability. We also thank \\nBlanca Eusse-Patino for being our liaison and for providing assistance to \\nmeet our deadlines. \\nFinally, we thank our families for putting precious family time on \\nhold while the book was in the making. They have been the main pillars \\nof support for our professional endeavors. \\n—Larissa T. Moss and Shaku Atre \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 34}, page_content='Stages and Steps \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 35}, page_content='1é a, Pe, oe Ste, G2 xe PR 332 oe a! \\nva ¢ soo DS 20981 cm \\n\" thle. Vn tis Erlayed es \\noo) ao ard fy conde. adel AG) - ; Ey 7 \\nabiiths ac Geri, de pac es ame \\nPES IE Os mic ite eG : \\nkirae © “wes Se sondinsidy i ance OES \\norn Ts ew at? Pcqucds Dasa Oe \\n(rdaLaes Capes Peel or as si ameter om = \\nChiat) eile -~Suhaenl aXsedees we i wee, \\nie etl @pI2s @c) ® Lew 4: \\nmi guieasepeoun! of ’e Cow ckiins, seb c \\nrohygis tet = overt serntdte? ah mcebabirs. \\nfires . soe Brim be Be » Mie welds ings \\nFilet ~ec cae. \\nLb \\n“eath —— > = > tas & patry PSL a \\nbceolt be he’ eee Am rer tee ee \\nO68 bd sat ee 8 * i SS \\n; cunt ie \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 36}, page_content='| Business Case \\nAssesment / \\no \\nEnterprise \\nInfrastructure \\n\\\\. Evaluation \\nProject \\nA. Planning \\nProject \\nRequirements \\n\\\\_ Definition \\n7 \\nMeta Data \\nRepository \\nAnalysis \\nData \\nAnalysis \\nApplication \\nPrototyping \\n8 \\nDatabase \\nDesign \\n10 \\nMeta Data \\nRepository \\nDesign \\n14 \\nMeta Data \\nRepository \\nDevelopment \\n15 \\nImplementation \\n16 \\nRelease \\nEvaluation \\nCHAPTER ZERO \\nGuide to \\nthe Development Steps \\nCHAPTER OVERVIEW \\nThis chapter covers the following topics: \\n@ Business intelligence (BI), with a focus on BI decision- \\nsupport applications, such as sales forecasting \\n@ The need for and the structure of Business Intelligence Road- \\nmap as a development guide \\n@ The 16 development steps applicable to BI decision-sup- \\nport projects \\n@ The three parallel development tracks usually followed by \\nBI project teams \\n@ Project team structure, including the roles and responsibili- \\nties assigned to the core team members and the extended \\nteam members \\n@ A brief justification for using Business Intelligence Roadmap \\nas your development guide for BI decision-support projects \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 37}, page_content='4 Guide to the Development Steps \\nBUSINESS INTELLIGENCE DEFINITION \\nBI is neither a product nor a system. It is an architecture and a collection of inte- \\ngrated operational as well as decision-support applications and databases that \\nprovide the business community easy access to business data. Business Intelligence \\nRoadmap specifically addresses decision-support applications and databases. \\nBI decision-support applications facilitate many activities, including those \\nlisted below: \\n* Multidimensional analysis, for example, online analytical processing (OLAP) \\n* Click-stream analysis \\n- Data mining \\n* Forecasting \\n* Business analysis \\n- Balanced scorecard preparation \\n* Visualization \\n* Querying, reporting, and charting (including just-in-time and agent-based \\nalerts) \\n* Geospatial analysis \\n- Knowledge management \\n+ Enterprise portal implementation \\n+ Mining for text, content, and voice \\n+ Digital dashboard access \\n* Other cross-functional activities \\nExamples of BI decision-support databases include the following: \\n- Enterprise-wide data warehouses \\n* Data marts (functional and departmental) \\n* Exploration warehouses (statistical) \\n* Data mining databases \\n* Web warehouses (for click-stream data) \\n* Operational data stores (ODSs) \\n* Operational marts (oper marts) \\n* Other cross-functional decision-support databases \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 38}, page_content='Development Approaches 5 \\nBusiness Intelligence Roadmap is primarily a project lifecycle guide for devel- \\noping BI decision-support applications using structured data. For BI applications \\nwith specialized requirements, such as using unstructured data (e.g., mining for \\ntext, content, and voice), building an enterprise portal, or incorporating XML- \\nenabled features and services, you will need to expand the activities and roles in \\nthe relevant development steps. Consult the topic-specific references listed at the \\nend of each chapter. \\nBI DECISION-SUPPORT INITIATIVES \\nBI decision-support initiatives are expensive endeavors. Disparate business data \\nmust be extracted and merged from online transaction processing (OLTP) systems, \\nfrom batch systems, and from externally syndicated data sources. BI decision- \\nsupport initiatives also call for new technology to be considered, additional tasks \\nto be performed, roles and responsibilities to be shifted, and analysis and decision- \\nsupport applications to be delivered quickly while maintaining acceptable quality. \\nA staggering 60 percent of BI projects end in abandonment or failure because \\nof inadequate planning, missed tasks, missed deadlines, poor project manage- \\nment, undelivered business requirements, or poor quality deliverables. Project \\nmanagers need to know the dos and don’ts of BI implementations based on reli- \\nable hands-on experience. \\nWhat is needed is a new, proven method for understanding and implement- \\ning the processes required in the successful deployment of BI decision-support \\napplications. \\nDEVELOPMENT APPROACHES \\nAlmost every kind of engineering project—structural engineering as well as soft- \\nware engineering—goes through six stages between inception and implementa- \\ntion, as illustrated in Figure 0.1. \\nAs the arrow in Figure 0.1 indicates, engineering processes are iterative. Once \\ndeployed, a product is continually improved and enhanced based on the feedback \\nfrom the business community that uses the product. Each iteration produces a \\nnew product release (version) as the product evolves and matures. (This release \\nconcept is explained in detail in Step 16, Release Evaluation. ) \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 39}, page_content='6 Guide to the Development Steps \\nSS I A IOS SS, \\nStage 6: \\nDeployment \\nStage 1: \\nJustification \\nEngineering \\nae Project Construction \\nStage 2: \\nPlanning \\nStage 4: \\nDesign \\nStage 3: \\nBusiness Analysis \\nFigure 0.1: Engineering Stages \\nStage 1. Justification: Assess the Stage 4. Design: Conceive a product \\nbusiness need that gives rise that solves the business \\nto the new engineering problem or enables the \\nproject. business opportunity. \\nStage 2. Planning: Develop strate- Stage 5. Construction: Build the \\ngic and tactical plans, which product, which should pro- \\nlay out how the engineering vide a return on investment \\nproject will be accomplished within a predefined time \\nand deployed. frame. \\nStage 3. Business analysis: Perform Stage 6. Deployment: Implement \\ndetailed analysis of the busi- or sell the finished product, \\nness problem or business then measure its effective- \\nopportunity to gain a solid ness to determine whether \\nunderstanding of the busi- the solution meets, exceeds, \\nness requirements for a or fails to meet the expected \\npotential solution (product). return on investment. \\nThe Traditional Development Approach \\nSince BI is an enterprise-wide evolving environment that is continually improved \\nand enhanced based on feedback from the business community, the system \\ndevelopment practices of the past are inadequate and inappropriate. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 40}, page_content='Development Approaches 7 \\nIn the past, systems were never designed or built with integration in mind. \\nEvery system had a beginning and an end, and every system was designed to solve \\nonly one isolated problem for one set of business people from one line of business. \\nThe old “single-swim-lane” development practices were suitable for such static \\nstand-alone systems. However, they are not well suited for integrated BI initia- \\ntives because the old practices do not include any cross-organizational activities \\nnecessary to sustain an enterprise-wide decision-support environment. In the \\npast, cross-organizational activities were not only deemed unnecessary but were \\nalso perceived to stand in the way of progress because they slowed down the projects. \\nFor nonintegrated system development, conventional waterfall methodolo- \\ngies are sufficient. They provide enough guidance for planning, building, and \\nimplementing stand-alone systems. However, these traditional methodologies do \\nnot cover strategic planning, cross-organizational business analysis, or evaluation \\nof new technologies with every project; nor do they embrace the concept of \\napplication releases. Traditional methodologies typically start with a functional \\nbusiness need, then concentrate on design and development, and finally end in \\nmaintenance, as illustrated in Figure 0.2. \\nUnlike static stand-alone systems, a dynamic, integrated BI decision-support \\nenvironment cannot be built in one big bang. Data and functionality must be \\nBusiness \\nNeed \\nProject \\nPlanning \\nFunctional \\nRequirements \\nSystem \\nAnalysis \\nImplementation Bey \\nCnr \\nFigure 0.2: Conventional Waterfall Deployment \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 41}, page_content='8 Guide to the Development Steps \\nDecision-Support \\nStrategy \\nmn Business \\nOpportunity \\nProject \\nPlanning \\nRelease \\nEvaluation \\nBI Application \\nReleases \\nTesting \\nDevelopment \\nFigure 0.3: The BI Application Release Concept \\nrolled out in iterative releases, and each deployment is likely to trigger new \\nrequirements for the next release, as shown in Figure 0.3. \\nFigure 0.3 highlights other major differences between BI applications and \\nstand-alone systems. \\n* BI applications are mostly driven by business opportunity rather than busi- \\nness need. \\n+ BI applications implement a cross-organizational decision-support strategy \\nrather than departmental decision-support silos. \\n* BI decision-support requirements are mostly strategic information require- \\nments rather than operational functional requirements. \\n* Analysis of BI projects emphasizes business analysis rather than system analy- \\nsis, and analysis is the most important activity when developing a BI decision- \\nsupport environment. \\n* Ongoing BI application release evaluations promote iterative development \\nand the software release concept rather than big-bang development. \\nThe Cross-Organizational Development Approach \\nWith the expansion of e-business comes an increasing demand for cross-organizational \\nintegration. This integration does not refer merely to bridging old systems across \\ndifferent platforms using enterprise application integration (EAI) middleware. \\nInstead, it refers to: \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 42}, page_content='Development Approaches 9 \\nSS TI A PS EST SS EAB A SS RR FO SS SY SL TSS \\n* Information consolidation \\n* Information integration \\n* Information integrity \\n* Seamless business functionality \\n* Streamlined organizational business processes \\nMoving an organization from a “single-swim-lane” development approach to \\na cross-organizational, “cross-swim-lane” development approach requires orga- \\nnizational changes, including a culture shift. No other initiative demonstrates this \\nas vividly as customer relationship management (CRM). If organizations would \\nimplement more cross-organizational BI operational applications (front-office as \\nwell as back-office) like CRM, they could significantly reduce their construction \\nefforts on BI decision-support applications. \\nAlthough in Business Intelligence Roadmap we do not address organizational \\nchanges and culture shifts, we do define the necessary BI project activities that \\nsupport an integrated enterprise-wide infrastructure. Both technical infrastruc- \\nture and nontechnical infrastructure are required core competencies for cross- \\norganizational integration. In addition to defining project activities, we identify \\nthe roles and responsibilities to be assigned to project team members for each \\ndevelopment step. \\nThe development steps outlined in this book form an engineering roadmap \\nthat provides a framework for developing different kinds of BI decision-support \\nprojects. The flexible entry and exit points of this framework allow you to start \\nwith any step as long as you meet the “entry criteria” outlined in the Entry and \\nExit Criteria and Deliverables Matrix. We also designed these steps to be agile and \\nadaptive so that you can organize and manage the development of a BI application \\nas multiple subprojects, each going through several of its own iterations or releases. \\nFor example, Figure 0.4 shows two iterations each for the Extract/Transform/ \\nLoad (ETL), Application, and Meta Data Repository subprojects. \\nThe approach presented in Business Intelligence Roadmap encourages the use \\nof parallel development tracks (subprojects) so that multiple development steps \\ncan be performed simultaneously and multiple project activities can occur con- \\ncurrently. Some project teams may choose to roll up project activities from mul- \\ntiple development steps into one step, while other project teams may not need to \\nperform some steps or activities at all. Figure 0.5 illustrates the dynamics of a typ- \\nical BI decision-support project, showing several steps running simultaneously \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 43}, page_content='10 Guide to the Development Steps \\nSee RS ESP SRT EE eA ETRE EEE OER RE I ES ENTE TT EE DE EC TS IE IE NEE A STEEL LDL SE \\nEne \\n1s‘ Iteration \\nMeta Data \\nRepository \\n2\" Iteration \\nApplication \\n1s Iteration \\nApplication \\nRelease \\nMeta Data \\nRepository \\n1s\\' Iteration \\nApplication \\n2\"4 Iteration \\nETL \\n2” Iteration \\nFigure 0.4: Iterative Subprojects of an Application Release \\n{Business Case\\\\ / \\nAssesment // Planning and \\nRequiremnnts \\nData \\nAnalysis Development \\n\\\\ Application \\nDevelopment Meta Data \\n\\\\ Repository \\nDevelopment \\nApplication \\nPrototyping \\nMeta Data \\nRepository \\nApplication Analysis \\nPrototyping \\nMeta Data \\nRepository \\nDevelopment / \\n{ Application \\n|\\\\ Prototyping \\nETE \\nDevelopment Application \\nPrototyping Meta Data \\nRepository \\nDesign \\nDatabase \\nDesign \\nFigure 0.5: The Dynamics of a BI Decision-Support Project \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 44}, page_content='Engineering Stages and the Development Steps 11 \\n(such as Step 5, Data Analysis, and Step 6, Application Prototyping) and multiple \\niterations of the same step (such as Step 9, ETL Design). \\nENGINEERING STAGES AND THE DEVELOPMENT STEPS \\nBI projects are organized according to the same six stages common to every engi- \\nneering project. Within each engineering stage, certain steps are carried out to see \\nthe engineering project through to its completion. Business Intelligence Roadmap \\ndescribes 16 development steps within these stages, as outlined below. \\nThe Justification Stage \\nStep 1: Business Case Assessment \\nThe business problem or business opportunity is defined and a BI solution is \\nproposed. Each BI application release should be cost-justified and should clearly \\ndefine the benefits of either solving a business problem or taking advantage of \\na business opportunity. \\nThe Planning Stage \\nStep 2: Enterprise Infrastructure Evaluation \\nSince BI applications are cross-organizational initiatives, an enterprise infra- \\nstructure must be created to support them. Some infrastructure components \\nmay already be in place before the first BI project is launched. Other infra- \\nstructure components may have to be developed over time as part of the BI \\nprojects. An enterprise infrastructure has two components: \\n1. Technical infrastructure, which includes hardware, software, middle- \\nware, database management systems, operating systems, network compo- \\nnents, meta data repositories, utilities, and so on. \\n2. Nontechnical infrastructure, which includes meta data standards, data- \\nnaming standards, the enterprise logical data model (evolving), method- \\nologies, guidelines, testing procedures, change-control processes, proce- \\ndures for issues management and dispute resolution, and so on. \\nStep 3: Project Planning \\nBI decision-support projects are extremely dynamic. Changes to scope, staff, \\nbudget, technology, business representatives, and sponsors can severely impact \\nthe success of a project. Therefore, project planning must be detailed, and \\nactual progress must be closely watched and reported. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 45}, page_content='12 Guide to the Development Steps \\nThe Business Analysis Stage \\nStep 4: Project Requirements Definition \\nManaging project scope is one of the most difficult tasks on BI decision-sup- \\nport projects. The desire to have everything instantly is difficult to curtail, but \\ncurtailing that desire is one of the most important aspects of negotiating the \\nrequirements for each deliverable. Project teams should expect these require- \\nments to change throughout the development cycle as the business people \\nlearn more about the possibilities and the limitations of BI technology during \\nthe project. \\nStep 5: Data Analysis \\nThe biggest challenge to all BI decision-support projects is the quality of the \\nsource data. Bad habits developed over decades are difficult to break, and the \\ndamages resulting from bad habits are very expensive, time consuming, and \\ntedious to find and correct. In addition, data analysis in the past was confined \\nto the view of one line of business and was never consolidated or reconciled \\nwith other views in the organization. This step takes a significant percentage \\nof the time allotted to the entire project schedule. \\nStep 6: Application Prototyping \\nAnalysis of the functional deliverables, which used to be called system analy- \\nsis, is best done through prototyping so it can be combined with application \\ndesign. New tools and programming languages enable developers to relatively \\nquickly prove or disprove a concept or an idea. Prototyping also allows business \\npeople to see the potential and the limits of the technology, which gives them \\nan opportunity to adjust their project requirements and their expectations. \\nStep 7: Meta Data Repository Analysis \\nHaving more tools means having more technical meta data in addition to the \\nbusiness meta data, which is usually captured in a computer-aided software \\nengineering (CASE) modeling tool. The technical meta data needs to be \\nmapped to the business meta data, and all meta data must be stored in a meta \\ndata repository. Meta data repositories can be licensed (bought) or built. In \\neither case, the requirements for what type of meta data to capture and store \\nshould be documented in a logical meta model. When licensing a meta data \\nrepository product, the requirements documented on this logical meta model \\nshould be compared to the vendor’s meta model, if one is provided. In addi- \\ntion, the requirements for delivering meta data to the business community \\nhave to be analyzed (e.g., online help function). \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 46}, page_content='Engineering Stages and the Development Steps 13 \\nThe Design Stage \\nStep 8: Database Design \\nOne or more BI target databases will store the business data in detailed or \\naggregated form, depending on the reporting requirements of the business \\ncommunity. Not all reporting requirements are strategic, and not all of them \\nare multidimensional. The database design schemas must match the infor- \\nmation access requirements of the business community. \\nStep 9: Extract/Transform/Load Design \\nThe ETL process is the most complicated process of the entire BI decision- \\nsupport project. It is also the least glamorous one. ETL processing windows \\n(batch windows) are typically small, yet the poor quality of the source data \\nusually requires a lot of time to run the transformation and cleansing pro- \\ngrams. Finishing the ETL process within the available batch window is a chal- \\nlenge for most organizations. \\nStep 10: Meta Data Repository Design \\nIf a meta data repository is licensed, it will most likely have to be enhanced \\nwith features that were documented on the logical meta model but are not \\nprovided by the product. If a meta data repository is being built, the decision \\nmust be made whether the meta data repository database design will be \\nentity-relationship based or object oriented. In either case, the design has to \\nmeet the requirements of the logical meta model. \\nThe Construction Stage \\nStep 11: Extract/Transform/Load Development \\nMany tools are available for the ETL process, some sophisticated and some \\nsimple. Depending on the requirements for data cleansing and data transfor- \\nmation developed during Step 5, Data Analysis, and Step 9, ETL Design, an \\nETL tool may or may not be the best solution. In either case, preprocessing \\nthe data and writing extensions to supplement the capabilities of the ETL tool \\nis frequently required. \\nStep 12: Application Development \\nOnce the prototyping effort has firmed up the functional requirements, true \\ndevelopment of the access and analysis application can begin. Developing the \\napplication can be a simple matter of finalizing an operational prototype, or \\nit can be a more involved development effort using different, more robust \\naccess and analysis tools. In either case, the front-end application development \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 47}, page_content='14 Guide to the Development Steps \\nactivities are usually performed in parallel with the activities of back-end ETL \\ndevelopment and meta data repository development. \\nStep 13: Data Mining \\nMany organizations do not use their BI decision-support environment to the \\nfullest extent. BI applications are often limited to prewritten reports, some of \\nwhich are not even new types of reports but replacements of old reports. The \\nreal payback comes from the information hidden in the organization’s data, \\nwhich can be discovered only with data mining tools. \\nStep 14: Meta Data Repository Development \\nIf the decision is made to build a meta data repository rather than to license \\none, a separate team is usually charged with the development process. This \\nbecomes a sizable subproject in the overall BI project. \\nThe Deployment Stage \\nStep 15: Implementation \\nOnce the team has thoroughly tested all components of the BI application, \\nthe team rolls out the databases and applications. Training is scheduled for \\nthe business staff and other stakeholders who will be using the BI application \\nand the meta data repository. The support functions begin, which includes \\noperating the help desk, maintaining the BI target databases, scheduling and \\nrunning ETL batch jobs, monitoring performance, and tuning databases. \\nStep 16: Release Evaluation \\nWith an application release concept, it is very important to benefit from les- \\nsons learned from the previous projects. Any missed deadlines, cost overruns, \\ndisputes, and dispute resolutions should be examined, and process adjust- \\nments should be made before the next release begins. Any tools, techniques, \\nguidelines, and processes that were not helpful should be reevaluated and \\nadjusted, possibly even discarded. \\nYou do not need to perform the development steps in sequence; most project \\nteams will likely perform them in parallel. However, because there is a natural \\norder of progression from one engineering stage to another, certain dependencies \\nexist between some of the development steps, as illustrated in Figure 0.6. Steps \\nstacked on top of each other in the diagram can be performed simultaneously, \\nwhile steps that appear to the right or left of each other are performed relatively \\nlinearly (with less overlap) because of their dependencies. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 48}, page_content=\"15 \\nsalsuapuadagq \\ndais \\n}uatdojanaq \\n:9'0 \\nainSi4 \\nEngineering Stages and the Development Steps \\njuawAojdaq \\nuonenjeag \\naseajay \\nQL \\nuolyejuswejduy| \\nSl \\njuawdojaneq uoneoiddy \\nAs \\njuawdojaneq \\n113 tL \\nUO!JONAJSUOD \\njuawdojenag \\nubiseq \\nsishjeuy \\nAioysoday \\nAsoysoday \\nAioy'sodey \\nReg \\nBaw \\neyeq \\nejay \\neyeq \\neo \\nvb \\nOL \\nZ \\nuonNuyaq \\nsjuewasinbay \\nBuidA\\\\ojo1g uolyeoiddy \\n9 \\nsiskjeuy \\nejeq \\nsishjeuy \\nssauisng \\nBuluueld \\nuoleoiisne \\nBujuuelg \\npealoig \\nS \\nuolyenjeng aunjonuysedju| eslidiejuy \\ncA \\njuowsessy aseg \\nsseuisng i \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 49}, page_content='16 Guide to the Development Steps \\nWhile some development steps are clearly project-specific, most development \\nsteps must be performed from a cross-organizational perspective. Thus the focus \\nof those project activities takes on a cross-functional dimension, and the review- \\ners of those activities should include business representatives from other lines of \\nbusiness. The main task for the business representatives from the other lines of \\nbusiness is to validate and ratify the strategies, policies, business rules, and stan- \\ndards either being used or being developed during the BI project. Table 0.1 indi- \\ncates which steps are project-specific and which ones are cross-organizational. \\nTable 0.1: Project-Specific versus Cross-Organizational Steps \\nDevelopment Step Project-Specific versus \\nCross-Organizational \\n1. Business Case Assessment Cross-organizational \\n2. Enterprise Infrastructure Evaluation (technical and Cross-organizational \\nnontechnical) \\n3. Project Planning Project-specific \\n4. Project Requirements Definition Project-specific \\n5. Data Analysis Cross-organizational \\n6. Application Prototyping Project-specific \\n7. Meta Data Repository Analysis Cross-organizational \\n8. Database Design Cross-organizational \\n9. ETL Design Cross-organizational \\n10. Meta Data Repository Design Cross-organizational \\n11. ETL Development Cross-organizational \\n12. Application Development Project-specific \\n13. Data Mining Cross-organizational \\n14. Meta Data Repository Development Cross-organizational \\n15. Implementation Project-specific \\n16. Release Evaluation Cross-organizational \\nLS SE NS TET AB I RS I SEL TEE A SE TIE \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 50}, page_content='Parallel Development Tracks 17 \\nPARALLEL DEVELOPMENT TRACKS \\nAs illustrated in Figure 0.7, every BI decision-support project has at least three \\ndevelopment tracks running in parallel after the project requirements have been \\ndefined and before implementation. \\n1. The ETL Track \\nThe ETL track is often referred to as the back end. The purpose of this devel- \\nopment track is to design and populate the BI target databases. The ETL track \\nis the most complicated and important track of a BI decision-support \\nproject. The fanciest OLAP tools in the world will not provide major benefits \\nif the BI target databases are not designed properly or if they are populated \\nwith dirty data. The team working on the ETL track is usually staffed with \\nknowledgeable business analysts, experienced database administrators, and \\nsenior programmers. \\n2. The Application Track \\nThe Application track is often referred to as the front end. The purpose of this \\ndevelopment track is to design and build the access and analysis applications. \\nJustification Stage: \\n1. Business Case Assessment \\nDeployment Stage: \\n15. Implementation \\n16. Release Evaluation \\nPlanning Stage: \\n2. Enterprise Infrastructure Evaluation \\n3. Project Planning \\nBusiness Analysis Stage: \\n4. Project Requirements Definition \\n5. Data Analysis \\n6. Application Prototyping \\n7. Meta Data Repository Analysis \\nDesign Stage: Construction Stage: \\n11. ETL Development : , D 12. Application Development a a eee \\n13. Data Mining ; R : Desi \\n14. Meta Data Repository Development 10. Meta Data Repository Design \\nFigure 0.7: Parallel Development Tracks (for Steps 5-14) \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 51}, page_content='18 Guide to the Development Steps \\nAfter all, the key reasons for building a BI decision-support environment \\nare to: \\n* Deliver value-added information \\n* Provide easy, spontaneous access to the business data \\nThe team for the Application track is usually staffed with subject matter \\nexperts, “power users,” and programmers who know Web languages, can \\neffectively use OLAP tools, and have experience building client/server-based \\ndecision-support applications that incorporate graphical user interfaces. \\n3. The Meta Data Repository Track \\nMeta data is a mandatory deliverable with every BI application. It can no \\nlonger be shoved aside as documentation because it must serve the business \\ncommunity as a navigation tool for the BI decision-support environment. \\nTherefore, the purpose of this development track is to design, build, and \\npopulate a meta data repository. The team members are responsible for \\ndesigning and building the access interfaces as well as the reporting and que- \\nrying capabilities for the meta data repository. The team working on the Meta \\nData Repository track is usually staffed with a meta data administrator and \\ndevelopers who have experience with building client/server-based interfaces \\nand are knowledgeable about Web applications. \\nTable 0.2 maps the Business Intelligence Roadmap stages and steps across these \\nthree development tracks. \\nThese three parallel tracks can be considered major subprojects of a BI \\nproject. Each will have its own team members and its own set of activities after \\nthe project requirements have been formalized. Discoveries made in one track \\ncan (and often do) impact the other tracks. Figure 0.8 shows the interaction of \\nthe three tracks across the development steps. \\nEach development track has specific deliverables that contribute to the over- \\nall BI project objectives. \\n* The ETL track delivers loaded BI target databases. \\n- The Application track delivers the BI reports and queries. \\n* The Meta Data Repository track delivers the meta data. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 52}, page_content='Parallel Development Tracks \\nTable 0.2: Stages and Steps across Development Tracks \\nStages ETL Application MDR \\nSteps Track Track Track \\nJustification \\nBusiness Case Assessment J JY v \\nPlanning \\nEnterprise Infrastructure Evaluation / J v \\nProject Planning J J Vv \\nBusiness Analysis \\nProject Requirements Definition J JY v \\nData Analysis J \\nApplication Prototyping J J \\nMDR Analysis / \\nDesign \\nDatabase Design Jv J \\nETL Design J \\nMDR Design J \\nConstruction \\nETL Development J \\nApplication Development J \\nData Mining Vv \\nMDR Development J \\nDeployment \\nImplementation J J J \\nRelease Evaluation J J v \\nAbbreviations: ETL, extract/transform/load; MDR, meta data repository. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 53}, page_content='20 Guide to the Development Steps \\nGo/No-Go Decision I Project Kickoff \\nSteps performed before and after the project \\nis split into the parallel development tracks \\n(Steps 1, 2, 3, 4, 15, and 16) \\nSteps performed in the ETL track (Steps 5, \\n8, 9, 11, and partial participation in Step 6) \\nSteps performed in the Application track (Steps \\n6, 12, 13, and partial participation in Step 8) \\nSteps performed in the Meta Data \\nRepository track (Steps 7, 10, and 14) \\nFigure 0.8: Steps Performed in Parallel Development Tracks \\nBI PROJECT TEAM STRUCTURE \\nEvery BI project team must have a complementary skill set to perform the neces- \\nsary activities for the three development tracks. Although each track will have its \\nown subproject team members, from the overall BI project management perspec- \\ntive the BI project team structure contains only two types of teams: \\n1. The core team \\n2. The extended team \\nThe Core Team \\nThe core team can be thought of as a SWAT team. A project SWAT team is a self- \\norganizing team—the members redistribute the workload among themselves, \\npeer-review each other’s task deliverables, make decisions together, brainstorm \\ntogether, and co-lead the project. The core team has permanent project core team \\nmembers and permanent step core team members. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 54}, page_content='BI Project Team Structure 21 \\n* Permanent project core team members must be available 100 percent of \\ntheir time from beginning to end of the BI project to perform project activities \\napplicable to the roles assigned to them. More importantly, they must co-lead \\nthe project. The optimum size for this team is four or five people, never \\nexceeding seven people. This team should be staffed with: \\n— One project manager (not an administrator) \\n— One representative from the business side \\n— One business analyst from the information technology (IT) department \\n(either a data administrator or a business liaison) \\n— One technical person from the IT department (either a senior systems ana- \\nlyst or a senior programmer) \\nPaw The business person’s full-time availability is a critical success factor for all Bl \\nprojects. If the business executives resist releasing one business person full- \\ntime, it indicates that they neither view nor support the BI project as a critical \\ncross-organizational strategic business initiative. \\n* Permanent step core team members must be available 100 percent of their \\ntime from beginning to end of those development steps that require their \\nfull-time involvement. For example, the ETL lead developer must be fully \\ndedicated to lead the activities of the ETL track. \\nAll core team members brainstorm together, assign work to each other, \\nreview each other’s deliverables, resolve issues, and make project-related deci- \\nsions together. \\nPaw Each person on the core team can and probably will be assigned multiple \\nroles, regardless of whether they are permanent project core team members \\nor permanent step core team members. \\nTable 0.3 lists the core team roles (in alphabetical order) and their major \\nresponsibilities. \\nPaw The business representative role on the core team is usually assigned to the \\nprimary business person representing the business community for whom the \\nBI application is being developed. He or she participates on the project as a \\nfull-time member of the project core team. If necessary or desired, this role \\ncan be assigned to more than one business person, with the stipulation that \\nevery business person will dedicate 100 percent of his or her time to the BI \\nproject. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 55}, page_content='22 Guide to the Development Steps \\nTable 0.3: Core Team Roles and Responsibilities \\nRole Major Responsibilities \\nApplication lead developer Designing and overseeing the development of the \\naccess and analysis application (e.g., reports, queries) \\nBI infrastructure architect Establishing and maintaining the BI technical \\ninfrastructure (in some organizations, overseeing the \\nnontechnical infrastructure as well); usually reports to \\nthe strategic architect on the extended team \\nBusiness representative Participating in modeling sessions, providing data \\ndefinitions, writing test cases, making business \\ndecisions, resolving disputes between business units, \\nand improving the data quality under the control of the \\nbusiness unit represented by this role \\nData administrator Performing cross-organizational data analysis, creating \\nthe project-specific logical data models, and merging \\nthe logical data models into an enterprise logical data \\nmodel \\nData mining expert Choosing and running the data mining tool; must have \\na Statistical background \\nData quality analyst Assessing source data quality and preparing data- \\ncleansing specifications for the ETL process \\nDatabase administrator Designing, loading, monitoring, and tuning the BI target \\ndatabases \\nETL lead developer Designing and overseeing the ETL process \\nMeta data administrator Building or licensing (buying), enhancing, loading, and \\nmaintaining the meta data repository \\nProject manager Defining, planning, coordinating, controlling, and \\nreviewing all project activities; tracking and reporting \\nprogress; resolving technical and business issues; \\nmentoring the team; negotiating with vendors, the \\nbusiness representative, and the business sponsor; has \\noverall responsibility for the project \\nSubject matter expert Providing business knowledge about data, processes, \\nand requirements \\nSSS SI EER EES SS EE ES TT SN I FS ES SS \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 56}, page_content='BI Project Team Structure 23 \\nSome roles can be combined and some are mutually exclusive. For example, \\none person can perform one of the following combinations of roles: \\n* Application lead developer and ETL lead developer (assuming the person has \\nthe different skill sets required for both) \\n* Data administrator, data quality analyst, and meta data administrator \\n(assuming the person has the required technical skills) \\n* Data quality analyst, subject matter expert, and business representative \\nMutually exclusive roles, which should never be assigned to the same person, \\nare listed below. \\n* Data administrator and database administrator: The data administrator pro- \\nduces process-independent logical data models, while the database adminis- \\ntrator produces process-dependent physical data models (logical database \\ndesigns). It would be difficult for one person to perform these bipolar activi- \\nties on the same project, even if the person had the skills to do both. \\n* Project manager and any nonlead role: Managing a BI decision-support project \\nis a full-time job and cannot be put in second position to any development work. \\nOne person will simply not have time to both manage the project and do the work. \\nThe Extended Team \\nThe extended team members also have responsibilities on the BI project, but for \\nthese members the BI project is not their main priority during the entire project \\nschedule. These members have to schedule time to work with the full-time core \\nteam members. They can also be called into sessions when their expertise is \\nneeded to resolve a problem or to help make a decision. \\nEach member on the extended team can be assigned one or multiple roles \\nand is responsible for the activities performed under each assigned role. Table 0.4 \\nlists the extended team roles (in alphabetical order) and their major responsibilities. \\nAs on the core team, some roles on the extended team can be combined and \\nsome are mutually exclusive. For example, one person can perform one of the fol- \\nlowing combinations of roles: \\n- Application developer, ETL developer, and meta data repository developer \\n(assuming the person has the different skill sets required for the three devel- \\nopment tracks) \\n* Web developer and Web master \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 57}, page_content='Guide to the Development Steps \\nTable 0.4: Extended Team Roles and Responsibilities \\nRole Major Responsibilities \\nApplication developer(s) Coding the report programs, writing query scripts, \\nand developing the access and analysis \\napplications \\nBI support (help desk staff) \\nBusiness sponsor \\nMentoring and training the business staff \\nChampioning the BI initiative and removing \\nbusiness-related roadblocks for the BI project team \\nETL developer(s) \\nIT auditor or QA analyst \\nCoding the ETL programs and/or preparing the \\ninstructions for the ETL tool \\nDetermining the risks and exposures of the BI \\nproject due to internal lack of controls or external \\nforces \\nMeta data repository developer(s) \\nNetwork services staff \\nCoding the meta data repository migration \\nprograms to load the meta data repository \\ndatabase; providing meta data reports and an \\nonline help function \\nMaintaining the network environment \\nOperations staff \\nSecurity officer \\nRunning the batch processes for the ETL cycles, the \\naccess and analysis application, and the meta data \\nrepository \\nEnsuring that security requirements are defined \\nand that security features are tested across all tools \\nand databases \\nStakeholders (other business \\nrepresentatives or IT managers) \\nHandling limited responsibilities on the BI project, \\nsuch as reviewing and ratifying the cross- \\norganizational standards and business rules the Bi \\nproject team uses or develops \\nStrategic architect Managing the overall technical infrastructure for \\nthe organization, including the BI technical \\ninfrastructure \\nTechnical services staff Maintaining the hardware infrastructure and the \\noperating systems \\n(Continued) \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 58}, page_content='BI Project Team Structure 25 \\nTable 0.4: (Continued) \\nRole Major Responsibilities \\nTesters Testing programming code created by the \\ndevelopers from the ETL, Application, and Meta \\nData Repository tracks \\nTool administrators Installing and maintaining the developer tools and \\nthe access and analysis tools \\nWeb developer(s) Designing the Web site and creating the Web \\npages for displaying reports and queries on the \\nintranet, extranet, or Internet \\nWeb master Setting up the Web server and Web security \\nMutually exclusive roles, which should never be assigned to the same person, \\nare: \\n* Developer (of any type) and tester: A developer testing his or her own pro- \\ngrams is like the fox guarding the henhouse. Even if the developer were moti- \\nvated to break his or her own code, it is unlikely that he or she would think of \\nall the possible test cases and carry out an objective test plan. However, a \\ndeveloper can take on the role of a tester for another developer’s programs, as \\ndone in peer reviews and integration testing. \\nAdditional Limited Roles \\nOther roles participate on the BI project on a limited, as-needed basis. \\n* Data owners are the major stakeholders in any BI initiative. They are respon- \\nsible for the quality of business data under their ownership and for validating \\nthe business meta data. \\n* The facilitator is a third-party participant during post-implementation \\nreviews. His or her responsibility is to lead the review meetings. \\n* The scribe is also a third-party participant during post-implementation \\nreviews. He or she is responsible for taking notes and documenting the meet- \\ning minutes and the resulting action items. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 59}, page_content='26 Guide to the Development Steps \\nThe BI Arbitration Board \\nThe discussion on roles and responsibilities cannot end without mention of the \\nBI arbitration board. On cross-organizational BI projects, technical as well as \\nbusiness disputes will arise that neither the core team nor the extended team will \\nbe able to resolve. A dispute resolution procedure should be established with \\nguidelines for handling these types of disputes. If a resolution cannot be achieved \\nthrough other prescribed means, the project team must have access to a body of \\nexecutives with the authority to be the tiebreaker. This body of executives is the \\nBI arbitration board, sometimes known as the BI steering committee. \\nBI arbitration boards can be organized in a variety of ways. A BI arbitration \\nboard can be a newly created group whose members include the business spon- \\nsor, the chief technology/information officer (CTO/CIO), IT managers, the chief \\noperating officer (COO), the chief financial officer (CFO), and line-of-business \\nmanagers. In some smaller organizations, even the chief executive officer (CEO) \\ncould be a member of this board. \\nIn other organizations, the BI arbitration board can be an existing commit- \\ntee. Most organizations already have some official or unofficial executive com- \\nmittee. For example, the CTO/CIO typically meets monthly with the employees \\nwho report directly to him or her, and the CEO typically meets monthly with \\nline-of-business executives, the CFO, and the COO. If a separate BI arbitration \\nboard cannot be established, then the BI project teams must have access to the \\nexisting executive committees. \\nJUSTIFICATION FOR USING THIS PROJECT LIFECYCLE GUIDE \\nIt has been said in the industry that “a paper airplane can be constructed with lit- \\ntle forethought, but a jet airplane cannot.” Similarly, a stand-alone system that \\nhas only a handful of business people using it can get by without a set of carefully \\nplanned and executed project activities, but a cross-organizational BI initiative \\ncertainly cannot. \\nAs the BI decision-support environment evolves over time, it is imperative \\nthat a strong foundation exists to support such expansion. To build a strong \\nfoundation, many things have to be considered and many tasks have to be per- \\nformed by many people. It is irresponsible to casually “make up” who does what \\nand when along the way. That type of ad hoc development approach would put \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 60}, page_content='Bibliography and Additional Reading 27 \\nthe organization’s large investment at risk and would pose an even bigger risk for \\nlosing business opportunities. There are quite a few casualties in the trenches of \\nlost opportunities! \\nThe question is not whether or not a set of formalized guidelines must be \\nused but what type of guidelines to use. A waterfall methodology is not suitable \\nfor the iterative releases of BI decision-support applications, but an agile and \\nadaptive development guide specifically geared toward BI decision-support \\napplications is. Business Intelligence Roadmap is such a guide. \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nAdelman, Sid, and Larissa Terpeluk Moss. Data Warehouse Project Management. \\nBoston, MA: Addison-Wesley, 2000. \\nBeck, Kent. Extreme Programming Explained: Embrace Change. Boston, MA: \\nAddison-Wesley, 2000. \\nHumphrey, Watts S. Winning with Software: An Executive Strategy. Boston, MA: \\nAddison-Wesley, 2002. \\nInmon, William H., Claudia Imhoff, and Ryan Sousa. Corporate Information Fac- \\ntory. New York: John Wiley & Sons, 1997. \\nZachman, John. The Zachman Framework: A Primer for Enterprise Engineering \\nand Manufacturing. La Canada, CA: Zachman International, 2002. \\nDM Review: http://www.dmreview.com \\nJournal of Data Warehousing: http://www.dw-institute.com \\nGlossaries: http://www.techweb.com/encyclopedia and \\nhttp://www.ncits.org/tc_home/k5htm/ANSDIT.htm \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 61}, page_content=\"Cah dar amyish etre anne, {fame to is w mca i weg \\n7a * \\nae \\npars ¥ \\nPaige 0p nol gy Loeonap apdl aepD oc [ot sd Dihenece tord UP croc mgeustied MM pr yee’ oR Pe \\neect Ming hs od OS eo hematin: vals Pav cto \\nBirds were ele colar tae « 10 ster ani ee Loc eousitm he hws dareciuitng. free ecs. mat TE teen ae \\nhing setinpemard nek: qaeed ia thes leg Sy egy ality bare itis. i. .~ \\naR (4G Ot) Os sadly’ taint \\nWV entetrwie<i (<2 vo Got Sew: 2s Fae ft? én. art ior 9 \\ni paweee oa) 4s on Oe orien Wa Sains oho 4, BE \\npant So's overt a! aap lS ae tA Tae \\nPaik Sg # ‘vos trababrt Sy he FAG (OCG Abe : adin, 62 ae luider 7 \\nSa iis og sy ok? sail a Tate St ¥ Mie. H is Meat \\nSob See \\n‘A Metta genres: shot ea enn ane \\nS Are oS aw. 2 sow at =) Seid eis \\nSP alters a oie) =e ie Le %* “ei ta “— Th | T = Aer; ii : Le Jn * “ah - \\n. ots ~ at tre ~ Tt) Cs oP rn el « 5 a \\norreenegh Sov caW ene y ai ice eer ¢ a i a 7 . x ~~ =) \\npantie 29: Eo app TA Ma EES AS Lames aT ye \\n- ouch: ccieean \\nMISTRAL Tere tow Users Yoga ee lle vrei age! a a \\n4 Nas ‘eo Ws Se «tebe di nia Paipiacateectneliiven \\nip @rraeiwW—s. bw ¢ Zip ee RMP ieee \\nliege tity & fas : jag Vee 5 : ws \\nones \\nyaad and we Mow ech rae itz \\nve =) An \\nbe Gee fi cece ou? oo, taneniel ir oem ae © \\nUnits 4hhi@ f/h.aqe coats Agtti Of aa \\nPeverte Wa. G2riyrre eek SAVE ly bon ole S=tal 5% \\n(1 é “Loge “=~ ro uw ate ramnebly ist \\nand) ts » Gres iw way tad oc od a Ng, \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 62}, page_content='Justification — \\n1 C Business Case \\ny Assesment , \\nbd See icon \\nrole Ot \\nCHAPTER ONE \\nStep 1: Business Case \\nAssessment \\nCHAPTER OVERVIEW \\nThis chapter covers the following topics: \\nm@ Things to consider during a business case assessment \\n@ The importance of developing a business justification and \\na business strategy for BI decision-support initiatives \\n@ Business drivers and strategic business goals, rather than \\nnew technology, as the motivating forces behind every BI \\nproject \\n@ Business analysis issues such as defining the organization’s \\ninformation needs, identifying data sources, and analyzing \\nthe current and desired quality of data \\n@ The use of cost-benefit analyses to demonstrate how (and \\nhow soon) a return on investment (ROI) can be achieved \\nm Risk assessment and the six major risk categories of tech- \\nnology, complexity, integration, organization, project team, \\nand financial investment \\n@ Brief descriptions of the activities involved in business case \\nassessment, the deliverables resulting from those activities, \\nand the roles involved \\nm@ The risks of not performing Step 1 \\n29 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 63}, page_content='30 Step 1: Business Case Assessment \\nTHINGS TO CONSIDER \\nAccess to Information \\nV Where do we get the information we need for making decisions today? \\nY What information do we already have? What additional information do we \\nneed? \\nBusiness Drivers and Sponsorship \\n/ What are the business drivers for an overall BI decision-support initiative? \\n¥ What are the specific business drivers for this BI application? \\n¥Y Who could be a potential business sponsor? \\n/ Do we already have a business sponsor for this BI application? \\nReadiness Assessment \\nV Are we ready for a BI decision-support environment? \\nV Have we performed a readiness assessment? \\n/ What do we need to do to get ready? Buy hardware? Acquire tools? Establish \\nstandards? Hire more staff? \\nRisks \\n¥ What are the risks of building a BI decision-support environment? \\n¥ What are the risks of not building a BI decision-support environment? \\nCost Justification \\nV Is it worth building this BI application, or will it cost more than we can jus- \\ntify? \\nY Do we know what all the BI project costs will be? \\n¥ Will we have to buy new hardware? Upgrade our network? Buy new tools? \\nHire consultants? \\nReturn on Investment \\n¥Y How will we measure ROI? For example: \\n+ Will the BI application have an effect on our customer service? \\n* Will it help us increase customer satisfaction? \\n* Will it help us increase our revenue? \\n* Will it help us make strategic decisions that will lead to increased profits? \\n* Will it help us reduce our costs? \\n* Can we expect to gain a bigger market share as a result of the BI application? \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 64}, page_content='Business Justification 31 \\nAlthough BI has captured the imagination of many organizations, the indus- \\ntry is still challenged to quantify benefits accurately, especially since an organiza- \\ntion cannot buy a BI product off the shelf and expect it to provide a complete \\nsolution to the business needs. “Business intelligence,” or intelligence about the \\nbusiness, is unique to every organization, as are the policies and business rules \\ngoverning the organization’s business practices. This uniqueness should be explored \\nfor competitive advantage. Buying an off-the-shelf product, which was not built \\naround the unique features of an organization, reduces the likelihood for com- \\npetitive advantage. \\nBUSINESS JUSTIFICATION \\nSince it usually costs millions of dollars to create a BI environment, an organiza- \\ntion considering such an initiative needs a BI strategy and a business justification \\nto show the balance between the costs involved and the benefits gained. A BI deci- \\nsion-support initiative provides numerous benefits—not only tangible benefits \\nsuch as increasing the sales volume but also intangible benefits such as enhancing \\nthe organization’s reputation. Many of these benefits, especially the intangible \\nones, are difficult to quantify in terms of monetary value. Nevertheless, you \\nshould prepare an itemized and detailed list of benefits in order to measure them \\nagainst the high cost of a BI implementation. Although the general benefits of BI \\ndecision-support initiatives are documented widely, they cannot justify your BI \\ninitiative unless you can associate these benefits to your organization’s specific \\nbusiness problems and strategic business goals. \\nJustification for a BI decision-support initiative must always be business- \\ndriven and not technology-driven. It would not be wise to set up an expensive BI \\ndecision-support environment only to experiment with new technology. There- \\nfore, each proposed BI application must reduce measurable “business pain” \\n(problems affecting the profitability or efficiency of an organization) in order to \\njustify building the application. \\nIt is best to start the business justification process by identifying the organiza- \\ntion’s strategic business goals. The BI decision-support initiative as a whole, and \\nthe proposed BI application specifically, should support those strategic business \\ngoals. This enables the ongoing viability of the BI decision-support environment. \\nIf BI applications are built without a good business justification, management \\nwill most likely not support the effort. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 65}, page_content='32 Step 1: Business Case Assessment \\nThe business representative should be primarily responsible for determining \\nthe business value of the proposed BI application. The information technology \\n(IT) department can become a solution partner with the business representative \\nand can help explore the business problems and define the potential benefits of \\nthe BI application. IT can also help clarify and coordinate the different needs of \\nthe varied groups of business people (knowledge workers, business analysts, busi- \\nness executives). For example, there could be different requirements for: \\n> Ease of use \\n> Level of data granularity \\n* Timeliness \\n* Data quality \\n* Security \\n- Amount of external data \\n* Historical requirements \\n* Tool capabilities \\nWith the business representative leading the business case assessment effort, \\nIT staff can assist with the four business justification components (Figure 1.1). \\nBusiness \\nAnalysis \\nIssues \\n- Business \\nDrivers \\nCost- \\nBenefit \\nAnalysis \\nFigure 1.1: Business Justification Components \\n* Business drivers: Identify the business drivers, strategic business goals, and \\nBI application objectives. Ensure that the BI application objectives support \\nthe strategic business goals. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 66}, page_content='Business Drivers 33 \\n* Business analysis issues: Define the business analysis issues and the informa- \\ntion needed to meet the strategic business goals by stating the high-level \\ninformation requirements for the business. \\n- Cost-benefit analysis: Estimate costs for building and maintaining a success- \\nful BI decision-support environment. Determine the ROI by assigning mone- \\ntary value to the tangible benefits and highlighting the positive impact the \\nintangible benefits will have on the organization. \\n* Risk assessment: Assess the risks in terms of technology, complexity, integra- \\ntion, organization, project team, and financial investment. \\nThe next four sections in this chapter explore each of these components. \\nBUSINESS DRIVERS \\nWithout strong business drivers and without an alignment with the strategic \\nbusiness goals of the organization, the BI decision-support initiative may falter. \\nFor example, let us assume that the organization wants to increase revenue by \\ndecreasing time to market. This translates into building BI applications as fast as \\npossible, no matter what other effects this might have (for example, as speed goes \\nup, quality goes down). Further, let us assume that the BI application objective is \\nto decrease operating costs by increasing productivity. This leads to building BI \\napplications that deliver business process improvements no matter what it takes \\n(for example, as quality goes up, speed goes down). In this example, the organi- \\nzation’s strategic goal and the BI application objective are both worthy business \\ndrivers for building a BI solution. However, because the strategic goal and the BI \\napplication objective are not compatible in terms of speed and quality issues, it \\nwill be difficult to get management’s support for this BI application. \\nThis example illustrates the importance of understanding the organization’s \\nstrategic business goals as well as the IT strategic plan and ensuring that the BI \\napplication objectives support both. This may be more difficult to do than it \\nappears. Even some of the most sophisticated organizations often do not have easily \\naccessible or well-articulated strategic business goals statements. Become a “detec- \\ntive” and review the organization’s annual report, public statements, newspaper \\ncoverage, syndicated articles, and internal memos for valuable information. \\nSubstantiate your business justification. Do not invent a business case where \\none does not exist just to get the BI project approved. Interview senior managers \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 67}, page_content=\"34 Step 1: Business Case Assessment \\nRE SS SEERA ES RE AE LEE EEE LE EEE LITA ALOE LIES \\nto confirm the organization’s strategic goals, and interview business managers \\nand business analysts to validate the BI application objectives. \\nLet us discuss an example of a valid business justification. An automobile \\nmanufacturer was rated near the bottom of a study on customer satisfaction and \\nproduct quality. This hurt the manufacturer in two ways. \\n1. The warranty costs were much higher than those of an average automobile \\nmanufacturer. These measurable costs were directly impacting the organiza- \\ntion’s bottom line. \\n2. Unsatisfied customers spread the word about the manufacturer: “I'll never \\nbuy another car from that company—and I'll tell all my friends.” The costs of \\ndamaged customer confidence and lost sales were immense but much more \\ndifficult to measure than the costs of warranty. \\nIn this example, the strategic business goals were to retain the customers and \\nto reduce the expenses on warranty costs. In order to achieve these two goals the \\nautomobile manufacturer had to be able to communicate the information about \\nmalfunctioning parts to the parts makers on a timely basis. If a parts maker did \\nnot improve the quality of a part, the automobile manufacturer would have to \\nbuy that part from a different parts maker. The automobile manufacturer also \\nneeded information about the customers who were returning the malfunctioning \\ncars in order to contact them for “damage control.” , \\nThis automobile manufacturer justified building a BI application to measure \\nmanufacturing quality and to relate the quality measures to loss of sales, cus- \\ntomer complaints, and customer defection. Quality measures were to be captured \\nat the time of assembly as well as from the warranty data. Since a major portion \\nof overall product quality is based on the quality of the parts that go into the \\nautomobile, the quality measures were to be provided to the parts makers \\nthrough secure Web access. By giving the parts makers this information, the auto- \\nmobile manufacturer believed the parts makers would be able to improve the \\nquality of their parts, which, in turn, would improve the overall quality of the \\nassembled automobile. In this case, the BI application objectives directly sup- \\nported the strategic business goals. \\nBusiness justification is an iterative process. As difficult as it might be to jus- \\ntify the business case, realize that business managers are aware of the buzz about \\nBI and would like to take advantage of any competitive benefit they can get. Reit- \\nerating the benefits will help crystallize the business justification and make every- \\none feel comfortable about funding the BI decision-support project. \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 68}, page_content='Business Analysis Issues 35 \\nOnce the strategic business goals and BI application objectives are verified \\nand matched, you can define the business analysis requirements for the BI appli- \\ncation that will allow the organization to meet its strategic business goals. \\nBUSINESS ANALYSIS ISSUES \\nIn most organizations, business analysis issues usually revolve around unmet \\ninformation needs from current heterogeneous data sources and poor quality of \\nthe source data. \\nInformation Needs \\nWith the help of business analysts, formulate the business issues that need to be \\nresolved by each BI application objective. Determine what results you want to \\nobtain from the business analysis, for example, answers to such questions as, \\n“Why are we losing 50 percent market share to ABC Company in New England?” \\nThen define the information requirements for the business issues at hand. Deter- \\nmine the subject areas, timing, level of detail, granularity of data, and even what \\nexternal data you need to answer the business questions. Identify the associated \\nbusiness roles (e.g., senior business management, business analyst, and so on) \\nthat would be active in the various decision-support functions. \\nIdentify possible data sources where the required information could reside. \\nData sources can be internal as well as external, and business insights often lie \\nburied in the relationships among the multiple data sources. \\nTypes of Data Sources \\nOne of the challenges in building a BI decision-support environment is to merge \\ndata from different. types of data sources. There are three major types of data \\nsources: operational, private, and external (Figure 1.2). \\nOperational Private External \\nFigure 1.2: Three Major Data Sources \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 69}, page_content='36 Step 1: Business Case Assessment \\nOperational Data \\nOnline transaction processing (OLTP) and batch systems provide internal opera- \\ntional data about subject areas, such as the following: \\n* Financial \\n* Logistics \\n* Sales \\n* Order entry \\n* Personnel \\n: Billing \\n* Research and engineering \\nPrivate Data \\nThis internal departmental data usually comes from the desktops and worksta- \\ntions of business analysts, knowledge workers, statisticians, and managers. Exam- \\nples include the following: \\n+ Product analysis spreadsheets \\n* Regional product usage spreadsheets \\n* Prospective customer databases \\nExternal Data \\nOrganizations often purchase external data from vendors that specialize in col- \\nlecting industry-specific information available in the public domain, such as the \\nfollowing: \\n* Health care statistics \\n* Customer profile information \\n* Customer catalog-ordering habits \\n* Customer credit reports \\nExternal data is usually clustered around the following categories: \\n* Sales and marketing data: lists of prospective customers \\n* Credit data: individual credit ratings, business viability assessments \\n* Competitive data: products, services, prices, sales promotions, mergers, takeovers \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 70}, page_content='Cost-Benefit Analysis or \\n> Industry data: technology trends, marketing trends, management science, \\ntrade information \\n* Economic data: currency fluctuations, political indicators, interest rate move- \\nments, stock and bond prices \\n* Econometric data: income groups, consumer behavior \\n* Demographic data: age profiles, population density \\n* Commodity data: raw material prices \\n* Psychometric data: consumer profiling \\n* Meteorological data: weather conditions, rainfall, temperature (especially for \\nagricultural and travel industries) \\nSource Data Quality \\nMerging and standardizing data is usually a requirement of every BI application \\nbut one that is not so easy to accomplish. One of the difficulties in merging and \\nstandardizing data from different types of data sources is that the data is stored in \\ndifferent file structures on different platforms. What makes the process even \\nmore difficult is that the keys for the same objects on different data sources usu- \\nally do not match, the definitions for the same apparent data are often inconsis- \\ntent, and the values are often missing or conflicting. In addition, different people \\nin the organization have authority to determine business rules and policies for \\ndata from different types of data sources, and resolving data conflicts among \\nthem or getting clarification is often all but impossible. \\nStandardizing data from internal operational data sources is difficult enough, \\nbut standardizing data from private and external data sources is a major chal- \\nlenge and could be costly. This cost should be calculated and included in the cost- \\nbenefit analysis. \\nCosT-BENEFIT ANALYSIS \\nA common complaint is that BI projects are hard to cost-justify. That can be true \\nif there is no obvious business problem to solve. One of the most difficult aspects \\nin building a business case for a BI application is to show an adequate ROI. \\nDespite the difficulty, you must demonstrate how, by analyzing and mining the \\ninformation in the BI decision-support environment, the organization can more \\neffectively maneuver and adapt to an increasingly changing marketplace. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 71}, page_content='38 Step 1: Business Case Assessment \\nBenefits are usually harder to quantify than costs, and it will take many high- \\nvalued benefits to offset the costs. A very effective method for justifying the \\nexpenditure of a BI application is to tie it directly to a business problem of mea- \\nsurable proportion. For example, let us assume an organization is losing $5 mil- \\nlion each year because it cannot curb insurance fraud due to insufficient and \\nunreliable data about its underwriting practices. If the proposed BI application \\ncan resolve that specific business problem, it will be relatively easy to justify. \\nTherefore, be as detailed as possible when identifying the benefits, even if it is dif- \\nficult to quantify a precise ROI. This way you can gain the confidence of business \\nexecutives and win approval for the BI project. \\nNote that not all business problems need a BI solution. For example, the \\ntypes of problems that do not require a BI application because they can be solved \\nin more economical and less complicated ways are: \\n* Provide easier online access to a flat file \\n+ Archive operational data \\n+ Merge two operational files for operational processing \\n* Separate the operational reporting function from the operational update \\nfunction \\nSometimes all you need to do to solve an operational problem is to buy a bet- \\nter reporting tool or move the data into a relational database; neither should be \\ninterpreted as a need for a BI solution. However, if the business problem hinges \\non an inability to analyze integrated cross-functional data or to extract from the \\noperational systems hidden intelligence needed to make strategic business deci- \\nsions, then a BI decision-support initiative is probably the right solution. \\nThe results of the cost-benefit analysis should succinctly state how the BI \\napplication would solve a business problem or enable a business opportunity. It \\nshould also state what type of information will be available, how that informa- \\ntion can be used to make better business decisions, and when and how the infor- \\nmation will be presented to the business community (e.g., monthly reports, ad \\nhoc access through online analytical processing [OLAP] tools). Once you have \\nclearly stated the business need and outlined the benefits, the next step is to esti- \\nmate and compare the detailed costs and benefits so you can produce the pro- \\njected ROI, which provides the justification for the BI project. \\nAll BI decision-support initiatives should fulfill at least one of the five benefit \\ncategories listed below (Figure 1.3). \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 72}, page_content='Cost-Benefit Analysis 39 \\nSS RS a I SS ES SE \\n{ \\nRevenue \\nIncrease \\nIncrease | \\nCustomer \\nSatisfaction . \\nImprovement, \\n_ Savings \\n_ Increase \\nFigure 1.3: Benefit Categories \\n1. Revenue increase, possibly in the form of: \\n* Identification of new markets and niches \\n- More effective suggestive selling \\n* Faster opportunity recognition \\n* Faster time to market \\n2. Profit increase, including possibilities for: \\n- Better targeted promotional mailings \\n+ Early warning of declining markets \\n* Identification of under-performing product lines or products \\n* Identification of internal inefficiencies \\n* More efficient merchandise management \\n3. Customer satisfaction improvement through: \\n- Improved understanding of customer preferences \\n* Improved customer-to-product matching \\n* Up-selling to customers \\n* Increased repeat business \\n- Faster resolution of customer complaints \\n4, Savings increase through: \\n* Reduction in wasted or out-of-date merchandise \\n- Reduction in requests for customized reporting \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 73}, page_content='40 Step 1: Business Case Assessment \\n5. Market share gain through: \\n* Increased numbers of customers who defect from the competition \\n* Much higher customer retention rate as compared with previous years and \\nwith the competition \\nIn addition to determining ROI, a business case assessment must include an \\nappraisal of risk. Any project is bound to involve some risks and, given the high \\ncosts of BI projects, performing a risk assessment is a high priority. \\nRisK ASSESSMENT \\nRisks are factors or conditions that may jeopardize a project. Risks should be \\nassessed for the following six major variables: \\n. The technology used for implementing the project \\n. The complexity of the capabilities and processes to be implemented \\n. The integration of various components and of data \\n. The organization and its financial and moral support \\n. The project team staff’s skills, attitudes, and commitment levels \\nNO oO —_ & bw . The financial investment in terms of ROI \\nTable 1.1 depicts a basic risk assessment matrix for these six variables, using \\nthe colors of a traffic light to indicate the severity of the risk: \\nGreen = low risk—go ahead with the project \\nYellow = medium risk—caution, proceed slowly \\nRed = high risk—stop, reevaluate before proceeding \\nEach organization should develop its own appropriate variables and risk con- \\nditions for analyzing the risks most likely to impact its BI project. In developing \\nthat detailed risk assessment matrix for your organization, expand on the ques- \\ntions listed below. \\n* Technology risk \\n— How mature are the selected technologies within the marketplace? \\n— How mature are the selected technologies within the organization? \\n— How many different technologies will co-exist? \\n— Do we have incompatible operating systems? \\n— Do we have incompatible database management systems (DBMSs)? \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 74}, page_content='Risk Assessment 41 \\nTable 1.1: Basic Risk Assessment Matrix \\nLevel of Risk \\nVariable Green (Low) Yellow (Medium) Red (High) \\nTechnology Experienced with Minimal experience -Newtechnology, — \\nmature technology with technology little experience _ \\nComplexity Simple, minimal Moderate, some Mission critical, will \\nworkflow impact workflow impact require extensive \\n_ reengineering» \\nIntegration Stand-alone, no Limited integration Extensive _ \\nintegration required integration \\nrequired | \\nOrganization Solid internal Supportive to a large Little internal — \\nsupport extent support \\nProject team Business experience, | Some business No business _ \\nbusiness-driven, experience, business- experience, only — \\ntalented, great driven, talented, fair technology-driven, \\nattitude attitude limited talent, bad \\nattitude © \\nFinancial Possible ROI within —_— Possible ROI within a Possible ROI after \\nInvestment a very short time moderate time frame a few years | - \\n* Complexity risk \\n— How complex is the overall IT environment? \\n— How complex is the BI application itself? \\n— How extensively will workflow have to change? Will it have to be com- \\npletely reengineered? \\n— How many sites will be supported? \\n— What is the degree of distribution of data, processes, and controls? \\n* Integration risk \\n— How many interfaces will the BI application have? \\n— Are there external interfaces? \\n— How much source data redundancy exists? \\n— Can the primary keys from various data sources be matched? \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 75}, page_content='42 Step 1: Business Case Assessment \\n— Do we have incompatible standards? No standards? \\n— Do we have “orphan” records as a result of referential integrity problems? \\n* Organization risk \\n— How much risk will business management tolerate? \\n— How much risk will IT management tolerate? \\n— How much financial and moral support can we expect when the project \\nencounters hurdles? \\n* Project team risk \\n— How much experience does the team have with successful implementations \\nof BI applications? \\n— How broadly based is that experience? \\n— How well balanced is the team? \\n— How is team morale? \\n— How likely is it that we may lose one or more team members? \\n— Do our team members’ skills cover all the basic disciplines? \\n— Will the business representative be an active player? \\n— How strong is the project manager? \\n* Financial investment risk \\n— How fast can ROI be expected? \\n— How likely is it that the costs will outweigh the benefits? \\n— Can financial risk be mitigated by using only proven technologies? \\nThe combination of high complexity and greater integration often results in a \\nhigher risk of failure to the organization. \\nExpand each of these risk categories with organization-specific detailed vari- \\nables and detailed conditions for each of the three severity rankings (low, \\nmedium, high). Table 1.2 shows an example of a detailed risk assessment matrix \\ntaken from a case study. \\nThe managers for the organization in this case study listed the detailed risk \\nvariables. Then for each variable, they described the conditions for each of the \\nthree risk severity rankings. For example, in the category for business workflow \\nsupport: \\n* Low risk = Supports business workflow seamlessly \\n* Medium risk = Requires some manual intervention \\n* High risk = Requires significant manual intervention \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 76}, page_content='Architecture \\nevaluation \\nExtensibility into \\nsubsequent \\nreleases \\nLogical data \\nmodel: \\ncompleteness \\nLogical data \\nmodel: \\nextensibility \\nMeta data \\n(business and \\ntechnical) \\nPhysical data \\nmodel: \\ncompleteness \\nPhysical data \\nmodel: extens- \\nibility for new \\nproduct types \\nWell-architected \\napplication \\nFully extensible into \\nsubsequent releases \\nAll information \\nrequirements met \\nFully extensible \\nComplete and easily \\nmaintainable \\nExistence of some \\narchitectural issues \\nRisk Assessment 43 \\nTable 1.2: Case Study: A Detailed Risk Assessment Matrix \\nLevel of Risk \\nVariable Green (Low) Yellow (Medium) Red (High) — \\nProject Supports every Supports most critical _—_ Fails to support \\nrequirements: critical ad hoc ad hoc reporting critical ad hoc \\nad hoc reporting requirements reporting \\nreporting requirement requirements \\nProject Supports every key Supports most key Fails to support — . \\nrequirements: business business requirements key business oe \\nAS/400 requirement requirements \\nBusiness Supports business Requires some Requires \\nworkflow workflow seamlessly manual intervention significant manual \\nsupport intervention \\nPoorly architected \\napplication \\nExtensible for most \\nrequirements \\nMost information \\nrequirements © \\ndocumented \\nNot extensible into \\nsubsequent \\nreleases \\nSignificantly mis- \\nsing information \\nrequirements \\nSome extensibility \\nissues \\nIncomplete or not \\neasily maintainable \\nComplete and tuned \\nFully extensible for \\nnew product types \\nComplete but not \\ntuned \\nNot extensible \\nNot incorporated — \\nIncomplete, cannot \\nbe evaluated — \\nLimited product type \\nextensibility \\nIncomplete, cannot \\nbe evaluated \\n(Continued) \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 77}, page_content='Table 1.2: (Continued) \\nVariable \\nPhysical data \\nmodel: source \\nsystem feeds \\nGreen (Low) \\nAcceptable design \\nsupport for source \\nsystems \\nInterfaces Supports external \\n(external and and internal \\ninternal) interfaces \\nAnalysis Easy to add \\ndimensions and \\nmeasures: \\nadding new \\nproduct lines \\nAnalysis \\ndimensions and \\nmeasures: ad- \\nding new tools \\nfor data analysis \\nUse of meta \\ndata repository \\nLoading of the \\nBI target \\ndatabases \\nPhysical \\ndatabase issues \\nPerformance \\nissues \\nSystems \\nmanagement \\nissues: \\nmaintenance \\nProposed cubes and \\nset of dimensions \\nsufficient to support \\nthe business \\nanalysts \\nFully developed \\nLoad procedures \\nestablished and \\nperform well \\nEffective and \\nefficient physical \\ndatabase design \\nConforms to stated \\nperformance \\nrequirements \\nSupport procedures \\nwell established and \\ndocumented \\nbs ies \\nset of dimensions 7 \\nStep 1: Business Case Assessment \\nLevel of Risk \\nPerformance or timing \\nconcerns \\nnited support for — \\nexternal and internal — \\ninterfaces \\nCan be sacedt ae \\nrequires significant \\ncube reconstruction \\nPropose d cubes and \\nLimited meta data \\nsupport \\nLoad procedures \\npoorly documented or \\nperform poorly \\nMinor issues with \\nphysical database \\ndesign \\nSome performance \\nissues \\nLimited support \\ndocumentation \\nPoor inne a \\nexternal and \\ninternal interfaces \\nProposed cubes \\nand set of \\ndimensions \\ninsufficient \\n(Continued) \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 78}, page_content='Business Case Assessment Activities 45 \\nTable 1.2: (Continued) \\nLevel of Risk \\nVariable Green (Low) Yellow (Medium) Red (High) \\nSupport issues Backup and disaster | Backup and disaster oug \\nrecovery procedures _—_ recovery procedures \\ndeveloped and developed but not \\ninstalled installed \\nSecurity Satisfies application Difficult to maintain \\nimplementation needs and is easy to \\nmaintain \\nThe managers then selected the applicable risk severity ranking for each vari- \\nable by highlighting the description that most accurately portrayed the condition \\nof their BI project using the colors green, yellow, and red. Out of 21 variables, \\nthey rated only two variables low risk, six variables medium risk, and thirteen \\nvariables high risk. The managers decided that the overall risk for this BI project \\nwas high. \\nHaving a realistic assessment of the severity of potential risks will help the \\nproject team create realistic estimates and expectations for the BI project. Con- \\nversely, unidentified and unmanaged risks can result in project failure or even \\njeopardize the entire BI initiative. \\nBUSINESS CASE ASSESSMENT ACTIVITIES \\nThe business case assessment activities do not need to be performed linearly. Fig- \\nure 1.4 indicates which activities can be performed concurrently. The list below \\nbriefly describes the activities associated with Step 1, Business Case Assessment. \\n1. Determine the business need. \\nJustification of a BI project is difficult only if there is no obvious business rea- \\nson for the BI application. There must be a clearly defined business informa- \\ntion need that cannot be satisfied with traditional decision-support methods. \\nThe business need should be tied to a financial consequence for the organiza- \\ntion, either as cost overruns or lost revenue. The financial consequence could \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 79}, page_content='46 Step 1: Business Case Assessment \\nSERRATE INE TS LA SST EB EE TE SS TD OI AE IT I! EO CLE IO EOL EELS SII SEE SOS ELE \\n1 \\nDetermine \\nbusiness need \\nis \\nAssess operational \\nsources and procedures \\nAssess current \\nDSS solutions \\nAssess competitors’ Bl \\ndecision-support initiatives \\nwy \\nDetermine Bl \\napplication objectives \\n8 \\nPerform risk \\nassessment \\nPerform cost- \\nbenefit analysis \\nPropose \\nBI solution \\nWrite assessment \\nreport \\nFigure 1.4: Business Case Assessment Activities \\nbe the result of a lost business opportunity (e.g., lack of access to vital infor- \\nmation) or a business problem (e.g., reporting inconsistencies or reliance on \\ndirty data). In either case, you must quantify the business need as a monetary \\nexpression (e.g., $5 million lost annually to the competition because of an \\ninability to cross-sell to current customers). \\n2. Assess the current decision-support system solutions. \\nExamine the current decision-support system (DSS) solutions and determine \\ntheir deficiencies. If the current solutions do not provide the information \\nneeded to mitigate the business problem, the reasons have to be understood. \\nIf the necessary information is not being delivered, it could be due to \\nresource shortages and long backlogs in IT’s workload. Other reasons could \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 80}, page_content='Business Case Assessment Activities 47 \\ninclude difficulty accessing and merging source data because of different key \\nstructures, missing keys, or data redundancy and inconsistencies. \\nAssess the operational sources and procedures. \\nWhile assessing the current DSS solutions, give special attention to the opera- \\ntional source data and operational procedures. The business problem could \\nexist because the business people cannot trust the information being deliv- \\nered to them. Data quality problems may be the result of poor data entry \\npractices, lack of edits, defective program code, or lack of training. A solution \\nto the business problem may be to tighten those procedures. \\n. Assess the competitors’ BI decision-support initiatives. \\nStaying ahead of the competition is extremely important in today’s economy. \\nIn order to stay ahead, you must know what your competitors are doing. It \\nwould be helpful to know about the competitors’ successes and failures with \\ntheir BI decision-support initiatives and whether they have achieved higher \\nsales or introduced innovative products. \\n. Determine the BI application objectives. \\nOnce you define the business problem and understand the deficiencies of the \\ncurrent environment, you can clearly state the BI application objectives. \\nThese objectives must be compared to the organization’s strategic business \\ngoals to ensure that they are in synch. \\nPropose a BI solution. \\nUsing the BI application objectives and the analysis results of the current \\nenvironment, including the current DSS solutions, you can now propose a BI \\nsolution. The business problem may be too complicated to address all at \\nonce, in which case you will need to devise an iterative release approach. \\nUnfulfilled requirements from previous BI projects must be evaluated and \\nthe decision must be made whether or not to include them in this release. \\n. Perform a cost-benefit analysis. \\nDetermine the projected BI application costs. In addition to new hardware, \\nsoftware, and tools, include ongoing maintenance fees and training costs. \\nRemember to account for the costs of new employees if you need to hire \\nmore staff to administer the new tools or to perform new business activities, \\nsuch as data mining. Determine the benefits of the BI application, both the \\ntangible and intangible ones. Itemize how the BI application will solve the \\nbusiness problem and save the organization money or increase the organiza- \\ntion’s profit margin. Finally, calculate the ROI and indicate the time frame in \\nwhich it will be realized. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 81}, page_content='48 Step 1: Business Case Assessment \\n8. Perform a risk assessment. \\nList all the possible risks for your project and create a risk assessment matrix. \\nIf you do not have sufficient information to produce a detailed risk assess- \\nment matrix at this time, use the six basic risk categories: technology, com- \\nplexity, integration, organization, project team, and financial investment. \\nDetermine the severity of each risk: low, medium, or high. Also determine \\nhow likely it is that each risk will materialize and what impact it would have \\non the BI project. \\n. Write the assessment report. \\nDescribe the business need (whether it is a business problem or a business \\nopportunity), and suggest one or more BI decision-support solutions. \\nInclude the results of the costs-benefit analysis and the risk assessment. Add a \\nshort summary to the report, and deliver it to the business sponsor as well as \\nexecutive management. \\nDELIVERABLE RESULTING FROM THESE ACTIVITIES \\nJe Business case assessment report \\nThe business case assessment report should document the following: \\n— Strategic business goals of the organization \\n— Objectives of the proposed BI application \\n— Statement of the business need (business problem or business opportunity) \\n— Explanation of how the BI application will satisfy that need (proposed BI \\nsolution) \\n— Ramifications of not addressing the business need and not committing to \\nthe proposed BI solution \\n— Cost-benefit analysis results \\n— Risk assessment \\n— Recommendations for business process improvements to the operational \\nsystems or to the operational business processes and procedures \\nThe assessment report should also have a one- or two-page executive over- \\nview that summarizes the details of the report. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 82}, page_content='Risks of Not Performing Step 1 49 \\nROLES INVOLVED IN THESE ACTIVITIES \\n® Business representative \\nThe business representative is the business person who will directly benefit \\nfrom the BI application and who will participate as a full-time member on the \\nproject core team. He or she should complete the benefits portion of the cost- \\nbenefit analysis and should assist the project manager with the risk assess- \\nment. \\n@ Business sponsor \\nThe business sponsor is the person holding the “purse strings.” He or she \\nensures that proper objectives for the BI application are established and that \\nthose objectives support the strategic business goals of the organization. He or \\nshe approves the business case assessment and helps set and negotiate the BI \\nproject scope to meet the stated BI application objectives. \\n@ Data quality analyst \\nThe quality of the source data is always overestimated. In reality, source data \\nquality is much worse than anyone can imagine. The data quality analyst has \\nto be able to estimate the time, effort, and cost associated with finding the \\ndirty data and cleansing it. \\n@ Project manager \\nThe project manager should have experience as a systems integrator. The BI \\ndecision-support environment requires the management and integration of \\nmultiple types of software as well as hardware. In addition, the project man- \\nager needs skills in managing the staff, the project, and the expectations of the \\nbusiness community. \\n@ Subject matter expert \\nExpertise in the business is mandatory, and the subject matter expert brings \\nthat expertise to the BI project. He or she should also have an understanding \\nof the competition and of the trends in the industry. \\nRISKS OF NOT PERFORMING STEP 1 \\nOne of the major risks of not performing this step is that you may end up build- \\ning a BI decision-support solution that has no strong business driver and does \\nnot support a strategic business goal. This can lead to a disappointed business \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 83}, page_content='50 Step 1: Business Case Assessment \\ncommunity and an unhappy management group at the end of the project. No \\nmatter how valuable the BI application is from an IT perspective, it may not meet \\nthe expectations of the business community. If the business people are not con- \\ntent with the information provided to them, they might reject other BI solutions \\nproposed by IT to solve other business problems. \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nAdelman, Sid, and Larissa Terpeluk Moss. Data Warehouse Project Management. \\nBoston, MA: Addison-Wesley, 2000. \\nBischoff, Joyce, and Ted Alexander. Data Warehouse: Practical Advice from the \\nExperts. Upper Saddle River, NJ: Prentice Hall, 1997. \\nDeMarco, Tom. Slack: Getting Past Burnout, Busywork, and the Myth of Total Effi- \\nciency. New York: Broadway Books, 2001. \\nDevlin, Barry. Data Warehouse: From Architecture to Implementation. Reading, \\nMA: Addison-Wesley, 1997. \\nDyché, Jill. e-Data: Turning Data into Information with Data Warehousing. Bos- \\nton, MA: Addison-Wesley, 2000. \\nEnglish, Larry P. Improving Data Warehouse and Business Information Quality: \\nMethods for Reducing Costs and Increasing Profits. New York: John Wiley & Sons, \\n1900: \\nHackney, Douglas. Understanding and Implementing Successful Data Marts. Read- \\ning, MA: Addison-Wesley, 1997. \\nInmon, William H., Claudia Imhoff, and Greg Battas. Building the Operational \\nData Store. New York: John Wiley & Sons, 1996. \\nInmon, William H., Claudia Imhoff, and Ryan Sousa. Corporate Information Fac- \\ntory. New York: John Wiley & Sons, 1997. \\nInmon, William H., John A. Zachman, and Jonathon G. Geiger. Data Stores, Data \\nWarehousing and the Zachman Framework: Managing Enterprise Knowledge. New \\nYork: McGraw-Hill, 1997. \\nJarke, Matthias, Maurizio Lenzerini, Yannis Vassiliou, and Panos Vassiliadis. Fun- \\ndamentals of Data Warehouses. New York: Springer, 2000. \\nKuan-Tsae, Huang, Yang W. Lee, and Richard Y. Wang. Quality Information and \\nKnowledge Management. Upper Saddle River, NJ: Prentice Hall, 1998. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 84}, page_content='Justification \\n2 \\nEnterprise \\nInfrastructure \\n\\\\ Evaluation \\nConstruction \\\\ \\nCHAPTER TWO \\nStep 2: Enterprise \\nInfrastructure Evaluation \\nCHAPTER OVERVIEW \\nAn enterprise infrastructure is to BI applications what a trans- \\nportation infrastructure is to automobile owners. In order to \\nsafely and comfortably travel with an automobile, there must \\nbe a physical infrastructure, such as roads, bridges, traffic \\nlights, and traffic signs, as well as nonphysical infrastructure, \\nsuch as standardized traffic rules and their interpretation. For \\nexample, without the universal interpretation of the rule that \\n“Green means go, red means stop,’ traffic lights would be of \\nno use. Similarly, an enterprise infrastructure consists of two \\nmajor components: \\n1. Technical infrastructure, such as hardware, middleware, \\nand database management systems (DBMSs) \\n2. Nontechnical infrastructure, such as standards, meta data, \\nbusiness rules, and policies \\nAccordingly, this chapter is divided into two sections—Step 2, \\nSection A, Technical Infrastructure Evaluation, and Step 2, Sec- \\ntion B, Nontechnical Infrastructure Evaluation. The first sec- \\ntion covers the following topics: \\n@ Things to consider about technical infrastructure \\n@ The importance of scalability for the hardware platform \\n@ Middleware, with emphasis on DBMS gateways since they \\nare one of the most important middleware components for \\nBI applications \\n@ DBMS requirements for the specific functionality needed to \\nsupport BI applications \\n@ Brief descriptions of the technical infrastructure activities, \\nthe deliverables resulting from those activities, and the \\nroles involved \\nm@ The risks of not performing Step 2, Section A \\n51 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 85}, page_content='52 Step 2: Enterprise Infrastructure Evaluation \\nThe second section, on nontechnical infrastructure, covers the following topics: \\n@ Things to consider about nontechnical infrastructure \\n@ Bad practices and old habits that lead to stovepipe development (automation silos) \\n@ The need for a nontechnical infrastructure to enable an integrated BI decision-support \\nenvironment \\nm@ The enterprise architecture components: business function model, business process \\nmodel, business data model, application inventory, and meta data repository \\n@ Enterprise standards for such things as data naming, data quality, and testing \\n@ Brief descriptions of the nontechnical infrastructure activities, the deliverables resulting \\nfrom those activities, and the roles involved \\n@ The risks of not performing Step 2, Section B \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 86}, page_content='Step 2, Section A: Technical Infrastructure Evaluation 53 \\nStep 2, Section A: Technical \\nInfrastructure Evaluation \\nTHINGS TO CONSIDER \\nHardware \\n¥ What hardware platforms do we already have or use? \\n¥ On which platform should we implement the BI application? \\n¥Y Do we need new hardware? What will it cost? \\n¥ Will we need more staff to maintain the new hardware? \\n¥ Will the new hardware integrate with our existing platforms? \\nV How will the new hardware scale to accommodate ever-increasing loads of \\nprocessing and volumes of data? \\nNetwork \\n¥ What type of local area network (LAN) are we using? \\nv¥ What type of wide area network (WAN) are we using? \\nV Is the bandwidth of our WAN sufficient to grow? \\nMiddleware \\n¥ What type of middleware do we already have or use? \\nVY Do we have the necessary middleware to retrieve the source data from heter- \\nogeneous platforms and transfer it to the BI decision-support environment? \\n¥ What is the operational source architecture? (e.g., enterprise resource plan- \\nning [ERP], legacy files) \\nVY Do we need new middleware? What will it cost? \\n¥ Will the connection be permanent between the source files (or source data- \\nbases) and the BI target databases? \\n¥ Which of our hardware, software, and middleware is proprietary? Have we \\npurchased it? Or are we leasing it? \\nDatabase Management Systems \\n/Y What DBMSs do we already have? \\n/ Will we need to buy a new DBMS? What will it cost? \\nVY Will the new DBMS be compatible with our operating system(s)? \\n/ What software tools can run with it? \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 87}, page_content='54 Step 2: Enterprise Infrastructure Evaluation \\nY Does our staff have the skills to use and administer the new DBMS? \\nY Will we have to hire more database administrators? \\nTools and Standards \\nY How are the business analysts currently analyzing the data? What reporting \\nand querying tools do they use? \\n¥ What additional tools and utilities do we need? \\n/Y What other software do these tools need to interact with? \\nY Do we know of any major problems with our technical infrastructure? \\n¥Y What are our technical standards for compatibility and access? \\nThe development efforts of early BI applications, such as the early data ware- \\nhouses, were relatively slow, labor-intensive, risky, and expensive. Extraction and \\ntransformation of operational data into a data warehouse frequently involved \\ncreating new, custom-written application code. The target databases were either \\nbased on proprietary DBMSs or were using proprietary hardware platforms. \\nThere was also a shortage of tools to administer, control, and expand the new \\ndecision-support environment. The lesson learned from the early BI days was \\nthat in order to reach the best performance results for data access and retrieval, a \\ncomprehensive application platform must be chosen. Therefore, it is important \\nto select the appropriate hardware, middleware, and DBMS and to ensure that \\nthese components are implemented properly. \\nTHE HARDWARE PLATFORM \\nFor adequate report and query performance, it is very important to have sufficient \\n“horsepower” with the hardware platform. Scalability is of utmost importance. \\nControlled Chaos \\nDo not despair if your computer environment looks like the one in Figure 2.1. \\nThis is more often the case than not in organizations of any size. What exists can \\nat best be described as controlled chaos! \\nAccompanying the hardware chaos are usually a huge portfolio of disparate \\nsoftware and a large staff with only enough skills to support the existing systems. \\nIn order to minimize the chaos, most organizations implementing a BI decision- \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 88}, page_content='The Hardware Platform 55 \\nFigure 2.1: Controlled Hardware Chaos \\nsupport environment have to consider at least four imperatives in hardware plat- \\nform selection. \\n1. New hardware platforms have to fit into the existing hardware configuration. \\n2. The DBMS on the selected hardware platform must perform well as database \\naccess and usage grow. Scalability is therefore one of the major issues to be \\naddressed. \\n3. Platform selection is restricted by the need for interoperability between vari- \\nous hardware platforms (if required). \\n4, Cost and return on investment (ROI) for the previous three qualifiers are \\ncontrolling factors. \\nHardware Platform Requirements \\nThe hardware must have sufficient power to handle complex access and analysis \\nrequirements against large volumes of data. It has to support not only predefined, \\nsimple queries on summary data but also ad hoc complex queries on detailed \\ndata. It must also be scalable because rapid changes will occur in: \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 89}, page_content='56 Step 2: Enterprise Infrastructure Evaluation \\n* Data volumes \\n* Updating frequencies \\n* Data access patterns \\n* Number of reports and queries \\n* Number of people accessing the BI target databases \\n* Number of tools running against the BI target databases \\n* Number of operational systems feeding the BI target databases \\nIt is useful to think of a BI decision-support environment in terms of a three- \\ntier computing architecture (Figure 2.2). First, the extract/transform/load (ETL) \\nengine extracts, cleanses, and transforms operational data. Then, using middle- \\nware, the BI target databases are populated. Finally, when data is requested, it is \\nmapped into suitable representations for the business community at the interface \\nlevel for running queries, reports, and online analytical processing (OLAP) appli- \\ncations. The interface level can be a customized graphical user interface (GUI) \\napplication, an enterprise portal, or Extensible Markup Language (XML) Web \\nservices. \\nApplication Interface \\nReport \\nMiddleware \\nLogical view of BI data \\nPhysical data in BI target databases \\nt Middleware | \\nETL Engine | \\nFigure 2.2: Three-Tier Computing Architecture \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 90}, page_content='The Middleware Platform 57 \\nTHE MIDDLEWARE PLATFORM \\nThe term middleware refers to runtime system software, which is layered between \\nthe application programs and the operating system. It acts as a bridge to integrate \\napplication programs and other software components in an environment with \\nmultiple network nodes, several operating systems, and many software products. \\nMiddleware is needed to run client/server architectures and other complex net- \\nworked architectures in a distributed computing environment. Therefore, the \\nmiddleware should support directory services, message-passing mechanisms, \\nand database gateways. \\nMost middleware falls into two major categories: \\n1. Distributed logic middleware supports program-to-program communication \\nbetween two pieces of custom-written application code. \\n2. Data management middleware connects an application or DBMS on one plat- \\nform with a DBMS running on another platform. \\nMiddleware can also be used to enable “reach-through” queries from sum- \\nmaries in the BI target databases to the underlying detail data held in operational \\nsystems. To keep the cost to a minimum, a number of organizations are already \\nusing gateways to transfer data from multiple heterogeneous sources of server \\ndata to client workstations, as illustrated in Figure 2.3. \\n* Client Workstations * Server Databases \\n* Client Interfaces * Server Interfaces \\n* SQL Requests Sent * Relational Tables Returned \\nSe \\nApplication A \\nNonrelational \\nDatabases \\nRelational \\nDatabases \\nApplication B \\nGateway \\nFigure 2.3: Gateway Example \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 91}, page_content='58 Step 2: Enterprise Infrastructure Evaluation \\nDBMS Gateways \\nDMBS gateways, a form of middleware, are generally required to connect the dif- \\nferent network architectures of desktop computers, remote clients, or small \\nenterprise servers to industrial-strength enterprise servers. \\nGateways fall into four major categories. \\n1. Point-to-point gateways provide access to only one type of DBMS. Vendors \\nmarket each point-to-point gateway as a different product. A point-to-point \\ngateway is easy to implement because it handles only one DBMS at a time. It \\nis also a less expensive solution compared with the other three gateway solu- \\ntions. However, when the organization requires access to multiple DBMSs, it \\nneeds multiple gateways. In that case, point-to-point gateways may not be a \\nless expensive solution than using a universal gateway. \\n2. Gateways that can be used universally provide access to different types of data- \\nbases on various platforms. Universal gateways require extensive effort to \\nimplement and maintain. As a result, these gateways become expensive. \\n3. Gateways using Structured Query Language (SQL) can access only “real” rela- \\ntional databases, not simulated ones. The SQL gateway translates the client \\nrequest into the native SQL syntax used by the server’s relational DBMS. \\n4, Gateways based on application programming interfaces (APIs) are driven by \\nvendor specifications. One of the major gateways of this type is open database \\nconnectivity (ODBC). A number of ODBC vendors provide drivers for \\naccessing databases residing on various servers. \\nOrganizational data is distributed across multiple DBMS platforms, cooper- \\nating across a network with different instruction sets from multiple vendors. \\nODBC-enabled applications can access multiple distributed data sources concur- \\nrently via ODBC’s common interface approach (Figure 2.4). \\nModules called database drivers can be added to link the applications to the \\nDBMS of their choice. Database drivers consist of dynamic link libraries (DLLs) \\nthat applications can invoke on demand. \\nTHE DBMS PLATFORM \\nThe database infrastructure changes with the size of the BI decision-support \\nenvironment, which in turn influences the selection of the DBMS, as shown in \\nFigure 2.5. A small departmental data mart application may reside on a local file \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 92}, page_content='The DBMS Platform 59 \\nApplication Application Application \\nODBC Common Interface \\nOracle DB2 \\nDriver Driver \\nFigure 2.4: ODBC-Enabled Applications \\nSQL \\nServer \\nDriver \\nIndustrial-Strength \\n5 oupemumiaarnam Enterprise Server \\nSmall Wore(our . peenoral DBMS ow ne Ramote Client Enterprise Server : an ; Tete adh - Relational DBMS Multidimensional DBMS \\nFigure 2.5: Database Infrastructures \\nserver, but a larger BI application may need the infrastructure support of an enter- \\nprise server, and very large enterprise-wide BI solutions may need to use a mainframe. \\nCriteria for Selecting a DBMS \\nThe following functions are important and necessary attributes of a DBMS for \\nhandling the workload of a large BI target database or very large database (VLDB): \\n* Degree of parallelism in handling queries and data loads \\n* Intelligence in handling dimensional data models and optimizers \\n* Database scalability \\n- Internet integration \\n* Availability of advanced index schemes \\n- Replication on heterogeneous platforms \\n* Unattended operations \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 93}, page_content='60 Step 2: Enterprise Infrastructure Evaluation \\nA DBMS is a sophisticated piece of software and consists of a number of fea- \\ntures that need to be evaluated. Features to look for in a DBMS for BI applica- \\ntions are listed below. \\n* Network support provided by the DBMS should be compatible with the orga- \\nnization’s data communications standards. \\n* Dimensional capability in the form of seamless support for fast and easy load- \\ning and maintenance of precompiled summaries is important. \\n* Adequate state-of-the-art triggers and stored procedures can be used as “event \\nalerters,” which trigger an action in response to a given set of circumstances. \\n* Administrative support features should provide for: \\n— Maintenance of consistent historical data \\n— Support for archiving (e.g., dropping the oldest week’s data when adding \\nthe data for a new week) \\n— Controls for implementing resource limits to display a warning when a \\nquery that consumes excessive resources is about to be terminated \\n— Workload tracking and tuning mechanisms \\n— Careful monitoring of activity and resource utilization \\n* Location transparency across the network must allow the access and analysis tools \\nto retrieve data from multiple BI target databases from a single workstation. \\n+ Future usage explosion must be supported by: \\n— Effective caching and sharing of data to minimize input/output (I/O) \\nbottlenecks \\n— Effective management of task switching while running many queries con- \\ncurrently \\n— Compatibility with multiple processors \\n- Scalability requires that the DBMS has the capability to support: \\n— Advanced functions for sorting and indexing \\n— Fault tolerance for uninterrupted processing \\n— Uninterrupted maintenance operations, such as unload, backup, and restore \\n— Checkpoints, recovery, and rapid restart of interrupted operations \\n* Query performance optimization should address aspects of query processing \\n(such as JOINs, sorting, and grouping) that require intensive use of the cen- \\ntral processing unit (CPU). \\n* Load process and performance must address: \\n— Data obtained directly from a variety of feeds, including disk files, network \\nfeeds, mainframe channel connections, and magnetic tapes \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 94}, page_content='Technical Infrastructure Evaluation Activities 61 \\n— Complete data loading and preparation, including format conversion, \\nintegrity enforcement, and indexing \\nThe security system must support unique passwords, password protection, \\nand the authorization constraints necessary for specific persons and for specific \\ntables of the database. The system administrator should provide restricted \\naccess to the views and virtual tables. \\nThe data dictionary should feed into a meta data repository, and the database \\nobjects should be linked to all data objects described in the enterprise logical \\ndata model. \\nSelecting and reevaluating the appropriate hardware, middleware, and DBMS \\ncomponents of the technical infrastructure are some of the most important activ- \\nities on BI projects because they ensure the continued scalability and high perfor- \\nmance of the BI applications. \\nTECHNICAL INFRASTRUCTURE EVALUATION ACTIVITIES \\nThe technical infrastructure evaluation activities do not need to be performed \\nlinearly. Figure 2.6 indicates two activities that can be performed concurrently. \\nThe list below briefly describes the activities associated with Step 2, Section A, \\nTechnical Infrastructure Evaluation. \\na \\nAssess existing \\nplatform \\nExpand current \\nplatform \\nWrite technical infrastructure \\nassessment report \\nNON \\n2 \\nEvaluate and \\nselect new products \\nFigure 2.6: Technical Infrastructure Evaluation Activities \\n1. Assess the existing platform. \\nReview the existing platform in terms of hardware, middleware, DBMS, and \\ntools. It is important to evaluate the interdependence of the tools for their \\nvarious purposes, such as the interdependence between a multidimensional \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 95}, page_content='62 Step 2: Enterprise Infrastructure Evaluation \\nreporting tool and an ad hoc querying tool. In addition, review the existing \\nnetwork architecture. One of the biggest bottlenecks today, especially in orga- \\nnizations with decentralized applications, is the lack of bandwidth coupled \\nwith a limited capacity for network growth. \\n. Evaluate and select new products. \\nAfter assessing the existing platforms, identify which types of new hardware, \\nsoftware, or networking components you must acquire. If the existing hard- \\nware platform appears to be sufficient, be sure to determine that it will be able \\nto provide the productivity and performance the organization expects from \\nit. Engage business representatives and stakeholders in the decision-making \\nprocess by including them in peer reviews during the selection process. \\n. Write the technical infrastructure assessment report. \\nCompile all findings about the existing platform into a report. Explain the \\nstrengths and weaknesses of the current hardware, middleware, DBMS, and \\ntools, and provide a list of missing technical infrastructure components nec- \\nessary to meet the project requirements. \\n. Expand the current platform. \\nOnce you have determined which new products need to be acquired, you can \\nbegin the process of evaluating, selecting, ordering, installing, and testing them. \\nDELIVERABLES RESULTING FROM THESE ACTIVITIES \\n1. Technical infrastructure assessment report \\nThis report should itemize the scalability and limitations of the hardware, \\nmiddleware, DBMS, and tool platform and should cover the following items: \\n— Servers \\n— Client workstations \\n— Operating systems \\n— Middleware (especially DBMS gateways) \\n— Custom interfaces \\n— Network components and bandwidth \\n— DBMS functionality and utilities (backup and recovery, performance \\nmonitoring) \\n— Development tools such as computer aided software engineering (CASE) \\nand ETL tools \\n— Access and analysis tools such as OLAP tools and report writers \\n— Meta data repository \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 96}, page_content='Risks of Not Performing Step 2, Section A 63 \\nInclude a gap analysis section and provide recommendations for upgrading \\nthe platform. Incorporate the product evaluation and selection results, listing \\nthe weighted requirements and the product features you evaluated. The \\nproduct and vendor evaluation and selection process is described in more \\ndetail in Step 10, Meta Data Repository Design. \\n2. Installation of selected products \\nIf you identified new products to purchase, write a request for proposal \\n(RFP) or a request for information (RFI) and send it to the vendors on the \\nshort list. After selecting a product, order, install, and test it. \\nROLES INVOLVED IN THESE ACTIVITIES \\n® Bl infrastructure architect \\nThe BI infrastructure architect is responsible for developing the capacity plans \\nfor the hardware, middleware, DBMS, and network in order to ensure the \\nscalability needed by the BI decision-support environment. The BI infrastruc- \\nture architect and the database administrator have to work side by side while \\nevaluating the current environment, determining the appropriate future plat- \\nforms, and implementing the selected technologies. \\n@ Database administrator \\nThe database administrator has to evaluate the current DBMS platform on the \\ncurrent hardware. The database administrator also has to evaluate the tools \\nand the middleware as they relate to the DBMS. He or she has to determine \\nthe future DBMS requirements and should participate in performing the tech- \\nnical infrastructure gap analysis. \\nRISKS OF NOT PERFORMING STEP 2, SECTION A \\nIn order to provide adequate performance in a growing BI decision-support envi- \\nronment, it is mandatory to assess the hardware, middleware, DBMS, and tools \\nfrom time to time. If you do not perform this part of Step 2, technical perfor- \\nmance could degrade to such an extent that the BI decision-support environment \\nbecomes unusable. It is also necessary to stay current with the existing technol- \\nogy. Technology advances occur every few months. Not staying current and not \\ntaking advantage of new and improved features can turn the BI decision-support \\nenvironment into an extinct dinosaur in a very short time. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 97}, page_content='64 Step 2: Enterprise Infrastructure Evaluation \\nStep 2, Section B: Nontechnical \\nInfrastructure Evaluation \\nTHINGS TO CONSIDER \\nLogical Data Model \\nY Do we already have logical data models for the source systems? If not, who is \\nresponsible for creating a logical data model for this BI project? \\nY Who are the data owners and business people who have to participate in the \\nvalidation of the logical data model and the business meta data? \\n/Y How many trained data administrators do we have? Will we have to hire \\nmore? \\nY Who will integrate our logical data model into the enterprise logical data \\nmodel? \\nY Who will validate the expanded enterprise logical data model? \\n¥ What CASE tool do we have for logical data modeling? Will we need to \\nlicense (buy) one? \\nMeta Data \\nY Do we already have a meta data repository? Will we need to license (buy) or \\nbuild a meta data repository? \\nV If we have one, how easy is it for the business people to access and navigate \\nthrough the meta data repository? Do we need to enhance it? \\nY Who is responsible for capturing all the meta data components? Who is \\nresponsible for loading the meta data into the meta data repository? \\nV How will we merge the new business meta data from the CASE tool with the \\nnew technical meta data from the ETL tool and the OLAP tool? \\nStandards, Guidelines, and Procedures \\nY Are our current standards too lax or too stringent? \\nVv Where are the standards documented? Are they being followed? \\nV How effective are our data quality guidelines for measuring dirty data and. \\nand triaging data cleansing? \\nV Are our change-control procedures easy to use? Do we have a template? \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 98}, page_content='The Effects of Stovepipe Development 65 \\nVv Do we have a template for an issue log? \\n¥ What are our testing standards? \\nVv Are we habitually testing too much or too little? Are we testing the right \\nthings? \\nVv How are we currently resolving technical and business disputes? \\nVv Do we need to create or change our dispute resolution procedure? \\n¥ What are the roles and responsibilities that will be assigned to the core team \\nmembers? \\nV Is our current team structure effective? \\nEnterprise-wide nontechnical infrastructure is a critical success factor for a \\nBI decision-support environment. Without a cross-organizational infrastructure, \\nBI applications would only contribute to the existing chaos of stovepipe applica- \\ntions and databases. \\nTHE EFFECTS OF STOVEPIPE DEVELOPMENT \\nIn the past, the mental model for providing an automated information technol- \\nogy (IT) solution to a business problem has been to “divide and conquer.” \\n1. Divide a large problem into smaller “digestible” pieces, that is, prioritize and \\nseparate the deliverables. \\n2. Conquer the problem by working on each piece individually, that is, build \\neach deliverable separately. \\nThis approach works very well for reducing risk by breaking a complex prob- \\nlem into small, manageable chunks. However, this approach also has a severe \\ndrawback when applied without a nontechnical infrastructure. Namely, it produces \\nstovepipe systems (automation silos). The effects of stovepipe systems are lost \\nbusiness knowledge and lost cross-organizational business view, which severely \\nimpact business analytics and data mining activities. \\nMost businesses are very complex, and as organizations mature, their busi- \\nness complexity increases. As business complexity is broken apart into smaller \\nand less complex components, the interrelationships among those individual \\ncomponents are lost. Much of the business intelligence is contained in these lost \\ninterrelationships, and that is a problem for BI applications. Most BI applications, \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 99}, page_content='66 Step 2: Enterprise Infrastructure Evaluation \\nel \\nDo we have \\nany indication \\nof fraudulent \\nactivities? \\nDo we know how \\nmuch of the \\ncustomers’ wallet \\nshare we have? \\nAre our products \\npriced competitively? Do we know what \\nour best customers \\nhave in common? \\nDo we know why \\nwe are losing \\nmarket share? Do we know what \\ngeneral classes of \\ncustomers we have? Can we forecast the \\nlong-term buying habits \\nof our Generation X \\ncustomers? \\nFigure 2.7: Fundamental Business Questions \\nand especially data mining applications, expect to find “golden nuggets” of busi- \\nness wisdom embedded in these complex interrelationships. \\nAlthough business managers can answer most questions about the business \\nfunctions of their own departments, when asked a question spanning two or \\nthree lines of business (where complex interrelationships have been lost), those \\nmanagers must scramble for weeks to piece together the answer. Fundamental \\nbusiness questions, such as the ones illustrated in Figure 2.7, present multimil- \\nlion-dollar problems to large organizations. \\nThe answers to these and many other questions do exist in the real business \\nworld. We have just been neglecting to design our systems in a cross-functional \\nmanner that would allow us to find these answers quickly. \\nTHE NEED FOR NONTECHNICAL INFRASTRUCTURE \\nAn organization needs to create a nontechnical infrastructure to prevent the BI \\ndecision-support environment from becoming as fragmented as the operational \\nand traditional decision-support environments, from which cross-organizational \\nquestions cannot be answered. Creating this infrastructure involves cross-organi- \\nzational activities such as those listed below. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 100}, page_content='The Need for Nontechnical Infrastructure 67 \\nConduct an extensive business analysis involving business people from many \\nlines of business. During this activity, define or redefine the lost complex \\ninterrelationships among business functions and business data. \\nAdopt a system of peer reviews to support cross-organizational attendance and \\nevaluation of business analysis activities. \\nResolve age-old disputes about data definitions and domains (valid data contents). \\nStandardize data names and data values to reflect true business rules and \\nbusiness policies. \\nGet agreement from the business people on the business rules and business pol- \\nicies in the first place. \\nCreate a regular forum for business people to maintain and review the stan- \\ndards, business rules, and business policies on an ongoing basis. \\nOver time, create one consolidated, nonredundant data architecture for the \\nentire enterprise to reflect the complex reality of the business; that is, create \\nan enterprise logical data model. This model documents the data inventory \\nof an organization. It is also the primary vehicle for mapping the inventory of \\noperational data to the inventory of BI data. \\nCreate a meta data repository and populate it with nonredundant meta data. \\nCreate an inventory of source data and map it to the applicable BI target data- \\nbases. Also create an inventory of other system components, such as programs, \\nreports, screens, and so on, thereby identifying the reusability of data and \\nprocess components. \\nCreate and manage one expanding central staging area (per load periodicity) \\nfor the ETL processes. Do not allow independent ETL processes for each data \\nmart solution. \\nEnterprise infrastructure activities, technical as well as nontechnical, are stra- \\ntegic cross-organizational activities. A central enterprise architecture group (Fig- \\nure 2.8) must manage and coordinate these activities. Many large organizations \\nhave a strategic enterprise architecture group whose charter is to integrate and \\nmanage the IT infrastructure components as assets of an organization. These infra- \\nstructure components are inventories or models of business functions, business \\nprocesses, business data, meta data, applications, and other technical implemen- \\ntation elements. If an organization does not have an enterprise architecture group, \\nthen data administration can perform the information architecture subfunction, \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 101}, page_content='68 Step 2: Enterprise Infrastructure Evaluation \\nBusiness | Business | Business | Business | Business | Business | Business \\njerloueul4 JewWosnD Joynquisig Aio\\\\uaau] \\n= \\nEnterprise \\nArchitecture \\nGroup \\nFigure 2.8: Enterprise Architecture Group \\nwhich includes creating and managing the enterprise logical data model and the \\nmeta data repository. If the organization has a separate meta data administration, \\nthe information architecture responsibilities would be divided between those two \\ngroups (data administration and meta data administration). \\nENTERPRISE ARCHITECTURE \\nAn enterprise architecture is comprised of a set of pictorial representations \\n(models) of the organization in terms of business functions, business processes, \\nand business data. Each enterprise architecture model is supplemented with support- \\ning meta data, such as standard definitions, business rules, and policies. The purpose \\nof these models is to document the set of business actions performed on any real- \\nworld object in the course of conducting business. In other words, enterprise \\narchitecture models describe the actual business in which the organization engages. \\nEvery active organization has an enterprise architecture by default, even if it is \\nnot documented. With undocumented architecture, the organization’s business \\nactions and business objects are most likely not consistently understood by every- \\none in the organization. The goal of documenting the architecture is to avoid \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 102}, page_content='Enterprise Architecture 69 \\n2 Business \\nProcess Model all \\n1 Business \\nFunction Model \\nBusiness \\nData Model \\nApplication \\nInventory \\nFile \\nPgm Cust | Emp | Prod \\nCmaster Cau D R \\nPayroll R Cc, U D \\nPmaster U,D R C,D \\nBonuses R U R \\nMeta Data \\nRepository \\nCrossref \\n+ Business Meta Data \\n* Technical Meta Data \\nFigure 2.9: Enterprise Architecture Components \\nabusing, misusing, or redundantly recreating unique processes or data about \\nbusiness objects, which can lead to losing sight of the cross-organizational picture. \\nA fully documented enterprise architecture includes at least five architectural \\ncomponents (Figure 2.9). The following subsections describe these components. \\nThe Business Function Model \\nThis model depicts the hierarchical decomposition of an organization’s nature of \\nbusiness; it shows what the organization does. This model is instrumental for \\norganizing or reorganizing the structure of an organization into its lines of busi- \\nness. Usually one vertical line of business supports a major business function on \\nthis model. Two examples of such an alignment are the loan-origination division \\nand the loan-servicing division of a mortgage-lending institution. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 103}, page_content='70 Step 2: Enterprise Infrastructure Evaluation \\nThe Business Process Model \\nThis model depicts the processes implemented for the business functions; it shows \\nhow the organization performs its business functions. This model is essential for \\nbusiness process reengineering as well as business process improvement initia- \\ntives, which often result from BI projects. For example, a business process model \\ncould be analyzed to determine whether it is possible to streamline a current \\nbusiness process called loan payment processing because customers have com- \\nplained about the long delays in posting their loan payments while their loans \\ncontinue to accrue interest. \\nThe Business Data Model \\nThis model, which is commonly called the enterprise logical data model or enter- \\nprise information architecture, shows what data is part of the organization’s busi- \\nness activities. This model depicts the following: \\n* Data objects participating in a business activity \\n* Relationships among these objects as they exist in the actual business activities \\n+ Data elements stored about these objects \\n* Business rules governing these objects \\nSince data objects and data elements are all unique, they appear in the real \\nworld only once. Therefore, they are documented in the business data model only \\nonce, regardless of the numbers of physical files and databases used for their stor- \\nage. There is only one business data model for an organization. This model and \\nthe meta data repository are the two most important nontechnical infrastructure \\ncomponents for an evolving BI decision-support environment. \\nThe Application Inventory \\nThe application inventory is an accounting of the physical implementation com- \\nponents of business functions, business processes, and business data (objects as \\nwell as data elements). It shows where the architectural pieces reside in the techni- \\ncal architecture. Application inventory entries include the relationships among \\nthe physical implementation components, such as programs, job streams, data- \\nbases, or files. \\nOrganizations should always identify, catalog, and document their applications \\nas well as the business rules about their business data as part of the development \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 104}, page_content='Enterprise Standards 71 \\nwork on every project—but they seldom do. Such inventories are paramount for \\nperforming impact analysis. Remember the colossal efforts of Y2K impact analy- \\nsis without such an inventory! \\nThe Meta Data Repository \\nAlthough “a picture is worth a thousand words,” business models without words \\nare not worth much. The descriptive details about the models are called meta \\ndata. Business meta data is collected during business analysis, and technical meta \\ndata is collected during design and construction. The two types of meta data are \\nlinked to each other and made available to the business community of the BI \\ndecision-support environment. Meta data is an essential navigation tool. Some \\nexamples of meta data components include the following: \\n* Column name \\n* Column domain (allowable values) \\n* Table name \\n* Program name \\n* Report name \\n* Report description \\n* Data owner \\n* Data definition \\n* Data quality metrics \\nENTERPRISE STANDARDS \\nOrganizations must establish architectural standards for their BI decision-sup- \\nport environments in the same way they set up standards for their Web sites. An \\norganization would never consider building its Web site with a different look and \\nfeel for each Web page. In the same vein, no organization should build a BI deci- \\nsion-support environment in which each BI application had a different look and \\nfeel. Therefore, all BI applications must adhere to the same enterprise standards \\nwithin an organization. Figure 2.10 lists the categories of standards to develop, \\nwhich are briefly described below. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 105}, page_content='72 Step 2: Enterprise Infrastructure Evaluation \\na cae De EE, \\nRe er ee ee \\nye EN Z \\nb. a. \\nEnterprise Standards \\nDevelopment Approach \\n_ Data Naming and Abbreviations \\nMeta Data Capture \\nLogical Data Modeling \\nData Quality \\nTesting \\nReconciliation \\nSecurity \\nService-Level Agreements \\nPolicies and Procedures \\nMUYES hmm \\nWE \\nCF: \\ng Y Ye | \\n4 Mo ERO SYR \\nFigure 2.10: Enterprise Standards \\nDevelopment Approach \\nBusiness Intelligence Roadmap provides a complete list of all the major activities \\nand tasks that are appropriate for BI projects. However, since scope and deliver- \\nables of BI projects can vary widely, not every BI project team has to perform \\nevery single activity in every step. Some BI projects may justifiably skip activities \\nwithin a step, combine activities from different steps into one, or skip entire \\nsteps. However, no BI project should be developed ad hoc. Organizations should \\nhave some guidelines that list the minimum number of activities required (mini- \\nmum work breakdown structure), the mandatory deliverables, sign-off require- \\nments, and workflow dependencies in order to control the project risks. \\nData Naming and Abbreviations \\nData naming and abbreviation standards for BI applications provide consistency \\nand a common look and feel useful for both developers and business people. \\nProven standards can be applied (such as the convention of name compositions \\nusing prime, qualifier or modifier, and class words), or new organization-specific \\nstandards can be created. The data administration group usually has been trained \\nin the various industry-standard naming conventions. \\nAbbreviations are part of naming standards, but they apply only to physical \\nnames (e.g., column names, table names, program names), not to business \\nnames. The organization should publish a standard enterprise-wide abbrevia- \\ntions list that includes industry-specific and organization-specific acronyms. \\nEvery BI project team should use these abbreviations and acronyms. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 106}, page_content='Enterprise Standards 73 \\nMeta Data Capture \\nMeta data is a world unto itself. Large amounts of descriptive information can be \\ncollected about business functions, business processes, business data objects, \\nbusiness data elements, business rules, data quality, and other architectural com- \\nponents. The organization needs standards or guidelines that govern who cap- \\ntures which meta data components and how, when, and where to capture them. \\nThe meta data repository should be set up in such a way that it supports the stan- \\ndards for meta data capture and usage. \\nLogical Data Modeling \\nLogical data modeling is a business analysis technique (not to be confused with \\nlogical database design). Every business activity or business function uses or \\nmanipulates business data in some fashion. A logical data model documents \\nthose logical data relationships irrespective of how the functions or the data are \\nimplemented in the physical databases and applications. \\nProject-specific logical data models should be merged into one cohesive, inte- \\ngrated enterprise logical data model. This activity usually is—and should be— \\nincluded in the job description for the data administration department, which may \\nbe part of the enterprise architecture group. The enterprise logical data model is \\nthe baseline business information architecture into which physical systems (oper- \\national or decision-support, including BI applications) are mapped. The organi- \\nzation should establish standards for creating the project-specific logical data models \\nfor BI projects and for merging the models into the enterprise logical data model. \\nData Quality \\nInformation can be only as good as the raw data on which it is based. Most orga- \\nnizations have a lot of dirty data—too much to cleanse it all. Each organization \\nmust establish guidelines about triaging (categorizing and prioritizing) dirty data \\nfor cleansing. In addition, the organization must create standards that define \\nacceptable quality thresholds and specify how to measure data quality during \\ndatabase loads. Instructions for error handling and suspending dirty data records \\nshould also be part of the standards. \\nTesting \\nTesting standards specify what types of tests should be performed and who should \\nparticipate in the various types of testing. The organization should provide \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 107}, page_content='74 Step 2: Enterprise Infrastructure Evaluation \\nguidelines that describe the types of test cases required at a minimum, how much \\nregression testing to perform, and under what circumstances to regression test. A \\nbrief description of a test plan, perhaps even a template, as well as instructions for \\nhow to organize and manage the various testing activities should be included. \\nReconciliation \\nThe BI decision-support environment will have multiple target databases and \\nmultiple BI applications. Since BI applications are not stand-alone systems, their \\ndevelopment must be coordinated and reconciled to guarantee consistency across \\nthe BI decision-support environment. That includes having one (logical) central \\nstaging area with reconciliation programming for every input-process-output \\nmodule regardless of whether the module is written in native code or produced \\nby an ETL tool. \\nSecurity \\nBI data is derived from operational data. Therefore, security guidelines that apply \\nto the operational data also apply to the BI data. However, if data is summarized \\nand the ability to drill down to the details is not enabled, some of the security fea- \\ntures can be relaxed. But rather than allowing the members of each project team \\nto make up the rules as they please, the data owners should establish security \\nstandards to guide the project teams on what types of security measures are man- \\ndatory for what types of data exposure. These standards should include guide- \\nlines for categorizing security risks. Security risks should be considered for data \\nsensitivity, application security, network security, and security against intrusions, \\nhacks, viruses, and other nuisances on the Web. \\nService-Level Agreements \\nOrganizations function according to explicit or implicit business principles. \\nBusiness principles are explicit if stated in mission or vision statements, implicit if \\nthey are just “understood” by the staff. For example, if an organization rewards \\nproject managers for meeting deadlines even though their applications are full of \\nerrors while it punishes project managers for missing deadlines even though their \\napplications are flawless, the implicit business principle is “speed before quality.” \\nService-level agreements (SLAs) ordinarily support the explicit as well as the \\nimplicit business principles. Therefore, SLA standards should state the business \\nprinciples and outline the minimum acceptable SLA measures to support those \\nprinciples. For example, “All projects must meet a 98 percent data quality threshold \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 108}, page_content='Nontechnical Infrastructure Evaluation Activities 75 \\nfor financial data.” SLA measures can also apply to query response time, timeli- \\nness, availability, and level of ongoing support. \\nPolicies and Procedures \\nStandards and guidelines should also cover the policies and procedures of an \\norganization, such as operating procedures, project change-control procedures, \\nissues management procedures, and dispute resolution procedures. Additional \\ntopics (e.g., communication processes, estimating guidelines, roles and responsi- \\nbilities, standard document format) should also be part of the policies and proce- \\ndures. The purpose of having policies and procedures, along with standards and \\nguidelines, is to help streamline and standardize the BI decision-support envi- \\nronment. In other words, policies, procedures, standards, and guidelines must \\nadd value for the organization as a whole—or they should not exist. \\nNONTECHNICAL INFRASTRUCTURE EVALUATION ACTIVITIES \\nThe nontechnical infrastructure activities need to be performed linearly, as indi- \\ncated in Figure 2.11. The list below briefly describes the activities associated with \\nStep 2, Section B, Nontechnical Infrastructure Evaluation. \\nImprove nontechnical \\ninfrastructure \\no e 4 \\nWrite nontechnical infrastructure \\nassessment report \\nAssess effectiveness of \\nnontechnical infrastructure \\ncomponents \\nFigure 2.11: Nontechnical Infrastructure Evaluation Activities \\n1. Assess the effectiveness of existing nontechnical infrastructure components. \\nThe policies, procedures, guidelines, and standards, which are all part of the \\nnontechnical infrastructure, exist to assist in the coordination and manage- \\nment of the BI decision-support environment. They should not hinder the \\nproject teams or slow them down unnecessarily. Therefore, review the appro- \\npriateness and effectiveness of all nontechnical infrastructure components at \\nthe beginning of each BI project. Expand, reduce, or revise any inadequate \\ncomponents as necessary. \\n- Eliminate unnecessary activities or tasks from the development methodol- \\nogy or add missing activities or tasks. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 109}, page_content='76 Step 2: Enterprise Infrastructure Evaluation \\n* Ensure that naming standards and abbreviations make sense and are com- \\nfortable to the business community. \\n* Review the logical data modeling and meta data strategies, and ensure that \\nthe data administration and meta data administration groups are adequately \\nstaffed. \\n* Refine the organization’s data quality initiative. \\n+ Examine the testing standards, and ensure that a sufficient amount of rec- \\nonciliation is being performed. \\n* Review the guidelines for SLAs and security. \\nTasks within this activity can be performed concurrently. \\n2. Write the nontechnical infrastructure assessment report. \\nSe \\nOnce you have assessed all the components of the existing nontechnical \\ninfrastructure, prepare a report that outlines your findings and gives recom- \\nmendations for improvement. If there are missing nontechnical infrastruc- \\nture components, prioritize which ones to include in the next BI project and \\nwhich ones to defer. \\nImprove the nontechnical infrastructure. \\nIn the project plan, give time estimates for modifying or improving nontech- \\nnical infrastructure components as well as for establishing new components. \\nIf the improvements must be completed prior to starting the BI project, cre- \\nate a separate infrastructure project with a separate team and a separate \\nproject plan. \\nDELIVERABLE RESULTING FROM THESE ACTIVITIES \\n1. Nontechnical infrastructure assessment report \\nThis report should document the deficiencies of the existing nontechnical \\ninfrastructure and should cover the following items: \\n— Standards \\n— Use of a development methodology \\n— Estimating guidelines \\n— Scope management procedure \\n— Issues management procedure \\n— Roles and responsibilities \\n— Security process \\n— Meta data capture and delivery \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 110}, page_content='Roles Involved in These Activities 77 \\n— Process for merging project-specific logical data models into the enterprise \\nlogical data model \\n— Data quality measures and triage process \\n— Testing process \\n— SLAs \\n— Support function \\n— Dispute resolution procedure \\n— Communication process \\nInclude a section for proposed improvements for those selected nontechnical \\ninfrastructure components that will be included in the BI project. \\nROLES INVOLVED IN THESE ACTIVITIES \\n® Bl infrastructure architect \\nIn some organizations, the BI infrastructure architect may have responsibility \\nover the nontechnical architectural components of the BI decision-support \\nenvironment. In other organizations, he or she works closely with the data \\nadministrator, meta data administrator, and data quality analyst. Occasionally \\nthe BI infrastructure architect oversees the activities of the data administrator, \\nmeta data administrator, and data quality analyst. It is up to the organization \\nto select the enterprise architecture reporting structure that is most appropri- \\nate for its organizational culture. \\n@ Data administrator \\nIn many organizations, data administration has the responsibility for most of \\nthe nontechnical infrastructure components, in particular logical data model- \\ning, data quality, naming standards, and meta data. However, since the area of \\nnontechnical infrastructure involves so many disciplines, the traditional data \\nadministration responsibilities should be divided among the data administra- \\ntor, the meta data administrator, the data quality analyst, and sometimes even \\nthe BI infrastructure architect. All of these roles are usually staffed by mem- \\nbers of the enterprise architecture group. \\n@ Data quality analyst \\nThe data quality analyst takes charge of finding and analyzing dirty data in the \\nsource files. Since it is impossible to cleanse all the dirty data, the organization \\nmust establish triaging procedures and prioritization guidelines. The data \\nquality analyst is the steward of those data quality standards. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 111}, page_content='78 Step 2: Enterprise Infrastructure Evaluation \\n® Meta data administrator \\nThe meta data administrator is responsible for the meta data repository. He or \\nshe must create it (or buy and install it), maintain it, and populate it. During \\nthe BI project, the data administrator will provide the business meta data, and \\nthe database administrator and data quality analyst (with the help of the ETL \\nand application lead developers) will provide the technical meta data. The \\nmeta data administrator must then merge all the meta data into the meta data \\nrepository and make it available to IT staff and to the business people. The \\nmeta data administrator should therefore establish the standards related to the \\nmeta data repository activities. \\nRISKS OF NOT PERFORMING STEP 2, SECTION B \\nBusiness intelligence is all about creating an enterprise architecture solution to \\nthe decision-support chaos that exists today. It is a cross-organizational initiative. \\nTherefore, cross-organizational activities are of critical importance. The absence of \\nthose activities will lead to stovepipe development and will add to the “spaghetti \\nchart” more data marts and more stand-alone BI applications that are neither \\nintegrated nor reconciled. As a result, the organization would continue to lose the \\nopportunity to enhance its business decisions and competitive advantages. \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nTechnical Infrastructure Evaluation \\nBischoff, Joyce, and Ted Alexander. Data Warehouse: Practical Advice from the \\nExperts. Upper Saddle River, NJ: Prentice Hall, 1997. \\nDevlin, Barry. Data Warehouse: From Architecture to Implementation. Reading, \\nMA: Addison-Wesley, 1997. \\nInmon, William H. Building the Data Warehouse. New York: John Wiley & Sons, \\n1996. \\nInmon, William H., Claudia Imhoff, and Greg Battas. Building the Operational \\nData Store. New York: John Wiley & Sons, 1996. \\nJarke, Matthias, Maurizio Lenzerini, Yannis Vassiliou, and Panos Vassiliadis. Fun- \\ndamentals of Data Warehouses. New York: Springer, 2000. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 112}, page_content=\"Bibliography and Additional Reading 79 \\nKelly, Sean. Data Warehousing: The Route to Mass Customization. New York: John \\nWiley & Sons, 1996. \\nKimball, Ralph, and Richard Merz. The Data Webhouse Toolkit: Building the Web- \\nEnabled Data Warehouse. New York: John Wiley & Sons, 2000. \\nLinthicum, David S. Enterprise Application Integration. Boston, MA: Addison- \\nWesley, 2000. \\nMoeller, R. A. Distributed Data Warehousing Using Web Technology: How to Build \\na More Cost-effective and Flexible Warehouse. New York: AMACOM American \\nManagement Association, 2001. \\nNontechnical Infrastructure Evaluation \\nAdelman, Sid, and Larissa Terpeluk Moss. Data Warehouse Project Management. \\nBoston, MA: Addison-Wesley, 2000. \\nBrackett, Michael H. Data Resource Quality: Turning Bad Habits into Good Prac- \\ntices. Boston, MA: Addison-Wesley, 2000. \\n. The Data Warehouse Challenge: Taming Data Chaos. New York: John \\nWiley & Sons, 1996. \\nBruce, Thomas A. Designing Quality Databases with IDEF1X Information Models. \\nNew York: Dorset House, 1992. \\nEnglish, Larry P. Improving Data Warehouse and Business Information Quality: \\nMethods for Reducing Costs and Increasing Profits. New York: John Wiley & Sons, \\n1990. \\nHoberman, Steve. Data Modeler's Workbench: Tools and Techniques for Analysis \\nand Design. New York: John Wiley & Sons, 2001. \\nInmon, William H. Building the Data Warehouse. New York: John Wiley & Sons, \\n1996. \\nInmon, William H., Claudia Imhoff, and Greg Battas. Building the Operational \\nData Store. New York: John Wiley & Sons, 1996. \\nInmon, William H., Claudia Imhoff, and Ryan Sousa. Corporate Information Fac- \\ntory. New York: John Wiley & Sons, 1997. \\nInmon, William H., John A. Zachman, and Jonathon G. Geiger. Data Stores, Data \\nWarehousing and the Zachman Framework: Managing Enterprise Knowledge. New \\nYork: McGraw-Hill, 1997. \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 113}, page_content='80 Step 2: Enterprise Infrastructure Evaluation \\nKuan-Tsae, Huang, Yang W. Lee, and Richard Y. Wang. Quality Information and \\nKnowledge Management. Upper Saddle River, NJ: Prentice Hall, 1998. \\nReingruber, Michael C., and William W. Gregory. The Data Modeling Handbook: \\nA Best-Practice Approach to Building Quality Data Models. New York: John Wiley \\n& Sons, 1994. \\nRoss, Ronald G. Business Rule Concepts. Houston, TX: Business Rule Solutions, \\n1998. \\nSimsion, Graeme. Data Modeling Essentials: Analysis, Design, and Innovation. \\nBoston, MA: International Thomson Computer Press, 1994. \\nZachman, John. The Zachman Framework: A Primer for Enterprise Engineering \\nand Manufacturing. La Canada, CA: Zachman International, 2002. \\nZachman Institute for Framework Advancement: http://www.zifa.com \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 114}, page_content='Justification ula CHAPTER THREE \\nStep 3: Project Planning \\nCHAPTER OVERVIEW \\nThis chapter covers the following topics: \\n@ Things to consider about project planning \\n@ Managing the BI project and planning for setbacks \\nData Societien sy m Items to address when creating a project charter, such as \\nbh Analysis 2). Prototyping 4  Repc goals and objectives, scope issues, project risks, constraints, \\nree assumptions, change control, and issues management \\n@ Aspects of project planning, with a focus on activities and \\nDesign ie ius tasks, estimating techniques, resource assignment, task \\nand resource dependencies, critical path determination, \\nand creation of the final project schedule \\nm Brief descriptions of the project planning activities, the \\n. deliverables resulting from those activities, and the roles \\n= involved \\n| / @ The risks of not performing Step 3 \\nConstruction \\n~ \\n81 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 115}, page_content='82 Step 3: Project Planning \\nTHINGS TO CONSIDER \\nBusiness Involvement \\nY Do we have a strong business sponsor? Do we have a backup business sponsor? \\nY Do we have stakeholders with whom we need to communicate regularly? \\n/Y How much time is the business representative committing to this project? Is \\nhe or she assigned to this project full-time, or will he or she be available on \\nrequest only? \\nProject Scope and Deliverables \\nVv Did we receive a formal request for a BI project? \\nVY How detailed are the requirements? \\nv¥ What are the requested deliverables? \\nY Can we implement the requested scope given the schedule and the available \\nresources? \\nCost-Benefit Analysis \\nVv Have we already performed a cost-benefit analysis? \\n¥ What is the expected return on investment (ROI)? \\nY How soon do we expect the ROI to materialize? \\nInfrastructure \\nV Did we review our technical and nontechnical infrastructure components? \\nY Does our infrastructure have any gaps? \\n¥ Which infrastructure components will we need to work on and deliver as \\npart of the BI project? \\n—Which technical infrastructure components? \\n—Which nontechnical infrastructure components? \\nStaffing and Skills \\nV Have we already identified the team members? \\n¥ Do all team members have the skills needed to perform the responsibilities \\nof their assigned roles? \\n¥ Should we schedule any training before the project kickoff? \\nV Is the project manager assigned to this project full-time? Or does he or she \\nhave other administrative responsibilities? If the latter, who will take over \\nthose other responsibilities for the duration of this project? \\nee \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 116}, page_content='Managing the BI Project 83 \\nBI projects are not like other projects with a finite and static set of require- \\nments from one business person or one department. Instead, the purpose of an \\nintegrated BI decision-support environment is to provide cross-organizational \\nbusiness analysis capabilities to all business people and all departments in the \\norganization. That involves a variety of new tasks, shifted roles and responsibili- \\nties, and a more hands-on project management approach. \\nMANAGING THE BI PROJECT \\nProject management in most organizations is treated as an administrative report- \\ning function. Detailed project planning and hands-on daily project control are \\noften minimized, if not ignored, especially when organizations try to get several \\nBI applications up and running very quickly. In their shortsightedness, organiza- \\ntions forget that extended planning activities often lead to shorter testing and \\nimplementation cycles and thus a shorter delivery time—exactly what the busi- \\nness community wants. \\nNo BI project gets off the ground without a few “kinks and bends”; delays are \\ncommon. For example, some products may not have enough capacity; others \\nmay not work well in a distributed environment. Switching vendors and products \\ncan prove costly in terms of time and money. Vendors often cannot offer the \\ncomprehensive solutions that businesses expect because the vendors are still \\nstruggling to integrate all the pieces of their BI products. This leaves integration \\nup to the organizations’ information technology (IT) staffs. \\nMany organizations do not adequately plan for these types of delays and set- \\nbacks, nor do they test their BI concepts and strategies adequately. Setbacks are \\ninevitable on a project as resource intensive as a BI application—even under the \\nbest of circumstances. Planning for setbacks will help management set realistic \\nrollout dates for the project. \\nDescribing project management activities in the most simplistic terms, the \\ngoal is to answer four basic questions. \\n1. What will be delivered? \\n2. When will it be done? \\n3. How much will it cost? \\n4. Who will do it? \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 117}, page_content='84 Step 3: Project Planning \\nFigure 3.1: Project Constraints \\nThese questions translate, respectively, into the four major project con- \\nstraints of scope, effort (time), budget, and resources (Figure 3.1). Before the \\nproject manager can create a project plan to address these constraints, he or she \\nmust spend some time defining the project to clearly understand the related \\nrequirements, risks, constraints, and assumptions. \\nDEFINING THE BI PROJECT \\nProject planning includes creating a project charter, which defines the project in \\nterms of: \\n* Goals and objectives \\n* Scope (the expected project deliverable) \\n* Risks \\n* Constraints \\n- Assumptions \\n* Change-control procedures \\n* Issues management procedures \\nThe project charter is the agreement made between the business sponsor and \\nthe IT staff for developing the BI application. If any component of the project \\ncharter changes, the entire project has to be reevaluated and all project con- \\nstraints have to be renegotiated. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 118}, page_content='Defining the BI Project 85 \\nProject Goals and Objectives \\nWhen defining a BI project, first address the goals and objectives. What is the rea- \\nson for building this BI application? How much business pain (in hard currency) \\ndoes that business problem, which the BI application is supposed to solve, cur- \\nrently cause? What are the strategic business drivers? Do the BI project objectives \\nfall in line with the strategic business objectives, or is this someone’s pet project? \\nProject objectives should be measurable statements, such as, “In order to \\nincrease market share by 10 percent next year, the sales department must have \\naccess to month-end sales data as well as pipeline data merged with prospect data \\nwithin five business days after the close of the weekly accounting cycle.” Project \\nobjectives must tie in with the expected ROI. The business representative will \\nhave to measure the effectiveness of the delivered BI application and report to the \\nbusiness sponsor whether the project was successful or not. \\nProject Scope \\nIt is impossible to create valid estimates for a project without a solid understand- \\ning of the scope. Traditionally, scope has been measured by the number of func- \\ntions the system will perform (function point analysis). On BI projects that is a \\nsure way to underestimate effort, budget, and resources. BI applications are data- \\nintensive, not function-intensive. Therefore, scope must be measured by the \\nnumber of data elements that have to be extracted from the source systems, trans- \\nformed and cleansed, and loaded into the BI target databases. \\nThe main reason for concentrating on data rather than functions is that ana- \\nlyzing and preparing source data takes much longer than providing data access \\nand enabling data analysis through reports and queries. The typical 80/20 rule \\nusually applies: 80 percent effort for data and 20 percent effort for functionality. \\nProject Risks \\nEvery project is subject to some risks—risks are unavoidable. Such risks could \\nseverely affect the project schedule as well as the project deliverables, depending \\non the likelihood that the risks will materialize and on the impact they would \\nhave on the project. Therefore, the risk assessment performed during Step 1, \\nBusiness Case Assessment, must be reviewed and expanded if necessary. The \\nproject manager must identify triggers for each risk and incorporate a mitigation \\nplan as well as a contingency plan into the project plan. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 119}, page_content=\"86 Step 3: Project Planning \\nTriggers are situations that signal a potential, perhaps imminent materializa- \\ntion of a risk. For example, if management is reviewing the budget for the \\nproject for no apparent reason, this indicates a possible trigger for the risk of \\nlosing management support for your BI project. \\nThe mitigation plan specifies what actions the project team can take to pre- \\nvent the risk from materializing. Continuing with the example above, you \\ncould solicit support from your business sponsor and promote the BI initia- \\ntive to other key executives in your organization to keep management's inter- \\nest in the BI project. Should the project run into trouble, the risk of having it \\ncancelled is mitigated or prevented. \\nThe contingency plan specifies alternatives in case the risk does materialize. \\nFor example, if you lose management support for the BI project due to a long \\nproject schedule, plan to shorten the release cycles by delivering a smaller \\nscope sooner. If you lose management support due to the business sponsor’s \\ndeparture from the organization, have an alternate sponsor ready to become \\nthe champion for the BI project. \\nSome common project risks include the following: \\nLack of management commitment \\nLost sponsor \\nLack of business participation \\nImposed, unrealistic schedule \\nUnrealistic scope for the schedule \\nUnrealistic expectations \\nUnrealistic budget \\nUntrained or unavailable staff \\nConstantly changing business priorities \\nIneffective project management \\nLimited scalability \\nProject Constraints \\nAll projects are subject to the same project constraints mentioned earlier: scope, \\neffort (time), budget, and resources (capable and available people). In reality, \\nthere is a fifth constraint: quality. Although quality is a measure of how well the \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 120}, page_content='Defining the BI Project 87 \\ndeliverables meet the requirements, it can also be considered a constraint that \\nmust be balanced with the other four constraints. \\nWhile everyone on the business side and in the IT department wants quality, \\nrarely is the extra time given or taken to achieve it because quality and effort are \\npolarized constraints. Higher quality requires more effort and thus more time to \\ndeliver. Since time factors drive most organizations, effort is their number one \\nconstraint (highest priority), followed by scope, budget, and resources (usually in \\nthat order); and quality gets pushed to the bottom of the heap (lowest priority), \\nas illustrated in Table 3.1. BI project constraints should never be in this order. \\nFortunately, organizations have full control over changing the priority of \\nproject constraints. To insist that time and scope be the top two constraints is \\nacceptable only on projects that have requirements connected to government- \\nimposed regulations. But in most of those cases, the operational systems (and \\noperational reports) are the ones affected by government-imposed deadlines, \\nrarely the downstream strategic decision-support applications. We strongly \\nadvise you to get quality out from the bottom of the heap and put scope there \\nbecause scope can and will continually be expanded through future BI applica- \\ntion releases. Table 3.2 shows our recommended order of project constraints. \\nAssumptions \\nAn assumption is anything taken for granted; it is a supposition or a presump- \\ntion. It is important to document assumptions because a wrong assumption \\ncould very quickly turn into a risk. Here is an example of how two assumptions \\non a project backfired. \\nTable 3.1: Typical Order of Project Constraints \\nPriority (Highest to Lowest) \\nConstraint 1 2 3 4 5 \\nEffort (time) Uf \\nScope v \\nBudget J \\nResources J \\nQuality J \\n| SS SSS SB EE ES ET I \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 121}, page_content='88 Step 3: Project Planning \\na SN ASS EE EE SE RS ST \\nTable 3.2: Recommended Order of Project Constraints \\nPriority (Highest to Lowest) \\nConstraint 1 2) 3 4 5 \\nQuality v \\nBudget v \\nResources J \\nEffort (time) vo \\nScope J \\nAssumption 1: “The vendor promises to deliver a new database server in May, \\nand by the end of June the IT staff will install and test a new database man- \\nagement system (DBMS) product on that server. This allows plenty of time \\nbefore the project deadline, which is September 30, the fiscal year-end.” \\nAssumption 2: “Joe Bamberg will be the database administrator on the \\nproject because he is the only person in our organization who has that partic- \\nular DBMS uh which is needed for the project. He has already joined the \\nproject team.” \\nProblems: On June 20 (one month late) the new server finally arrives, and on \\nJuly 1 Joe Bamberg quits the organization. The new DBMS product does not \\nget installed and tested on the new server until the end of September. \\nImpact: The project is delayed by three months at a budget overrun of \\n$60,000 (much of it paid as consulting fees for the high-priced consultant \\nwho had to fill in for Joe Bamberg). \\nImportant assumptions should have counterpart risks, in case the assumptions \\neither turn out to be false or do not materialize, as in the example above. For each \\ncounterpart risk, identify triggers, a mitigation plan, and a contingency plan. \\nChange-Control Procedures \\nTraditional waterfall methodologies became so popular in part because the \\nsigned-off, phased development approach attempted to curb scope creep. The \\nmental model was “Change is bad—business people must be held to their deci- \\nsions.” Since BI applications are supposed to be catalysts for improved decision \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 122}, page_content='Defining the BI Project 89 \\nmaking, the mental model must change to “Change is good—business people \\nshould refine and improve their decisions.” However, uncontrolled change can \\nstill kill a project. \\nThe solution is to manage the changes. Many organizations track their \\nchange requests by logging the date of the change request, the name of the \\nrequestor, the desired change, to whom it was assigned, and when it was imple- \\nmented. That is a good practice, but tracking changes is not the same thing as \\nmanaging them. \\nTo manage a change, you need to start with a baseline—the agreement \\nbetween the business sponsor and the IT staff, as documented in the project char- \\nter. Every change request, once logged, undergoes an impact analysis and a cost- \\nbenefit analysis to determine the effects of the change on the project. Changes, \\nunless they are minute, always impact the three constraints of effort (time), \\nscope, and quality. Some changes also impact the other two constraints (budget \\nand resources). When one constraint changes, the remaining constraints will \\nhave to be renegotiated. Unfortunately, business managers and IT managers fre- \\nquently put the project teams under unwarranted pressure to incorporate scope \\nchanges without slipping the schedule. \\nPaw It is not rational to request a significant scope change to a carefully deliberated \\nand agreed-upon project plan without adjusting any of the other constraints. \\nIt is not rational because the business representative, the project manager, \\nand the core team members who developed the plan together believed they could \\ncomplete the project under the agreed-upon constraints. When the scope con- \\nstraint changes, the plan is no longer doable without changes to some of the \\nother constraints, namely effort (time), budget, resources, and quality, to absorb \\nthe impact of the scope change. Therefore, depending on how critical the change \\nrequest is, the business representative has to decide whether to: \\n* Cut back from the current scope by eliminating some of the originally \\nrequested data and functionality \\n+ Extend the deadline \\n* Declare the requested change unfeasible at this time and postpone it \\n- Incorporate the requested change in the next release \\n- Eliminate complicated transformations, edit checking, and testing, which \\nwill impact the quality of the deliverable \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 123}, page_content='90 Step 3: Project Planning \\nIssues Management Procedures \\nIssues, whether related to business or technical concerns, always come up during \\nprojects. Similar to change requests, issues must be not only tracked but also \\nmanaged. Every issue must be assigned to a person who has the responsibility for \\nits resolution. Any activity regarding the issue must be dated and described on \\nthe issues log. At the end of the project, all issues must have a resolution, even if \\nthat resolution is a deferral of the issue to a future BI release. Table 3.3 shows an \\nexample of an issues log. \\nSome issues are minor and can be resolved without impact on the project. \\nOther issues can turn into risks or change requests and have to be dealt with \\naccordingly. Therefore, managing issues includes impact analysis and change \\ncontrol. \\nPLANNING THE BI PROJECT \\nProject planning is not a one-time activity. Since a project plan is based on esti- \\nmates, which are frequently no more than best guesses, project plans must be \\nadjusted constantly. The number one telltale sign that a project is not being man- \\naged is a static project plan on which estimates and milestones have never \\nchanged from the day they were first developed. \\nHere is the sequence of activities for preparing a project plan. \\n. Create a work breakdown structure listing activities, tasks, and subtasks. \\n. Estimate the effort hours for these activities, tasks, and subtasks. \\n. Assign resources to the activities, tasks, and subtasks. \\n. Determine the task dependencies. \\n. Determine the resource dependencies. \\n. Determine the critical path based on the dependencies. \\nN DB Oo & WO NH . Create the detailed project plan. \\nActivities and Tasks \\nBI projects are composed of many activities, each with a long checklist of tasks. \\nRegardless of how experienced the project manager is, it is impossible for any \\nperson to remember all the tasks that need to be performed on a BI project. At a \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 124}, page_content='91 Planning the BI Project \\n—_———————————————————————— \\n€00Z \\n‘QIGLIIEAR \\nSI \\nJAAJaS \\n‘pied \\n/1Z/8 \\nUOY \\nWO} \\n[JE \\nPIAladoy \\n\"Y9OM \\n3X9U \\ndIqeIIEAe \\n3q \\n0} \\npayadxq \\n€00Z \\n‘pajse} \\nSuleqg \\npuke \\npajje}sul \\n/VL/8 \\nS| \\nJBMJ9S \\n“pied] \\nUOY \\npajjey \\n\"Y89M \\n9UO \\nul \\nSl \\na}ep \\nAUaAtjag \\nualjddns \\nJOYJOUL \\nWO \\nJaAlas \\ne 1aB \\n€00Z \\n0} \\n9/ge \\naq \\n|[IM \\n9H \\n‘ples \\n/LE/L \\nUOY \\nWO \\n[Jed \\npaAladoy \\n\"yoom \\n“dIOW \\nJO \\nUJUOW \\n‘(1osuods) \\nduo \\nU! \\ndn-mojjo4 \\n“aijddns \\n9UO \\naq \\nP[NOD \\nsul|peap \\nyoelg \\nWeqoy \\nAq \\npaidadze \\nJOYJOUL \\nO} \\nYDUMS \\n0} \\najqe \\npefoid \\nuo \\npeduy \\nAejaq \\n‘syaam \\n3aiu} \\nAjUO \\naq \\nAew \\ndH \\n‘sanieusaye \\n‘Jaijddns \\nyyM \\nwajqoldg \\n€007Z \\n‘ajnpaups \\npefoid \\nau} \\n0} \\n€00Z \\nssndsIp \\n0} \\nWOddns \\n‘yda} \\n‘paidedxa \\nuole]]e}sul \\n€00Z \\n/1Z/8 \\nAejaq \\n‘siatiddns \\npaysyms \\n/VC/L \\nWOJ} \\nP1ed] \\nUOY \\nYUM \\nJol \\nIa \\nJamas \\njo \\nAejaq \\nJEC/L \\nLOO \\najDq \\nuoHnjosay \\najpqd \\nuayb, \\nuoRDYy \\nOL \\nuondisaq \\nanss] \\najpq \\n‘ON \\nuonoy \\npaubissy \\nanssj \\nanss| \\npasoj[) \\nCCL \\nes \\n307 \\nSanss| \\n:€°€ \\najqel \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 125}, page_content='92 Step 3: Project Planning \\nminimum, the project manager must rely on some existing comprehensive list of \\nthe most necessary activities. Naturally, not all activities have to be performed on \\nevery project. Not even every step has to be performed on every project. The \\nproject manager selects the minimum number of steps and activities needed to \\nproduce an acceptable deliverable under the imposed constraints. \\nThe development approach in Business Intelligence Roadmap is neither as lin- \\near nor as rigorous as that followed in traditional methodologies. It is a much \\nmore dynamic approach to application development. When using our develop- \\nment approach, it may often look and feel like you are working on a prototype— \\nbut it is not a prototype. The same discipline applied under a traditional method- \\nology must be applied to BI projects in terms of controlling scope, mitigating \\nrisks, and time-boxing weekly activities. (Time-boxing refers to planning, assign- \\ning, and managing activities on a detailed level in weekly increments.) Despite the \\ndiscipline, you must expect constant rework during the development cycle and build \\ntime for it into the project plan. For example, analysis activities can show up on your \\nproject plan as early as Step 3, Project Planning, and as late as Step 12, Applica- \\ntion Development. Or you may want to plan another short iteration through \\ndatabase design activities during Step 11: Extract/Transform/Load Development. \\nThe project plan must reflect this dynamic nature of application development. \\nSince changes and setbacks are to be expected, certain “completed activities” will \\nhave to be revisited and reworked. The project plan should anticipate that and \\nreflect it on the schedule. The easiest way to plan for these internal iterations is to \\nuse the concept of “looping” or “refactoring” by dividing the project into multiple \\nsmall subprojects, each with a deliverable, albeit not completed. Then revisit and \\nrevise each deliverable, adding more data and more functionality until the entire \\nBI application is completed with the desired deliverable. This iterative refinement \\napproach gives the project development effort the feeling of prototyping. \\nEstimating Techniques \\nOnce you have selected the activities and tasks for the project and organized the \\nproject into subprojects, you can derive the base estimates by using one of three \\nmethods: \\n1. Historical, based on learned patterns (how long it took on the last project) \\n2. Intuitive, based on intuition and experience (“gut” estimating) \\n3. Formulaic, based on the average of possibilities (Figure 3.2) \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 126}, page_content='Planning the BI Project 93 \\nBest Estimate + (4 x Average Estimate) + Worst Estimate \\n6 \\nFigure 3.2: Formula-Based Estimating \\nEstimating BI project activities is much more difficult than estimating tradi- \\ntional projects because no two BI projects are alike. For example, you may use a \\nnew tool, work with new team members, or have no experience with a new \\ndesign method. All three estimating techniques listed above expect you to relate \\nto some prior project experience. \\n- The historical estimating technique expects you to have statistics on how long \\nsimilar projects took in the past—but you may not have had a similar project \\nbefore. \\nThe intuitive estimating technique expects you to predict, or guess, based on \\nprior experience how long it will take to complete a similar activity—but you \\nmay have never performed a similar activity. \\nThe formula-based estimating technique expects you to know the longest \\ntime it may take to complete an activity, the shortest time, and the most \\nprobable time—but you would not know what the longest, shortest, and \\nmost probable times for an activity could be if you had never performed that \\nactivity before. \\nIn all those cases, it is best to consult with other people (in-house staff or out- \\nside consultants) who have already developed a similar BI application because \\nyour own uneducated guesses may be gross underestimates. This also demon- \\nstrates how important it is to track actual time on BI projects. You will need that \\ninformation for estimating your next BI project. \\nResource Assignment \\nEffort estimates cannot be completed until the activities and tasks are assigned \\nbecause the estimates must take into consideration each team member’s skills \\nand subject matter expertise as well as the environmental factors that affect him \\nor her. \\n* Skills—the ability to perform specific tasks. Has the team member done this \\ntype of work before? \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 127}, page_content='94 Step 3: Project Planning \\nTE SRS ETL RP EE DL CS I IS EE ED, \\nTable 3.4: Environmental Factors That Can Affect Team Members’ Availability \\nAdministrative Factors Non-Work-Related Factors \\nLack of computer access Vacation \\nTime required to troubleshoot other Illness \\nsystems Jury duty \\nMeetings Personal time off \\nE-mails and in-baskets Medical appointments \\nTraining seminars Religious holidays \\n* Subject matter expertise—the possession of facts or concepts about a specific \\nsubject matter. Is the team member an expert in this business area? \\n* Environmental factors—administrative and non-work-related activities. Table \\n3.4 lists some examples. \\nTask Dependencies \\nNot all activities and tasks have to be performed serially—many can be per- \\nformed in parallel as long as there is sufficient staff. The first step in determining \\nwhich tasks can be performed in parallel is to identify task dependencies and \\ndevelop the critical path. Most project-planning tools support the four types of \\ntask dependencies (Figure 3.3). Finish to Start and Start to Start are the most \\ncommon task dependencies; Start to Finish is the most infrequent. \\nFinish to Start Start to Start \\nFinish to Finish Start to Finish \\nFigure 3.3: Task Dependencies \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 128}, page_content='Planning the BI Project 95 \\n1. Finish to Start indicates that Task 2 cannot start until Task 1 finishes. \\n2. Start to Start indicates that Task 2 can start at the same time as Task 1. \\n3. Finish to Finish indicates that Task 2 cannot finish until Task 1 finishes. \\n4. Start to Finish indicates that Task 2 cannot finish until Task 1 starts. \\nThe more tasks that can be performed simultaneously, the faster the project \\nwill get done. To take advantage of task dependencies, you need the right number \\nof resources with the right skills at the right time. \\nResource Dependencies \\nA shortage of staff can quickly reverse the benefits of having few task dependen- \\ncies. For example, tasks that could have been performed in parallel but cannot be \\nassigned to multiple staff members because of a staff shortage must revert to \\nbeing executed in sequence. Figure 3.4 shows how four tasks can be accomplished \\nin 10 days with adequate staffing; Figure 3.5 shows that it will take 14 days to \\ncomplete the same tasks if only one person is available to work on them. (Note \\nthat in Figure 3.5 the time required to compile the findings is reduced by one day \\nbecause there is no longer a need for two analysts to collaborate.) \\nCritical Path Method \\nOnce you have identified the task dependencies and leveled the resources (that is, \\nassigned the tasks and adjusted the dependencies for the available resources), use \\nConduct \\ninterviews \\n5 days \\nAnalyze \\nfiles \\n5 days \\nWrite \\nreport \\n3 days \\nCompile \\nfindings \\n2 days \\nFigure 3.4: Elapsed Days When Two People Can Work on the Tasks \\nConduct Analyze Compile Write \\ninterviews files findings report \\n5 days | 5 days 1 day 3 days \\nResource dependency \\nFigure 3.5: Elapsed Days When Only One Person Is Available \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 129}, page_content='96 Step 3: Project Planning \\nDetermine problem Analyze cost-benefit Determine critical \\nor opportunity of new project success factors Project Approval \\nIdentify resources Pa o \\navailable a Critical Path \\nFigure 3.6: Critical Path Method \\nthe critical path method (CPM) to outline task duration, indicating any lag time \\nfor tasks not on the critical path (Figure 3.6). This provides the visibility needed \\nto reassign resources or to renegotiate project constraints. \\nIn this example, the task “Identify resources available” can be performed in \\nparallel with the tasks “Analyze cost-benefit of new project” and “Determine crit- \\nical success factors.” Since the task “Identify resources available” is estimated to \\ntake 4 days, and the other two tasks combined are estimated to take only 3 days, \\nthe task “Identify resources available” is on the critical path. If this task were to \\ntake 5 days to complete instead of 4, it would delay the milestone “Project \\napproval” by one day. However, if either of the other two tasks were delayed by \\none day, it would not affect the milestone “Project approval.” \\nProject Schedules \\nOnce you have determined all the tasks, resources, dependencies, and estimates, \\nyou can schedule the project on the calendar. The most common and most famil- \\niar representation of a project schedule is a Gantt chart. Figure 3.7 shows an example. \\nCreating a useful project plan requires some effort, but maintaining the \\nproject plan (adjusting it) is not as labor intensive as it used to be prior to the \\navailability of project management tools. Becoming proficient on a sophisticated \\nproject management tool takes some time and requires a solid understanding of \\nproject management principles. \\nOnce you key into the tool all the planning components (e.g., tasks, esti- \\nmates, resources, dependencies), any adjustments you subsequently make to the \\ncomponents automatically cascade through the entire project plan, updating all \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 130}, page_content='97 Planning the BI Project \\nWey) \\nHuey \\ne jo \\najdwexq \\n:7’¢ \\naun3i4 \\nBysm \\nII1g \\nHusn7 \\n|W!g \\nBysnq \\nie \\n| \\nHysn7 \\nIg \\nBasnq \\nm8 \\n| \\n6ysn7 \\n|IW!g \\nHysn7 \\n|I1g \\n‘ejuny \\nxejy \\nYadoog \\nwoy \\nSIN \\nxoly \\njadooa \\ncea \\nAuaems \\nauer \\n| \\nJadoog \\nwo, \\n‘6ysn7 \\njII1g \\n4o}e}) \\ne \\n| \\nAuaems \\neuer \\nKuaems \\nauer \\n| \\n[e \\na \\nAugams \\nauer \\na i —-. \\nAuaams \\nauer \\n| \\nJedoog \\nwo, \\n| \\n6ysn7 \\nja \\nJove \\nUIE \\n| \\nSIUNL \\nXaly \\n3jUNL \\nray \\n| \\nBsn II \\nlee \\nLelé \\nSMAINBY \\nSSAIHO1g \\nUl \\nYOM 9/€ \\nuonejuaseid \\naninoexe \\naAI5 \\nyodai \\n|Buy \\nJaAlaq \\nyodai \\njeuy \\nasinay \\nyoda \\njeuy \\nmainay \\nyodai \\njeuy \\naredaiy \\nuejd \\nyoaloud \\nasedaig \\n| \\nSuojepuawwooes \\nSsnosiq \\nHuljeew \\nUOISsIA \\njONpUOD \\n| \\nsyJewyoueg \\nezAjeuy \\nsOulpuy \\nayepien \\nsBulpuy \\nayepyjosuoD \\nsuolsses \\ndnoib \\nayey!oe4 \\nSMAIAJAYUI \\nJONPUOD \\nSMAIAJOJU! \\nB|NDAYOS \\nS891NOS \\nJDB}aS \\nsajyoud \\nBuimaiasayul \\nay \\nseBeyoed \\nuoiejualo \\n1aAaq \\nsebeyoed \\nuolejuat0 \\ndojaneq \\nuoeyioey \\nuoleziueBio \\njonpuoD \\nJeueyew \\nezAjeuy \\njeuayew \\nJayaq \\n| \\nseireuuolsenb \\ndojaneq \\n| \\n7 \\nSSOYNOS3AY \\nAieniqe4 \\n002 \\nALIAILOV \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 131}, page_content='98 Step 3: Project Planning \\ncharts and reports. Although the results must still be reviewed and validated, an \\nexperienced project manager who is skilled on the project management tool does \\nnot need to become a slave to the tool or to the project planning activities. \\nPROJECT PLANNING ACTIVITIES \\nThe project planning activities do not need to be performed linearly. Figure 3.8 \\nindicates which activities can be performed concurrently. The list below briefly \\ndescribes the activities associated with Step 3, Project Planning. \\nDetermine project \\nrequirements \\nDetermine condition of \\nsource files and databases \\nRevise risk \\nassessment \\nDetermine or revise \\ncost estimates \\nSy) \\nIdentify critical \\nsuccess factors \\nCreate high-level \\nproject plan \\nPrepare \\nproject charter \\nKick off \\nproject \\nFigure 3.8: Project Planning Activities \\n1. Determine the project requirements. \\nYou may have already prepared the objectives for the project and some high- \\nlevel requirements for the proposed scope during Step 1, Business Case Assess- \\nment. However, most likely they are not of sufficient detail to start the planning \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 132}, page_content=\"Project Planning Activities 99 \\n= \\noy \\nprocess. As part of the scope definition, review and revise the following \\nrequirements: data, functionality (reports and queries), and infrastructure \\n(technical and nontechnical). \\n. Determine the condition of the source files and databases. \\nYou can neither complete the project schedule nor commit to a delivery date \\nwithout a good understanding of the condition of the source files and data- \\nbases. Take some time to review the data content of these operational files \\nand databases. Although you will perform detailed source data analysis dur- \\ning Step 5, Data Analysis, right now you need to glean just enough informa- \\ntion to make an educated guess about the effort needed for data cleansing. \\nDetermine or revise the cost estimates. \\nDetailed cost estimates must include hardware and network costs as well as \\npurchase prices and annual maintenance fees for tools. In addition, you must \\nascertain the costs for contractors, consultants, and training. A more indirect \\ncost is associated with the learning curve for the business and IT staff members. \\nRemember to factor that into the cost estimates as well as the time estimates. \\n. Revise the risk assessment. \\nReview and revise the risk assessment performed during Step 1, Business \\nCase Assessment (or perform a risk assessment now if you skipped that step). \\nRank each risk on a scale of 1 to 5 according to the severity of its impact on \\nthe BI project, with 1 indicating low impact and 5 indicating high impact. \\nSimilarly, rank the likelihood of each risk materializing, with 1 being “proba- \\nbly won't happen” and 5 being “we can almost count on it.” \\n. Identify critical success factors. \\nA critical success factor is a condition that must exist for the project to have a \\nhigh chance for success. Some common critical success factors are a proactive \\nand very supportive business sponsor, full-time involvement of a business \\nrepresentative, realistic budgets and schedules, realistic expectations, and a \\ncore team with the right skill set. \\nPrepare the project charter. \\nThe project charter is similar to a scope agreement, a document of under- \\nstanding, or a statement of work. However, the project charter is much more \\ndetailed than the usual 3- to 4-page general overview of the project that con- \\ntains only a brief description of resources, costs, and schedule. The project \\ncharter is a 20- to 30-page document developed by the core team, which \\nincludes the business representative. Present the project charter and the \\nproject plan to the business sponsor for approval. \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 133}, page_content='100 Step 3: Project Planning \\nig Create a high-level project plan. \\nProject plans are usually presented in the form of a Gantt chart that shows \\nactivities, tasks, resources, dependencies, and effort mapped out on a calen- \\ndar (Figure 3.7). Some project managers also create Pert charts, which show \\nthe graphic representation of the CPM on the calendar. \\n. Kick off the project. \\nOnce you have planned the project, assigned the resources, and scheduled the \\ntraining, you are ready to kick off the project. This is usually accomplished \\nwith an orientation meeting for the entire team (the core team members as \\nwell as the extended team members). Project kickoff should also include set- \\nting up communication channels (e.g., newsletters, e-mails, Web pages) with \\nthe rest of the organization to keep stakeholders and interested parties up-to- \\ndate on the project’s progress. \\nDELIVERABLES RESULTING FROM THESE ACTIVITIES \\n1. Project charter \\nThis document represents the agreement between the IT staff and the busi- \\nness sponsor about the definition, scope, constraints, and schedule of the BI \\nproject. It also serves as the baseline for all change requests. A project charter \\ncontains the following sections: \\n— Goals and objectives (both strategic goals for the organization and specific \\nobjectives for the BI project) \\n— Statement of the business problem \\n— Proposed BI solution \\n— Results from the cost-benefit analysis \\n— Results from the infrastructure gap analysis (technical and nontechnical) \\n— Functional project deliverables (reports, queries, Web portal) \\n— Historical requirements (how many years of history to store) \\n— Subject area to be delivered \\n— Entities (objects), significant attributes, relationships (high-level logical data \\nmodel) \\n—Items not within the project scope (originally requested but subsequently \\nexcluded from the scope) \\n— Condition of source files and databases \\n— Availability and security requirements \\n— Access tool requirements \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 134}, page_content='Rol es Involved in These Activities 101 \\n~ \\n— Roles and responsibilities \\n— Team structure for core team and extended team members \\n— Communication plan \\n— Assumptions \\n— Constraints \\n— Risk assessment \\n— Critical success factors \\nProject plan \\nA project plan may contain multiple graphs (such as a CPM chart, a Pert chart, \\nor a Gantt chart) detailing task estimates, task dependencies, and resource \\ndependencies. Most project-planning tools can also produce additional tabu- \\nlar reports on resources and schedule. \\nROLES INVOLVED IN THESE ACTIVITIES \\no Application lead developer \\nThe application lead developer works closely with the data administrator and \\nthe database administrator to understand the data access, data analysis, and \\ngeneral data requirements as well as the tool capabilities. He or she must esti- \\nmate the effort for application prototyping and development, which the \\nproject manager will include in the project plan. \\nBusiness representative \\nAlthough the business representative does not actively produce estimates for \\nthe work to be performed by the technicians, he or she must be involved in the \\nentire planning process in order to negotiate the project constraints. The busi- \\nness representative must also understand how much of his or her time will be \\nrequired on the BI project and what is expected of him or her. \\nData administrator \\nThe data administrator needs to participate in the requirements discussions in \\norder to determine the data scope of the BI project. The data administrator \\nwill provide any data models that exist for the objects and data elements in the \\nrequested subject area. If no data models exist, the data administrator can \\ndraw a straw-man model (that is, a first-cut draft of a logical data model) and \\nuse it to validate the understanding of the requirements and the scope. The \\ndata administrator works with the data quality analyst to assess the condition \\nof the source files and databases. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 135}, page_content='102 Step 3: Project Planning \\no \\n® \\n® \\nData quality analyst \\nThe main responsibility of the data quality analyst is to assess the condition of \\nthe source files and databases and to estimate the data-cleansing effort based \\non that assessment. To assess the quality of the source data quickly, the data \\nquality analyst can use the functions of a data-cleansing tool, or he or she can \\nwrite customized domain analysis reports. \\nDatabase administrator \\nThe database administrator needs to understand the scope and schedule of the \\nproject from the DBMS perspective so that he or she can be available for data- \\nbase design and application design activities, as well as ongoing project reviews. \\nETL lead developer \\nThe ETL lead developer works with the data administrator and the data qual- \\nity analyst to understand what types of data transformations and data cleans- \\ning the BI application will require. Based on the condition of the source files \\nand databases, he or she will give ETL estimates to the project manager for the \\nproject plan. \\nMeta data administrator \\nThe meta data administrator is responsible for defining the tasks and esti- \\nmates for the meta data repository track. Working closely with the data \\nadministrator, the meta data administrator has to start exploring what the \\nmeta data requirements for this BI project are and whether they can be met \\nwith the current meta data repository (if one exists). He or she has to deter- \\nmine the meta data repository effort for the project plan. \\nProject manager \\nBI projects are not for rookie project managers. The project manager must \\nhave successfully managed several large projects before. The project manager \\nmust also be familiar with a project management tool to minimize the time \\nrequired for preparing charts and reports. \\nSubject matter expert \\nThe subject matter expert will assist the other team members in preparing the \\nproject plan and the project charter. Either the subject matter expert or the \\nbusiness representative must be an active, full-time participant in this step. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 136}, page_content='Bibliography and Additional Reading 103 \\nRISKS OF NOT PERFORMING STEP 3 \\nIt is impossible to build a BI application ad hoc without a plan. You may as well \\ntake a dart, throw it at a calendar, and commit to the date the dart hits. In other \\nwords, the project will veer out of control if it is not planned well. You may miss \\ndeadlines, have runaway expenses without accountability, implement the wrong \\nsolution—or you may never get to the implementation. A BI decision-support \\nenvironment is very complicated, and BI projects are very costly. The risks of \\nundertaking such projects without adequate planning and control are unacceptable. \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nAdelman, Sid, and Larissa Terpeluk Moss. Data Warehouse Project Management. \\nBoston, MA: Addison-Wesley, 2000. \\nAdelman, Sid, et al. Impossible Data Warehouse Situations: Solutions from the \\nExperts. Boston, MA: Addison-Wesley, 2003. \\nBrooks, Frederick P., Sr. The Mythical Man-Month: Essays on Software Engineer- \\ning, Second Edition. Reading, MA: Addison-Wesley, 1995. \\nCharvat, Jason. Project Management Nation: Tools, Techniques, and Goals for the \\nNew and Practicing IT Project Manager. New York: John Wiley & Sons, 2001. \\nDeMarco, Tom. Slack: Getting Past Burnout, Busywork, and the Myth of Total Effi- \\nciency. New York: Broadway Books, 2001. \\nHumphrey, Watts S. Winning with Software: An Executive Strategy. Boston, MA: \\nAddison-Wesley, 2002. \\nJarke, Matthias, Maurizio Lenzerini, Yannis Vassiliou, and Panos Vassiliadis. Fun- \\ndamentals of Data Warehouses. New York: Springer, 2000. \\nLewis, James P. The Project Manager’s Desk Reference, Second Edition. McGraw- \\nHill Trade, 1999. \\nMarmel, Elaine. Microsoft Project 2000 Bible. New York: John Wiley & Sons, 2000. \\nMoeller, R. A. Distributed Data Warehousing Using Web Technology: How to Build \\na More Cost-Effective and Flexible Warehouse. New York: AMACOM American \\nManagement Association, 2001. \\nYourdon, Edward. Death March. Upper Saddle River, NJ: Prentice Hall, 1997. \\nProject Management Institute: http://www.pm.org . \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 137}, page_content=\"o> \\nas a ter Pal Sir waka my 4 hey ; \\ni \\n§ ie \\nyi wee etry, agile manngees \\nce) “cura, PAL ta UF ait eo img pre yam. \\nrst te cary A bas bom or ie : \\nHea bake Afi) Mia CP eo iF per See iite Ve It enrioy a6 \\nBoy, Ss \\ntig ts \\nod ee ee mn) urn, 2 ae eee \\nPARP aA Age BetATR JAM ie my ie Ata — \\neg r ce pp » Paras GR? 6 ete. sac. \\nDe malis cer. ean Ms mde: \\n48 4s Bie Sede-ncibiah sage \\n' dentiny Aer ore: om emp: Aten A an Rew ot 208 \\n7 fw Gon ee GRR gis ah 1 £40 ae \\nNEALE om wRT Se? shanna: Hie \\nfeat gyrak GZ? a ADEPT erin Fee 2k Hi O47 Hey \\nGRR eee ; z. . \\nof gpg aod Babee pin 4 shscret + a ai hs necae 4 sale Cay cael : \\n% ears sre ae \\noh Bit Liat ia ae Cree: os tutes ‘ . \\n~ wetted pink harman weeps Det poem rato. wit a exnal a \\n0 D> reas 29M 7 = Beet = iat +4 \\nSIS waned 2 (ADM ralokbecinwsh otha ane es Seat a \\nMoana esate tee a aetewed nehyrpauh Weak ec snlee apcnmebarenets Abi ea : ipa oS \\n- ¢ 7 7 pales \\nCee! pe one iit, Aiea \\nee a 2 aoe \\nLOWMAN Soe \\n(an \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 138}, page_content='Justification ae iad CHAPTER FOUR \\nbee Step 4: Project \\nie Requirements Definition \\nCHAPTER OVERVIEW \\nThis chapter covers the following topics: \\nProject \\nRequirements \\nDefinition \\n@ Things to consider when defining requirements \\n@ The differences between general business requirements \\nand project-specific requirements \\n@ The appropriate people to interview to determine general \\nbusiness requirements \\nm@ The sections to complete in a business requirements report Design : a i, \\nThe appropriate people to interview when gathering \\nproject-specific requirements for a BI application \\n@ The sections to include in an application requirements \\ndocument \\n@ Interviewing considerations and interviewing tips \\ng@ Brief descriptions of the activities involved in requirements \\ndefinition, the deliverables resulting from those activities, \\nand the roles involved \\n@ The risks of not performing Step 4 \\nDeployment , \\n105 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 139}, page_content='106 Step 4: Project Requirements Definition \\nTHINGS TO CONSIDER | \\nFunctional Requirements \\n/ What types of information do the business people in our organization need? \\nWhat types of business questions are they unable to answer today and why? \\n¥ What reports do they want? \\nY Which reports are most important? Which are least important? Which \\nreports can be replaced with “canned” queries? \\n/¥ What types of queries will the business analysts run? \\n/Y Who will administer the query libraries and set up the universes, for exam- \\nple, data views in online analytical processing (OLAP) tools? \\nVY Are the business analysts and knowledge workers planning to write many ad \\nhoc queries? Can we get some samples of old queries from them? \\nData Requirements \\n¥ What data do the business people need? Where do they get that data today? \\nY How clean is the data today? How clean does it have to be? \\n¥ What data is considered most critical to the business? \\nY Can the data be summarized? If yes, by what dimensions? \\n¥ Will the business analysts want the capability to drill down to the detail? \\nHow granular does the detail have to be? \\n/Y Do other business people need the same data? Do we eee who they are? \\nWill they be available to validate the meta data? \\n¥ What are the expectations for the timeliness of the data and the availability \\nof the data? \\nHistorical Requirements \\n¥ How many years of history do we need to keep? \\n¥ Can we start collecting history from this point forward or do we have to load \\ndata from old archived files? \\nSecurity Requirements \\nV How secure does the data have to be? What type of security exists on the \\noperational source data? \\nVv Are the security requirements homogeneous (should all the data have the \\nsame level of security)? \\nY Who should have access to the data? \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 140}, page_content='107 \\nPerformance Requirements | \\n2 Vv What is the slowest response time the business people will accept for a query \\nY Can reports be run overnight rather than during the day in order to avoid \\nresource contention with interactive usage of the BI target databases? \\nY How often and for how long will knowledge workers and business analysts \\naccess the BI target databases during the day for ad hoc reporting and data \\nanalysis? \\nRequirements come in two flavors: (1) general high-level business require- \\nments for the BI decision-support environment, which are identified at the onset of \\na BI initiative and are periodically reviewed, and (2) project-specific requirements, \\nwhich concentrate on the detailed deliverables expected from each BI application \\nrelease. Table 4.1 lists the differences between the two types of requirements. \\nTable 4.1: General Business Requirements versus Project-Specific Requirements \\nGeneral Business Requirements \\nPurpose * Determine the general \\nbusiness needs of the \\norganization for a BI decision- \\nsupport environment \\n* Business executives \\n¢ Information technology (IT) \\nmanagers \\n+ IT staff \\n¢ Line-of-business managers \\n* Subject matter experts \\nInterviewees \\nDeliverable ¢ Business requirements report \\nContent of \\ndeliverable \\n¢ Findings \\n° Issues \\n* Opportunities \\n* Recommendations \\n¢ Next steps \\nProject-Specific Requirements \\n¢ Define the specific functions and \\ndata to be delivered at the end of \\na BI project \\n* Business sponsor \\n* Business representative \\n¢ “Power users” \\n* Stakeholders (knowledge workers, \\nbusiness analysts, data owners) \\n¢ Subject matter experts \\n¢ Application requirements \\ndocument \\n¢ Functional requirements \\n¢ Data requirements \\n* Data-cleansing requirements \\n* Security requirements \\n¢ Performance requirements \\n* Availability requirements \\n| SSS AS A SY SS IS SPOR EE FETS PE SEB REE CR LIE ESIC IE IEEE EO IEEE TEE BEE EEE AG EE \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 141}, page_content='108 Step 4: Project Requirements Definition \\nGENERAL BUSINESS REQUIREMENTS \\nMarketing strategies often propel the BI decision-support initiatives at organiza- \\ntions because of the constant challenge to keep up with the competition and to \\nretain market share. To a large degree, it is the marketing focus that drives the \\nimpetus for more knowledge about the business, in particular about its customers. \\nMarketing strategies have had an impact on the evolution of decision-support \\nsystems since the early days of IT. Figure 4.1 shows the effect this evolution has \\nhad on increasing the decision-support value of customer-centric applications. \\n* Traditional decision-support systems focused on product-related opera- \\ntional processes of the organization. Decision-support capabilities were lim- \\nited, and marketing efforts revolved around products, not customers. \\nCustomer information files were the first attempt to aggregate all customer- \\nrelated data from dozens, if not hundreds, of disparate operational systems \\ninto one central file. Decision-support focus started to shift from products to \\ncustomers. \\nHouse-holding databases contained customer hierarchies in order to help \\nbusiness managers understand customer-to-customer relationships. These data- \\nbases also contained organizational hierarchies in order to help business execu- \\ntives understand organizational and regional profitability. House-holding was \\nthe rudimentary precursor of customer relationship management (CRM). \\nBusiness \\nIntelligence \\nRelative \\nDecision- Customer \\nSupport Relationship \\nValue Management \\nData \\nWarehousing \\nHouse-Holding \\nDatabases Customer \\nInformation \\nFiles \\nTraditional \\nDecision-Support \\nSystems \\n1975 21.985 E995 ~ 2000 ~ 2005 \\nFigure 4.1: Increasing Decision-Support Value \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 142}, page_content='General Business Requirements 109 \\nData warehousing was the first ambitious undertaking of cross-organizational \\nintegration of data for decision-support purposes, such as sales reporting, \\nkey performance indicators, performance trend analysis, and so on. Due to \\nthe enormous effort involved, a wave of new tools started to flood the market, \\nwith extract/transform/load (ETL) and OLAP tools leading the pack. \\nCustomer relationship management focuses on customer-product (sales) \\nrelationships, as well as on customer service, customer buying behavior, and \\nother knowledge about customers. The goal is to improve customer sales and \\nservices through personalization and mass customization. \\nBusiness intelligence is a more holistic and sophisticated approach to cross- \\norganizational decision-support needs. It uses data mining to gain hidden \\n(nonexplicit) knowledge about customers, general market conditions, and \\ncompetitive products. The goal is to “predict” the future by analyzing the \\npresent, thereby gaining a competitive edge. \\nBesides marketing, other departments in the organization are also keen to \\ntake advantage of today’s technologies to solve their business needs. Such depart- \\nments include finance, product management, portfolio management, customer \\nservice, engineering, and inventory management, to name a few. \\nInterviewees for General Business Requirements \\nDetermining the general business needs of the organization requires interviewing \\nindividuals at every level of the organizational hierarchy, both on the business \\nside and on the IT side. \\nBusiness executives are the visionaries. They know which direction the orga- \\nnization should move and how to achieve new goals. They also know what \\nthe organization’s business pains are. The business executives’ requirements \\nwill be focused around strategic information from the BI decision-support \\nenvironment. \\nIT managers support the operational systems of the business areas. They \\nknow the deficiencies of these systems very well, and they are aware of the \\nbacklog for decision-support requirements. Their input can be helpful in \\nidentifying unfulfilled decision-support requirements and in determining \\nhow the BI application can improve the workload for IT. \\nIT staff work directly with the business staff. The IT staff have firsthand \\nknowledge of the unfulfilled requirements. They also know the technical \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 143}, page_content='110 Step 4: Project Requirements Definition \\nRS a SPS ES ARERR IPO SE SAPD SIRE FRPP RL REET SE FL ES EE OES SE TLE LIS LID \\nskills of the business people with whom they work. This information will \\nbecome valuable input for access and analysis tool selection. \\n- Line-of-business managers are responsible for the smooth operations of the \\norganization. They focus on tactical decisions on a daily basis. Their require- \\nments frequently include a mixture of strategic information and operational \\ninformation. \\nSubject matter experts are the senior business analysts with the 10,000-foot \\nview of a department or a division. Sometimes they are the “power users”; \\nother times they act as internal business consultants. In addition to having an \\noverall business view, subject matter experts are usually very familiar with \\ndetailed operational data and can give a lot of insights into current data qual- \\nity problems. \\nData Quality Requirements \\nData quality must be discussed with all interviewees. Questions to ask fall into \\nthree categories: existing data quality, desired data quality, and prioritization for \\ndata cleansing. \\n1. Existing data quality: Different interviewees might have a different perspec- \\ntive of what is clean and what is not. They will also have a different perspec- \\ntive of what should be cleansed and what can remain “dirty.” \\n2. Desired data quality: Knowledge workers “in the trenches” typically have a \\nhigher tolerance for dirty data than business executives do, mainly because \\nthe knowledge workers have learned over the years how to decipher and \\ninterpret their bad data. \\n3. Prioritization for data cleansing: Critical and important data must be sorted \\nout from insignificant data. Business executives and line-of-business manag- \\ners should make that decision. \\nData quality affects business people in all critical business areas of an organi- \\nzation, especially strategic decision-makers, business operations staff, customer \\nsupport staff, and marketing staff. \\n* Strategic decision-makers: Probably more than anyone else, strategic decision- \\nmakers (the business executives of the organizations) are affected by poor- \\nquality data. The decisions they make have an effect on the organizational \\nlifeline. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 144}, page_content='General Business Requirements 111 \\n* Business operations staff: Line-of-business managers and their staff could \\nbe much more efficient if they did not have to constantly resolve errors and \\nwaste time on rework. \\n* Customer support staff: The customer representatives and the sales force \\nhave direct contact with the organizations’ customers. Poor-quality data puts \\na tremendous burden on this group to keep the customers satisfied and to \\nprevent them from leaving. \\n* Marketing staff: Managers and knowledge workers in the marketing department \\ndo not want to waste millions of dollars by soliciting customers who are not \\nworth soliciting, by sending marketing materials to customers who have moved, \\nor by pursuing dissatisfied customers who have defected to the competition. \\nBusiness Requirements Report \\nThe deliverable from a high-level business requirements activity is a report on the \\nfindings, issues, opportunities, recommendations, and next steps, as shown in \\nFigure 4.2. \\nFindings, Issues, Opportunities Recommendations Next Steps \\nFigure 4.2: Business Requirements Report Content \\n* Findings: The compilation of all requirements from the interviewees should \\nbe sorted by topic. Each finding should be associated with the interviewees \\nand the interview dates. \\n* Issues: A separate list should highlight critical business issues, so that these \\nissues can be addressed immediately. Not all business issues require a BI solution. \\n* Opportunities: Obvious business opportunities should also be extracted and \\nhighlighted from the findings. Again, not all business opportunities will \\ntranslate into BI requirements. \\n+ Recommendations: After analyzing the findings, issues, and opportunities, a \\nlist of recommendations should be added. These can be recommendations for \\ncorrecting a problem on the existing systems or for building a new BI solution. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 145}, page_content='112 Step 4: Project Requirements Definition \\n* Next steps: Certain recommended actions are more critical than others, and \\nsome recommended actions may depend on the completion of others. This \\nsection of the report should list the prioritized sequence of actions to be \\ntaken toward implementing a BI solution. \\nThis report is not listed as a deliverable for a BI project because it occurs out- \\nside of an already approved BI project. It may be used in lieu of a business case \\nassessment report, if the business case assessment is high-level and not specific to \\na BI application. \\nPROJECT-SPECIFIC REQUIREMENTS \\nRequirements gathering for a specific project deliverable focuses on defining the \\nexplicit business needs of the business sponsor for whom the BI application is \\nbeing developed. The project requirements should be stated in business terms \\nand should describe the business problem to be solved as well as the acceptance \\ncriteria for the BI solution. Figure 4.3 shows an example of a requirements \\nstatement. \\nPane A precompiled wish list of data elements and a stack of mock reports do not \\nconstitute a requirements definition. : \\n“It currently takes us 3 weeks to compile sales data from all regions \\nand another 3 weeks to analyze it and make an investment correction. \\nEvery week of delay is costing us an estimated $50,000. Our \\nexpectation is to reduce the delay to 1 week. If we could have the \\ndata integrated and available within 3 days after close of business, \\nand if we could have the following query capabilities ..., we could \\ncomplete our analysis in 2 days. In order to do that we require the \\nfollowing data... .” \\nFigure 4.3: Requirements Definition Statement \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 146}, page_content='Project-Specific Requirements 113 \\nThe application requirements document must clearly state the BI project \\nobjectives and expected deliverables in terms of: \\nNature of the existing business problem \\nDamage (lost business opportunity, exceeded operating costs) caused to the \\norganization by the existing business problem \\nWhy the problems cannot be solved without a BI solution \\nHow the BI application will solve the problem \\nDetailed requirements for reports and canned queries on the desired subject \\nareas \\nRequirements for graphical representation tools, such as OLAP \\nPrioritized, detailed data requirements for: \\n— All data required for the BI target database(s) as well as for reports and queries \\n— All potential data source files and source databases \\nPaw Source data requirements should be defined in as much detail as possible and \\nas early as possible to enable rigorous source data analysis in the next step. \\nWaiting until the design stage to determine how to source the BI target data- \\nbases is too late. \\nPrioritized, detailed functional requirements for the data-cleansing transfor- \\nmations \\nRequirements for historical data (how many years of history) \\nRequired security features \\nRequested service-level agreements (SLAs) for query response time, data \\ncleanliness, hours and days of the BI application’s availability, and tool func- \\ntionality \\nDefining requirements is a different activity than designing a solution. Exer- \\ncise caution—do not jump into designing the BI application at this time, as \\nmany technicians tend to do. \\nInterviewees for Project-Specific Requirements \\nThe interviews for project-specific requirements are limited to those individuals \\nwho are directly involved with the BI project and those who are directly impacted \\nby the BI application. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 147}, page_content='114 Step 4: Project Requirements Definition \\n- The business representative should provide the details about the work he or \\nshe is performing. It is important to understand the business workflow and \\nwhere the bottlenecks are since they point to potential challenges with the \\ndata or the functionality. Overlooking these challenges could possibly lead to \\nunderestimating the project effort. \\nThe business sponsor sets the objectives for the BI application and states the \\nbusiness need as well as the expectations for the return on investment. He or \\nshe should prioritize the requested deliverables if the scope is too large given \\nthe project constraints of effort (time), budget, resources, and quality. \\n“Power users” often perform the analysis functions, which the BI application \\nis supposed to replace. They have a wealth of information about the detailed \\nrequirements for solving the stated business problem. \\nStakeholders could be other knowledge workers, business analysts, or busi- \\nness managers who are performing similar functions and who will use the \\ndata in the BI target databases for their own decision-support needs. The BI \\nproject team should identify these stakeholders early to determine potential \\noverlapping needs. Stakeholders could also be the data owners. The data own- \\ners should always be included in the interviewing process because it is their \\nresponsibility to verify that their data is being used and interpreted correctly. \\nSubject matter experts could be the same people as the “power users” or \\ncould be senior business analysts. They, along with the business representa- \\ntive, are the prime interviewees for project-specific requirements. \\nApplication Requirements Document \\nThe deliverable from a project-specific requirements definition activity is a \\nrequirements document itemizing the detailed functional requirements, the \\ndetailed data requirements, and the potential sources of data. This document \\nshould also detail the requirements for data cleansing, performance, data secu- \\nrity, and availability, as shown in Figure 4.4. \\nRO \\nFunctions Data Cleansing Performance Security Availability \\nFigure 4.4: Application Requirements Document Content \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 148}, page_content=\"Project-Specific Requirements 115 \\nFunctions: All functional requirements for reporting and for data access and \\nanalysis should be listed and prioritized. This includes contents and algo- \\nrithms for reports and queries, ad hoc capabilities, Web displays, and other \\ngraphical representations. Summarization and aggregation requests as well as \\ndrill-down capabilities must be described as well. \\nData: The desired subject areas (e.g., product, customer, orders, campaign) \\nshould be confirmed, and the required data elements should be defined. Be \\njudicious about the data scope because going after too much data “just in case \\nthey'll need it some day” leads to more complex data models and more time \\nand money spent for data extraction, cleansing, and maintenance. \\nPaw IT technicians can help identify which source data may not have to be \\nincluded in the BI target databases based on current low usage of data. \\nHowever, the final decision on whether or not to include rarely used \\nsource data must be made by a business person, not by IT. \\nIn addition, all previously identified potential source files and source databases \\nshould be reviewed. If storing history is a requirement, the archived source \\nfiles must also be identified and reviewed. Additional data-specific require- \\nments should be defined, such as data load frequency (e.g., daily, weekly, \\nmonthly) and data security. \\nData cleansing: The list of requested data elements must be prioritized into \\ncritical, important, and insignificant categories. The tolerance level for dirty \\ndata must be defined for each data element in the critical category, for exam- \\nple, “Monthly Sales Total: dirty data threshold = 2 percent; Daily Average \\nPortfolio Amount: dirty data threshold = 0.05 percent.” Next, the dirty data \\ntolerance level must be defined for each data element in the important cate- \\ngory. Insignificant data elements are often passed across without cleansing, \\nmainly due to time constraints. \\nPerformance: Most knowledge workers of operational systems are accus- \\ntomed to subsecond response times. Expectations must be set and managed \\nin this respect. Techniques and technologies can improve report and query \\nresponse times, but rarely—if ever—will the response times be as low as sub- \\nseconds. The question to ask is not what the desired response time is but what \\nan acceptable response time is, followed by the question of how much busi- \\nness management is willing to pay in order to get a better response time. \\nSecurity: Since the data in the BI target databases is the same data as in the \\noperational systems, it should be given similar security considerations. Some \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 149}, page_content='116 Step 4: Project Requirements Definition \\nexceptions may apply if the data is highly summarized and no drill down to \\nthe detail is allowed or even available. \\nAvailability: Requests for 24/7 availability are rarely valid since a BI decision- \\nsupport environment primarily supports strategic decision making. The require- \\nment for 24/7 availability is typically an operational requirement. However, it \\ncould be valid under some circumstances, such as for international compa- \\nnies that have offices around the globe and that will access a centralized data- \\nbase. In addition to determining hours and days of availability, the \\npercentage of availability during scheduled hours should also be specified, for \\nexample, “97 percent availability Monday through Saturday between 5 A.M. and \\n11 P.M. EST and 90 percent availability Sunday between 5 A.M. and 3 P.M. EST.” \\nTHE INTERVIEWING PROCESS \\nThe more detailed the requirements document, the more the scope can be solidi- \\nfied and the more the estimates for the effort can be validated. To accumulate the \\nnecessary details in order to understand the business process, the interview team \\nmust spend some time interviewing all the stakeholders of the application and \\nstudying their environment. When documenting the project requirements, use \\ngraphic techniques whenever possible, such as bubble charts, cause-and-effect \\ndiagrams, entity-relationship diagrams, star schema models, and even functional \\ndecomposition diagrams and data flow diagrams where appropriate. Diagrams \\nmake excellent communication tools. Through visualization, the interviewee can \\nbetter verify the interviewer’s understanding of the requirements. \\nInterviewing Considerations \\nBefore scheduling the interviews, some preparation is required. Figure 4.5 lists \\nitems that need to be considered for the interviewing process. \\nInterview Team Interviewees Research Questionnaire Schedule \\nFigure 4.5: Items to Consider for the Interviewing Process \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 150}, page_content='The Interviewing Process 117 \\nInterview team: Preferably, the interviewer should not conduct the interview \\nand take notes at the same time. He or she should team up with a “scribe” \\nwho can take notes during the interviews. It is difficult to keep the momen- \\ntum of the meeting going if you have to ask the questions, write down the \\nanswers, and think of the next question to ask all at the same time. \\nInterviewees: Interviews can be conducted with individuals or groups of \\nindividuals. Group interviews work well among peers from the same work \\narea if they share similar responsibilities. What one person says often triggers \\na thought in another person. This synergy can be very productive. The draw- \\nback of group interviewing is that some interviewees may not be as honest or \\nforthcoming in their responses. The most effective approach to interviewing \\nis often a balance between individual interviews and group interviews. \\nResearch: Before scheduling the interviews, the interviewer should spend some \\ntime researching existing documents, reports, and Web sites, including competi- \\ntors’ Web sites. It helps to have as much understanding as possible of the indus- \\ntry, the business processes, and the organization’s terminology and acronyms. \\nQuestionnaire: A questionnaire for the major topics should be prepared and \\nmailed to the interviewees before the scheduled interviews. That gives the \\ninterviewees a chance to prepare and to bring supporting documentation to \\nthe interview. \\nInterview schedule: Do not schedule more than four one-hour interviews \\nper day because it will take at least one hour after each interview to review, fill \\nin, or clarify the interview notes. It is imperative to complete or rewrite the \\nnotes taken during an interview on the same day of that interview, so that no \\nambiguity or incompleteness remains. \\nInterviewing Tips \\nThe following interviewing practices can make the process run smoothly and \\neffectively: \\nThe initial interview should focus on the basic requirements necessary to \\nsolve a specific business problem. Do not dwell on any of the mechanical and \\nlogistical aspects, and do not promise anything hastily. There will be time to \\nget into detailed analysis later. \\nFrequently, interviewees will be quite comfortable telling you what they cur- \\nrently have, but they can provide only minimal insight into what they want \\nbut do not have. Be prepared to guide them with leading questions. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 151}, page_content='118 Step 4: Project Requirements Definition \\n- Be prepared to hear and resolve conflicting views and priorities. This is espe- \\ncially true when speaking with knowledge workers, business analysts, and \\nbusiness managers from different departments and from different levels of \\nthe organizational hierarchy. \\n* Taking notes usually involves a fair amount of scribbling (or, if using a laptop, \\na fair amount of abbreviating). While the discussions are still fresh in the \\nminds of the interviewer and the scribe, they should review the notes imme- \\ndiately after each interview and expand on the scribbles and abbreviations. By \\nthe end of the day, the notes must be in such condition that they can be \\nunderstood several days or weeks later. \\nTape recording interviews can be very helpful when the interview team con- \\nsists of only one person. Making a tape allows the interviewer to concentrate \\non the questioning rather than on note taking. It is imperative to ask the \\ninterviewees for their permission to record the interview session. Many inter- \\nviewees do not like to be recorded, and other interviewees may not be as \\nforthcoming and honest when they know they are being recorded. \\nAs soon as time permits after each interview, transcribe the interview notes \\ninto a clean interview notes document and send it to all interviewees who \\nparticipated in that interview for their approval. Ask the interviewees to \\nchange any misinterpretations and add anything they forgot to mention dur- \\ning the interview. \\nPROJECT REQUIREMENTS DEFINITION ACTIVITIES \\nThe activities for defining project requirements do not need to be performed lin- \\nearly. Figure 4.6 indicates which activities can be performed concurrently. The list \\nbelow briefly describes the activities associated with Step 4, Project Requirements \\nDefinition. \\n1. Define the requirements for technical infrastructure enhancements. \\nYou should have already reviewed the technical infrastructure components to \\ndetermine whether they can support the BI application or whether changes \\nare required. Requirements for technical infrastructure components could \\ninclude one or more of the following: \\n— New or additional hardware \\n— New database management system (DBMS) or upgrades to the existing DBMS \\n— New development tools \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 152}, page_content='Project Requirements Definition Activities 119 \\nDefine requirements for \\ntechnical infrastructure \\nenhancements \\nExpand \\nlogical data model \\nDefine requirements for \\nnontechnical infrastructure \\nenhancements \\nWrite application \\nrequirements document \\nReview \\nproject scope \\nS77 as \\n” \\nDefine preliminary \\nservice-level agreements \\n3 \\nDefine reporting \\nrequirements \\nDefine requirements \\nfor source data \\nFigure 4.6: Project Requirements Definition Activities \\n— New data access or reporting tools \\n— New data mining tool \\n— New meta data repository or enhancements to it \\n— New network requirements \\n2. Define the requirements for nontechnical infrastructure enhancements. \\nYou should have also reviewed and evaluated the nontechnical infrastructure \\ncomponents. If changes are required, define these requirements now. Non- \\ntechnical infrastructure components to be added or revised could include: \\n— Estimating guidelines \\n— Roles and responsibilities \\n— Standards \\n— Procedures for: \\n» Use of a methodology \\n» Scope management (change control) \\n» Issues management \\n» Security process \\n» SLAs \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 153}, page_content='120 Step 4: Project Requirements Definition \\na RS ES nS \\n» Prioritization \\n» Testing process \\n» Support functions \\n» Dispute resolution \\n» Meta data capture and meta data delivery \\n» Data quality measures and triage process \\n» Communication \\n3. Define the reporting requirements. \\nDuring the interview process, collect or create sample report layouts and que- \\nries. Define and document business rules for deriving data and for creating \\naggregations and summaries. It is advisable to determine who will be the \\nstewards of the query libraries and universes (data views in OLAP tools). \\n4. Define the requirements for source data. \\nDefine the detailed data requirements and select the most appropriate source \\nfiles and source databases from the potential list of sources created during \\nprior steps. Spend some time on defining the data-cleansing requirements \\nand the critical business rules for the data. Perform some cursory data analy- \\nsis on suspected poor-quality data so that the scope and the effort estimates \\ncreated during Step 3, Project Planning, can be validated. \\n5. Review the project scope. \\nCompare the detailed requirements to the high-level scope in the project \\ncharter. Determine whether the scope is still doable and whether the esti- \\nmates are still realistic. If you have learned something that puts the commit- \\nment in the project charter in question, it is time to renegotiate. \\n6. Expand the logical data model. \\nA high-level logical data model was probably produced during earlier steps \\n(Step 1, Business Case Assessment, or Step 3, Project Planning). Using the \\ninformation from the interview sessions, expand the logical data model with \\nnewly discovered entities, relationships, and attributes. If a logical data model \\nwas not produced during prior steps, create a high-level logical data model \\nfor the data requirements in preparation for the data analysis activities. \\n7. Define preliminary service-level agreements. \\nAlthough many technicians may argue that it is much too early to commit to \\nSLAs, most business people will ask for them because they constitute the \\nacceptance criteria. It is best to find the outermost acceptable limits for each \\nof the following SLAs and refine them as the project progresses: \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 154}, page_content='Roles Involved in These Activities 121 \\n— Availability \\n— Security \\n— Response time \\n— Data cleanliness \\n— Ongoing support \\n. Write the application requirements document. \\nIn the application requirements document, itemize the requirements for \\nfunctions, data, cleansing, performance, security, and availability. In addi- \\ntion, list the requirements for enhancing technical and nontechnical infra- \\nstructure components during the BI project. Include the high-level logical \\ndata model in this document. \\nDELIVERABLE RESULTING FROM THESE ACTIVITIES \\n1. Application requirements document \\nThis document should contain the following sections: \\n— Technical infrastructure requirements \\n— Nontechnical infrastructure requirements \\n— Reporting requirements \\n— Ad hoc and canned query requirements \\n— Requirements for source data, including history \\n— High-level logical data model \\n— Data-cleansing requirements \\n— Security requirements \\n— Preliminary SLAs \\nInclude a list of conducted interviews in date order, a list of the interviewees, \\nand a summary of the interview notes. \\nROLES INVOLVED IN THESE ACTIVITIES \\n® Application lead developer \\nThe application lead developer should add application-specific data access \\nand data analysis questions to the interview questionnaire and should lead \\nthat portion of the interviews. He or she should not conduct separate inter- \\nviews but should participate with the data quality analyst and data adminis- \\ntrator in the same interviews. Business people get very annoyed when different \\nIT people ask them the same questions in different interviews. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 155}, page_content='122 Step 4: Project Requirements Definition \\n® Business representative \\nIn addition to sharing the same responsibilities as the subject matter expert, \\nthe business representative should be prepared to demonstrate his or her daily \\nwork routine to the data quality analyst, data administrator, and application \\nlead developer either before or after the interview sessions. \\n@ Data administrator \\nThe data administrator can be of great help to the data quality analyst by par- \\nticipating with follow-up questions and scribing the answers. In addition, the \\ndata administrator will get a jump start on his or her logical data modeling \\nactivities by hearing the interview discussions firsthand. Such participation in \\nthe interviews also eliminates the need for the data administrator to revisit \\nsome topics with the interviewees where he or she might have had questions. \\n@ Data quality analyst \\nThe data quality analyst, the data administrator, and the application lead \\ndeveloper should develop an approach for conducting the interviews. They \\nneed to decide when and how they will take turns being the interviewer, the \\nscribe, and the observer. Most likely, the data quality analyst will be the princi- \\npal interviewer. \\n@ Meta data administrator \\nThe meta data administrator may join the interview team either as a partici- \\npant or as an observer, depending on the scope of the proposed meta data \\nrepository solution. The meta data administrator should add his or her own \\nset of meta data requirements questions to the questionnaire and should lead \\nthat portion of the interviews. \\n@ Subject matter expert \\nThe subject matter expert together with the business representative must be \\nprepared to address the topics on the questionnaire. He or she should also \\nbring to the interview sessions any reports, forms, screen layouts, code manu- \\nals, and other documents that support or explain the project requirements. \\nRISKS OF NOT PERFORMING STEP 4 \\nSome organizations combine requirements definition activities with data analysis \\nor with application prototyping activities. While that can be an effective \\napproach, the danger lies in losing sight of the big picture, that is, the objectives \\nand scope of the project. When data modelers dig into the data details too soon, \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 156}, page_content='Bibliography and Additional Reading 123 \\nanalysis paralysis often results. When the application developers start prototyp- \\ning too soon, scope creep often occurs. Other potential risks are that functional- \\nity or data are missed, security issues are ignored, requirements are not \\nprioritized, and business objectives are not targeted. For all these reasons it is \\nadvisable to separate requirements gathering from data analysis and prototyping. \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nAdelman, Sid, and Larissa Terpeluk Moss. Data Warehouse Project Management. \\nBoston, MA: Addison-Wesley, 2000. \\nCockburn, Alistair. Writing Effective Use Cases. Boston, MA: Addison-Wesley, \\n2000. \\nDyché, Jill. e-Data: Turning Data into Information with Data Warehousing. Bos- \\nton, MA: Addison-Wesley, 2000. \\nEnglish, Larry P. Improving Data Warehouse and Business Information Quality: \\nMethods for Reducing Costs and Increasing Profits. New York: John Wiley & Sons, \\n1999. \\nHoberman, Steve. Data Modeler’s Workbench: Tools and Techniques for Analysis \\nand Design. New York: John Wiley & Sons, 2001. \\nImhoff, Claudia, Lisa Loftis, and Jonathan G. Geiger. Building the Customer-Centric \\nEnterprise: Data Warehousing Techniques for Supporting Customer Relationship \\nManagement. New York: John Wiley & Sons, 2001. \\nInmon, William H., Claudia Imhoff, and Ryan Sousa. Corporate Information Fac- \\ntory. New York: John Wiley & Sons, 1997. \\nJackson, Michael. Software Requirements and Specifications: A Lexicon of Practice, \\nPrinciples, and Prejudices. Reading, MA: Addison-Wesley, 1995. \\nJarke, Matthias, Maurizio Lenzerini, Yannis Vassiliou, and Panos Vassiliadis. Fun- \\ndamentals of Data Warehouses. New York: Springer, 2000. \\nKimball, Ralph, Laura Reeves, Margy Ross, and Warren Thornthwaite. The Data \\nWarehouse Lifecycle Toolkit: Expert Methods for Designing, Developing, and \\nDeploying Data Warehouses. New York: John Wiley & Sons, 1998. \\nKovitz, Benjamin L. Practical Software Requirements: A Manual of Content and \\nStyle. Greenwich, CT: Manning Publications Company, 1998. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 157}, page_content='124 Step 4: Project Requirements Definition \\nMoeller, R. A. Distributed Data Warehousing Using Web Technology: How to Build \\na More Cost-Effective and Flexible Warehouse. New York: AMACOM American \\nManagement Association, 2001. \\nRoss, Ronald G. The Business Rule Concepts. Houston, TX: Business Rule Solu- \\ntions; Ine 1998. \\nVon Halle, Barbara. Business Rules Applied: Building Better Systems Using the Busi- \\nness Rules Approach. New York: John Wiley & Sons, 2001. \\nWiegers, Karl E. Software Requirements. Redmond, WA: Microsoft Press, 1999. \\nWood, Jane, and Denise Silver. Joint Application Development. New York: John \\nWiley & Sons, 1995. \\nYourdon, Edward. Death March. Upper Saddle River, NJ: Prentice Hall, 1997. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 158}, page_content='ion aes CHAPTER FIVE \\nStep 5: Data Analysis Bs Eom wry : ye \\nPlanning \\nCHAPTER OVERVIEW \\nBusiness Analysis This chapter covers the following topics: \\nm@ Things to consider when analyzing source data for BI appli- \\ncations \\n> i The difference between the systems analysis phase of a \\ng Meta D traditional methodology and the business-focused data \\nanalysis performed during this step \\n@ Top-down logical data modeling, including project-specific \\nlogical data models, integrated enterprise logical data \\nmodels, and data-specific business meta data components \\ngathered during the logical data modeling process \\nm@ Bottom-up source data analysis, including how to apply \\nthree sets of transformation rules to the source data: tech- \\nnical data conversion rules, business data domain rules, \\nand business data integrity rules \\n@ The responsibilities for data archeology, data cleansing, \\nand data quality enforcement, plus the need to triage (pri- \\noritize) data-cleansing activities \\n@ Brief descriptions of the activities involved in data analysis, \\nthe deliverables resulting from those activities, and the \\nroles involved \\n@ The risks of not performing Step 5 \\n125 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 159}, page_content='126 Step 5: Data Analysis \\nTHINGS TO CONSIDER \\nSource Data \\nY Do we know where the source data resides? In what systems? In what files? In \\nwhat databases? \\nV Are there multiple potential sources for the same data? \\nVv Has the requested source data already been modeled? \\nY How current is the business meta data on those models? \\nV Have the data owners ratified the business meta data? \\nY Do we know who the data owners are? Who has authority over the source \\ndata? \\nVv Is there any other type of documentation available for the requested source \\ndata? Is it current and complete? \\nVv Where is that documentation? In a meta data repository? In programs? In \\nmanuals? \\nData Quality \\n¥Y Do we know how clean the source data is? \\nV How clean does the data have to be according to our business representative? \\n¥ Will that be clean enough for other knowledge workers, business analysts, \\nand business managers who will use the same data? \\nY Do we know who they are? \\nVv Where do we get the business rules for the data? From the data owners? \\nFrom the business representative on the project? \\nData Cleansing \\nV Have data errors already been documented by other project teams? If so, \\nwhere is that documentation? \\n¥ Who would know what the known data errors are? \\nVv Are codes being translated inside operational programs? If so, in which \\nprograms? \\nV Does a code translation book exist for encoded fields? \\n¥ Do we already know which data is critical, which is important, and which is \\ninsignificant (for data-cleansing triage purposes)? \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 160}, page_content='Business-Focused Data Analysis 127 \\nOperational systems are developed as stovepipe automation solutions for \\nindividual business units and not as support for the executive decision-making \\nprocess. Therefore, operational systems are not designed to integrate or reconcile \\nwith each other in order to provide a consistent cross-organizational view. BI \\napplications, on the other hand, are designed to do just that—provide integrated \\nand reconciled business data to the business community. \\nBUSINESS-FOCUSED DATA ANALYSIS \\nFor many organizations, the BI decision-support initiative is the first attempt to \\nbring business data together from multiple sources in order to make it available \\nacross different departments. Organizations that use a traditional systems devel- \\nopment methodology on their BI projects usually run into severe source data \\nproblems when they try to implement their extract/transform/load (ETL) pro- \\ncesses because traditional development methodologies do not have steps for ana- \\nlyzing data domains early in the development process. They have, at best, a \\nsystems analysis phase for the application functions but no business-focused data \\nanalysis phase for the underlying data. \\nThe business-focused data analysis step is the most critical cross-organiza- \\ntional step described in Business Intelligence Roadmap. \\nStep 5, Data Analysis, is different from a systems analysis phase in a tradi- \\ntional methodology. The activities traditionally performed during systems analy- \\nsis are geared toward producing a design decision for the system to be built. The \\nactivities performed during data analysis are geared toward understanding and \\ncorrecting the existing discrepancies in the business data, irrespective of any sys- \\ntem design or implementation method. Data analysis is therefore a business- \\nfocused activity, not a system-focused activity. \\nFigure 5.1 points out that two complementary methods are required to per- \\nform rigorous data analysis: \\n1. Top-down logical data modeling for integration and consistency \\n2. Bottom-up source data analysis for standardization and quality \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 161}, page_content='128 Step 5: Data Analysis \\n| RR oS SE RE EA IE RNS EEE EEE \\nTop-Down \\nLogical Data \\nModeling \\nBottom-Up \\nSource Data \\nAnalysis \\nFigure 5.1: Complementary Data Analysis Techniques \\nTOP-DOWN LOGICAL DATA MODELING \\nThe most effective technique for discovering and documenting the single cross- \\norganizationally integrated and reconciled view of business data is entity- \\nrelationship (E-R) modeling, also known as logical data modeling. A popular \\napproach to E-R modeling in the early 1980s was to model all the data for the \\nentire organization all at once. While this approach was a worthwhile architec- \\ntural endeavor, it did not yield better systems because the process was not inte- \\ngrated with the systems development lifecycle. A more effective approach is to \\nincorporate E-R modeling into every project and then merge the project-specific \\nlogical data models into one consolidated enterprise data model over time. \\nProject-Specific Logical Data Model \\nE-R modeling is based on normalization rules, which are applied during top- \\ndown data modeling as well as during bottom-up source data analysis. Using \\nnormalization rules along with other data administration principles assures that \\neach data element within the scope of the BI project is uniquely identified, cor- \\nrectly named, and properly defined and that its domain is validated for all busi- \\nness people who will be accessing the data. Thus, the normalized project-specific \\nlogical data model yields a formal representation of the data exactly as it exists in \\nthe real world, without redundancy and without ambiguity. \\nThis formal representation of data follows another normalization rule: pro- \\ncess independence. Therefore, by definition, a logical data model, which is based \\non normalization rules, is also process independent. Process independence \\nmeans that the structure and content of the logical data model are not influenced \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 162}, page_content='Top-Down Logical Data Modeling 129 \\nAccess Path \\nIndependent \\nDesign \\nIndependent \\nDatabase \\nIndependent \\nE-R Model: \\nBusiness View \\nProgram \\nIndependent \\nHardware \\nIndependent \\nTool \\nIndependent \\nFigure 5.2: Process Independence of Logical Data Models \\nby any type of database, access path, design, program, tool, or hardware, as \\nshown by the X markings in Figure 5.2. \\nBecause of its process independence, a logical data model is a business view, \\nnot a database view and not an application view. Therefore, a unique piece of \\ndata, which exists only once in the real business world, also exists only once in a \\nlogical data model even though it may be physically stored in multiple source files \\nor multiple BI target databases. \\nEnterprise Logical Data Model \\nIt is the responsibility of an enterprise architecture group, or of data administra- \\ntion if the organization does not have an enterprise architecture group, to merge \\nthe project-specific logical data models into an integrated and standardized \\nenterprise logical data model, as illustrated in Figure 5.3. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 163}, page_content='130 Step 5: Data Analysis \\nProject A Project B Project C \\n“= Enterprise Logical Data Model \\nFigure 5.3: Creating an Enterprise Logical Data Model \\nThis enterprise logical data model, also known as the enterprise information \\narchitecture, is not constructed all at once, nor is it a prerequisite for BI projects to \\nhave a completed one. Instead, the enterprise logical data model evolves over time \\nand may never be completed. It does not need to be completed because the objec- \\ntive of this process is not to produce a finished model but to discover and resolve \\ndata discrepancies among different views and implementations of the same data. \\nThese data discrepancies exist en masse among stovepipe operational systems \\nand are the root causes of an organization’s inability to provide integrated and \\nconsistent cross-organizational information to its business people. The discovery \\nof these discrepancies should be embraced and celebrated by the BI project team, \\nand especially by the business people, because poor-quality data is finally being \\naddressed and resolved. Gaining control over the existing data chaos is, after all, \\none major function of any BI decision-support initiative. \\nPaw If organizations would follow business analysis best practices by developing \\nlogical data models for all their operational applications and merging them \\n(over time) into an enterprise logical data model, the BI decision-support \\ndevelopment effort could be significantly reduced. This would enable Bl \\nproject teams to increase the speed of delivering reliable decision-support \\ninformation to the business people. In other words, the BI project teams could \\ndeliver the “quick hits” that everyone wants—and deliver them with quality. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 164}, page_content='Top-Down Logical Data Modeling 131 \\nLogical Data Modeling Participants \\nLogical data modeling sessions are typically facilitated and led by a data adminis- \\ntrator who has a solid business background. If the data administrator does not \\nhave a good understanding of the business, a subject matter expert must assist \\nhim or her in this task. \\nThe business representative and the subject matter expert assigned to the BI \\nproject are active participants during the modeling sessions. If the data is being \\nextracted from several different operational systems, multiple data owners may \\nhave to participate on the BI project because each operational system may be \\nunder the governance of a different owner. Data owners are those business indi- \\nviduals who have authority to establish business rules and set business policies \\nfor those pieces of data originated by their departments. When data discrepancies \\nare discovered, it is the data owners’ responsibility to sort out the various busi- \\nness views and to approve the legitimate usage of their data. This data reconcilia- \\ntion process is and should be a business function, not an information technology \\n(IT) function, although the data administrators, who usually work for IT, facili- \\ntate the discovery process. \\nSystems analysts, developers, and database administrators should also be \\navailable to participate in some of the modeling sessions on an as-needed basis. \\nThese IT technicians maintain the organization’s applications and data structures, \\nand they often know more than anyone else about the data—how and where it is \\nstored, how it is processed, and ultimately how it is used by the business people. \\nIn addition, these technicians often have in-depth knowledge of the accuracy of \\nthe data, how it relates to other data, the history of its use, and how the content \\nand meaning of the data have changed over time. It is important to obtain a com- \\nmitment to the BI project from these IT resources since they are often busy \\n“fighting fires” and working on enhancements to the operational systems. \\nStandardized Business Meta Data \\nA logical data model, representing a single cross-organizational business view of \\nthe data, is composed of an E-R diagram and supporting business meta data. \\nBusiness meta data includes information about business data objects, their data \\nelements, and the relationships among them. Business meta data as well as tech- \\nnical meta data, which is added during the design and construction stages, ensure \\ndata consistency and enhance the understanding and interpretation of the data in \\nthe BI decision-support environment. A common subset of business meta data \\ncomponents as they apply to data (as opposed to processes) appears in Figure 5.4, \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 165}, page_content='132 Step 5: Data Analysis \\nData \\nOwnership \\nData \\nPolicy \\nData \\nContent \\nData \\nLength \\nData \\nRelationship \\nData \\nIdentifer \\nData \\nDefinition \\nFigure 5.4: Data-Specific Business Meta Data Components \\n- A data name, an official label developed from a formal data-naming taxon- \\nomy, should be composed of a prime word, a class word, and qualifiers. Each \\ndata name uniquely identifies one piece of data within the logical data model. \\nNo synonyms and no homonyms should exist. \\n- A data definition is a one- or two-sentence description of a data object or a \\ndata element, similar to a definition in a language dictionary. If a data object \\nhas many subtypes, each subtype should have its own unique data definition. \\nA data definition explains the meaning of the data object or data element. It \\ndoes not include who created the object, when it was last updated, what sys- \\ntem originates it, what values it contains, and so on. That information is \\nstored in other meta data components (e.g., data ownership, data content). \\n- A data relationship is a business association among data occurrences in a \\nbusiness activity. Every data relationship is based on business rules and busi- \\nness policies for the associated data occurrences under each business activity. \\nA data identifier uniquely identifies an occurrence of a data object. A data \\nidentifier should be known to the business people. It should also be “minimal,” \\nwhich means it should be as short as possible (composed of just enough data \\nelements to make it unique). In addition, a data identifier should be nonintelli- \\ngent, with no embedded logic. For example, account numbers 0765587654 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 166}, page_content='Bottom-Up Source Data Analysis 133 \\nand 0765563927, where 0765 is an embedded branch number, would be poor \\ndata identifiers. \\nPaw A logical data identifier is not the same thing as a primary key in a database. \\nAlthough a data identifier can be used as a primary key, it is often replaced by \\na surrogate (‘made-up’) key during database design. \\nData type describes the structure of a data element, categorizing the type of \\nvalues (character, number, decimal, date) allowed to be stored in it. \\nData length specifies the size of a data element for its particular data type. \\nFor example, a decimal data element can be an amount field with two digits \\nafter the decimal point or a rate field with three digits after the decimal point. \\nData content (domain) identifies the actual allowable values for a data ele- \\nment specific to its data type and data length. A domain may be expressed as \\na range of values, a list of allowable values, a generic business rule, or a \\ndependency rule between two or more data elements. \\nA data rule is a constraint on a data object or a data element. A data constraint \\ncan also apply to a data relationship. A data constraint can be in the form of a \\nbusiness rule or a dependency rule between data objects or data elements, for \\nexample, “The ceiling interest rate must be higher than the floor interest rate.” \\nData policy governs the content and behavior of a data object or a data ele- \\nment. It is usually expressed as an organizational policy or a government reg- \\nulation. For example, “Patients on Medicare must be at least 65 years old.” \\nData ownership identifies the persons who have the authority to establish \\nand approve the business meta data for the data objects and data elements \\nunder their control. \\nAlthough logical data models are extremely stable, some of these business \\nmeta data components (such as data content, data rules, data policy, data owner- \\nship) occasionally change for legitimate reasons. It is important to track these \\nchanges in the meta data repository. \\nBOTTOM-UP SOURCE DATA ANALYSIS \\nData analysis cannot stop after top-down logical data modeling because the \\nsource data often does not follow the business rules and policies captured during \\nthe modeling sessions. If bottom-up source data analysis were not performed, the \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 167}, page_content='134 Step 5: Data Analysis \\ndata problems and business rule violations would not be discovered until the ETL \\nprocess was being implemented. Some data quality problems would not be dis- \\ncovered at all until after implementation, and then only if somebody complained \\nabout them. As Figure 5.5 shows, source data mapping must adhere not only to \\nthe usual technical data conversion rules but also to the business data domain \\nrules and to the business data integrity rules. \\nTechnical \\nData Conversion | <— _ Always Performed \\nBusiness \\nData Integrity \\nRules \\nOa \\nData Domain \\noo tk \\nOften Neglected \\nFigure 5.5: Source Data-Mapping Rules \\nTechnical Data Conversion Rules \\nAny time data is mapped from one system to another, whether for traditional sys- \\ntems conversion or for source-to-target mapping in BI applications, the following \\ntechnical rules must be observed. \\n1. The data types of the source data elements must match the data types of the \\ntarget data elements. \\n2. The data lengths must be adequate to allow the source data elements to be \\nmoved, expanded, or truncated into the target data elements. \\n3. The logic of the programs manipulating the source data elements must be \\ncompatible with and applicable to the content of the source data elements. \\nOtherwise the results will be unpredictable. \\nBusiness Data Domain Rules \\nA much larger effort of source data analysis revolves around business data \\ndomain rules. These rules are more important to the business people than the \\ntechnical data conversion rules. A source data element can meet all three techni- \\ncal data conversion rules but still have incorrect values. Business data domain \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 168}, page_content='Bottom-Up Source Data Analysis 135 \\nrules are rules about the semantics (meaning and interpretation) of data content. \\nThey are used to identify and correct data violations like those listed in Table 5.1. \\nBusiness Data Integrity Rules \\nSimilar to business data domain rules, business data integrity rules are much \\nmore important to improving information quality than are the technical data \\nconversion rules. The business data integrity rules govern the semantic content \\namong dependent or related data elements, as well as constraints imposed by \\nbusiness rules and business policy. Table 5.2 lists examples of violations to busi- \\nness data integrity rules. \\nTable 5.1: Data Domain Violations \\n1. Missing data values (a big issue on BI projects) \\n2. Default values; for example, “0”, “999”, “FF”, blank \\n3. Intelligent ‘dummy’ values, which are specific default (or dummy) values that actually \\nhave a meaning; for example, using a value of “888-88-8888’ for the social security \\nnumber to indicate that the person is a nonresident alien \\n4. Logic embedded in a data value, such as an implied business rule; for example, using \\nlower-valued ZIP codes (postal codes) to indicate a state on the east coast, such as \\n07456 in New Jersey, and higher-valued ZIP codes to indicate a state on the west \\ncoast, such as 91024 in California \\n5. Cryptic and overused data content; for example, using the values “A, B, C, D’ of a data \\nelement to define type of customer, while the values “E, F, G, H” of the same data \\nelement define type of promotion, and the values “I, J, K, L’ define type of location \\n6. Multipurpose data elements, that is, programmatically and purposely redefined data \\ncontent; for example, the redefines Clause in COBOL statements \\n7. Multiple data elements embedded in, concatenated across, or wrapped around free- \\nform text fields; for example, Address lines 1 through 5 containing name and address \\ndata elements: \\nAddress line 1: Brokovicz, Meyers, and Co \\nAddress line 2: hen, Attorneys at Law \\nAddress line 3: 200 E. Washington Bouleva \\nAddress line 4: rd, \\nAddress line 5: Huntsville OR 97589 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 169}, page_content='136 Step 5: Data Analysis \\nRA TAY ET TOE ICL SE SLL OED AEE ELIE DESDE DEES EEF III DIED IEEE EEL EEDA EE, \\nTable 5.2: Data Integrity Violations \\n1. Contradicting data content between two or more data elements; for example, \\n“Boston, CA’ (instead of MA) \\n2. Business rule violation; for example, for the same person, “Date of Birth = 05/02/1985’ \\nand “Date of Death = 11/09/1971” \\n3. Reused primary key (same key value used for multiple object instances); for example, \\ntwo employees with the same employee number (when one employee left the \\ncompany, his or her employee number was reassigned to a new employee) \\n4.No unique primary key (multiple key values for the same object instance); for \\nexample, one customer with multiple customer numbers \\n5. Objects without their dependent parent object; for example, job assignment points to \\nemployee 3321, but the employee database contains no employee 3321 \\n6. A real-world relationship between two data objects, or between two occurrences of \\nthe same data object, that cannot be built because it is not tracked by the operational \\nsystems; for example, a customer refinances a mortgage loan but the operational \\nsystem does not track the relationship between the old paid-off loan and the new \\nrefinanced loan \\nEvery critical and important data element must be examined for these \\ndefects, and a decision must be made whether and how to correct them. The \\ninformation consumers (business people who will be using those data elements \\nto make business decisions) and data owners should make that decision after dis- \\ncussing the impact of the cleansing effort with the business sponsor, the project \\nmanager, and the core team. \\nDATA CLEANSING \\nOne of the goals stated most frequently for BI applications is to deliver clean, \\nintegrated, and reconciled data to the business community. Unless all three sets \\nof data-mapping rules are addressed, this goal cannot be achieved. Many organi- \\nzations will find a much higher percentage of dirty data in their source systems \\nthan they expected, and their challenge will be to decide how much of it to \\ncleanse. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 170}, page_content='Data Cleansing 137 \\nData Quality Responsibility \\nData archeology (the process of finding bad data), data cleansing (the process of \\ncorrecting bad data), and data quality enforcement (the process of preventing \\ndata defects at the source) are all business responsibilities—not IT responsibili- \\nties. That means that business people (information consumers as well as data \\nowners) must be involved with the data analysis activities and be familiar with \\nthe source data-mapping rules. \\nSince data owners originate the data and establish business rules and policies \\nover the data, they are directly responsible to the downstream information con- \\nsumers (knowledge workers, business analysts, business managers) who need to \\nuse that data. If downstream information consumers base their business deci- \\nsions on poor-quality data and suffer financial losses because of it, the data own- \\ners must be held accountable. In the past, this accountability has been absent \\nfrom stovepipe systems. Data quality accountability is neither temporary nor BI- \\nspecific, and the business people must make the commitment to accept these \\nresponsibilities permanently. This is part of the required culture change, discus- \\nsion of which is outside the scope of this book. \\nThe challenge for IT and for the business sponsor on a BI project is to enforce \\nthe inescapable tasks of data archeology and data cleansing to meet the quality \\ngoals of the BI decision-support environment. \\nPaw Step 5, Data Analysis, may be time intensive since many battles may rage \\namong the business people as to the valid meaning and domain of data. \\nAlthough data-cleansing tools can assist in the data archeology process, \\ndeveloping data-cleansing specifications is mainly a manual process. IT manag- \\ners, business managers, and data owners who have never been through a data \\nquality assessment and data-cleansing initiative often underestimate the time and \\neffort required of their staff by a factor of four or more. \\nSource Data Selection Process \\nPoor-quality data is such an overwhelming problem that most organizations will \\nnot be able to correct all the discrepancies. When selecting the data for the BI \\napplication, consider the five general steps shown in Figure 5.6. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 171}, page_content='138 Step 5: Data Analysis \\nit i i) \\nIndentity | Analyze Select || Prepare data- | Select j \\n| requireddata © datacontent ==—S dataforBl =—cleansingspecs tools \\nFigure 5.6: Source Data Selection Process \\nLe Identify the required data. \\nIdentify the data of interest and the significance of this data. Data cleansing is \\na collaborative effort between business analysts who are familiar with the seman- \\ntics of the data and data quality analysts who know the program-specific \\nmeanings of the data (e.g., the use and meaning of a “flag” value or redefined \\nrecord layouts). \\n. Analyze the data content. \\nAnalyze the data for content, meaning, and importance. Many organizations \\nhave accumulated massive amounts of data in files and databases. This data \\nconstitutes a prospective gold mine of valuable business knowledge and is \\npotentially a good source for data mining. However, the quality of the data \\ncontent must be assessed first, since mining dirty data is of little value. \\n. Select the data for BI. \\nDetermine which data to include in the BI application. Select only the data \\nthat will meet core business requirements. Even with automated tools, the \\ncost of assuring data quality for an all-inclusive BI decision-support environ- \\nment becomes prohibitive for most organizations. Some questions to con- \\nsider when selecting data appear below. \\n— Is this data clean enough for decision-support usage? \\n— If not, can this data be cleansed, at least partially? Do we know how? \\n— Is the dirty data the reason for building this BI application? Is cleansing this \\ndata therefore mandatory? \\n— How much effort will it take to figure out how to cleanse the data? \\n— How much will the data-cleansing effort cost? \\n— What is the benefit of cleansing the data as opposed to moving it into the \\nBI application at the current level of dirtiness? \\n— What are the data quality expectations from the information consumers \\nand from business management in general? \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 172}, page_content='Data Cleansing 139 \\n4. Prepare the data-cleansing specifications. \\nThe IT staff, working with the business representative, will get to know the \\nbusiness rules needed to write the data-cleansing specifications. In essence, \\nthis is a source data reengineering process. \\n5. Select the tools. \\nSelect the ETL and cleansing tools. Determine whether it is appropriate and \\ncost-effective to acquire an ETL tool, a cleansing tool, or both. Examine the \\nsuitability and effectiveness of those tools. Some data-cleansing specifications \\ncan be very complicated. Be sure the tools are capable of handling them. \\nPaw Automated tools do not eliminate the manual labor of source data analysis; \\nthey only reduce it. \\nKey Points of Data Selection \\nWhen identifying and selecting the operational data to be used to populate the BI \\ntarget databases, some key points should be considered. Applying the source data \\nselection criteria shown in Figure 5.7 minimizes the need for and effort of data \\ncleansing. \\n* Data integrity \\n* Data precision \\nv4 * Data accuracy \\nSN + Data reliability \\nES: * Data format \\nFigure 5.7: Source Data Selection Criteria \\n- Data integrity: How internally consistent is the data? This is the most impor- \\ntant criterion. \\n— The greater the proportion of manually entered data (data keyed in with \\nfew or no data controls, edits, and validations), the lower the integrity. \\n— Programming errors also contaminate great masses of data—and do so \\nautomatically. \\n— The lower the integrity, the greater the cleansing requirement. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 173}, page_content='140 Step 5: Data Analysis \\n- Data precision: How precise is the data? This is the next important criterion. \\n— How is the data represented internally? \\n— For numeric data, what is the scale and precision of the data? \\n— For date data, how is it formatted? \\n+ Data accuracy: How correct is the data? \\n— Are there edit checks in the data entry program? \\n— Are dependent values cross-checked? For example, does the data entry pro- \\ngram forbid an expiration date to precede an effective date? \\n— Is there an operational process in place for correcting data? \\n— Are calculated values stored? What, if any, mechanisms are in place to keep \\nthese values accurate? \\n* Data reliability: How old is the data? \\n— What generation is the data (month-end, weekly, daily)? \\n— Was the data obtained from direct sources or from downloads? \\n— Is the source of the data known? \\n— Is the data a duplicate of data in another data store? If so, is the data current? \\n* Data format: The closer the data is to the destination data format, the fewer \\nthe conversion requirements will be. From highest to lowest, the format pri- \\norities are: \\n— Data from a relational database (e.g., DB2, Oracle) \\n— Data from a nonrelational database (e.g., IMS, CA- IDMS) \\n— Flat files (e.g., VSAM, ISAM) \\nPaw Source data quality will be only as good as the enforcement of quality pro- \\ncesses in the operational systems. Mandatory quality processes should \\ninclude data entry rules and edit checks in programs. If those processes are \\nnot enforced or do not exist, data usually gets. corrupted, regardless of \\nwhether the data is in a relational database or in an old VSAM file. \\nTo Cleanse or Not to Cleanse \\nMany organizations struggle with this question. Data-cleansing research indicates \\nthat some organizations downplay data cleansing to achieve short-term goals. \\nThe consequences of not addressing poor-quality data usually hit home when their \\nbusiness ventures fail or encounter adverse effects because of inaccurate data. \\nIt is important to recognize that data cleansing is a labor-intensive, time- \\nconsuming, and expensive process. Cleansing all the data is usually neither cost- \\njustified nor practical, but cleansing none of the data is equally unacceptable. It is \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 174}, page_content='Data Analysis Activities 141 \\ntherefore important to analyze the source data carefully and to classify the data \\nelements as critical, important, or insignificant to the business. Concentrate on \\ncleansing all the critical data elements, keeping in mind that not all data is equally \\ncritical to all business people. Then, cleanse as many of the important data ele- \\nments as time allows, and move the insignificant data elements into the BI target \\ndatabases without cleansing them. In other words, you do not need to cleanse all \\nthe data, and you do not need to do it all at once. \\nCleansing Operational Systems \\nWhen the selected data is cleansed, standardized, and moved into the BI target \\ndatabases, a question to consider is whether the source files and source databases \\nshould also be cleansed. Management may ask, why not spend a little extra \\nmoney and time to cleanse the source files and databases so that the data is con- \\nsistent in the source as well as in the target? This is a valid question, and this \\noption should definitely be pursued if the corrective action on the source system \\nis as simple as adding an edit check to the data entry program. \\nIf the corrective action requires changing the file structure, which means \\nmodifying (if not rewriting) most of the programs that access that file, the cost \\nfor such an invasive corrective action on the operational system is probably not \\njustifiable—especially if the bad data is not interfering with the operational needs \\nof that system. Remember that many companies did not even want to make such \\ndrastic changes for the now infamous Y2K problem; they made those changes \\nonly when it was clear that their survival was at stake. Certainly, a misused code \\nfield does not put an organization’s survival at stake. Hence, the chances that \\noperational systems will be fixed are bleak. \\nDATA ANALYSIS ACTIVITIES \\nThe activities for data analysis do not need to be performed linearly. Figure 5.8 \\nindicates which activities can be performed concurrently. The list below briefly \\ndescribes the activities associated with Step 5, Data Analysis. \\n1. Analyze the external data sources. \\nIn addition to requiring internal operational source data, many BI applications \\nneed data from external sources. Merging external data with internal data \\npresents its own set of challenges. External data is often dirty and incomplete, \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 175}, page_content='142 Step 5: Data Analysis \\nSSS ES SS PS AE EE EE ES OE A SE LE OE SE IE SSSI SI \\nExpand enterprise \\nlogical data model \\nRefine logical \\ndata model \\nWrite data-cleansing \\nspecifications \\nAnalyze external \\ndata sources \\nResolve data \\ndiscrepancies \\nAnalyze source \\ndata quality \\nFigure 5.8: Data Analysis Activities \\nand it usually does not follow the same format or key structure as internal \\ndata. Identify and resolve these differences during this step. \\n2. Refine the logical data model. \\nA high-level, project-specific logical data model should have been created \\nduring one of the previous steps. In addition, some or all of the internal and \\nexternal data may have been modeled on other projects and may already be \\npart of the enterprise logical data model. In that case, extract the representa- \\ntive portion of the enterprise logical data model and expand it with the new \\ndata objects, new data relationships, and new data elements. If the required \\ndata has not been previously modeled, create a new logical data model for the \\nscope of this BI project. It should include all internal as well as external data \\nelements. \\n3. Analyze the source data quality. \\nAt the same time that the logical data model is created or expanded, the qual- \\nity of the internal and external source files and source databases must be ana- \\nlyzed in detail. It is quite common that existing operational data does not \\nconform to the stated business rules and business policies. Many data ele- \\nments are used for multiple purposes or are simply left blank. Identify all \\nthese discrepancies and incorporate them into the logical data model. \\n4, Expand the enterprise logical data model. \\nOnce the project-specific logical data model is relatively stable, merge it back \\ninto the enterprise logical data model. During this merge process additional \\ndata discrepancies or inconsistencies may be identified. Those will be sent \\nback to the BI project for resolution. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 176}, page_content='Deliverables Resulting from These Activities 143 \\n5. Resolve data discrepancies. \\nOccasionally data discrepancies discovered during data analysis involve other \\nbusiness representatives from other projects. In that case, summon the other \\nbusiness representatives as well as the data owners to work out their differ- \\nences. Either they will discover a new legitimate subtype of a data object or a \\nnew data element, which must be modeled as such, or they will have to \\nresolve and standardize the inconsistencies. \\n6. Write the data-cleansing specifications. \\nOnce all data problems are identified and modeled, write the specifications \\nfor how to cleanse the data. These specifications should be in plain English so \\nthey can be validated by the data owner and by business people who will use \\nthe data. \\nDELIVERABLES RESULTING FROM THESE ACTIVITIES \\n1. Normalized and fully attributed logical data model \\nThis project-specific logical data model is a fully normalized entity-relationship \\ndiagram showing kernel entities, associative entities, characteristic entities, \\ncardinality, optionality, unique identifiers, and all attributes. \\n2. Business meta data \\nThe business entities and attributes from the logical data model must be \\ndescribed with meta data. Data-specific business meta data components \\ninclude data names, data definitions, data relationships, unique identifiers, \\ndata types, data lengths, domains, business rules, policies, and data owner- \\nship. These are usually captured in the tool repository of the computer-aided \\nsoftware engineering (CASE) tool. \\n3. Data-cleansing specifications \\nThis document describes the cleansing logic that must be applied to the \\nsource data in order to bring it into compliance with the technical data con- \\nversion rules, the business data domain rules, and the business data integrity \\nrules. This document will be used to create the transformation specifications \\non the source-to-target mapping document in Step 9, ETL Design. \\n4, Expanded enterprise logical data model \\nThis deliverable is produced behind the scenes by data administration or the \\nenterprise architecture group when it merges the project-specific logical data \\nmodel into the enterprise logical data model. Any rejected entities or \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 177}, page_content='144 Step 5: Data Analysis \\nSa \\nattributes and any discrepancies between the models will be presented to the \\nBI project team for resolution. \\nROLES INVOLVED IN THESE ACTIVITIES \\n® Business representative \\nThe business representative assigned to the BI project is a major contributor \\nduring the top-down logical data modeling activities as well as the bottom-up \\nsource data analysis activities. He or she provides the business meta data to the \\ndata administrator and assists the data quality analyst in analyzing the source \\nfiles. \\n@ Data administrator \\nThe data administrator is trained in logical data modeling, business meta \\ndata, normalization techniques, business data domain rules, business data \\nintegrity rules, and standardization methods. The job description of a data \\nadministrator matches the activities of the Data Analysis step. The data \\nadministrator will be the lead person during this step and will facilitate all of \\nthe data modeling sessions. He or she also has the responsibility of document- \\ning the logical data model and the supporting business meta data in the CASE \\ntool. \\n@ Data quality analyst \\nThe data quality analyst is a systems analyst, trained in using the technical data \\nconversion rules, in reading as well as writing programs, and in extracting \\ndata from all types of source files and source databases. Finding the data viola- \\ntions in the source files and source databases is the prime responsibility of the \\ndata quality analyst. He or she works closely with the data administrator to \\nmodel data anomalies and to correct the data violations with help from the \\nbusiness representative and the data owners. \\n@ ETL lead developer \\nThe ETL lead developer must be involved in the modeling reviews and must \\nbe aware of the magnitude of data quality problems found in the source files \\nand source databases. He or she needs to understand the complexity of cleans- \\ning the data because the cleansing algorithms must be incorporated into the \\nETL process. In some cases, the ETL tool will not be able to support some \\ncleansing algorithms, and custom code may have to be written. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 178}, page_content='Risks of Not Performing Step 5 145 \\n® Meta data administrator \\nAs the custodian of meta data and the administrator of the meta data reposi- \\ntory, the meta data administrator needs to know what business meta data \\ncomponents are being collected and how. Some meta data components may \\nbe entered into a CASE tool, while other components may be captured in \\nword processing documents or in spreadsheets. The meta data administrator \\nwill have to extract the meta data components from the various files and tools \\nand merge them into the meta data repository. \\n® Stakeholders (including data owners) \\nThe business people using the BI applications are usually downstream infor- \\nmation consumers and not the data owners. During this step, both informa- \\ntion consumers and data owners have the responsibility to standardize the \\nbusiness data and to set rules and policies for the data. Continuing disagree- \\nments over data between data owners and information consumers must be \\npushed up to business executives for resolution. \\n@ Subject matter expert \\nThe subject matter expert assists the data administrator and data quality analyst \\nby interpreting the business data, explaining the business rules and policies for \\nthe data, and determining the domain (valid values) of the data. In addition, \\nthe subject matter expert is responsible for finding data problems in the source \\ndata files and source databases and for suggesting how to correct them. \\nRISKS OF NOT PERFORMING STEP 5 \\nBusiness managers, IT managers, and IT technicians often do not want to take \\nthe time to perform rigorous data analysis, which involves logical data modeling, \\nsource data archeology, and data cleansing. They see those activities as a waste of \\ntime. They judge the success of a BI project by the speed with which it gets deliv- \\nered, rather than by the quality of its deliverable. As a result, organizations often \\ncreate stovepipe data marts and populate them “suck and plunk” style with the \\nsame data they have on the source files and source databases, thereby copying all \\nthe existing data impairments to the new BI decision-support environment. \\nInstead of eliminating their existing data problems, they just compounded \\nthem—now there are additional redundant and inconsistent BI target databases \\nand applications to maintain. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 179}, page_content='146 Step 5: Data Analysis \\nOf all the 16 steps presented in Business Intelligence Roadmap, Step 5, Data \\nAnalysis, is the most critical cross-organizational step. This step is a major differen- \\ntiator between a traditional systems development approach and a cross-organizational \\ndevelopment approach. The activities of business-focused data analysis force the \\ninformation consumers and the data owners to reconstruct a cross-organizational \\nview and to clean up their expensive data chaos, not only in the BI decision-support \\nenvironment but in their operational systems as well. These are all prerequisites \\nfor improving the business executives’ abilities to make decisions. Without this \\nstep, you are just building another traditional stovepipe decision-support system, \\nnot a BI solution. \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nAdelman, Sid, and Larissa Terpeluk Moss. Data Warehouse Project Management. \\nBoston, MA: Addison-Wesley, 2000. \\nAiken, Peter H. Data Reverse Engineering: Slaying the Legacy Dragon. New York: \\nMcGraw-Hill, 1995. \\nAtre, Shaku. Data Base: Structured Techniques for Design, Performance, and Man- \\nagement, Second Edition. New York: John Wiley & Sons, 1988. \\nBischoff, Joyce, and Ted Alexander. Data Warehouse: Practical Advice from the \\nExperts. Upper Saddle River, NJ: Prentice Hall, 1997. \\nBrackett, Michael H. Data Resource Quality: Turning Bad Habits into Good Prac- \\ntices. Boston, MA: Addison-Wesley, 2000. \\n. The Data Warehouse Challenge: Taming Data Chaos. New York: John \\nWiley & Sons, 1996. \\nDownes, P. M. Practical Data Analysis. Pinner, Middlesex, UK: Blenheim Online \\nPublications, 1989. \\nEnglish, Larry P. Improving Data Warehouse and Business Information Quality: \\nMethods for Reducing Costs and Increasing Profits. New York: John Wiley & Sons, \\n1999) \\nHoberman, Steve. Data Modeler’s Workbench: Tools and Techniques for Analysis \\nand Design. New York: John Wiley & Sons, 2001. \\nInmon, William H., John A. Zachman, and Jonathon G. Geiger. Data Stores, Data \\nWarehousing and the Zachman Framework: Managing Enterprise Knowledge. New \\nYork: McGraw-Hill, 1997. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 180}, page_content='Bibliography and Additional Reading 147 \\nJarke, Matthias, Maurizio Lenzerini, Yannis Vassiliou, and Panos Vassiliadis. Fun- \\ndamentals of Data Warehouses. New York: Springer, 2000. \\nKuan-Tsae, Huang, Yang W. Lee, and Richard Y. Wang. Quality Information and \\nKnowledge Management. Upper Saddle River, NJ: Prentice Hall, 1998. \\nReingruber, Michael C., and William W. Gregory. The Data Modeling Handbook: \\nA Best-Practice Approach to Building Quality Data Models. New York: John Wiley & \\nSons, 1994. \\nRoss, Ronald G. The Business Rule Concepts. Houston, TX: Business Rule Solu- \\ntions, Inc., 1998. \\nSimsion, Graeme. Data Modeling Essentials: Analysis, Design, and Innovation. \\nBoston, MA: International Thomson Computer Press, 1994. \\nVon Halle, Barbara. Business Rules Applied: Building Better Systems Using the Busi- \\nness Rules Approach. New York: John Wiley & Sons, 2001. \\nZachman, John. The Zachman Framework: A Primer for Enterprise Engineering \\nand Manufacturing. La Canada, CA: Zachman International, 2002. \\nInformation Impact International, Inc.: http://www. infoimpact.com \\nZachman Institute for Framework Advancement: http://www.zifa.com \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 181}, page_content=\"eM tinted core! bos omilen Paina’ dee \\n— QagePhab. |) Ste ie cigy ? ERR agape? clan wre \\nAGATA EO) eres relent hh Geet GAT 5 \\ndee peo Real canes Ta Web hatte , \\nyee Set Sy Os Ve isle \\n. Soc omar pei ce: tals ) Sth edve Oomgetish Me a \\n7 \\n: \\n: \\nFae, ‘ a, 1 (> \\n- season ST tid i gaia.) 20h seas ia ae : \\n7 won aes 281, : \\na Pe giant! angie, olameereS Gell on 3 \\n400) gor iajeqme) nord? tk \\net age ion aid eri grohiggiects ity. 4st ean \\neel, Wee fea Weg aaa 8 | is yee \\nHediigh ya ees soe ih mary, fame Rata) ae face ie wen ue \\nVatiane dias tee \\nua Atee the a7 rh eA Sere IN | 20! dana cee \\n: ee ee andes eae \\nPan DIRE. Ore “Vs Aaaer bleu Ce > Paes an eae \\nMagied, \\\\ stad 665m fi wpe, (4) Fence 140 all’: Cry \\nPeper, Mica Vi Das Kesoate “Aiibe~ fh on an ot Gd i Fee, hater, MAAculcr--00 a, 3,0 \\npee, [Og Uicay 4 a04 sats ealloage ie Dae Chak? Stew Verte Je \\nWide @ Sai, 1 \\nWiese, I At fre imas [4G tna gen, O24 nein aiieiais us Pine \\nPiles 2's arid, | dpey \\npagar Kayrry 0 igen itey Tie WR inigs die) ft wiipen biaiiienié \\n(OMS & Geviadins [> 97 908 lnprmpian Pais ‘New Vereen dew hel \\nt \\n= fo \\nore \\ner iien, <aiy <cow Cheb Werhhneet Tiadt wil oe \\ntr [ogtee—feee YL Adin eG DP de. Sy, \\nbe, ‘AGL eet), ii A oA ism 6SC \\nVe reap aml oh * eee Freeeediied) \\nich: NOG iveeealy, | \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 182}, page_content='Justification \\nPlanning \\n4} Application | Meta Dat \\n/\\\\ Prototyping /, & tory \\nCHAPTER SIX \\nStep 6: Application \\nPrototyping \\nCHAPTER OVERVIEW \\nThis chapter covers the following topics: \\n@ Things to consider about prototyping \\n@ How prototyping can provide an effective way to validate \\napplication requirements \\n@ The concept of “time-boxing’ prototyping activities \\n@ Best practices for prototyping \\n@ Prototyping considerations such as proper team structure, \\ndeadline management, scope and deliverables, and busi- \\nness participation \\nm@ The purposes and implications of the six different types of \\nprototypes: show-and-tell, mock-up, proof-of-concept, \\nvisual-design, demo, and operational \\n@ Guidelines for prototyping \\nm@ An example of a skill survey used to determine the skill \\nsets of the business people who will participate in the pro- \\ntotype and will later use the BI application \\n@ Brief descriptions of the activities involved in application \\nprototyping, the deliverables resulting from those activities, \\nand the roles involved \\n@ The risks of not performing Step 6 \\n149 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 183}, page_content='150 Step 6: Application Prototyping \\nTHINGS TO CONSIDER \\nObjectives \\nVY Are the objectives for this prototype clear? \\nY Do we know what kind of prototype we want to build? \\nV Have we developed a prototype in the past? \\n/ If we have, what was our experience? What lessons did we learn? \\nY How will the business people benefit from prototyping this BI application? \\nY How will the organization benefit? \\nScope and Schedule \\n¥ What is the scope of the prototype? \\nY How will we manage scope changes? \\nY How much time do we have for this prototype? \\n/Y How many versions (iterations) of the prototype are we planning to create \\nbefore starting real development work? \\nVY How will we time-box prototype activities? By version? By activity? By \\ndeliverable? \\nDeliverables \\nVv Are the requirements clear about the prototype deliverables? \\n¥V What reports do the business people expect from the BI application? Will we \\nprototype all of those reports? If not, which ones? \\n¥ What queries will the business analysts write against the BI target databases? \\nWhich of these queries should we prototype? \\nVY Are any business analysts currently using spreadsheets to satisfy their query \\nneeds? Will the prototype include reports to replace all those spreadsheets? \\n¥ What data do we need for the prototype database? \\n¥ Will a BI application interface be required? If so, are we prototyping it? For \\nhow many business people? What do they have now? \\nVv Are we going to include a Web front end in the prototype? \\nBusiness Participation \\n¥Y Who will use the BI application? How many of those business people will be \\ninvolved with the prototype? \\n¥ Where are the business people located? How will they connect to the BI \\napplication? By local area network (LAN)? By wide area network (WAN)? \\nThrough the intranet? \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 184}, page_content='Purposes of Prototyping 151 \\nVv Have we worked with these business people in the past? \\n¥ What types of technical skills do they have? What technical skills are needed \\nto participate in the prototype? \\n¥Y How much will they participate in this prototype? Hands-on, full-time \\ninvolvement? Occasional demo reviews only? \\nTools and Methods \\nv What tools will we use to develop the prototype? \\n¥ Will we use the same tools to develop the final BI application? \\nY How will lessons learned be communicated to the extract/transform/load \\n(ETL) team? \\nThere is nothing business people like more than to see their requirements \\nturn into a tangible deliverable they can “touch and feel” very quickly. A proto- \\ntype accomplishes that goal. \\nPURPOSES OF PROTOTYPING \\nPrototyping can be an effective method for validating the project requirements \\nand finding missing pieces and discrepancies in the requirements. Business peo- \\nple seldom think of all the details when they state their requirements. They often \\nforget to include dependent processes or related data. A prototype can also help \\nthem focus on their access path requirements because they will see the capabilities \\nof the BI technology and the access and analysis portion of their BI application. \\nIf time and budget permit, building a prototype for the original requirements \\nallows the business community to test, extend, or change those requirements at \\nan early stage when the impact on the project schedule is not yet high. The costs \\nof experimenting with different database designs, different visualization meth- \\nods, different development tools, or different application programming tech- \\nniques are much less during prototyping than during development because they \\ndo not affect a full-scale application. \\nAnother purpose for prototyping is to verify that the design as well as the \\nselected tools, database management system (DBMS), and other technology com- \\nponents will be appropriate for the BI decision-support environment. If the func- \\ntions of all technology components perform as expected during the prototype \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 185}, page_content='152 Step 6: Application Prototyping \\ndevelopment, then the chances of having a successful BI implementation are \\nincreased. Therefore, testing the technology features is a valuable benefit of pro- \\ntotyping, regardless of whether you are using existing technology components or \\nbuying new ones. \\nTesting the technology for performance, however, is usually not a valid pur- \\npose for a prototype. A prototype is not a stress-test environment. It is usually \\nloaded with only small sets of data, and its main purpose is to try out visual \\ninterfaces and functionality. \\nTime-Boxing \\nEveryone likes prototyping. It is fun and creative, dynamic and exciting—and it is \\nmeant to be short. Thus, a word of caution: It is tempting to endlessly expand the \\nscope of the prototype. Prolonging the prototyping effort beyond its original \\npurpose reduces the cost-effectiveness of the prototype and produces diminish- \\ning returns, as shown in Figure 6.1. It also reduces control over the project as the \\nprototype starts to feel like a runaway train. \\nEach prototype iteration should be limited in duration to just a few weeks, \\nand the activities within each prototype iteration should be time-boxed for every \\nweek, as illustrated in Figure 6.2. Prototyping activities are carefully planned and \\nmonitored. Each participant must know which tasks to perform and which task \\ndeliverables to produce by the end of every week. \\nAs unexpected discoveries arise (one main reason for prototyping is to find \\nout what does not work), the plan should be revised for every team member who \\nis affected by that discovery. The plan and schedule for the prototype can be \\nextended or shortened. A plan does not dictate what must be done; it is only a \\nproposal for activities that make the most sense at the time. If something does \\nnot make sense anymore, change it. \\nCalendar \\n1/12 [ ano! | Rigen Ween | \\n| RT eee \\nDiminishing Returns \\nFigure 6.1: Uncontrolled Prototyping Activity \\nPrototype \\nDeliverable \\nCost-Effective \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 186}, page_content='Best Practices for Prototyping 153 \\nCalendar \\n1/26 2/9 2/16 \\nFigure 6.2: Controlled (Time-Boxed) Prototyping Activity \\nBEST PRACTICES FOR PROTOTYPING \\nA few lessons learned regarding prototyping appear below. \\nLimit the scope: Limit the functional scope as well as the data scope of each \\nprototype iteration to a specific subset of the application. This helps to focus \\nthe business people on one small piece of their overall requirements. They \\ncan learn about the capabilities and limitations of the new environment with- \\nout getting bogged down with the complexities of the whole development \\neffort. It is also a good general training indoctrination in how to use the new \\ntechnology and the new application. \\nUnderstand database requirements early: The prototype will help the data- \\nbase administrator understand the access path requirements to the BI target \\ndatabases, the reporting dimensions needed for application development \\nwith online analytical processing (OLAP) tools, the levels of aggregation and \\nsummarization needed, and what type of data is usually accessed together. \\nThe database administrator will be able to start making some database design \\ndecisions, such as how to cluster tables and where to place the data sets. The \\ndatabase administrator will also get a sense of the performance expectations \\nand the anticipated size of the databases. \\nChoose the right data: Carefully select sample data for the prototype. The \\nsample data set should be a meaningful representation of the source data so \\nthat all functions and features of the prototype can be tested. Keep the sample \\ndata set small so as not to spend too much time on loading and testing. Try to \\nselect clean data for the prototype. You do not want to have your prototype \\nresults tarnished because of dirty data. You also do not want to take the time \\nto cleanse data while creating the prototype unless the purpose of the proto- \\ntype is to test your transformation logic or the transformation functionality \\nof an ETL tool or a data-cleansing tool. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 187}, page_content='154 Step 6: Application Prototyping \\n- Test tool usability: Test the usability of the access and analysis tools. Make \\nsure the query tools are easy to use and do not intimidate the business people \\nwho need to use them. Test the features of the report writer on one of the \\nmore complicated reports. Give the business people hands-on experience \\nwith the OLAP tool. Although multidimensional analysis is relatively intui- \\ntive for most business people, the capability of dynamically drilling down and \\nrolling up with a tool is still a new experience for many. \\nInvolve the business people: Test the prototype with more than one business \\nperson. Try it with a single business person first, then add more business peo- \\nple from different business units or departments. Be sure to measure the per- \\nformance of the prototype as you add more people. Observe the business \\npeople while they use the prototype. You will be able to see how they react to \\nthe prototype when you test it with them. Address any difficulties or misgiv- \\nings immediately so that the problems do not become roadblocks during \\napplication development. \\nConsiderations for Prototyping \\nTo build a successful prototype and to produce the optimal physical database \\ndesign, the prototyping team must first understand how the business people will \\nretrieve the data and what they will do with it. The team members should ask \\nsuch questions as the following: \\n- Are there frequently asked business questions? \\n+ What dimensions of the data are prevalent on reports? \\n- Are there reporting patterns among departments? \\nPrototyping is a useful technique to ensure that the business people and the \\nprototyping team understand and agree on the functional business requirements. \\nA prototype could also ensure that everyone agrees on what is expected from the \\nfinal BI application. Important considerations about developing a prototype are \\nbriefly described below. \\n* Prototyping team: The prototyping team should be small. One of the many \\nreasons why some software companies have become successful is that their \\nproject teams are very small. They do not staff their projects with more than \\nseven or eight people. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 188}, page_content='Best Practices for Prototyping 155 \\nDeadline management: When project teams routinely miss deadlines, shrink \\nthe size of the team. This is exactly the opposite of what many organizations \\ndo. Most organizations put more people on the team, which usually backfires \\nbecause more people require more time for communication, and that slows \\ndown the project even more. By shrinking the size of the team, the people \\nremaining on the team may have more work to do, but they will get things \\ndone faster. \\nScope: Try to build “slimware,” that is, deliverables with the barest number of \\nfeatures possible to satisfy the purpose of the prototype. This can head off \\n“code bloat” down the road when the application code needs to be written. \\nDeliverables: Each prototype should have a well-defined deliverable. Plan to \\nuse an iterative process for prototyping, and try to control the activities on \\neach prototype iteration in weekly increments with weekly deliverables. \\nDelivery methods: Test the graphical user interfaces (GUIs), Web-enabled \\ninterfaces, and other delivery methods. \\nData integration: Try to have only a few data integration requirements in \\nyour prototype scope. Prototyping should not be used to address all project \\nrequirements but only to get a basic understanding of the major deliverables. \\nBusiness participation: The prototype should include at the most five to \\neight business people. Consider the politics involved in selecting the right \\nblend of business people for the prototyping activities. \\nSuccess criteria: Encourage business participation in the prototyping process \\nfrom the beginning, especially during the activities of needs assessment and \\nGUI construction. Be sure to include the business representative and the \\nbusiness sponsor when establishing the success criteria for the prototype. \\nRemember, their definition of success or failure is the one that counts. You \\nmay also consider building a coalition comprised of the business representa- \\ntive and the business sponsor, IT managers, and other senior business man- \\nagers who will support the BI project beyond the prototype. \\nBefore starting the prototype, review the Things to Consider section at the \\nbeginning of this chapter to determine the overall scope of the prototype, the \\nprototype’s purpose, how many business people will participate, and the level of \\ncomplexity. Use this information to carve out and focus on one or two essential \\nfunctions that have the highest payback. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 189}, page_content='156 Step 6: Application Prototyping \\nTYPES OF PROTOTYPES \\nPrototyping is a visual communication technique used to help the BI project \\nteam understand and refine the scope of the project requirements. There are dif- \\nferent types of prototypes, each with a different purpose and life expectancy. \\nThese prototypes are discussed below in the order of least to most functionality, \\nsophistication, and reusability. \\nShow-and-Tell Prototype \\nA show-and-tell prototype serves as a demo for management and business peo- \\nple, as described in Table 6.1. It could also be used to obtain budget approval or \\nto get a business sponsor for the BI application during Step 1, Business Case \\nAssessment. \\nTable 6.1: Show-and-Tell Prototype \\nPurposes Implications \\n* Avoid costly coding by only * Business people may mistake the \\ndemonstrating “look and feel.’ prototype for a functioning system. Be \\n¢ Gain buy-in from business people. sure to explain that there is no \\n* Gain business support for the BI functionality at all—it is only for visual \\napplication. communication. \\n¢ Secure funding for the BI application. * Concentrate on displaying the most \\nimportant screens to get business buy-in. \\nMock-Up Prototype \\nThe purpose of a mock-up prototype is to understand the access and analysis \\nrequirements and the business activities behind them. Therefore, mock-up pro- \\ntotypes are completed in a very short time, as mentioned in Table 6.2. Since the \\nmock-up prototype is just a front for a BI application, it is usually a throwaway. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 190}, page_content='Types of Prototypes 157 \\nIB ESSE PR I ST SS SE I IE \\nTable 6.2: Mock-Up Prototype \\nPurposes Implications \\n¢ Understand the application * Pay attention to interfaces: building \\nrequirements. interfaces gives the impression of \\n* Understand the business activities. working code. \\n* Initiate system functions. * Use a less sophisticated programming \\n* Speed is of the essence. language to build the prototype faster. \\nFor example, you may want to use Visual \\nBasic for the prototype and write the final \\naccess and analysis application in C++. \\nProof-of-Concept Prototype \\nThe purpose of a proof-of-concept prototype is to explore implementation \\nuncertainties. This method allows the identification of risks and unknowns, \\nthereby enabling the decision whether or not to proceed with the project, as indi- \\ncated in Table 6.3. \\nTable 6.3: Proof-of-Concept Prototype \\nPurpose Implications \\n¢ Explore implementation risks and * Stay narrow in scope. \\nunknowns to decide whether or not to * Do not build any application interfaces. \\nproceed. * Build only enough functionality to make \\na go/no-go decision. \\nVisual-Design Prototype \\nA visual-design prototype is a step up from a mock-up. It is ideal for developing \\ninterface specifications for the access and analysis portion of the BI application. \\nGood interface specifications are mandatory, as listed in Table 6.4. Visually, it is \\nimportant for business people to have as much information as possible on the \\nsame screen to avoid toggling between screens. Once the code is generated, this \\ntype of prototype may survive and be incorporated into the final BI application. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 191}, page_content='158 Step 6: Application Prototyping \\nTherefore, unless you are certain that this prototype is a throwaway, stay away \\nfrom “quick and dirty” code. There is no such thing as a one-time-use-only program. \\nOnce a program works, even if it does not work well, it is liable to be used forever. \\nTable 6.4: Visual-Design Prototype \\nPurposes Implications \\n¢ Understand the design of visual * If the intent is to use the prototype like a \\ninterfaces. mock-up only, write it in a language \\n* Develop specifications for visual different from the delivery language so \\ninterfaces and displays. you can complete it faster. \\n¢ If the intent is to potentially use the \\nprototype for the final BI application, \\nwrite it in the delivery language from the \\nstart so you can reuse it for the real BI \\napplication. Allocate additional time for \\nwriting quality code. \\nDemo Prototype \\nA demo prototype is used to convey vision and partial functionality to business \\npeople, business managers, potential customers, or other external groups, as indicated \\nin Table 6.5. It is not fully functioning, but it is more sophisticated than code stubs. \\nTable 6.5: Demo Prototype \\nPurposes Implications \\n* Convey the vision of the BI application to —* On the initial screen, graphically convey \\nthe business people or to external groups. what percentage of the application is \\n* Test the market for the viability of a full- represented by the prototype so you set \\nscale BI application. realistic expectations. Otherwise, the \\n* Test or demonstrate the usability of the business people may mistake this \\nproposed access and analysis portion of prototype for a functioning application. \\nthe BI application. \\nSS RS SSS SSE TR ED RA TTR OR SS SSS EEE \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 192}, page_content='Building Successful Prototypes 159 \\nOperational Prototype \\nAn operational prototype is the most involved, most extensive, and most time- \\nconsuming of all prototypes. As a result, it is also the most expensive, most com- \\nplete, most functional, and most likely to survive and evolve into the real access \\nand analysis portion of the BI application. The purpose of this prototype is to \\nobtain feedback from the business people who participate in the prototyping \\nactivities through the actual use of the application’s functionality. This is accom- \\nplished by designing the entire access and analysis application up front but using \\nonly a basic part of the code to generate the prototype. It can be considered a bare- \\nbones application, with just enough functionality to evoke feedback, as men- \\ntioned in Table 6.6. This type of prototype is also excellent for hands-on training. \\nTable 6.6: Operational Prototype \\nPurposes Implications \\n* Create an almost fully functioning pilot * On the initial screen, graphically convey \\nfor alpha or beta use of the access and what percentage of the application is \\nanalysis portion of the BI application. represented by the prototype so you can \\n¢ Obtain feedback through real hands-on set realistic expectations. \\ntrials of the bare-bones application. * This prototype has a high potential for \\nevolving into the final access and \\nanalysis portion of the BI application. \\n¢ Write the prototype in the delivery \\nlanguage. Allocate additional time for \\nwriting quality code. \\nBUILDING SUCCESSFUL PROTOTYPES \\nBuilding a successful prototype starts with defining its purpose and setting its \\nscope. The purpose and scope of a prototype can never be the implementation of \\na full-scale BI application, which is comprised of an ETL process, an access and \\nanalysis application, and a meta data repository. There are two main reasons why \\na prototype can never produce a complete BI application. \\n1. While portions of the ETL process and some functionality of the ETL tool \\ncan be tested in a prototype, the entire ETL process is too complicated and \\nwould take too long to be an appropriate scope for prototyping. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 193}, page_content='160 Step 6: Application Prototyping \\n2. Similarly, the design and some functionality of the meta data repository can \\nbe tested in prototyping, but developing a robust, production-worthy, enter- \\nprise-wide meta data repository is outside the scope of prototyping. \\nTherefore, the most appropriate and the most common purpose and scope \\nfor prototyping is to demonstrate the overall usefulness of the access and analysis \\nportion of a BI application by using a small subset of functionality and data. \\nConsequently, prototyping is the best way for the project team members of the \\nApplication track to perform “systems analysis,” which is systems-focused analy- \\nsis of functional requirements that leads to application design. To take it a step \\nfurther, if the BI project team chooses to build an operational prototype, it is \\nconceivable that after several prototyping iterations the operational prototype \\ncan evolve into the final access and analysis application. \\nOnce the prototyping activities are in progress, it is quite common to make \\nnew discoveries that lead to new requirements, which can affect not only the scope \\nof the prototype but also the scope of the source data analysis activity, the ETL \\nprocess, and the meta data repository. Be sure to review and renegotiate the project \\nconstraints when the scope changes, and be sure to communicate daily with the \\nproject team members of the ETL track and the Meta Data Repository track. \\nPrototype Charter \\nPrepare a prototype charter, which is similar to a project charter but much smaller \\nand less formal. A prototype charter is an agreement between the business sponsor \\nand the IT staff for developing a prototype. It should include the following sections: \\n- The primary purpose of the prototype, for example, whether the focus is on \\ntesting queries for marketing analysis, demonstrating executive information, \\nrunning a financial analysis report, or fulfilling another specific purpose. \\n- The prototype objectives, including a statement of what type of prototype \\nwill be built. Each type of prototype takes a different amount of effort and \\nproduces different results. It must be clear to the business people what the \\nlimitations of the prototype will be. \\n: A list of business people who will: \\n— Participate in building the prototype \\n— Sign off on the prototype \\n— Use (test) the prototype \\n* The data, including information on the type of data, the amount of data, and \\nthe consolidation level of data that will initially be brought into the prototype \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 194}, page_content='Building Successful Prototypes 161 \\n> The hardware and software platforms on which the prototype will be con- \\nstructed and the language in which it will be written. \\n- The measures of success should be itemized for the prototype. How will you \\nknow whether it was worthwhile to prototype portions of your BI application? \\n* An application interface agreement is also important to cover the following: \\n— Compliance with standards (or development of standards if none exist) \\n— Necessary level of understanding and skills required \\n— Ease of use (“user-friendliness” ) \\nRegardless of how much we use the term “user-friendly system,” it is still an \\noxymoron, like a “simple programming change.” In most cases, we seem to be \\nlooking for “system-friendly users” instead of developing “user-friendly systems.” \\nExpress the goals for ease of use in terms of quantifiable criteria for: \\n+ The minimum time it takes to learn the new application. \\n* The speed of task accomplishment (e.g., time to analyze a market condition). \\n* The retention rate of queries over a period of time. \\n* Subjective satisfaction; business people like applications that are intuitive and \\nforgiving. \\n* The effectiveness of the help function (if included in the prototype). Is the \\nhelp function really helping people resolve problems? Are the business people \\nmaking use of the help function frequently? What is their feedback about the \\ncontent of the help function? \\nGuidelines for Prototyping \\nCreate prototyping guidelines and communicate them to all prototype partici- \\npants. Table 6.7 lists some sample guidelines. \\nAdditional considerations appear below. \\n* With each prototype iteration, plan to expand the number of data types, and \\nplan to increase the functionality and the volume of data. \\n* Keep the type and placement of GUI components consistent among proto- \\ntypes. If you are choosing a pull-down menu for certain types of displays, do \\nnot switch to radio buttons on another prototype. The business people may \\nneed to reach consensus on some basic standardization for the BI decision- \\nsupport environment. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 195}, page_content='162 Step 6: Application Prototyping \\nTable 6.7: Prototyping Guidelines \\n. Do not deviate from the basic purpose for which the prototype is being developed. \\n. Develop a working prototype quickly; therefore, keep the scope small. \\n. Acknowledge that the first iteration will have problems. \\n. Frequently demonstrate the prototype to stakeholders. \\n. Solicit and document top-down as well as bottom-up feedback on the prototype. \\n. Ask for ongoing validation of the prototype results. \\nSI 6) Ol SB WN: = . Continue to cycle between demonstrating and revising the prototype until its \\nfunctionality is satisfactory to all parties. \\njee) . Review your prototyping approach and modify it if necessary before proceeding with \\nthe next prototype iteration. \\nSkills Survey \\nThe business people who will participate in the prototype and will later use the BI \\napplication should be evaluated to determine their skill sets. What level of busi- \\nness knowledge do they have about the business functions addressed by the BI \\napplication? Are they experts in using computers but do not know much about \\nthe business functions? Or are they experts in the business functions but have not \\nused a computer extensively before? . \\nYou may want to use a skills matrix, similar to Table 6.8, to assess the skill sets \\nof the business people in order to determine how simple or how sophisticated the \\nprototype and the final BI application need to be. \\nIf the survey shows an overwhelming number of people with XX skill sets \\n(expert in computer skills and expert in application knowledge), build as many \\nshortcuts as possible. If the survey shows an overwhelming number of people \\nTable 6.8: Skills Matrix \\nComputer Skill \\nBusiness Functions Knowledge Beginning (B) Advanced (A) Expert (X) \\nBeginning (B) BB BA BX \\nAdvanced (A) AB AA AX \\nExpert (X) XB XA XX SS FE ES SE SLE TS I SE TIE \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 196}, page_content='Application Prototyping Activities 163 \\nwith BB skill sets (beginner in computer skills and beginner in application \\nknowledge), provide as much guidance and help functionality as possible. If the \\nsurvey shows an overwhelming number of people with any other skill set combi- \\nnation, you need to take a hard look at your proposed solution and decide \\nwhether only one solution will be sufficient. If the BI application is designed for \\nonly one level of skills but has to satisfy everybody using the application, either it \\nwill be perfect for beginners but the experts will be bored and frustrated, or it will \\nbe perfect for experts but the beginners will be lost and frustrated. \\nAPPLICATION PROTOTYPING ACTIVITIES \\nThe activities for application prototyping do not need to be performed linearly. \\nFigure 6.3 indicates which activities can be performed concurrently. The list below \\nbriefly describes the activities associated with Step 6, Application Prototyping. \\n1 \\nAnalyze access \\nrequirements \\nYj. <Y7 SS \\nDesign reports \\nand queries \\n2 \\nDetermine scope \\nof prototype \\nPrepare \\nprototype charter \\nDemonstrate \\nprototype \\nBuild \\nprototype Select tools \\nfor prototype \\nFigure 6.3: Application Prototyping Activities \\n1. Analyze the access requirements. \\nBased on the business needs, determine the access requirements for reports \\nand queries. Most access requirements will probably be multidimensional, \\nwhich makes them perfect candidates for prototyping. Also, assess the skill \\nsets of the business people participating in the prototype activities. \\n2. Determine the scope of the prototype. \\nThe business representative and the project manager should determine the \\nscope of the prototype. The scope should be small enough that the prototype \\ncan be built and tested in a matter of days or weeks. It should contain only a \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 197}, page_content='Step 6: Application Prototyping \\nsubset of data, just enough to support the functionality chosen for the proto- \\ntype. Prototyping by definition is iterative, which allows functionality and \\ndata to be added with each prototype iteration. \\n. Select tools for the prototype. \\nYou may want to evaluate the existing suite of tools at your organization \\navailable for building the prototype. People are already trained on those tools \\nand feel comfortable using them. The comfort factor is a big enabler. If you \\ndecide to select new tools, determine how much training is required, and \\nschedule the training sessions as soon as possible. \\n. Prepare the prototype charter. \\nPut together a short and informal prototype charter that outlines the main \\npurpose for the prototype, the scope of the prototype, what platform it will \\nbe built on, how many iterations you are planning, the time frame for com- \\npleting the prototype, and who will participate. \\n. Design the reports and queries. \\nBased on the access requirements, design the prototype database and the \\nreports and queries. If a Web front end is part of the prototype, design the Web \\npages as well. Select the relevant data for the prototype, and map the data from \\nthe source files and source databases to the prototype database. Be sure to consult \\nwith the data quality analyst to learn about source data problems. It is best to \\nleave out poor-quality data rather than contaminate the prototype with it. \\n. Build the prototype. \\nBuild the prototype based on the initial database design, report and query \\ndesigns, and Web page designs. Expect that the design will change several \\ntimes. Use this opportunity to test various database and application tuning \\ntechniques. The database structures as well as the reports and queries devel- \\noped during the prototype could be used as a yardstick to validate the time \\nand cost estimates for the final BI application. \\n. Demonstrate the prototype. \\nPrepare demonstrations with as much functionality as the type of prototype \\nyou have chosen allows. A show-and-tell prototype will have much less func- \\ntionality than an operational prototype. Run the demonstrations for a short \\ntime and solicit approval for the BI project and additional support for the BI \\ninitiative as a whole. The demonstrations should be considered a BI market- \\ning activity in addition to being a vehicle for validating the requirements and \\nfunctionality of the BI application. \\nRepeat the process outlined above for additional prototype iterations. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 198}, page_content='Roles Involved in These Activities 165 \\nDELIVERABLES RESULTING FROM THESE ACTIVITIES \\n1. Prototype charter \\nThis document is similar to a project charter because it represents an agree- \\nment between the business sponsor and the IT staff regarding the prototyp- \\ning activities for the BI project. It contains the following sections: \\n— Primary purpose for the prototype \\n— Prototype objectives \\n— Prototype participants \\n— Data to be used for the prototype \\n— Hardware and software platforms to be used \\n— Measures of success \\n— Application interface agreement \\n2. Completed prototype \\nThe main deliverable from this step is a completed prototype. This can be a \\ndemo, a few mocked-up screens, or a partially functioning BI application. \\n3. Revised application requirements document \\nDuring prototyping, you may discover new requirements or decide to change \\nor drop some of the original ones. Reflect these changes in the application \\nrequirements document. \\n4. Skills survey matrix \\nThis matrix indicates the skill sets of the business people. It should state whether \\na business person has beginning, advanced, or expert skills in computer usage as \\nwell as knowledge about the business functions pertaining to the BI application. \\n5. Issues log \\nDocument any issues that came up during prototyping (whether they were \\nresolved or not) in an issues log, indicating status or final resolution, impact \\non the real BI application, action items to pursue, and to whom the action \\nitems were assigned. \\nROLES INVOLVED IN THESE ACTIVITIES \\n@ Application lead developer \\nThe application lead developer should review the application requirements \\ndocument with the business representative, and together they should prepare \\na short and informal prototype charter. The application lead developer should \\nalso review the existing or mock-up report and query layouts, which will form \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 199}, page_content='166 Step 6: Application Prototyping \\nthe basis for the prototype design. He or she also has to make plans for sched- \\nuling the prototype demonstrations. \\n® Business representative \\nThe primary responsibility of a business representative is to use the prototype \\nto learn about the feasibility and the look and feel of the BI application. The \\nbusiness representative should assist the application lead developer in creating \\nthe prototype charter. The business representative also needs to review the \\noverall BI project requirements and revise them if necessary. This can be \\naccomplished only if the business representative participates in the design and \\nthe review of the prototype and is actively involved in the demonstrations. \\n@ Database administrator \\nThe database administrator is responsible for designing and loading the pro- \\ntotype database with sample source data or sample test data. He or she should also \\nreview all database access calls (Structured Query Language [SQL] statements). \\n@ Stakeholders \\nThe stakeholders do not directly participate in the BI project activities, but \\nthey have a vested interest in the project. They should take part in the proto- \\ntype demonstrations and provide input regarding any additional common \\naccess requirements for reports, queries, and ad hoc usage. \\n@ Subject matter expert \\nThe subject matter expert has to analyze and discuss the access and analysis \\nrequirements for reports and queries with the prototyping team. He or she \\nshould work with the business representative and project manager to deter- \\nmine the purpose, goals, and primary use of the prototype. \\n@ Web master \\nThe Web master has to review the existing tools slated for use with Web access \\nto the BI application. The Web master also has to evaluate the usability of the \\nprototype design with regard to Web access and has to determine the neces- \\nsary interfaces. \\nRISKS OF NOT PERFORMING STEP 6 \\nThe main purpose of prototyping is to make sure that the design of the database, \\nthe design of the access and analysis application, and the BI technologies selected \\nwill be able to meet the business requirements when the BI application is imple- \\nmented as intended. By building a successful prototype, you can also validate the \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 200}, page_content='Bibliography and Additional Reading 167 \\naccuracy of your cost and time estimates for the full-scale final BI application. \\nThe risk of not performing this step is that you may build a BI solution that will \\ncost much more and take much longer than you expected—and that you will not \\nrealize it until it is too late. \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nBajaj, Chandrajit. Trends in Software: Data Visualization Techniques. New York: \\nJohn Wiley & Sons, 1999. \\nBeck, Kent. Extreme Programming Explained: Embrace Change. Boston, MA: \\nAddison-Wesley, 2000. \\nCockburn, Alistair. Agile Software Development. Boston, MA: Addison-Wesley, \\n2002. \\nDevlin, Barry. Data Warehouse: From Architecture to Implementation. Reading, MA: \\nAddison-Wesley, 1997. \\nHumphrey, Watts S. Winning with Software: An Executive Strategy. Boston, MA: \\nAddison-Wesley, 2002. \\nKimball, Ralph, Laura Reeves, Margy Ross, and Warren Thornthwaite. The Data \\nWarehouse Lifecycle Toolkit: Expert Methods for Designing, Developing, and \\nDeploying Data Warehouses. New York: John Wiley & Sons, 1998. \\nShneiderman, Ben. Designing the User Interface: Strategies for Effective Human- \\nComputer Interaction. Boston, MA: Addison-Wesley, 1998. \\nTurkle, Sherry. Life on the Screen: Identity in the Age of the Interface. New York: \\nSimon & Schuster, 1997. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 201}, page_content='- wy \\nsnellotges Ni 1 aiiieun aete jtrieli.® Ont Mine Sa ey ee \\nHewebAle SA, ea TE TE tele Perd o que. eit anierotaey weit y aire \\nVion Tibeeaging ooh rhb meriabs px ery ey 1079 capi thayert oat hasan \\nTheyre? veep walt lie ud) Seine a yreanaaeel ochineg \\niti Wns ‘Gated ther tah lve che bid oh fnel of (ie tht opel \\n| [apalennes so yprotaenr Sagan ieethd ¢ co) hes prom aly ‘¢ohdes \\n7 ible nly iq. foarte), TH ta) een a muses : \\n- 0! i i teres end. 7 what 40 aulginia® yqpine: y win! m2 scanty, easy 6 if i <eel™, ie a! f Si \\na A Le Ayer ane sctivily areved it] ned ; \\naH gpd, sw, nel Sonunian\\' renner es coat a \\n: The bie Ghali 4 eronnuble dip eign en — \\nteed Sopa lplads, 2A Mbpaccarnet!] wAttere aly ath cael k ois, \\ngreiowm ol! ijateeie 40094 A le treet | wipe) lang re: ‘Lye r \\nsold cyilD crib ongimaesvesbaen enue, as say (pie? wa aa Wve] x \\n; Thap piekghodorny ilar’ 60) 44 pela eal? an 4D, uy aa \\n(Al iahod ay rant, mira i linke gree thon danibhie g . \\n: bye AC rasaiel te ioey anal fiiie ila siege i carl te Ss af ; \\nmx ie ST NEG ME ar Brin ai apr re Lapse ig ca \\nWis hig Glare eaters 6G tLetri reqh tetedh aan AT \\nibe _ PET OORT ramon eal ds cat elt liga wad { anani agehin i. \\nwa HH Mihi ant SAGA he) HN WEEE Nie - \\n=e BN pote’ iets eile Ate Tiel \\nsped whvtvanl Wi te\" yr Ah! Line rae GAL ree 5 igi \" cold @ \\n> a WOW pita PAP i) & eke ore “ram datey / 7 oo \\nig> “WW A $ptetacst thi, \"le NOL OueiT™ areola 4 ets ly ar Shp - \\nPIR ITY Gig + Griese’ STIVOG 4 iil ian Wh dots 7 ae \\nee 46 ae = \\nwe \\ni \\nx 5 \\n6 \\nSiren ir PCa? Pe ejeneye; See A : \\niwi i ne oe LO ie ee GRO? eG hed \\ni) cer + ie i “eT onl PY \\\\% app aiiiu;, pm \\npel! Gig Alsee (yi eg eld tes alsa ~ ap pat, Nag R \\nemaAles’) O46 Nk Wile ti. “pall “uw @Vre i tips vy apn Me \\nreece \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 202}, page_content='<r Step 7: Meta Data \\nPlanning | Repository Analysis \\nCHAPTER OVERVIEW \\nThis chapter covers the following topics: \\n@ Things to consider when analyzing whether to license (buy) \\nor build a meta data repository \\nmg Why it is important to deliver meta data with every BI \\nproject Meta Data \\nRepository \\nAnalysis \\nm@ The differences between the two categories of meta data: \\nbusiness meta data and technical meta data \\n@ How a meta data repository can help business people find \\nand use their business data after the data has been stan- \\ndardized for the BI decision-support environment \\nm@ The four groupings of meta data components: ownership, \\ndescriptive characteristics, rules and policies, and physical \\ncharacteristics \\n@ How to prioritize meta data for implementation purposes i ie, B Be ap @ \\nwONS TUK \\na= m Five common difficulties encountered with meta data \\n\\\\ [Meta Data | repository initiatives: technical, staffing, budget, usability, \\n\\\\ “hy and political challenges \\nyy @ The entity-relationship (E-R) meta model used to document \\nthe meta data requirements /\\\\ SS \\n@ A definition and examples of meta-meta data \\nDeployment DENG @ Brief descriptions of the activities involved in meta data \\n( : repository analysis, the deliverables resulting from those \\nactivities, and the roles involved \\n@ The risks of not performing Step 7 \\n169 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 203}, page_content='170 Step 7: Meta Data Repository Analysis \\nTHINGS TO CONSIDER \\nMeta Data Repository Usage \\n¥Y Who will be using the meta data in the meta data repository? \\nY What standards do we have in place for its use? What standards do we need \\nto develop? \\nY Do we already have a meta data repository? If not, will we license (buy) one \\nor build one? \\nY Will this meta data repository support only the BI decision-support envi- \\nronment, or will it be used for all systems throughout the organization? \\nY How will we know if we are using the meta data repository effectively? \\nMeta Model Requirements \\n/Y Do we need to create a meta model for the meta data repository, or do we \\nalready have one? \\nV If we have one, what meta data objects do we need to add to it? \\n¥ Which meta data repository products support our meta model? \\nV Are these meta data repository products extendable? \\nMeta Data Repository Security \\n¥ What type of security will we need for the meta data repository? \\n¥ Who will be authorized to enter and maintain the meta data? \\nV Will everyone be authorized to access any meta data at any time? \\nMeta Data Capture \\n¥ What types of business meta data do we need to capture? \\nV Will we be using a computer-aided software engineering (CASE) tool to \\ncapture the business meta data? \\nv What type of technical meta data do we need to capture? \\nVv Will we be capturing technical meta data in the extract/transform/load \\n(ETL), online analytical processing (OLAP), and other access and analysis \\ntools? \\nV How will we extract the meta data from these tools and migrate it to the \\nmeta data repository? Who is responsible for migrating it? \\nY Who will connect the business meta data from the CASE tool to the techni- \\ncal meta data from the ETL, OLAP, and other tools? | \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 204}, page_content='171 \\nMeta Data Delivery \\n¥Y How will meta data be displayed? How will it be accessed? Will we have a \\nWeb interface to the meta data repository? \\nVv Will we need to produce meta data reports? What types of reports? \\n¥ How will these reports be distributed? \\n¥ Will there be a help function (online tutorial)? Will the help function be \\ncontext sensitive? \\nStaffing \\n¥ Do we already have a meta data administrator? If not, do we have a data \\nadministrator with technical skills who can perform the functions of a meta \\ndata administrator? \\nV Will we have to hire more meta data administrators? \\nV How will meta data responsibilities be divided among data administrators \\nand meta data administrators? \\nA meta data repository is a database. But unlike ordinary databases, a meta \\ndata repository is not designed to store business data for a business application. \\nInstead, it is designed to store contextual information about the business data. \\nExamples of contextual information about business data include the following: \\n* Meaning and content of the business data \\n* Policies that govern the business data \\n* Technical attributes of the business data \\n- Specifications that transform the business data \\n* Programs that manipulate the business data \\nContextual information about business data inherently exists in every organi- \\nzation, whether it is documented or not. When contextual information is docu- \\nmented, it is known as meta data. When the information is not documented, it is \\nusually not known to everyone in the organization. As a result, business people \\noften invent their own business rules and create their own redundant data along \\nwith redundant processes, not realizing (or sometimes not caring) that what they \\nneed may already exist. Forty years of such practices have now brought most \\norganizations to the brink of drowning in data and dehydrating from lack of \\ninformation. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 205}, page_content='172 Step 7: Meta Data Repository Analysis \\nTHE IMPORTANCE OF META DATA \\nMeta data describes an organization in terms of its business activities and the busi- \\nness objects on which the business activities are performed. Consider, for example, \\na sale of a product to a customer by an employee. The sale is a business activity and the \\nproduct, customer, and employee are the business objects on which the sale activity is \\nperformed. Business activities and business objects, whether manual or automated, \\nbehave according to a set of relationships and rules, which are defined by the busi- \\nness. These activities and objects, and the relationships and rules that govern them, \\nprovide the context in which the business people use the business data every day. \\nMeta data is so important for the BI decision-support environment because it \\nhelps metamorphose business data into information. The difference between \\ndata and information is that information is raw data within a business context. \\nMeta data provides that business context; that is, meta data ensures the correct \\ninterpretation (based on activities, objects, relationships, and rules) of what the \\nbusiness data actually means. \\nFor example, what is profit? Is it the amount of money remaining after a \\nproduct has been sold and everybody who was involved in that product has been \\npaid? Or is it a more complicated calculation, such as “total annual revenue \\nminus sum of average base cost per product minus actual staff overhead minus \\naccumulated annual production bonuses minus wholesale discounts minus cou- \\npons divided by twelve?” Does every business person have the same understand- \\ning of profit? Is there one and only one calculation for profit? If there are different \\ninterpretations of profit, are all interpretations legitimate? If there are multiple \\nlegitimate versions for profit calculations, then multiple data elements must be \\ncreated, each with its own unique name, definition, content, rules, relationships, \\nand so on. All of this contextual information about profit is meta data. \\nSince meta data provides the business context in which business data is used, \\nmeta data can be viewed as a semantic (interpretive) layer of the BI decision-sup- \\nport environment. This semantic layer helps the business people navigate \\nthrough the BI target databases, where the business data resides. It also helps the \\ntechnicians manage the BI target databases as well as the BI applications. \\nSome important characteristics of meta data and meta data repositories are \\nlisted below. \\n* A meta data repository is populated with meta data from many different \\ntools, such as CASE tools, ETL tools, OLAP tools, and data mining tools. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 206}, page_content='The Importance of Meta Data 173 \\n* Meta data documents the transformation and cleansing of source data and \\nprovides an audit trail of the periodic data loads. \\n* Meta data helps track BI security requirements, data quality measures, and \\ngrowth metrics (for data volume, hardware, and so on). \\n* Meta data provides an inventory of all the source data that populates the BI \\napplications. \\n* Meta data can be centrally managed, or it can be distributed. Either way, each \\ninstance of a meta data component should be unique, regardless of its physi- \\ncal location. \\nMeta Data Categories \\nThere are two categories of meta data: business meta data and technical meta data. \\n1. Business meta data provides business people with a roadmap for accessing \\nthe business data in the BI decision-support environment. Since many busi- \\nness people are relatively nontechnical, they should have access to meta data, \\nwhich defines the BI decision-support environment in business terms they \\nunderstand. \\n2. Technical meta data supports the technicians and “power users” by provid- \\ning them with information about their applications and databases, which \\nthey need in order to maintain the BI applications. \\nTable 7.1 highlights some differences between business meta data and techni- \\ncal meta data. \\nTable 7.1: Business Meta Data versus Technical Meta Data \\nBusiness Meta Data Technical Meta Data \\n* Provided by business people * Provided by technicians or tools \\n¢ Documented in business terms on data ¢ Documented in technical terms in \\nmodels and in data dictionaries databases, files, programs, and tools \\n* Used by business people ¢ Used by technicians, “power users,” data- \\nbases, programs, and tools (e.g., ETL, OLAP) \\n* Names fully spelled out in business ¢ Abbreviated names with special charac- \\nlanguage ters, such as “_” (underscore) or “—’ (dash), \\nused in databases, files, and programs \\nRS EE SE ET TL SL II I AT IAL DE AE IT EE IOI TE \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 207}, page_content='174 Step 7: Meta Data Repository Analysis \\nMETA DATA REPOSITORY AS NAVIGATION TOOL \\nMeta data is not new; it has always been part of operational systems. It can be \\nfound in systems documentation, record layouts, database catalogs, and data dec- \\nlaration sections in programs. The role of meta data in an operational environ- \\nment was always viewed as systems documentation, which was mainly used by the \\ntechnicians who maintained the operational systems. When some of the systems \\ndocumentation (meta data) became outdated, the technical staff had enough \\nskills to read through the actual programming code to extract the information \\nthey were looking for, such as the meaning and content of a data element. Thus, \\nmore often than not, meta data was treated as an afterthought. \\nIn a BI decision-support environment, meta data takes on a new level of \\nimportance. A new audience has to be serviced, namely, the business people. \\nMeta data helps them locate, manage, understand, and use the data in the BI tar- \\nget databases. Meta data has a new role: navigation, not just documentation. \\nBusiness people ordinarily do not have the technical skills, nor the time or desire, \\nto decipher programming code. They also do not want to stay dependent on the \\nIT department to interpret the meaning and content of the data after it has been \\nmanipulated by the programs. Rather than calling a programmer, a business per- \\nson should be able to access the meta data, which would then help him or her \\neffectively navigate through the BI decision-support environment and interpret \\nthe BI data. As illustrated in Figure 7.1, meta data describes what data is available \\nMeta Data \\nRepository \\nWhere is the \\ninformation \\nWe * What data do we have? \\n* Where is it located? \\n* What format is it stored in? \\n+ Who is responsible for the content? \\n+ When was the source data last updated? \\n+ Which tools should be used for retrieval? \\n+ Has someone prepared the query or report | need? \\n“..¢ How do | initiate it? \\nvipa \\nFigure 7.1: Using a Meta Data Repository as a Navigation Tool \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 208}, page_content='Meta Data Repository as Navigation Tool 175 \\nin which BI target database, where the data came from, how to access it, how to \\ndrill down to the detailed data for closer examination, and how to use it. \\nData Standardization \\nIf business data had been stored and used in a consistent, approved manner all \\nalong, the data redundancy and inconsistency problems that currently plague \\nmany operational systems would not exist to the extent they do today. Unfortu- \\nnately, bad habits die hard. Developers and business people still explicitly or \\nimplicitly reuse the business data in operational systems for different purposes. \\nFor example, developers still explicitly redefine data elements in their programs, \\nand business people still implicitly redefine (invent new codes for) existing data \\nelements to capture unrelated information. Documentation of these redefinitions \\nalso remains poor or nonexistent. If any documentation exists, it is rarely distrib- \\nuted to everyone in the organization who needs it, and it is very seldom kept up- \\nto-date. Therefore, business people continue to invent their own business rules \\nand create their own redundant data along with redundant processes. \\nEvery BI project team must address this existing data chaos and must make \\nevery attempt to promote the standardization of data. While standardizing the \\nbusiness data for the BI decision-support environment, the BI project team \\nshould document all changes made to the data so that everyone can be aware of them. \\nThis documentation takes the form of meta data in the meta data repository. For \\nexample, a source data element could be renamed to conform to new naming \\nstandards, or data values could be filtered, added, or transformed to enforce a \\nbusiness rule. In both cases, the BI data in the BI target database would no longer \\nmatch the source data in the source file or source database. The meta data would \\nprovide the navigation between the two. \\nUsing BI applications without knowing that the business data was changed \\nand how it was changed can be a frustrating experience that can eventually end \\nwith the business people no longer wanting to use the BI applications at all. That \\nwould be devastating since one of the most important aspects of a BI decision- \\nsupport initiative is to provide an easy-to-use, intuitive way for the business people \\nto access and query the data. An easy-to-use application means the business people: \\n* Have no need to be relational technology experts \\n- Have no need to know Structured Query Language (SQL) \\n* Have no need to know the physical structure of the databases \\n* Have no need to know the location of their data \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 209}, page_content='176 Step 7: Meta Data Repository Analysis \\n- Have no need to guess the meaning of the data \\n* Have no need to search for the required information \\nMETA DATA CLASSIFICATIONS \\nSince BI projects can generate a great number of meta data components, it is useful \\nto classify these components and to prioritize them for incremental implementation. \\nGroupings of Meta Data Components \\nMeta data components can be sorted into four meta data groupings or classifica- \\ntions: ownership, descriptive characteristics, rules and policies, and physical \\ncharacteristics (Figure 7.2). The meta data repository should be able to store the \\nmeta data components of all four classifications, as listed below. \\n2 \\nDescriptive \\nCharacteristics \\n« Business data \\n« Business processes \\n* Data owner \\n3 + Application owner \\n¢ Business rules Rules and \\n¢ Business policies Policies \\n4 \\nPhysical \\nCharacteristics \\n* Technical data features \\n* Application features \\nFigure 7.2: Meta Data Classifications \\nOwnership \\n* Data owner: Data is owned by the organization. However, since the organiza- \\ntion is a legal entity and not a person, someone in the organization must take \\non the authority and responsibility to set policy, determine rules, and estab- \\nlish standards for the organizational data. This authority and responsibility \\ncan be distributed among line-of-business managers or assigned to a data \\nownership committee (whose members will most likely be some or all of the \\nline-of-business managers). An example of distributed data ownership is a \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 210}, page_content='Meta Data Classifications 177 \\nmanager of the human resource department who has the authority and \\nresponsibility to establish policies, rules, and standards for payroll data but \\nnot for product data. With data ownership by committee, the committee \\nestablishes policies, rules, and standards for all data by consensus, by delega- \\ntion to a committee member, or by some other committee rule. \\nApplication owner: Traditionally, ownership has been assigned to a system as \\na whole. Since a system is usually composed of an application and its data, \\n“system ownership” implies that the same person has authority to set policy, \\ndetermine rules, and establish standards for both data and functionality (the \\napplication). That may be a valid condition for operational systems where \\ndata is originated, but it is not valid for BI applications because most business \\npeople using the BI applications are not the same individuals who originate \\nthe operational data. Therefore, BI information consumers may own the BI \\napplication, but most of them will not own the data. \\nDescriptive Characteristics \\nName: Every data object, data element, and business process should have a \\nunique name. \\nDefinition: Every data object, data element, and business process should have \\na brief definition explaining what it is. \\nType and length: Every data element should have an official type and length \\ndeclared for it, even if the data elements in the source systems or the columns \\nor cells on the target databases may deviate from it. That deviation would \\nalso be defined as meta data under the data element, the column, or the cell \\nwhere it occurred. \\nDomain: Every data element should have a declared set of allowable values, \\neven if the set is all-inclusive, such as “any character, number, or sign.” \\nNotes: Additional facts of interest about data or processes should be included. \\nThis is a catchall for free-form comments, such as “Dispute between engi- \\nneering and marketing regarding the meaning of Product Subcomponent \\nType Code was turned over to the BI steering committee for resolution.” \\nRules and Policies \\nRelationships: Data objects are related to each other through business activi- \\nties. The meta data repository should be able to store information about \\nthese relationships. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 211}, page_content='178 Step 7: Meta Data Repository Analysis \\n- Business rules and business policies: These components can apply to data as \\nwell as to processes. They can be technical data conversion rules, business \\ndata domain rules, business data integrity rules, or processing rules. \\nSecurity: Requirements for security can apply to data, meta data, processes, \\ndatabases, applications (programs and screens), tools, and Web sites. \\nCleanliness: Metrics about the ETL reconciliation totals and about the qual- \\nity of the BI data should be stored. The metrics can be expressed as reliability \\npercentages of a data load (e.g., 89 percent of the customer type code is valid) \\nor as record counts stating the number of records filtered (rejected) and the \\nnumber of records passed through during the ETL process. \\nApplicability: Data does not live forever. Occasionally, new data is invented \\nand captured, and old data is retired and no longer used. Since the BI target \\ndatabases store many years of history, some columns or cells will not have \\nvalues for all time periods because the data was not applicable or did not exist \\nduring certain time periods. If spikes appear on trend analysis graphs, the \\nmeta data repository should be consulted to determine the applicability of \\nthat particular piece of data. \\n- Timeliness: Business people will want to know when the source data was last \\nupdated and which of the versions of the operational systems were used for \\nthe update. Not all operational systems run daily or on the same day of the \\nmonth. One operational system may run on the last calendar day of the \\nmonth while another may run on the last business day of the month. Some \\noperational systems do not “close out the month” until they complete an \\nadjustment run four to ten days after the last calendar day of the month. \\nPhysical Characteristics \\n* Origin (source): Since BI target databases only store existing operational data \\n(internally generated and externally purchased), the origin or source for each \\ndata element should be documented. One column in the BI target database \\ncan be populated with data elements from multiple sources. For example, the \\ncolumn Account Balance in the Account table could be populated from the \\ndata element Demand Deposit Account Balance in the Checking Account \\nsource database and from the data element Time Deposit Account Daily Balance \\nin the Savings Account Transaction file. Conversely, one source data element \\ncan feed multiple columns in the BI target database. For example, the data \\nelement Type Code may be used for two purposes in the operational system. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 212}, page_content='Meta Data Classifications 179 \\nThe data values “A”, “B”, and “C” of Type Code may be used to populate the \\ncolumn Customer Type Code in the Customer table, and the data values “N”, \\n“O”, and “P” of the same Type Code may be used to populate the column \\nProduct Type Code in the Product table. \\nPhysical location: Several meta data components (e.g., tables, columns, \\ndataset names) should describe where the data resides in the BI decision-sup- \\nport environment. \\nTransformation: Very few data elements can be moved from source to target \\nwithout any type of transformation. At a minimum, the data type and length \\nmay have to change, or single-character codes may have to be translated into \\nmulti-character mnemonics. In the worst case, lengthy business rules may \\nrequire more complicated transformations involving editing, filtering, com- \\nbining, separating, or translating data values. \\nDerivation: This component stores the calculation for derived columns. \\nWhile derived columns are customarily not stored in operational systems, it \\nis the norm to store them in BI target databases. \\nAggregation and summarization: Similar to derivation, aggregation and \\nsummarization rules should be stored as meta data. \\nVolume and growth: The size and growth of BI target databases are often \\nenormous. Therefore, projected as well as actual volumes should be docu- \\nmented as meta data in terms of the number of rows and the percentage of \\nexpected growth. \\nBusiness people most frequently access the meta data components in the \\ndescriptive characteristics classification as well as the rules and policies classifica- \\ntion (Figure 7.3). Technicians typically access the meta data components in the \\nphysical characteristics classification (Figure 7.4). \\nPrioritization of Meta Data Components \\nCapturing all meta data components may not be necessary or practical for all BI \\nprojects. However, capturing none is unacceptable. As a rule, meta data should be \\na deliverable with every BI project. It will serve the business people to recognize \\ntheir old data, trace what happened to it (transformation), locate it in the new BI \\ntarget databases, and determine how to use it properly. In other words, the busi- \\nness people will greatly benefit from having meta data available to help them nav- \\nigate through the BI decision-support environment. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 213}, page_content='180 Step 7: Meta Data Repository Analysis \\nContent \\nBusiness rules \\nTransformation Business policies 5 baa : l 5 quality \\nDerivation Valid values °%s° Metrics Aggregation \\nC=A+B \\niy \\nBusiness names \\nDefinitions Timeliness \\nApplicability \\nOrigin ot \\n(Source) Security (Ownership) \\nFigure 7.3: Meta Data Usage by Business People \\nContent \\nValid values \\nTransformation Ranges \\nDerivation Business rules \\nAggregation \\nC=A+B \\nTechnical names \\nSize and length \\nPhysical Location \\nTable name \\nColumns \\nIndices \\nTechnician \\nSecurity \\n(Implementation) \\nFigure 7.4: Meta Data Usage by Technicians \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 214}, page_content='Meta Data Classifications 181 \\nNot all meta data components have the same value to all business people or \\nall BI applications. It might be useful to prioritize the meta data components into \\nthree groups: mandatory, important (beneficial but not mandatory), and \\noptional. Table 7.2 shows a recommended prioritization scheme for capturing \\nmeta data components in a meta data repository. \\nTable 7.2: Prioritization of Meta Data Components \\nMeta Data Mandatory Important Optional \\nOwner A \\nBusiness data name / \\nTechnical data name f \\nDefinition of \\nType and length oY \\nContent (domain) Wa \\nRelationships Y \\nBusiness rules and policies f \\nSecurity f \\nCleanliness Ue \\nApplicability f \\nTimeliness Sf \\nOrigin (source) o \\nPhysical location (BI databases) f \\nTransformation Y \\nDerivation f \\nAggregation oY \\nSummarization S) \\nVolume and growth \\nNotes v \\na I I IE I EE I SE I TT \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 215}, page_content='182 Step 7: Meta Data Repository Analysis \\nPaw All mandatory meta data components, and as many important meta data com- \\nponents as possible, should be captured and stored in the meta data reposi- \\ntory. Optional meta data components could be postponed to future Bl \\napplication releases. \\nMETA DATA REPOSITORY CHALLENGES \\nGood ideas are often hard to implement. Providing a meta data repository is a \\ngood idea but also quite a challenging one, regardless of whether the decision is \\nmade to license (buy) a commercially available product or to build a repository \\nfrom scratch. This section briefly describes the challenges faced when imple- \\nmenting a meta data repository (Figure 7.5). \\nBudget \\nStaffing e @ \\n® Usability \\nlee @ Political \\nChallenges \\nFigure 7.5: Meta Data Repository Challenges \\nTechnical Challenges \\nBuilding a meta data repository is not a trivial task. It is a project in itself, with its \\nown project plan, its own development steps, and its own staff. All the technology \\nchallenges that apply to databases and applications can surface on meta data \\nrepository projects. \\nLicensing a meta data repository product is an alternative to building one, but \\nthe “plain vanilla” versions of commercially available meta data repository prod- \\nucts often do not meet all the meta data requirements of a BI decision-support \\nenvironment. Therefore, licensing a meta data repository product still necessi- \\ntates extensive analysis of the requirements in order to select the right product, as \\nwell as a considerable implementation effort to enhance it. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 216}, page_content='Meta Data Repository Challenges 183 \\nEnhancing licensed software comes with its own challenges. The source code \\nfor the product may not be available. The vendor may insist on incorporating the \\nrequested enhancements for a price and at his or her own speed. The time and \\neffort required for product maintenance increase because the enhancements \\nmust be reapplied to the new releases and versions of the licensed meta data \\nrepository product. \\nStaffing Challenges \\nMeta data should be “living” documentation stored in a database, that is, in the \\nmeta data repository. Storing meta data as paper documents is guaranteed to \\nturn it into “shelfware” within months, if not weeks. This means that, at a mini- \\nmum, one meta data administrator must be dedicated full-time to managing the \\nmeta data repository content and the software. If a meta data repository is being \\nbuilt as part of the BI project, a staff of one person will not be enough. The meta \\ndata repository effort will require an analyst, a data modeler, a database designer, \\nand one or more developers. \\nBudget Challenges \\nAlthough many BI experts think of meta data as the “glue” of the BI decision- \\nsupport environment, most organizations allocate little or no money for creating \\nand maintaining a meta data repository. They still regard meta data as systems \\ndocumentation for technicians, rather than a navigation tool for business people. \\nThe pain of access frustration and data confusion must often reach an intolerable \\nlevel before organizations include meta data as a mandatory and standard deliv- \\nerable of their BI projects. \\nPaw Lack of meta data has frequently been cited as one of the reasons for BI appli- \\ncation failure. \\nUsability Challenges \\nUsing a meta data repository should be completely intuitive. Business people \\nshould be able to click on an icon and immediately get the requested information \\nabout a table or column, a chart or report, or even a business query. More com- \\nplex inquiries against the meta data repository should be handled with built-in or \\ncustomized macros. However, the most polished way to present meta data is to \\ninclude it in BI queries, as shown in Figure 7.6. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 217}, page_content='184 Step 7: Meta Data Repository Analysis \\nMonthy Sales Report \\nUS Sales ($) | Canada Sales ($) Total Sales ($) \\nJanuary Apples \\nBananas \\nCoconuts ; \\nFebruary Apples 22,500 8,500 \\nBananas 10,000 \\nCoconuts \\nMarch Apples \\nBananas 9,900 \\nCoconuts 2,400 =k \\nData Quality Load Statistics: \\n51% of $ values not loaded \\n10% of source records not loaded \\nMeta Data ———»> \\nFigure 7.6: Example of Meta Data in a BI Query \\nUnfortunately, many meta data repository products are still designed by tech- \\nnicians for technicians rather than for business people. Some of these products \\nstill have a cryptic meta data language, lack sophisticated reporting capabilities, \\nare not context sensitive, and require an understanding of the meta model that \\ndescribes the meta data objects and their relationships. \\nPolitical Challenges \\nBuilding an enterprise-wide meta data solution is difficult because departmental \\ndifferences must be reconciled and cross-departmental politics must be resolved. \\nThese disputes, although totally predictable, are rarely taken into account when \\nthe project plan is created. As a result, projects are delayed while these issues are \\naddressed or pushed up to business executives and steering committees. This \\ngives the impression that BI projects are difficult, controversial, tiresome, drain- \\ning, slow, and generally undesirable work. \\nDespite all these challenges, a meta data repository is a mandatory compo- \\nnent of every BI decision-support environment. \\nTHE LOGICAL META MODEL \\nRegardless of whether the meta data repository is licensed or built, and regardless of \\nthe implementation method (centralized, decentralized, or distributed, as discussed \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 218}, page_content='The Logical Meta Model 185 \\nin Step 10, Meta Data Repository Design), the meta data repository should sup- \\nport a logical meta model, which reflects the meta data requirements. As with \\nbusiness data, each component of meta data is unique by nature. It is important \\nto define these unique meta data objects, their contents, their interrelationships, \\nand their interdependencies, independent of how they will be stored or accessed. \\nThe technique for this activity is logical data modeling, only in this case it will \\nproduce a logical meta model. \\nA logical meta model is a data model that indicates objects, the relationships \\nbetween the objects, and the cardinality and optionality of the relationships. The \\ndifference between a logical meta model for a meta data repository and a logical \\ndata model for a business application lies in the nature of the objects. Objects in a \\nlogical meta model represent meta data, such as entity, attribute, definition, \\ndomain, table, column, and index. Objects in a logical data model represent busi- \\nness data, such as customer, product, employee, account, and location. \\nThe Entity-Relationship Meta Model \\nA logical meta model is created during the first meta data initiative and is \\nexpanded with each subsequent initiative. The logical representation of meta data \\nobjects should be captured as an E-R diagram because of its explicit definitions of \\nthe meta data objects, the relationships among them, and the contents of the \\nobjects. Figure 7.7 shows an example of an E-R meta model. \\nAn E-R meta model primarily helps people understand, communicate, and \\nvalidate the meta data requirements. Therefore, an E-R meta model should be \\nviewed as a requirements model to be used for evaluating meta data repository \\nFigure 7.7: Entity-Relationship Meta Model. (Short vertical lines indicate “one,” and the \\ncrow’s feet indicate “many.”) \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 219}, page_content='186 Step 7: Meta Data Repository Analysis \\nproducts and for setting a baseline when designing a customized meta data \\nrepository, even if its physical meta model (database design) ends up being \\nobject-oriented (OO). \\nMeta-Meta Data \\nSince meta data is the contextual information about business data, meta-meta \\ndata is the contextual information about meta data. Many components of meta- \\nmeta data are similar to those of meta data. For example, every meta data object \\nshould have components that cover name, definition, size and length, content, \\nownership, relationship, business rules, security, cleanliness, physical location, \\napplicability, timeliness, volume, and notes. The meta-meta data for a meta data \\nobject might look like this: \\n* Name: Entity \\n* Relationship: related to one or many tables \\n* Security: read by all, updated by the data administrator \\n* Ownership: the data administrator \\n* Origin: ERWIN CASE tool \\n* Physical location: MDRSYSENT table \\n* Cleanliness: 2 percent missing data \\n* Timeliness: last updated on November 1, 2002 \\n* Volume and growth: 2,391 rows, growth rate 1 percent annually \\nMETA DATA REPOSITORY ANALYSIS ACTIVITIES \\nThe activities for meta data repository analysis do not need to be performed lin- \\nearly. Figure 7.8 indicates which activities can be performed concurrently. The list \\nbelow briefly describes the activities associated with Step 7, Meta Data Repository \\nAnalysis. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 220}, page_content='Meta Data Repository Analysis Activities 187 \\nAnalyze meta data \\nrepository requirements \\nia Ce \\n5 \\nAUS hy cua ical Creat requirements for g ay meta model meta-meta data meta data repository \\n\"3 Analyze meta data \\nrepository access and \\nreporting requirements \\n~~ \\nFigure 7.8: Meta Data Repository Analysis Activities \\n1. Analyze the meta data repository requirements. \\nWork with the business representative to determine and prioritize the meta \\ndata requirements for your specific BI project. Indicate which of the meta \\ndata components are mandatory, important, and optional. If a meta data \\nrepository already exists, determine which meta data components need to be \\nadded, if any. Update the latest version of the application requirements docu- \\nment (revised during or after prototyping). \\n2. Analyze the interface requirements for the meta data repository. \\nWhether a meta data repository is licensed or built, it must accept meta data \\nfrom different sources. Business meta data will have to be extracted from \\nCASE tools, word processing documents, or spreadsheets. Technical meta \\ndata will have to be extracted and merged from database management system \\n(DBMS) dictionaries, ETL tools, data-cleansing tools, OLAP tools, report \\nwriters, and data mining tools. \\n3. Analyze the meta data repository access and reporting requirements. \\nPopulating a database is meaningless unless the content can be accessed, que- \\nried, and reported. This is as true for meta data as it is for business data. Iden- \\ntify the meta data access requirements, security requirements, and help \\nfunction requirements. Evaluate alternative display modes, such as Portable \\nDocument Format (PDF), Hypertext Markup Language (HTML), SQL, \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 221}, page_content='188 Step 7: Meta Data Repository Analysis \\ncanned queries, or proprietary meta data repository reporting software. A \\ncontext-sensitive help tutorial would be a beneficial feature to include. \\n4. Create the logical meta model. \\nDraw the logical meta model as an E-R model to explicitly show the relation- \\nships between meta data objects, even if you plan to implement the meta data \\nrepository as an OO database. In other words, the logical meta model should \\nalways be an E-R model, while the physical meta model (the meta data repos- \\nitory database design created in Step 10, Meta Data Repository Design) can \\nbe either an E-R model or an OO model. \\n5. Create the meta-meta data. \\nWhile the logical meta model shows the meta data repository requirements at \\na glance, the meta-meta data describes the required meta data components in \\ndetail. \\nDELIVERABLES RESULTING FROM THESE ACTIVITIES \\n1. Logical meta model \\nThis data model is a fully normalized E-R diagram showing kernel entities, \\nassociative entities, characteristic entities, relationships, cardinality, optional- \\nity, unique identifiers, and all attributes for meta data repository objects. \\n2. Meta-meta data \\nThe meta data entities and attributes from the logical meta model must be \\ndescribed with meta data. Meta data—specific meta data components (meta- \\nmeta data) are meta data names, meta data definitions, meta data relation- \\nships, unique identifiers, types, lengths, domains, business rules, policies, and \\nmeta data ownership. \\nROLES INVOLVED IN THESE ACTIVITIES \\n® Data administrator \\nThe data administrator gathers the business meta data in a CASE tool during \\nthe logical data modeling activities. This meta data will be one of the sources \\nfor the meta data repository. The data administrator, in collaboration with the \\nmeta data administrator, writes and publishes the data standards. He or she \\nmay also assist with creating the meta model and the meta-meta data. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 222}, page_content='Risks of Not Performing Step 7 189 \\n® Meta data administrator \\nThe meta data administrator has primary responsibilities for storing and pro- \\nviding access to the meta data and for maintaining the meta data repository. \\nHe or she must analyze the meta data requirements, identify the meta data \\ncomponents, and produce or enhance the logical meta model and the meta- \\nmeta data. \\n® Subject matter expert \\nThe subject matter expert participates in this step by representing the business \\npeople and their meta data requirements. The subject matter expert identifies \\nsecurity requirements and data ownership and works with the data adminis- \\ntrator, the meta data administrator, the data owners, and other business peo- \\nple to standardize names, definitions, content, and business rules. \\nRISKS OF NOT PERFORMING STEP 7 \\nSince one of the BI decision-support objectives is to eliminate inconsistencies, the \\nsource data must be standardized. Standardization invariably results in changing \\nmuch of the source data. Changes may include renaming the data, splitting one \\nsource data element into multiple target columns, or populating one target col- \\numn from multiple source data elements. It can also mean translating codes into \\nmnemonics, standardizing (changing) data values, and filtering out inappropri- \\nate or invalid data. In the end, business people will not be able to reconcile their \\noperational source data to the BI target data unless they have a trace of these \\nchanges. This trace is called meta data, and business people need it to navigate \\neffectively through the BI decision-support environment. \\nWithout meta data, the business people would have a difficult time under- \\nstanding and using the transformed data in the BI target databases. It would be as \\nfrustrating as aimlessly driving a car for weeks or months without a map, guess- \\ning your way to your destination. Once the business people perceive the BI appli- \\ncation as difficult to use or they think the BI data is unreliable because it no \\nlonger matches the source data in the operational systems, they could label the BI \\ndecision-support initiative a failure. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 223}, page_content='190 Step 7: Meta Data Repository Analysis \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nAdelman, Sid, and Larissa Terpeluk Moss. Data Warehouse Project Management. \\nBoston, MA: Addison-Wesley, 2000. \\nBrackett, Michael H. Data Resource Quality: Turning Bad Habits into Good Prac- \\ntices. Boston, MA: Addison-Wesley, 2000. \\n. The Data Warehouse Challenge: Taming Data Chaos. New York: John \\nWiley & Sons, 1996. \\nDevlin, Barry. Data Warehouse: From Architecture to Implementation. Reading, \\nMA: Addison-Wesley, 1997. \\nHackney, Douglas. Understanding and Implementing Successful Data Marts. Read- \\ning, MA: Addison-Wesley, 1997. \\nInmon, William H., J. D. Welch, and Katherine L. Glassey. Managing the Data \\nWarehouse: Practical Techniques for Monitoring Operations and Performance, \\nAdministering Data and Tools and Managing Change and Growth. New York: John \\nWiley & Sons, 1996. \\nMarco, David. Building and Managing the Meta Data Repository: A Full Lifecycle \\nGuide. New York: John Wiley & Sons, 2000. \\nReingruber, Michael C., and William W. Gregory. The Data Modeling Handbook: \\nA Best-Practice Approach to Building Quality Data Models. New York: John Wiley & \\nSons, 1994, \\nRoss, Ronald G. The Business Rule Concepts. Houston, TX: Business Rule Solutions, \\nInc., 1998. \\nSimsion, Graeme. Data Modeling Essentials: Analysis, Design, and Innovation. \\nBoston, MA: International Thomson Computer Press, 1994. \\nSperley, Eric. The Enterprise Data Warehouse: Planning, Building, and Implemen- \\ntation. Upper Saddle River, NJ: Prentice Hall, 1999. \\nTannenbaum, Adrienne. Metadata Solutions: Using Metamodels, Repositories, \\nXML, and Enterprise Portals to Generate Information on Demand. Boston, MA: \\nAddison-Wesley, 2002. \\nData Management Association (DAMA): http://www.dama.org \\nDM Review magazine: http://www.dmreview.com \\nEnterprise Warehousing Solutions, Inc.: http://www.EWSolutions.com \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 224}, page_content='Justification CHAPTER EIGHT \\nStep 8: Database Design \\nPlanning \\nCHAPTER OVERVIEW \\nThis chapter covers the following topics: \\nm@ Things to consider about database design \\n@ The differences in database design philosophies and in \\nbest design practices for operational databases and for Bl \\ntarget databases \\n@ The multidimensional design premise of aggregation and \\nsummarization \\n_ @ Basic explanations of a star schema and a snowflake \\nDatabase Mata Data schema \\nDesign } , | \\n. @ Aspects of physical database design, including implemen- \\ntation options (such as free space and buffer space), physi- \\ncal dataset placement, partitioning, clustering, indexing, \\nreorganizations, backup and recovery, and parallel query \\nexecution \\nie \\nConstruction \\\\ / | o @ Brief descriptions of the activities involved in database \\n4 : : ro a design, the deliverables resulting from those activities, and \\nthe roles involved \\n@ The risks of not performing Step 8 \\n191 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 225}, page_content='192 Step 8: Database Design \\nTHINGS TO CONSIDER \\nReports and Queries \\n/¥ What common reporting patterns exist across departments? \\nY What level of detailed data will the business people require for drill-down \\nqueries? \\nY How much ad hoc querying against detail data do we project will occur? \\n/ How many reporting dimensions should we consider? What are they? \\n/ How many new dimensions may have to be added in the future? \\nDesign Considerations \\nV Should we store aggregated and summarized data? \\nY How much concurrent usage of the data should we expect? \\nV How big will the BI target databases be? What are the projected data volumes \\nand growth factors? \\n¥Y How much historical data will we keep? \\n¥ What will be the frequency of loads? \\nV Will the databases need to be distributed? \\n¥ What are the availability requirements? \\nPerformance Considerations \\n¥ What are the performance requirements? \\nV How will we cluster the tables? By the date column or by other columns? \\nV What tables should be co-located? \\nVY How will we partition the tables? Will we partition by date? \\n¥ What types of indexing algorithms should we use (B-tree, hash, inverted file, \\nsparse, binary)? \\n¥Y Can we run multiple operations (queries, loads) in parallel? \\nSelection of Database Management System \\n¥ Which database management system (DBMS) are we using for our existing \\napplications? Will we use the same DBMS for the BI target databases? \\nY Will our current DBMS scale to the expected size? \\nVv Are we satisfied with the current DBMS? If not, what are we doing about it? \\n¥ Will we need to license (buy) another DBMS? \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 226}, page_content='Differences in Database Design Philosophies 193 \\nStaffing \\n¥ What skills do we have available to design the BI target databases? \\nV Do we have enough database administrators? \\nY Can one database administrator be dedicated to this project full-time? \\nY Does he or she have multidimensional design skills? If not, how soon can he \\nor she receive training? \\n¥ Will we need to hire a consultant to mentor the database administrator and \\nthe team? \\nBI decision-support requirements for aggregated and summarized data have \\nintroduced a new type of database design and a new way of storing data. This new \\nmultidimensional database design schema, coupled with new BI technology, sup- \\nports the ability to “slice and dice” information in myriad ways for reporting and \\nanalysis purposes. In order to implement the capabilities of slicing and dicing, \\ndatabase administrators and developers must learn new design techniques and \\nmust acquire a new way of working with the databases. They must begin by under- \\nstanding the ways in which the data will be accessed. Data can be accessed either \\nin a conventional way (usually detailed records retrieved with Structured Query \\nLanguage [SQL] queries) or in a multidimensional way (usually summarized \\nrecords retrieved with an online analytical processing [OLAP] tool). Multidimen- \\nsional data storage and data access techniques, which support slicing and dicing, \\nallow information to be viewed from a variety of perspectives, such as Products \\nby Factory by Market Segment and Market Segments by Product by Factory. \\nDIFFERENCES IN DATABASE DESIGN PHILOSOPHIES \\nThere is a completely different design philosophy behind BI target databases as \\ncompared with operational databases. Table 8.1 summarizes the differences \\nbetween these two types of databases. \\nOperational Databases \\nThe intent of operational database design is to prevent the storage of the same \\ndata attributes in multiple places and thus to avoid the update anomalies caused \\nby redundancy. In other words, from an operational perspective you want to \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 227}, page_content='194 Step 8: Database Design \\nTable 8.1: Operational Databases versus BI Target Databases \\nOperational Databases BI Target Databases \\n* Geared toward eliminating redundancy, = * Geared toward supporting a wide range \\ncoordinating updates, and repeating the of queries and reports. Queries and \\nsame types of operations many times a reports may vary from one business \\nday, every day (for example, airline analyst to another or from one \\nreservations, deposits and withdrawals department to another. All of the queries \\nfrom bank accounts, hotel room and reports may not run on the same \\nreservations). day and may not run every day (for \\nexample, quarterly trend analysis reports \\non regional sales, monthly order \\nfulfillment report). \\n* Most of the transactional systems require Although response time is important, \\nsubsecond response time. subseconds cannot be expected. Typical \\nresponse times are seconds, minutes, or \\nhours. \\n* Highly normalized to support consistent Highly denormalized to provide quick \\nupdates and maintenance of referential retrieval of a wide range and a large \\nintegrity. amount of data. Data that belongs \\ntogether from an analytical reporting \\nperspective is usually stored together. \\n+ Store very little derived data. Data is Store large amounts of derived data. This \\nusually derived dynamically when saves time for the queries and reports. \\nneeded. \\n* Do not store historical data. Historical Store large amounts of historical data, \\nrecords are archived. often at some level of summarization, \\nbut just as often at a detailed level. \\n¢ Lightly summarized, mostly for reporting + Many levels of precalculated, \\npurposes. summarized data, from lightly \\nsummarized to highly summarized. \\navoid storing the same data in multiple columns in multiple tables so they do not \\nget out of synch. Designing normalized database structures is key for developing \\nrelational databases in support of that intent. Normalization ensures that the data \\nis created, stored, and modified in a consistent, nonredundant way. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 228}, page_content='Differences in Database Design Philosophies 195 \\nMost operational systems are designed with a data-in philosophy (data \\nentry), not a data-out philosophy (reporting and querying). The objective of a \\ndata-in philosophy is to make data entry as efficient as possible, running hun- \\ndreds of thousands of transactions per day, while eliminating or minimizing \\nredundancies in the data. Data redundancy leads to inconsistencies, and incon- \\nsistencies are often the reason for poor-quality data. Therefore, in trying to solve \\nthe enormous data quality and data redundancy problems in operational sys- \\ntems, the goal is to avoid redundancy (except for key redundancy, which is \\nunavoidable). This goal is achieved through normalization. \\nWhile normalization works well for operational systems, the requirements \\nfor reporting are different from the requirements for data entry. Reporting uses \\ndata that has already been created, which means update anomalies cannot occur. \\nWhile it is of great benefit that the data is consistent and nonredundant as a result \\nof a normalized database design, that same design makes reporting difficult. For \\nexample, to create strategic trend analysis reports, many tables have to be \\naccessed, and every row in those tables has to be read. This is not only complex \\nbut also extremely inefficient when run against a normalized database design \\nbecause it requires scanning tables and performing large multi-table JOINs. For \\nthat reason, most BI target databases are based on a multidimensional design, in \\nwhich the data for the strategic trend analysis reports is stored in a precalculated \\nand presummarized way. \\nFigure 8.1 illustrates the general difference between an operational normal- \\nized design and a BI multidimensional design. \\nInventory \\nItem \\nMonthly Regional \\nSummary Summary \\nOperational—Normalized Design Bl—Multidimensional Design \\nFigure 8.1: Operational normalized versus BI Multidimensional Designs \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 229}, page_content='196 Step 8: Database Design \\nIn this example, the operational database design shows an Order database \\nwhere customers are associated with orders, and each order is composed of many \\nline items. With each placed order, the line items have to be subtracted from a \\nseparate Inventory database. The BI target database design shows a database with \\nsummaries that are used to identify trends over time. In this design, the same \\ndata about orders, line items, and inventory may exist in multiple tables \\n(Monthly Summary, Regional Summary, Product Summary), albeit summarized \\nby different dimensions. While operational databases generally store granular \\n(atomic) data, BI target databases, for the most part, store summarized data. \\nBI Target Databases \\nContrary to the data-in philosophy (data entry) of operational systems, the data- \\nout philosophy (reporting and querying) of BI applications includes the follow- \\ning design considerations. \\n- BI target databases are designed for simplified, high-performance data \\nretrieval, not for efficiency of data storage and maintenance (which are \\nimportant design considerations for operational databases). \\nEliminating or minimizing data redundancy is not a goal in designing BI tar- \\nget databases. If a choice must be made, data redundancy is favored over \\ncomplexity, but the redundancy must be controlled. Redundant data must be \\nconsistent and reconcilable. \\nBasic assumptions for designing BI target databases are listed below. \\n— Data is stored in such a manner that it is readily accessible in ways that are \\nof interest to the business people. \\n— The design is driven by access and usage. \\n— A normalized design is not necessarily intuitive for a business person and \\ncould therefore become quite complex. \\n— No BI data can be invented! All data in the BI target databases must exist in \\nor be derivable from current internal or external operational data sources. \\nA key decision for all BI applications is whether or not, and at what level, to \\nstore summarized data in the BI target databases. The database administrator and \\nthe lead developer may decide to store both detailed data and summarized data, \\neither together in the same BI target database or in different BI target databases. \\nThis database design decision must be based on access and usage requirements. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 230}, page_content='Logical Database Design 197 \\nLOGICAL DATABASE DESIGN \\nBecause of the differences in intent and purpose between operational systems and \\nBI applications, different database design techniques have been devised for BI \\ntarget databases. These highly denormalized designs store aggregated and sum- \\nmarized data in a multidimensional fashion. Logical database designs are docu- \\nmented as physical data models with technical meta data. \\nAggregation and summarization are probably the most significant contribu- \\ntors to good BI application performance. If most business analysts need to see \\ntheir data summarized, these totals should be precalculated and stored for quick \\nretrieval. It is important to discuss the level of granularity with the business rep- \\nresentative, as well as with other business analysts who will be using the BI target \\ndatabases, since they will expect the database design to allow them to drill down \\nto a certain level of detail. \\nMultidimensional database designs support the quick retrieval of a wide \\nrange of data. Two popular multidimensional design techniques are the star \\nschema and the snowflake schema, both described below. \\nThe Star Schema \\nIn a star schema, data is represented as an array of precalculated values, called \\nfacts, around which analysis is performed. These precalculated facts represent \\natomic operational data values that have been presummarized by certain dimen- \\nsions, such as customer, product, and time. A dimension in a star schema is simi- \\nlar to an entity in a logical data model: it is a business object about which data is \\ncollected for business purposes. \\nThe star schema mirrors the view of a business query. As the name implies, \\nthe star schema has a single object in the middle, called the fact table, which is \\nconnected in a radial fashion to a number of objects, called dimension tables. Fig- \\nure 8.2 presents an example of a star schema. \\nA star schema has two, and only two, levels: the fact table and a series of sin- \\ngle-level dimension tables. Fact tables have the following characteristics: \\n- A fact table represents a critical business event (a business activity or transac- \\ntion, such as a sale or a claim). \\n- The facts are the quantifiable aspects of the business event; that is, they are \\ncolumns in the fact table. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 231}, page_content='Step 8: Database Design \\nPR ST SE TI EES LE ATE TELE \\nTIME PRODUCT \\nTime ID \\nDay of Week \\nWeek of Month \\nMonth \\nYear \\nCentury \\nSeason Name \\nTime ID \\nStore ID \\nProduct ID \\nCustomer ID \\nDollar Sales \\nUnit Sales \\nPayment Type Store ID \\nStore Address \\nSquare Feet \\nDistrict Name \\nDistrict Location \\nRegion Code \\nRegion Manager \\nFigure 8.2: Star Schema \\nProduct ID \\nProduct Name \\nProduct Category \\nProduct Price \\nProduct Size \\nProduct Color \\nCUSTOMER \\nCustomer ID \\nCustomer Name \\nCustomer Phone \\nCustomer Income \\nCustomer Age \\nCustomer Gender \\n: A fact table links to its related dimension tables (business objects, such as cus- \\ntomer or product). \\nA fact table has a long composite key comprised of the primary keys of the \\nrelated dimension tables (which are foreign keys in the fact table). \\nA number of highly redundant fact tables may exist for a given subject area. \\nEach fact table could contain a different aggregation level of the same data. \\nFor example: \\n— Sales facts by store by region by date \\n— Sales facts by product by store by date \\n— Sales facts by customer by region by date \\nFact tables are long and narrow: the tables have an immense number of rows \\n(long), but there are relatively few columns in the tables (narrow). \\nDimension tables have very different characteristics. \\nDimension tables are business objects, which represent the different perspec- \\ntives from which the facts in a fact table can be viewed and analyzed. \\nfrom a specific business perspec \\ntogether into one table. This pro \\nacceptable in this design schema. \\nDimension tables usually have a one-attribute primary key. \\nDimension tables are denormalized, which means that data belonging together \\ntive, such as a roll-up hierarchy, is grouped \\nduces some redundant data values, which is \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 232}, page_content='Logical Database Design 199 \\nDimension tables are short and wide: the tables have relatively few rows \\n(short), but there are many columns in the tables (wide). \\nWhenever possible, dimension tables should be shared by the fact tables \\n(conformed dimensions). \\nOne dimension is always a time dimension with attributes describing the \\ntimestamp, such as calendar year, quarter, season, fiscal period, or accounting \\nperiod. Some other examples of common dimension tables are customer, \\nproduct, policy, sales representative, region, and store. \\nMost multidimensional DBMSs effectively deal with the optimization of large \\nmulti-table JOINs. One method for determining whether the DBMS is resolving \\nthe query efficiently is to look at the optimized plan for the query. For example: \\nIf the fact table is the last table JOINed, this is an indicator of optimization. If \\nthe fact table appears to be somewhere in the middle, or even somewhere \\ntoward the beginning, the DBMS may not be resolving the JOIN optimally, \\nunless it uses more sophisticated JOIN algorithms. \\nIf the DBMS does not use Cartesian product JOINs, the DBMS may take the \\nqualifying row keys and apply them against a composite fact table index, or it \\nmay apply them via an index intersection against multiple fact table single- \\ncolumn indices. \\nIn either case, verify that your DBMS is executing multidimensional queries in \\nthe most efficient manner since your performance depends on it. \\nThe star schema is the most popular database design schema for BI applica- \\ntions for a variety of reasons. \\nIt yields the best performance for trend analysis queries and reports that \\ninclude years of historical data. \\nIt provides maximum flexibility for multidimensional data analysis. \\nIt is supported by most of the relational DBMS vendors with modifications to \\ntheir DBMS optimizer. \\nIts simplicity makes complex data analysis much less difficult than with a stan- \\ndard normalized design. It is much easier to ask questions such as the following: \\n— Which insurance broker is giving us the most or the least lucrative business? \\n— What are the most frequently occurring types of claims from this insurance \\nbroker? \\n— When are these claims occurring? \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 233}, page_content='200 Step 8: Database Design \\nThe preceding questions are typical drill-down questions (asking for more \\ndetailed data) and typical roll-up questions (asking for more summarized data). \\nThe Snowflake Schema \\nA snowflake schema is a variation of a star schema, except in a snowflake the \\npoints of the star radiate into more points, as shown in Figure 8.3. \\nIn snowflake schemas, the levels of the hierarchies in the dimension tables are \\nnormalized, thereby increasing the number of tables. Table 8.2 lists the advan- \\ntages and disadvantages of snowflake schemas. \\nTIME \\nTime ID \\nDistrict ID \\nREGION District Name \\nDistrict Location \\nRegion ID \\nDistrict ID \\nRegion ID \\nRegion Code \\nRegion Manager \\nFigure 8.3: Snowflake Schema \\nTable 8.2: Advantages and Disadvantages of Snowflake Schemas \\nAdvantages Disadvantages \\nPRODUCT \\nProduct ID \\nDay of Week Product Name \\nWeek of Month Product Category \\nMonth Product Price \\nYear FACT Product Size \\nCentury Time ID Product Color \\nSeason Name Store ID \\nProduct ID \\nCustomer ID \\nSTORE poate. CUSTOMER Unit Sales \\nStore ID Payment Type Customer ID \\nDISTRICT Store Address Customer Name \\nSquare Feet Customer Phone \\nCustomer Income \\nCustomer Age \\nCustomer Gender \\n* The size of the dimension tables is \\nreduced and data value redundancy is \\navoided because parent-child hierarchies \\nare no longer collapsed. JOINS. \\n* The increased number of tables may \\nadversely affect query performance \\nbecause of the necessary additional \\n* Application flexibility is increased. ¢ Database maintenance effort is increased \\nbecause there are more tables to maintain. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 234}, page_content='Physical Database Design 201 \\nPHYSICAL DATABASE DESIGN \\nBecause BI applications usually require operational detailed data as well as sum- \\nmarized data, and because they often need to store some or all of that data redun- \\ndantly, the size of some BI target databases can be enormous. Databases approaching \\nor exceeding one terabyte of data are called very large databases (VLDBs). Design- \\ning VLDBs is a big challenge, and the day-to-day chores of maintaining these \\nVLDBs are demanding. Many difficult physical design decisions need to be made, \\nand some highly effective performance enhancements need to be used. The fol- \\nlowing sections present some suggested guidelines. \\nImplementation Options \\nAlmost every DBMS lets the database administrator choose from a number of \\nimplementation options. Give considerable attention to selecting the right \\noptions when implementing a BI target database. It takes experience to know \\nwhich combination of options will meet the desired performance level. Imple- \\nmentation decisions include the following: \\n* How much free space to choose \\n* How much buffer space to declare \\n* How large to set the blocksize \\n* Whether to use any compaction technique \\nPhysical Dataset Placement \\nAnother basic issue that affects performance is the placement of the datasets. \\nMethods for achieving fast response include combinations of: \\n* Storing frequently referenced data on fast devices. \\n* Storing different aggregation levels on different platforms. For performance \\nreasons, it may be necessary to store aggregate data on distributed midrange \\nservers while keeping detail data on the mainframe. \\n* Striping disks in an interleaved fashion to optimize input/output (I/O) con- \\ntroller usage. Using lots of small disks instead of a few large disks, separating \\nthose disks onto separate controllers, and writing the data across devices \\nincreases I/O throughput. \\n- Placing datasets in a way that lengthy seeks are avoided when possible. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 235}, page_content='202 Step 8: Database Design \\n- Selecting address and search schemes that require few seeks, preferably only \\none per retrieval. \\n* Running multiple operations in parallel. \\nAlso consider whether to separate indices from data and put them on separate disks. \\nPartitioning \\nEnsure that tables are partitioned effectively across multiple disks. This is partic- \\nularly important for VLDBs where fact tables can reach several hundred \\ngigabytes. Partitioning allows the data of one “logical” table to be spread across \\nmultiple physical datasets. The physical data distribution is based on a partition- \\ning column, which is most commonly date. Since a partitioning column must be \\npart of the table’s primary key, the partitioning column cannot be a derived col- \\numn, and it cannot contain NULL values. Partitioning enables you to back up \\nand restore a portion of a table without impacting the availability of other por- \\ntions of the same table that are not being backed up or restored. \\nClustering \\nDefine cluster table requirements, and physically co-locate related tables on the \\ndisk drive. Clustering is a very useful technique for sequential access of large \\namounts of data. Clustering is accomplished through clustering indices that \\ndetermine in which sequential order the rows in the tables are physically stored in \\nthe datasets. Ideally, you want to cluster the primary key of each table to avoid \\npage splits, that is, to make sure that new rows inserted into the tables will be \\nstored sequentially on the disk according to the columns in their clustering index. \\nUsing this technique can dramatically improve performance because sequential \\naccess of data is the norm in BI applications. When the rows of a table are no \\nlonger stored in the same order as its clustering index (data fragmentation), per- \\nformance will suffer and the table has to be reorganized. \\nIndexing \\nThere are two extreme indexing strategies, neither of which is advisable: one \\nstrategy is to index everything, and the other is to index nothing. Instead of veer- \\ning to these extremes, index those columns that are frequently searched and that \\nhave a high distribution in values, such as Account Open Date. Do not index col- \\numns that have a low distribution in values, such as Gender Code. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 236}, page_content='Physical Database Design 203 \\nOnce you have decided which columns to index, determine the index strategy \\nto use. Most DBMSs provide several access methods to choose from, either \\nsequential access or direct access using any of the following well-known indexing \\nalgorithms: \\n* B-tree \\n* Hash \\n* Inverted file \\n* Sparse \\n* Binary \\nConsult with your DBMS vendor to choose the most optimum access \\nmethod (indexing algorithm) for the DBMS product you are using. \\nReorganizations \\nOccasionally you will need to reorganize the databases because incremental loads \\nwill fragment the datasets over time, and inserted rows will no longer be stored in \\na logical sequence. This fragmentation may result in long data retrieval chains, \\nand performance can drop off significantly. Most DBMSs provide reorganization \\nroutines to rearrange the fragmented database in order to reclaim space occupied \\nby deleted data or to move records from overflow areas into free space in prime \\ndata areas. \\nThe basic activities involved in reorganizing a database are to copy the old \\ndatabase onto another device, reblock the rows, and reload them. This is not a \\ntrivial effort for BI target databases. The good news is that all DBMSs can per- \\nform a partial reorganization routine on database partitions, which is another \\nreason for the database administrator to partition the BI target databases. \\nBackup and Recovery \\nSince software and hardware may fail, it is necessary to establish backup and \\nrecovery procedures. DBMSs provide utilities to take full backups as well as incre- \\nmental backups. Many organizations are under the misguided impression that \\nthe BI target databases can always be recreated from the original source data. \\nThey neglect to realize that it may take a very long time to recreate the BI target \\ndatabases if they have to rerun all the initial and historical extract/transform/load \\n(ETL) programs—assuming the original source files are still available. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 237}, page_content='204 Step 8: Database Design \\nDisaster recovery is also an issue for BI applications. If the backup tapes or \\ncartridges are destroyed during a disaster, it could be difficult to recreate your BI \\ntarget databases, and it could take a very long time (if recovery is possible at all). \\nFor this reason, many companies choose to store their database backups in \\nremote locations. \\nParallel Query Execution \\nTo improve the performance of a query, break down a single query into compo- \\nnents to be run concurrently. Some DBMS products offer transparent parallel \\nexecution, which means you do not need to know how to break down a query \\ninto components because the DBMS does it for you. Performance is greatly \\nincreased when multiple portions of one query run in parallel on multiple pro- \\ncessors. Other applications of parallel query execution are loading tablespace par- \\ntitions, building indices, and scanning or sorting tables. Parallel processing is a \\nvery important concept for BI applications and should be considered whenever \\npossible. \\nDATABASE DESIGN ACTIVITIES \\nThe activities for database design do not need to be performed linearly. Figure 8.4 \\nindicates which activities can be performed concurrently. The list below briefly \\ndescribes the activities associated with Step 8, Database Design. \\n1. Review the data access requirements. \\nThe database administrator must review the data access and analysis require- \\nments (reports, queries), which were analyzed and finalized during Step 6, \\nApplication Prototyping. He or she also has to review the prototyping results \\nwith the application lead developer to help determine the most appropriate \\ndesign schema for the BI target databases. \\n2. Determine the aggregation and summarization requirements. \\nBefore committing to the final design schema for the BI target databases, the \\ndatabase administrator needs to finalize the data aggregation and summari- \\nzation requirements with the business representative and the application lead \\ndeveloper. Pay close attention to aggregation and summarization explosion \\nand to data explosion in general. Business people often ask for data “just in \\ncase” they will need it some day, and then they rarely use it, if ever. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 238}, page_content='Database Design Activities 205 \\n. coca \\nDetermine aggregation/ \\nsummarization \\nrequirements \\n1 \\nReview data access \\nrequirements \\n3 \\nDesign BI \\ntarget databases \\nDesign physical \\ndatabase structures \\n%; \\nBuild BI \\ntarget databases \\n6 \\nDevelop database \\nmaintenance procedures \\niv \\nPrepare to monitor and \\ntune database design \\nPrepare to monitor and \\ntune query design \\nFigure 8.4: Database Design Activities \\n3. Design the BI target databases. \\nThe widespread claims that all BI applications are only about multidimen- \\nsional analysis and multidimensional reporting are not true! For example, \\nsome financial analysts (statisticians) reporting to the CFO or the CEO will \\nemphatically state their requirements similar to this: “I need to be able to ask \\nany question of any detailed data in any way. Don’t try to box me into any \\npredetermined reporting patterns. I have none!” These analysts need total ad \\nhoc flexibility against historical detailed data and are always willing to give up \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 239}, page_content='206 Step 8: Database Design \\nperformance, even if it means that their queries will run for hours or over- \\nnight. Although these types of analysts are definitely in the minority, they do \\nexist, and you must take their data access requirements into consideration. \\nTherefore, while the designs of most of your BI target databases will be based \\non a multidimensional schema, some will be based on an entity-relationship \\nschema. Database designs are documented as physical data models. \\nThe data access requirements and the data aggregation and summarization \\nrequirements will determine the most appropriate database design. If there \\nare obvious reporting patterns or if the requirements ask for slice and dice \\nanalysis capabilities, then the most appropriate database design is a multidi- \\nmensional one. If there are no reporting requirements and if the business \\nanalysts insist that they need ad hoc access to their detail data, then the most \\nappropriate design is the entity-relationship design, which is more normal- \\nized with few or no aggregations or summaries. \\nThese are not the only two design schemas applicable for BI target databases. \\nFor some types of access and analysis requirements, a hybrid design may be \\nthe most appropriate. \\n4. Design the physical database structures. \\nClustering, partitioning, indexing, and appropriately placing the datasets are \\nthe four most important characteristics of physical database design. The \\ndatabase administrator should cluster the most frequently used tables in \\norder to reduce the disk arm movement. He or she must also determine \\nwhere to place the datasets and how to partition tables across multiple disks. \\nFinally, he or she has to select an index strategy. \\n5. Build the BI target databases. \\nThe physical databases are built when the data definition language (DDL) is \\nrun against the DBMS. The database administrator uses the DDL to describe \\nthe database structures (e.g., storage groups, database partitions) to the DBMS. \\nDatabase security is established when the data control language (DCL) is run \\nagainst the DBMS. In standard relational databases, security is imposed at the \\ntable or view level. Because of the dimensional nature of BI target databases, \\nthe capability to drill down into detail data, sometimes across databases, pre- \\nsents an often-overlooked security risk. \\nGrant database authority either to individuals or to groups into which indi- \\nviduals have been assigned. Managing security on an individual level can \\nquickly become a maintenance nightmare, which is why most organizations \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 240}, page_content='Deliverables Resulting from These Activities 207 \\nprefer to set up group identifiers (group IDs). Each group ID is granted some \\nform of create, read, update, delete (CRUD) access to the tables. An audit \\ntrail can then show which specific “user ID” under which group ID accessed \\nthe database. If there is a breach of security, the “infiltrator” can often be \\nlocated through this audit trail. \\n6. Develop database maintenance procedures. \\nOnce the database goes into production, it will be important to set aside time \\nfor taking database backups or reorganizing fragmented tables. Therefore, \\nestablish procedures to address database maintenance functions. \\n7. Prepare to monitor and tune the database designs. \\nOnce the BI application is implemented, the BI target databases have to be \\nmonitored and tuned. The best database design does not guarantee contin- \\nued good performance, partly because tables become fragmented and partly \\nbecause actual usage of the BI target databases changes over time. Monitor \\nperformance of queries at runtime with a performance-monitoring utility \\nthat has diagnostic capabilities. It does not help to know that performance \\nhas degraded without knowing the causes. Diagnosing performance prob- \\nlems is usually much harder than discovering them. \\n8. Prepare to monitor and tune the query designs. \\nSince performance is such a challenge on BI applications, you must explore \\nall tricks of the trade to address this problem. Parallel query execution is one \\nof those tricks that could boost query performance. \\nDELIVERABLES RESULTING FROM THESE ACTIVITIES \\n1. Physical data model \\nThe physical data model, also known as the logical database design, is a dia- \\ngram of the physical database structures that will contain the BI data. \\nDepending on the selected database design schema, this diagram can be an \\nentity-relationship diagram, a star schema diagram, or a snowflake diagram. \\nIt shows tables, columns, primary keys, foreign keys, cardinality, referential \\nintegrity rules, and indices. \\n2. Physical design of the BI target databases \\nThe physical database design components include dataset placement, index place- \\nment, partitioning, clustering, and indexing. These physical database compo- \\nnents must be defined to the DBMS when the BI target databases are created. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 241}, page_content='208 Step 8: Database Design \\n3. Data definition language \\nThe DDL is a set of SQL instructions that tells the DBMS what types of phys- \\nical database structures to create, such as databases, tablespaces, tables, columns, \\nand indices. \\n4. Data control language \\nThe DCL is a set of SQL instructions that tells the DBMS what types of \\nCRUD access to grant to people, groups, programs, and tools. \\n5. Physical BI target databases \\nRunning (executing) the DDL and DCL statements builds the actual BI target \\ndatabases. \\n6. Database maintenance procedures \\nThese procedures describe the time and frequency allocated for performing \\nongoing database maintenance activities, such as database backups, recovery \\n(including disaster recovery), and database reorganizations. The procedures should \\nalso specify the process for and the frequency of performance-monitoring \\nactivities. \\nROLES INVOLVED IN THESE ACTIVITIES \\n@ Application lead developer \\nThe application lead developer and the database administrator should review \\nall lessons learned during the prototyping activities. The application lead \\ndeveloper should help the database administrator determine which queries \\nand reports can be executed in parallel and what type of security is needed. \\n@ Data administrator \\nThe data administrator should provide the logical data model and the meta \\ndata to the database administrator. The logical data model and the meta data \\nwill be helpful to the database administrator when he or she designs the BI \\ntarget databases. This is true even if a multidimensional database design \\nschema was chosen because the entities and relationships on the logical data \\nmodel are the perfect starting point for designing conformed dimensions and \\nnormalized snowflake dimensions. \\n@ Database administrator \\nThe database administrator has the primary responsibility for database \\ndesign. He or she needs to know the access paths, weigh the projected data \\nvolumes and growth factors, and understand the platform limitations. He or \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 242}, page_content='Bibliography and Additional Reading 209 \\nshe must create and run the DDL and DCL to build the physical databases. In \\naddition, he or she is responsible for choosing the most appropriate imple- \\nmentation options. \\nPane Database administrators, not programmers, should design databases. \\nDatabase design usually is—and should be—part of the job description for \\ndatabase administrators because it requires special product-specific train- \\ning on the DBMS optimizer. \\n@ ETL lead developer \\nThe ETL process is dependent on the database design. The ETL lead developer \\nshould be involved in the database design activities in order to stay informed \\nabout any database design changes that will affect the ETL process or the ETL \\nprogramming specifications. \\nRISKS OF NOT PERFORMING STEP 8 \\nTables are not flat files in a database, and they are not just a different way to casu- \\nally store some data. Relational DBMS engines are based on intricate internal sets \\nof rules. These rules must be understood and followed. Organizations hire data- \\nbase administrators to do just that. However, too often programmers who are not \\nintimately familiar with the internal workings of their DBMS engines are allowed \\nto design the BI target databases, and they design them poorly. This could have a \\ncatastrophic effect on performance. In fact, it could kill the BI application, if not \\nthe entire BI decision-support initiative. \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nAtre, Shaku. Distributed Databases, Cooperative Processing and Networking. New \\nYork: McGraw-Hill, 1992. \\n. Data Base: Structured Techniques for Design, Performance, and Manage- \\nment, Second Edition. New York: John Wiley & Sons, 1988. \\nBischoff, Joyce, and Ted Alexander. Data Warehouse: Practical Advice from the \\nExperts. Upper Saddle River, NJ: Prentice Hall, 1997. \\nBontempo, Charles J., and Cynthia Maro Saracco. Database Management: Princi- \\nples and Products. Upper Saddle River, NJ: Prentice Hall, 1996. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 243}, page_content='210 Step 8: Database Design \\nBruce, Thomas A. Designing Quality Databases with IDEF1X Information Models. \\nNew York: Dorset House, 1992. \\nCorey, Michael J., and Michael Abbey. Oracle Data Warehousing: A Practical \\nGuide to Successful Data Warehouse Analysis, Build, and Roll-out. Berkeley, CA: \\nOsborne McGraw-Hill, 1996. \\nHackney, Douglas. Understanding and Implementing Successful Data Marts. Read- \\ning, MA: Addison-Wesley, 1997. \\nHoberman, Steve. Data Modeler’s Workbench: Tools and Techniques for Analysis \\nand Design. New York: John Wiley & Sons, 2001. \\nInmon, William H. Building the Data Warehouse. New York: John Wiley & Sons, \\n1996. \\nInmon, William H., Claudia Imhoff, and Greg Battas. Building the Operational \\nData Store. New York: John Wiley & Sons, 1996. \\nKimball, Ralph, and Richard Merz. The Data Webhouse Toolkit: Building the Web- \\nEnabled Data Warehouse. New York: John Wiley & Sons, 2000. \\nKimball, Ralph, Laura Reeves, Margy Ross, and Warren Thornthwaite. The Data \\nWarehouse Lifecycle Toolkit: Expert Methods for Designing, Developing, and \\nDeploying Data Warehouses. New York: John Wiley & Sons, 1998. \\nDBMS-specific optimization rules obtainable from the DBMS vendors: \\nIBM: http://www.ibm.com/support/us \\nOracle: http://www.oracle.com \\nNCR Teradata: http://www. teradata.com/library/default.asp \\nMicrosoft SQL Server: http://www. microsoft.com/sql/default.asp \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 244}, page_content='CHAPTER NINE \\nStep 9: Extract/ \\nTransform/ \\nLoad Design \\nCHAPTER OVERVIEW \\nThis chapter covers the following topics: \\n@ Things to consider about extract/transform/load (ETL) \\ndesign \\n= Common BI implementation strategies, such as data marts, \\noperational data stores, enterprise data warehouses, and \\nWeb warehouses \\n@ How to reformat, reconcile, and cleanse the source data for \\nthree different sets of ETL programs: initial load, historical \\nload, and incremental load \\n@ Various approaches for extracting data from the opera- \\ntional source files and source databases \\n@ Typical source data problems encountered during transfor- \\nmation, such as duplicate primary keys, inconsistent data \\nvalues, different data formats, and embedded process logic \\n@ Load considerations, such as referential integrity and \\nindexing \\n@ The source-to-target mapping document, the process flow \\ndiagram, and the staging area \\n@ Eight steps to follow when evaluating ETL products and \\nvendors \\nm Brief descriptions of the activities involved in ETL design, \\nthe deliverables resulting from those activities, and the \\nroles involved \\nm@ The risks of not performing Step 9 \\n211 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 245}, page_content='212 Step 9: Extract/ Transform/ Load Design \\nae \\nTHINGS TO CONSIDER \\nTools \\nV Have we selected an ETL tool, or are we writing the ETL programs from scratch? \\nY Will the ETL tool run on the platform where the source files are? On a sepa- \\nrate server? \\nV Do we have a separate data-cleansing tool? Will we run it before or during \\nthe ETL process? \\nVY Do we have an efficient sort utility? \\nETL Staging \\nV How big is our ETL staging window? How many hours per night? Per week? \\nDo we have a smaller window at month-end because of other month-end \\nprocesses? How much smaller? \\nY Can we fit our ETL process into those windows or will we have to run over \\nseveral days or nights? \\n/Y How many source data elements do we have to extract? And how many \\nsource files and source databases do we have to access? \\nETL Process Flow \\n/Y How many programs can we run in parallel to shorten the ETL runtime? \\nY How long will the initial load take? Have we prototyped it? \\nY How long will it take to load the historical data? How many years of history \\ndo we need to load? \\nY Do we know how long the incremental loads will run? \\n¥ Should we insert rows or use the database management system (DBMS) load \\nutility? \\n¥ Should we use a third-party load utility to speed up the process? Do we \\nalready have a third-party load utility, or do we need to buy one? \\n¥ When and how will the data be archived? On disk? On tape? Do we have to \\nwrite archival programs at this time or can we postpone that additional pro- \\ngramming effort to a future release? \\nPerformance Considerations \\n¥Y How would ETL load performance be affected if we left referential integrity \\n(RI) turned on? \\nV How high would the risk of data corruption be if we turned RI off? \\nly How much RI checking do we want to perform in the ETL programs? ‘ \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 246}, page_content='Implementation Strategies 213 \\nReconciliation \\n¥ At how many points in the ETL process do we need to count input and out- \\nput records? \\nV Are the record layouts and database structures different on the old historical \\nfiles and databases than they are on the current files and databases? How do \\nwe reconcile them? \\nVv Do we need to reconcile changed codes? Reused and redefined fields? \\nVY How many data elements do we have to reconcile? How many codes? How \\nmany amounts? \\n¥ Will dirty data be rejected? How will that be reflected in the reconciliation \\ntotals? \\n¥ Will the load counts and reconciliation totals be stored as meta data? \\nQuality Metrics \\nVY How will data quality errors be counted? What data quality metrics do we \\nneed to compile in the programs? \\nV Will we store those metrics as meta data in the meta data repository or print \\nthem in a report? \\nSource data for the BI applications will come from a variety of platforms, \\nwhich are managed by a variety of operating systems and applications. The pur- \\npose of the ETL process is to merge data from these heterogeneous platforms into \\na standard format for the BI target databases in the BI decision-support environ- \\nment, as shown in Figure 9.1. \\nIMPLEMENTATION STRATEGIES \\nThere are several types of BI decision-support implementation strategies with \\nevery conceivable combination of BI target databases (e.g., operational data store \\nand enterprise data warehouse; Web warehouse and data marts; exploration ware- \\nhouses and data mining databases; data marts and operational marts [oper marts]). \\nBy far the most popular implementation strategy is a data mart environment. \\nRegardless of which implementation strategy is selected, there is a right way \\nand a wrong way to implement it. The wrong way is to build a collection of \\nstand-alone BI target databases, each with its own independent ETL process. This \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 247}, page_content='214 Step 9: Extract/ Transform/ Load Design \\nDB2/UDB DB2 DB2 \\nFOCUS Oracle IMS \\nMicrosoft Access Sybase CA-IDMS \\nParadox Informix NCR-Teradata \\nFoxPro CA-OpenlIngres VSAM \\nLotus Notes ISAM \\nFlat Files \\nBI Target \\nDatabases \\nFigure 9.1: Heterogeneous Data Sources \\napproach will not produce an integrated and reconciled BI decision-support \\nenvironment because creating separate ETL processes is no different than devel- \\noping traditional stovepipe decision-support systems. \\nThe right way to implement a chosen strategy is to build a BI decision-sup- \\nport environment in which all BI target databases are integrated and reconciled. \\nWhen building this environment, it is critical to perform the common data trans- \\nformations for all BI target databases only once and to reconcile these data trans- \\nformations back to the operational source files and source databases. This will \\ndemonstrate the validity of the data in the various BI target databases. It is also \\nimportant to reconcile all the data across the different BI target databases in order \\nto demonstrate the data consistency among the various BI target databases. Both \\nreconciliation processes are best accomplished with a coordinated ETL effort for \\nall BI target databases, as illustrated in Figure 9.2. \\nPaw The most important ETL rule for an integrated BI implementation strategy is \\nto share one coordinated ETL process. This is what differentiates BI from a tradi- \\ntional decision-support approach. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 248}, page_content='Preparing for the ETL Process a5 \\nAccounts \\nPayable/ \\nAccounts \\nReceivable \\nCustomer \\nMaster Resources \\nCustomer \\nFinance Marketing Relationship Resources \\nData Mart Data Mart Data Mart Management Data Mart \\nData Mart \\nFigure 9.2: Integrated BI Implementation Strategy \\nPREPARING FOR THE ETL PROCESS \\nThe ETL process begins with preparations for reformatting, reconciling, and \\ncleansing the source data. \\n* Reformatting: The source data residing in various different source files and \\nsource databases, each with its own format, will have to be unified into a \\ncommon format during the ETL process. \\n* Reconciling: The tremendous amount of data in organizations points to \\nstaggering redundancy, which invariably results in staggering inconsistencies. \\nThese have to be found and reconciled during the ETL process. \\n* Cleansing: Dirty data found during data analysis and prototyping will have \\nto be cleansed during this process. \\nBefore designing the ETL process, it is necessary to review the following: \\n* Record layouts of the current as well as the historical source files \\n* Data description blocks for the current as well as the historical source databases \\n* Data-cleansing specifications for the source data elements \\nMost source data for the ETL process is current operational data from the \\noperational systems, but some of the source data may be archived historical data. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 249}, page_content='216 Step 9: Extract/ Transform/ Load Design \\nTable 9.1: Sets of ETL Programs \\nInitial Load Historical Load Incremental Load \\nInitial population of BI Initial population of BI Ongoing population of Bl \\ntarget databases with target databases with target databases with \\ncurrent operational data archived historical data current operational data \\n1 2 3 \\nIf the data requirements include a few years of history to be backfilled from the start, \\nthree sets of ETL programs must be designed and developed, as listed in Table 9.1. \\nIf the decision is made to write the ETL programs in a procedural language \\n(e.g., C++ or COBOL), the transformation specifications for the three sets of \\nprograms must be prepared and given to the ETL developers. If an ETL tool will \\nbe used, ETL instructions (technical meta data) must be created for the three sets \\nof load processes. The ETL technical meta data will reflect the same logic that \\nwould have been written in custom programs if no ETL tool had been available. \\nThe technical meta data should be stored in a meta data repository. \\nThe Initial Load \\nThe process of preparing the initial load programs is very similar to a system con- \\nversion process, such as the one many organizations perform when they move their \\nold operational systems to an enterprise resource planning (ERP) product. In gen- \\neral, the first task of a system conversion process is to map selected data elements \\nfrom the source files or source databases to the most appropriate data elements in \\nthe target files or target databases. A “most appropriate data element” in a target \\nfile or target database is one that is the most similar in name, definition, size, length, \\nand functionality as the source data element. The second task of a system conver- \\nsion process is to write the conversion (transformation) programs to transform \\nthe source data. These conversion programs must also resolve duplicate records, \\nmatch the primary keys, and truncate or enlarge the size of the data elements. \\nUsually missing from conversion programs, and unfortunately also missing from \\nmost ETL processes, are data cleansing and reconciliation. Organizations repeatedly \\nmiss prime opportunities to bring order to their data chaos when they continue \\nto “suck and plunk” the data from source to target as is. Their only concern is that \\nthe receiving database structure does not reject the source data for technical rea- \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 250}, page_content='Preparing for the ETL Process 217 \\nsons, such as duplicate keys, or data type and length violations. That is not good \\nenough for BI applications because business people expect data quality and data \\nconsistency for business reasons. Thus, when designing the load processes, data \\ncleansing and reconciliation must become part of the ETL process flow. \\nThe Historical Load \\nThe historical load process could be viewed as an extension of the initial load \\nprocess, but this type of conversion is slightly different because historical data is \\nstatic data. In contrast to live operational data, static data has served its opera- \\ntional purpose and has been archived to offline storage devices. The implication \\nis that, as some old data expires and some new data is added over the years, the \\nrecord layouts of archived files are usually not in synch with the record layouts of \\nthe current operational files. Therefore, the conversion programs written for the \\ncurrent operational files usually cannot be applied to archived historical files \\nwithout some changes. For example, in a frequently changing operational system, \\nit is not unusual for five years of archived historical files to have five (or more) \\nslightly different record layouts. Even though the differences in the record layouts \\nmay not be drastic, they still have to be reconciled. In addition, the cleanliness of \\nthe data may not be the same across all archived files. What was once valid in a \\nhistorical file may no longer be valid. The data transformation specifications have \\nto address these differences and reconcile them. All these factors contribute to the \\nreasons why the ETL process can get very lengthy and very complicated. \\nThe Incremental Load \\nOnce the processes for populating the BI target databases with initial and historical \\ndata have been devised, another process must be designed for the ongoing incre- \\nmental load (monthly, weekly, or daily). Incremental loads can be accomplished \\nin two ways, extract all records or deltas only, as shown in Table 9.2. The design of \\nthe ETL extract process will differ depending on which option is selected. \\nTable 9.2: Incremental Load Options \\nExtract All Records Extract Deltas Only \\nExtract source data from all operational Extract source data only from those \\nrecords, regardless of whether any data operational records in which some data \\nvalues have changed since the last ETL values have changed since the last ETL \\nload or not. load (“net change’). \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 251}, page_content='218 Step 9: Extract/ Transform/ Load Design \\nExtracting all records is often not a viable option because of the huge data \\nvolumes involved. Therefore, many organizations opt for delta extracts (extracting \\nonly records that changed). Designing ETL programs for delta extraction is much \\neasier when the source data resides on relational databases and the timestamp \\ncan be used for determining the deltas. But when the data is stored in flat files \\nwithout a timestamp, the extract process can be significantly more complex. You \\nmay have to resort to reading the operational audit trails to determine which \\nrecords have changed. \\nAn alternative may be to extract a complete copy of the source file for every \\nload, then compare the new extract to the previous extract to find the records \\nthat changed and create your own delta file. Another alternative is to ask the \\noperational systems staff to add a system timestamp to their operational files. \\nOccasionally they may agree to do that if the change to their operational systems \\nis trivial and does not affect many programs. However, in most cases operations \\nmanagers will not agree to that because any changes to their file structures would \\nalso require changes to their data entry and update programs. Additional code \\nwould have to be written for those programs to capture the system timestamp. It \\nwould not be cost-effective for them to change their mission-critical operational \\nsystems and spend a lot of time on regression testing—just for the benefit of a BI \\napplication. \\nProcessing Deleted Records \\nAnother aspect that needs to be carefully considered for incremental loads is that \\nof deleted operational source records. When certain records are logically deleted \\nfrom the source files and source databases (flagged as deleted but not physically \\nremoved), the corresponding rows cannot automatically be deleted from the BI \\ntarget databases. After all, one of the main requirements of BI target databases is \\nto store historical data. \\nThe ETL process must follow a set of business rules, which should define \\nwhen an operational deletion should propagate into the BI target databases and \\nwhen it should not. For example, perhaps an operational record is being deleted \\nbecause it was previously created in error, or because the record is being archived, \\nor because the operational system stores only “open” transactions and deletes the \\n“closed” ones. Most likely, the business rules would state that you should delete \\nthe related row from the BI target database only in the case where the record was \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 252}, page_content='Designing the Extract Programs 219 \\ncreated in error. Since your BI target database stores historical data, the business \\nrules would probably not allow you to delete the related row in the other two \\ninstances. \\nWhen records are physically deleted from the source files or source databases, \\nyou would never know it if you are extracting only deltas. Delta extract programs \\nare designed to extract only those existing records in which one of the data values \\nchanged; they cannot extract records that do not exist. One way to find the phys- \\nically deleted records is to read the operational audit trails. Another option is to \\nextract a complete copy of the source file, compare the new extract to the previ- \\nous extract to find the records that were deleted, and then create your own delta \\nfiles. In either case, once the deleted records are identified, the ETL process has to \\nfollow a set of business rules to decide whether or not to physically remove the \\nrelated rows from the BI target databases. \\nDESIGNING THE EXTRACT PROGRAMS \\nFrom an operational systems perspective, the most favored way to create extracts \\nmight be to just duplicate the entire contents of the operational source files and \\nsource databases and to give the duplicates to the BI project team. However, the \\nETL developers would have the burden of working with huge files when they only \\nneed a subset of the source data. \\nFrom the BI project perspective, the most favored way to create extracts \\nmight be to sort, filter, cleanse, and aggregate all the required data in one step if \\npossible and to do it right at the source. However, in some organizations that \\nwould impact the operational systems to such a degree that operational business \\nfunctions would have to be suspended for several hours. \\nThe solution is usually a compromise: the extract programs are designed for \\nthe most efficient ETL processing, but always with a focus on getting the required \\nsource data as quickly as possible. The goal is to get out of the way of operational \\nsystems so that the daily business functions are not affected. This is easier said \\nthan done, for a number of reasons. \\nSelecting and merging data from source files and source databases can be \\nchallenging because of the high data redundancy in operational systems. The \\nextract programs must know which of the redundant source files or source data- \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 253}, page_content='220 Step 9: Extract/ Transform/ Load Design \\nbases are the systems of record. For example, the same source data element (e.g., \\nCustomer Name) can exist in dozens of source files and source databases. These \\nredundant occurrences have to be sorted out and consolidated, which involves a \\nnumber of sort and merge steps, driven by a number of lookup tables cross-refer- \\nencing specific keys and data values. \\nAnother way to produce small and relatively clean extract files is to extract \\nonly those source data elements that are needed for the BI application and to \\nresolve only those source data quality problems that pertain to the business data \\ndomain rules, without attempting to sort out and consolidate redundant occur- \\nrences of data. However, even that compromise will not work in many large orga- \\nnizations because the data-cleansing process would slow down the extract process, \\nwhich in turn would tie up the operational systems longer than is acceptable. \\nIn many large organizations, the BI project team is lucky to get three to four \\nhours of processing time against the operational systems before those operational \\nsystems have to “go live” for the operational functions of the next business day. \\nThis is the main reason why populating the BI target databases is split into three \\nseparate processes: extract, transform, and load (Figure 9.3). \\nBI Target \\nDatabases \\nFigure 9.3: ETL Processes \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 254}, page_content='Designing the Transformation Programs 221 \\nDESIGNING THE TRANSFORMATION PROGRAMS \\nUsing the 80/20 rule, 80 percent of ETL work occurs in the “T” (transform) por- \\ntion when extensive data integration and data cleansing are required, while \\nextracting and loading represent only 20 percent of the ETL process. \\nSource Data Problems \\nThe design of the transformation programs can become very complicated when \\nthe data is extracted from a heterogeneous operational environment. Some of the \\ntypical source data problems are described below. \\n- Inconsistent primary keys: The primary keys of the source data records do \\nnot always match the new primary key in the BI tables. For example, there \\ncould be five customer files, each one with a different customer key. These \\ndifferent customer keys would be consolidated or transformed into one stan- \\ndardized BI customer key. The BI customer key would probably be a new sur- \\nrogate (“made-up”) key and would not match any of the operational keys, as \\nillustrated in Figure 9.4. \\nInconsistent data values: Many organizations duplicate a lot of their data. The \\nterm duplicate normally means the data element is an exact copy of the origi- \\nnal. However, over time, these duplicates end up with completely different \\nCUST-NUM X(9) \\nVSAM ISAM One 2m, \\nQSAM - esi Element 7S 4 \\nBDAM Desktop Tools = yan : One Flat Files — Standardized \\nBI Data Format \\nCUSTOMER-ID 9(8) | = etsemh | i ; e Dy > — Homonyms — : \\n: CUSTOMER. ID 4 \\nOracle, DB2, CID INT - Data © \\nSybase, etc. Element. \\n(relational) Inconsistent \\nKeys { \\\\ \\nFigure 9.4: Resolution of Inconsistent Primary Keys \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 255}, page_content='aoe Step 9: Extract/ Transform/ Load Design \\ndata values because of update anomalies (inconsistent updates applied to the \\nduplicates), which have to be reconciled in the ETL process. \\n* Different data formats: Data elements such as dates and currencies may be \\nstored in a completely different format in the source files than they will be \\nstored in the BI target databases. If date and currency conversion modules \\nalready exist, they need to be identified; otherwise, logic for this transforma- \\ntion has to be developed. \\nInaccurate data values: Cleansing logic has to be defined to correct inaccu- \\nrate data values. Some of the data-cleansing logic can get extremely compli- \\ncated and lengthy. The correction of one data violation can take several pages \\nof cleansing instructions. Data cleansing is not done only once—it is an \\nongoing process. Because new data is loaded into the BI target databases with \\nevery load cycle, the ETL data-cleansing algorithms have to be run every time \\ndata is loaded. Therefore, the transformation programs cannot be written \\n“quick and dirty.” Instead, they must be designed in a well-considered and \\nwell-structured manner. \\nSynonyms and homonyms: Redundant data is not always easy to recognize \\nbecause the same data element may have different names. Operational sys- \\ntems are also notorious for using the same name for different data elements. \\nSince synonyms and homonyms should not exist in a BI decision-support \\nenvironment, renaming data elements for the BI target databases is a com- \\nmon occurrence. \\nEmbedded process logic: Some operational systems are extremely old. They \\nrun, but often no one knows how! They frequently contain undocumented \\nand archaic relationships among some source data elements. There is also a \\nvery good chance that some codes in the operational systems are used as \\ncryptic switches. For example, the value “00” in the data element Alter-Flag \\ncould mean that the shipment was returned, and the value “FF” in the same \\ndata element could mean it was the month-end run. The transformation \\nspecifications would have to reflect this logic. \\nData Transformations \\nBesides transforming source data for reasons of incompatible data type and length \\nor inconsistent and inaccurate data, a large portion of the transformation logic \\nwill involve precalculating data for multidimensional storage. Therefore, it should \\nnot be surprising that the data in the BI target databases will look quite different \\nthan the data in the operational systems. Some specific examples appear below. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 256}, page_content='Designing the Load Programs 223 \\n* Some of the data will be renamed following the BI naming standards (syn- \\nonyms and homonyms should not be propagated into the BI decision-support \\nenvironment). For example, the data element Account Flag may now be called \\nProduct_Type_Code. \\nSome data elements from different operational systems will be combined \\n(merged) into one column in a BI table because they represent the same logical \\ndata element. For example, Cust-Name from the CMAST file, Customer_Nm \\nfrom the CRM_CUST table, and Cust_Acct_Nm from the CACCT table may \\nnow be merged into the column Customer_Name in the BI CUSTOMER \\ntable. \\nSome data elements will be split across different columns in the BI target \\ndatabase because they are being used for multiple purposes by the opera- \\ntional systems. For example, the values “A’, “B”, “C”, “L?, “M”, “N”, “X”, “Y”, and \\n“Z” of the source data element Prod-Code may be used as follows by the \\noperational system: “A,” “B,” and “C” describe customers; “L,” “M,” and “N” \\ndescribe suppliers; and “X,” “Y,” and “Z” describe regional constraints. As a \\nresult, Prod-Code may now be split into three columns: \\n— Customer_Type_Code in the BI_ CUSTOMER table \\n— Supplier_Type_Code in the BI_SUPPLIER table \\n— Regional_Constraint_Code in the BI_ ORG_UNIT table \\nSome code data elements will be translated into mnemonics or will be spelled \\nout. For example: \\n— “A” may be translated to “Corporation” \\n— “B” may be translated to “Partnership” \\n— “C” may be translated to “Individual” \\nIn addition, most of the data will be aggregated and summarized based on \\nrequired reporting patterns and based on the selected multidimensional \\ndatabase structure (star schema, snowflake). For example, at the end of the \\nmonth, the source data elements Mortgage-Loan-Balance, Construction-Loan- \\nBalance, and Consumer-Loan-Amount may be added up (aggregated) and \\nsummarized by region into the column Monthly_Regional_Portfolio_Amount \\nin the BI_LPORTFOLIO fact table. \\nDESIGNING THE LOAD PROGRAMS \\nThe final step in the ETL process is loading the BI target databases, which can be \\naccomplished in either of two ways: (1) by inserting the new rows into the tables \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 257}, page_content='224 Step 9: Extract/ Transform/ Load Design \\nor (2) by using the DBMS load utility to perform a bulk load. It is much more \\nefficient to use the load utility of the DBMS, and most organizations choose that \\napproach. \\nOnce the extract and transformation steps are accomplished, it should not be \\ntoo complicated to complete the ETL process with the load step. However, it is \\nstill necessary to make design decisions about referential integrity and indexing. \\nReferential Integrity \\nBecause of the huge volumes of data, many organizations prefer to turn off RI to \\nspeed up the load process. However, in that case the ETL programs must perform \\nthe necessary RI checks; otherwise, the BI target databases can become corrupt \\nwithin a few months or even weeks. Acting on the idea that RI checking is not \\nneeded for BI applications (because no new data relationships are created and \\nonly existing operational data is loaded) does not prevent database corruption! \\nCorruption of BI target databases often does occur, mainly because operational \\ndata is often not properly related in the first place, especially when the opera- \\ntional data is not in a relational database. Even if the operational data comes from \\na relational database, there is no guarantee of properly enforced RI because too \\nmany relational database designs are no more than unrelated flat files in tables. \\nWhen RI is turned off during the ETL load process {as it should be, for perfor- \\nmance reasons), it is recommended to turn it back on again after the load pro- \\ncess has completed in order to let the DBMS determine any RI violations \\nbetween dependent tables. \\nIndexing \\nPoorly performing databases are often the result of poorly performing indexing \\nschemes. It is necessary to have efficiently performing indices, and to have many \\nof them, because of the high volume of data in the BI target databases. However, \\nbuilding index entries while loading the BI tables slows down the ETL load pro- \\ncess. Thus, it is advisable to drop all indices before the ETL load process, load the \\nBI target databases, and then recreate the indices after completing the ETL load \\nprocess and checking RI. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 258}, page_content='Designing the ETL Process Flow 225 \\nDESIGNING THE ETL PROCESS FLOW \\nThe Source-to-Target Mapping Document \\nBefore the ETL process flow can be designed (or enhanced), the detailed ETL \\ntransformation specifications for data extraction, transformation, and reconcilia- \\ntion have to be developed, given that they will dictate the process flow. A com- \\nmon way to document the ETL transformation specifications is in a source-to- \\ntarget mapping document, which can be a matrix or a spreadsheet (Table 9.3). \\nThe source-to-target mapping document should list all BI tables and col- \\numns and their data types and lengths. It should map the applicable source data \\nelements to the columns, along with their data types and lengths, and it should \\nshow the source files and source databases from which the source data elements \\nare being extracted. Finally, and most importantly, the document should specify \\nthe transformation logic for each column. \\nThis document can then be used to create the actual programming specifica- \\ntions for the ETL developers or to create instructions (technical meta data) for \\nthe ETL tool. \\nThe ETL Process Flow Diagram \\nOnce the source-to-target mapping document has been completed, the ETL lead \\ndeveloper, with the help of the database administrator and the data quality ana- \\nlyst, must design the ETL process flow, as illustrated by the example in Figure 9.5. \\nThe purpose for the ETL process flow diagram is to show the process depen- \\ndencies between all extracts, sorting and merging utilities, transformations, tem- \\nporary work files or tables, error-handling processes, reconciliation activities, and \\nthe load sequence. The ETL programs, or ETL tool modules, will have to run in \\nthis sequence. \\n* Extracts: There may be operational interdependencies among several source \\nfiles and source databases from which data is being extracted. These interde- \\npendencies have to be understood because they may affect the timing and the \\nsequence of running the ETL extract programs. \\n- Sorting and merging utilities: Almost every step requires the extracted data \\nto be sorted in a particular fashion so that it can be merged before further \\nprocessing can occur. Sorting can also greatly improve load performance. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 259}, page_content='ign Extract/ Transform/ Load Des Step 9 226 \\nOND \\nUQTM \\npiodet \\nOf \\nAequinu \\nTewoAsNno Meu uUHbTtssyY 2514 \\nGute) \\nwee \\npzo0sea \\nOf \\nZequinu \\nZTeuojsnd \\nmMsu \\nubtssy \\nun \\n= \\n9POD-OdV \\nFI \\nesta \\nWON-LSNO \\nYUITM \\npiosez \\nof \\nAequnu \\nZJewoqysno \\nMeu \\nup \\ntssy \\nU8 \\n«ats \\n= \\nSPOOQ-OdV \\nFI \\nLSNO YEWOLSNO \\nzZeqsen—asno \\nee \\nsa, \\nsuolprifpads \\nuonpuLiofsuD4 \\naspDqp}0a /afl4 A2DANOS \\nCain) \\nONO \\nLNT \\ndIO \\n(GI \\nWOAN-LSNO \\nYdHOaLNI \\nGI \\nYWHWOLSNO \\nYaHNOLSNO \\ny}buaT \\njuaulajq \\nDDG \\ny}buaT \\nuwinjo) \\naIqDL \\n/adkL \\n/adky \\njuawndo0g \\nsuiddej| \\n}98Je]-0}-3d1NOS \\ne \\nJo \\najdwexy \\n:€°6 \\naIGeL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 260}, page_content=\"227 \\nWeISEIG \\nMO|4 \\nSS8D0Jd \\n119 \\na[dwes \\n:¢'6 \\naunSiy \\nsjoedsold \\nsjoedsold \\nJ0exXy \\nsppedsold \\nSJQWO}SND \\nmt \\na \\npeyog \\nSJSWOJSND \\nWOS \\nspedsolg \\nafuay| \\n8}l4 \\nOu} \\nJawojysng \\nSIBWOISND \\naha \\n= \\nae \\ni? \\noS \\nJawosno \\nSJOUZ \\ny \\nSS) \\nsjunoooy \\nuYoley\\\\ \\njunoooy \\nSUOI]OBSUBI] \\nSJUNODOY \\nJOeRIXA \\n5 \\njunosoy \\nkL \\ns]unoDOy \\na \\neels: \\nsjunosoy \\n0S \\nsjunodoy \\n49}]1-4 \\nog S \\nSe \\n» \\na \\nSa|BS \\nMOEN \\nJ0eI}Xy \\n=} \\nti \\nCate) \\nLu fe?) = ~~ on \\n£ \\ni= \\na \\nDes \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 261}, page_content='228 Step 9: Extract/ Transform/ Load Design \\n* Transformations: Most of the data has to be transformed for a variety of rea- \\nsons. It is important to examine the most opportune times to perform the \\ntransformations. Remember that there is only one coordinated ETL process \\nfor the BI decision-support environment. Therefore, transformations applica- \\nble to all source data, such as data type and code conversions or data domain \\nenforcements, should be performed early in the ETL process flow. Transfor- \\nmations specific to a target database, such as aggregation and summarization \\nfor a specific data mart, should occur toward the end of the ETL process flow. \\nTemporary work files or tables: Sorting, merging, and transforming require \\na lot of temporary storage space to hold the interim results. These temporary \\nwork files and tables can be as large or larger than the original extracts. Fur- \\nthermore, these temporary work files and tables are not really “temporary.” \\nPlan to have that space available for your staging area permanently. \\nError-handling processes: During the ETL process many errors are detected \\nas the data-cleansing specifications are applied to the source data. If error \\nreports are created or erroneous records are rejected into a suspense file, they \\nshould be shown on the ETL process flow diagram. \\nReconciliation activities: Every program module that manipulates data \\nshould produce reconciliation totals. This can be in the form of input and \\noutput record counts, specific domain counts, or amount counts. Record \\ncounts are sufficient for extract, sort, and merge modules. Domain counts are \\nappropriate for more complicated transformation specifications, such as sep- \\narating data values from one source data element into multiple target col- \\numns. Amount counts are usually performed on all amount data elements, \\nwhether they are moved as is, transformed into a new format, or used in a \\ncalculation. (ETL reconciliation will be described in more detail in Step 11, \\nETL Development.) \\nLoad sequence: It is necessary to determine the sequence in which the tables \\nhave to be loaded because of their potential interdependencies and because of \\na possible recursive relationship on one table. For example, the Product \\ndimension table may have to be loaded before the Sales table is loaded, if RI is \\nturned on and if the sales data references products. Other tables may be loaded \\nsimultaneously, which can greatly improve the speed of the load process. \\nThe Staging Area \\nA staging area is the place where the ETL process runs. It refers to dedicated disk \\nspace, ETL program libraries, temporary and permanent work files and tables—even \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 262}, page_content='Evaluating ETL Tools 229 \\na dedicated server. The staging area can be centralized or decentralized. For \\nexample, it can be a central mainframe staging area if most of the source data is in \\nflat files on a mainframe. It can also be on a dedicated server onto which the \\nsource data is loaded. Many times the staging area is decentralized. For example, \\na convoluted mainframe file with many redefines and occurs clauses may \\nhave to be flattened out with a COBOL program in a staging area on the main- \\nframe before it is downloaded to a staging area on a UNIX box for further pro- \\ncessing by an ETL tool. \\nThe ETL process is by far the most complicated process to be designed and \\ndeveloped in any BI project. Since there is only one (logical) coordinated ETL \\nprocess for the BI decision-support environment, expanding the ETL programs \\nwith each new BI application becomes very complicated, and regression testing \\nrequires more and more time. For these reasons, most organizations prefer to use \\nan ETL tool for all or some of the ETL process, especially for the extract and \\ntransformation processes, as shown in Figure 9.6. \\n\" ETL Tool Functions DBMS Utility \\noe \\nBI Target \\nDatabases \\nP= DONG Ze SS \\nFigure 9.6: Common Use of ETL Tools in the ETL Process \\nEVALUATING ETL TOOLS \\nWhen using an ETL tool, the transformation specifications get translated into \\ninstructions for the ETL tool. These instructions can then be stored as technical \\nmeta data in the meta data repository. Expanding the ETL process and running \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 263}, page_content='230 Step 9: Extract/ Transform/ Load Design \\nregression tests are made easier with the tool because there is less human inter- \\nvention and therefore fewer chances to introduce errors. \\nWhen evaluating ETL products, follow these steps. \\n1. Perform a cost-benefit analysis to compare licensing (buying) an ETL product \\nwith building the ETL process in-house. Although both options can be \\nexpensive for different reasons (licensing a very sophisticated ETL tool is \\nexpensive, but so is maintaining custom-built software), your first choice \\nshould be licensing an ETL tool. If the ETL tool cannot handle all of the \\nrequired transformations, supplement the licensed product with your own \\nspecialized code for those transformations. If your transformation require- \\nments are simple and you have a small budget, you may want to buy a less \\nsophisticated ETL tool or consider building your own ETL process. \\n2. Compile a list of ETL products and vendors that are likely to meet your require- \\nments. Attend trade shows to learn more about the products and vendors. \\nCaveat emptor—be a cautious and skeptical buyer. \\nLet your transformation and cleansing requirements—not vendor hype— \\ndrive your product evaluation and selection process. \\n3. Compare the ETL products and vendors to your weighted data transformation \\nrequirements. Include the business rules for data cleansing as part of your \\nETL tool selection criteria. For example, some ETL tools cannot read flat files \\nand cannot perform some of the very complicated transformations. If you \\nneed those capabilities, you must be aware of ETL tool limitations because \\nyou may need to license an additional data-cleansing tool to perform those \\nprocesses, or augment the ETL tool functionality with custom-written code. \\n4. Evaluate each ETL product objectively and prepare a scorecard that compares \\nthe product features and their effectiveness. The reputation and responsive- \\nness of a vendor are equally as important as the features of the products. \\nTherefore, prepare another scorecard comparing the vendors. \\n5. Check the vendors’ client references by talking with people at organizations \\nthat already use the tools you are considering. This is the most cost-effective \\nand informative way to evaluate the tools. \\n6. Narrow the list of ETL products and vendors to a short list of two or three can- \\ndidates. Otherwise, you will waste too much time comparing all the products, \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 264}, page_content='ETL Design Activities 231 \\nand it may take “forever” to make the final decision. You might then select an \\ninferior tool just to end the frustration and delay. \\n7. Arrange for product demos since “seeing is believing.” Spend some time pre- \\nparing the test cases so that all vendors on the short list get to demonstrate \\nthe performance and effectiveness of their products using the same test cases. \\n8. Test the vendor products even though it takes away time from your project \\nschedule. Testing is the best way to discover any glitches that may happen \\nbefore using a vendor product in production. Try to negotiate a 30-day trial \\nperiod. \\n(The process of evaluating and selecting products and vendors is described in \\nmore detail in Step 10, Meta Data Repository Design.) \\nETL DESIGN ACTIVITIES \\nThe activities for ETL design do not need to be performed linearly. Figure 9.7 \\nindicates which activities can be performed concurrently. The list below briefly \\ndescribes the activities associated with Step 9, ETL Design. \\n4 \\nDesign ETL \\nprograms \\n{ \\nCreate source-to-target \\nmapping document \\n3 \\nDesign ETL \\nprocess flow \\n3) \\nSet up ETL \\nstaging area \\n2 \\nTest ETL tool \\nfunctions \\nFigure 9.7: ETL Design Activities \\n1. Create the source-to-target mapping document. \\nUse the source data analysis results and the business rules from the previous \\nsteps and incorporate them into the transformation specifications. Docu- \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 265}, page_content='232 Step 9: Extract/ Transform/ Load Design \\nment the transformation specifications in a source-to-target mapping matrix \\nor spreadsheet. \\n2. Test the ETL tool functions. \\nIt is very important to test the ETL tool functions before designing the ETL \\nprocess flow and before deciding how to set up the staging area. For example, \\nit would be worthless to install a currently popular ETL tool that cannot read \\nflat files on a mainframe if 90 percent of your source data is in flat files on \\nyour mainframe. Therefore, test the ETL tool functions and determine \\nwhether supplemental code must be written to perform some complicated \\nand lengthy transformations that the tool cannot handle. \\n3. Design the ETL process flow. \\nThe most challenging aspect of ETL design is creating an efficient ETL pro- \\ncess flow. Because most data staging windows are very small—only a few \\nhours per night—the ETL process must be streamlined as much as possible. \\nThat means breaking the ETL process into small program components so \\nthat as many as possible can be run in parallel. \\n4, Design the ETL programs. \\nSince most organizations require several years of historical data to be loaded \\nwith the first BI application release, there are three sets of ETL programs to \\nconsider: the initial load, the historical load, and the incremental load. The \\nincremental load will probably be a delta load and will therefore be the most \\ncomplicated to design. Modularize the ETL programs as much as possible, \\nand create programming specifications for each ETL program module. \\n5. Set up the ETL staging area. \\nDetermine whether you need a centralized staging area on a dedicated server \\nor whether it would make more sense to implement a decentralized staging \\narea in your environment. Deciding factors are the type and location of \\nsource files and source databases, as well as the functions, capabilities, and \\nlicensing terms of the ETL tool. \\nPaw Do not create a separate staging area for each data mart. A decentralized, \\ncoordinated staging area is not the same thing as separate, uncoordinated \\nstaging areas for different BI target databases and different BI applications. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 266}, page_content='Roles Involved in These Activities 233 \\nDELIVERABLES RESULTING FROM THESE ACTIVITIES \\n1. Source-to-target mapping document \\nThis document contains the transformation specifications for each BI column, \\nincluding instructions for data cleansing, RI checking, reconciliation, and \\nerror handling, as well as algorithms for aggregations and summarizations. \\n2. ETL process flow diagram \\nThe ETL process flow diagram shows the process sequence and the process \\ndependencies among all ETL process components, such as program modules, \\ntemporary and permanent work files and tables, and sort, merge, and load \\nutilities. \\n3. ETL program design document \\nThis document is created from the source-to-target mapping document after \\nthe ETL process flow has been determined. It contains the actual program- \\nming specifications for every ETL program module for the initial load, his- \\ntorical load, and incremental load. Portions of this document will be given to \\ndifferent ETL developers to code the program modules. \\n4, Staging area \\nThe staging area should contain program libraries with version control as well \\nas dedicated space for temporary and permanent work files and tables. \\nROLES INVOLVED IN THESE ACTIVITIES \\n@ Data quality analyst \\nWorking with the ETL lead developer, the data quality analyst must transfer \\nhis or her knowledge about the condition of the source files and source data- \\nbases discovered during Step 5, Data Analysis. Since the data quality analyst \\nusually has a systems analysis background, he or she can assist in or even take \\nover creating the source-to-target mapping document. \\n@ Database administrator \\nThe database administrator must be involved in the design of the ETL process \\nbecause of its database aspects (RI, indexing, clustering, and the use of the \\nDBMS load utility). The database administrator can provide valuable input to \\nthe ETL process flow and can sometimes reduce the ETL staging window by \\nseveral hours. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 267}, page_content='234 Step 9: Extract/ Transform/ Load Design \\n@ ETL lead developer \\nThe ETL lead developer is responsible for the entire ETL process. With the \\nhelp of the database administrator, the data quality analyst, and the subject \\nmatter expert, the ETL lead developer designs the ETL process flow and cre- \\nates the ETL program design document with the actual programming specifi- \\ncations for the ETL developers (or instructions for the ETL tool). \\n® Subject matter expert \\nThe subject matter expert plays an advisory role during this step. Since the \\nsubject matter expert was involved in identifying the source data and finding \\nthe data quality problems, he or she should participate in creating the source- \\nto-target mapping document. The subject matter expert will also be the liai- \\nson to the business representative who must validate the business rules used in \\nthe ETL process. \\nRISKS OF NOT PERFORMING STEP 9 \\nThis is not an optional step—not even if you plan to use an ETL tool. Every BI \\nproject team must evaluate the source data and figure out how to improve it, \\nchange it, standardize it, and make it more useful before moving it into the BI \\ntarget databases. A BI project is not like a systems conversion project, where you \\nsimply try to move from one technology platform to another while transferring \\nthe data as is. A BI project is more like a system redesign or a business process \\nimprovement project, where you want to change the data. You cannot afford to \\nmove data as is from source to target and then wait for the database to reject a \\ndata element for technical reasons. You must plan and design the required \\nchanges for business reasons. \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nAdelman, Sid, and Larissa Terpeluk Moss. Data Warehouse Project Management. \\nBoston, MA: Addison-Wesley, 2000. \\nAiken, Peter H. Data Reverse Engineering: Slaying the Legacy Dragon. New York: \\nMcGraw-Hill, 1995. \\nBrackett, Michael H. Data Resource Quality: Turning Bad Habits into Good Prac- \\ntices. Boston, MA: Addison-Wesley, 2000. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 268}, page_content='Bibliography and Additional Reading 235 \\n. The Data Warehouse Challenge: Taming Data Chaos. New York: John \\nWiley & Sons, 1996. \\nHackney, Douglas. Understanding and Implementing Successful Data Marts. Read- \\ning, MA: Addison-Wesley, 1997. \\nImhoff, Claudia, Lisa Loftis, and Jonathan G. Geiger. Building the Customer-Centric \\nEnterprise: Data Warehousing Techniques for Supporting Customer Relationship \\nManagement. New York: John Wiley & Sons, 2001. \\nKimball, Ralph, and Richard Merz. The Data Webhouse Toolkit: Building the Web- \\nEnabled Data Warehouse. New York: John Wiley & Sons, 2000. \\nKimball, Ralph, Laura Reeves, Margy Ross, and Warren Thornthwaite. The Data \\nWarehouse Lifecycle Toolkit: Expert Methods for Designing, Developing, and Deploy- \\ning Data Warehouses. New York: John Wiley & Sons, 1998. \\nPonniah, Paulraj. Data Warehousing Fundamentals: A Comprehensive Guide for IT \\nProfessionals. New York: John Wiley & Sons, 2001. \\nSperley, Eric. The Enterprise Data Warehouse: Planning, Building, and Implemen- \\ntation. Upper Saddle River, NJ: Prentice Hall, 1999. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 269}, page_content='7 a = \\n- (apie wy © aannt Pou —— ruil @ &* Piethicee sitet teat \\nBare oe fen & ~The (5S oe i ehgrt Se Fegiphewel, \\na. s. feat ene \\nPAT, eile wenasl.) wee aes py teprg seal saa \\nThs wi. fedal eras is ryui sae fey ‘pune aa singer \\nnag oi a ay eh pe eon L. 1 od erties ef al ae uae \\np> Sis ree | \\nmien oth em earthy pokey Be \\nae ee anaes oi e vibes ak “ a ads am i \\neee dairies sah ate = an ee aie \\nih coral. \\nprobe Asses Sree 1 aud AW na) AN QVrh simu — \\nTha he varanwlavqenes A olaamsmebiey gemlwibe payer \\neo: FMS aster BSW otol fet wet @ \\nDirerwh Gel aratyepakind, beep At Sra nlats oenipeiel wT a i$) 4iBb : \\nTR afte Het Oey——0\" DATE Be bk Pie : nn ae \\npele vert: ges aaliiy hs wade Oe o%. gem it tee ity \\nGare) ie qusihadw 4 4) Bde & on Het | bain ai \\neenget daleeed) / ° niet er ie Te aie Fengepylagy crimes, alvere \\nthe dun ae & Mh ge rr W th pa @ (im Pipi Ke a \\nSOR Te abl ete | (mei SRE S Menge ie Oh, a vant P| ; \\nWanPilitger > He Pah. @ ape Gil Son Wed he ede *¢ erat \\n<Sesfiger O°.) GEST 14.00% \\n— \\nampep re al. ce Fenty, Pere \\nSeen On), cts! Sera cae id Aa. Mite ivd « Wittey met \\nwee 2 Rad) Aghlise: “ele, TOD, \\n‘Gam, Wan be fate dw ve hy wnamingt Sheng th Sager é \\n> AB, 14 ws & os \\nGm Atatett A. Pree iP pail Viney eae MUP ay fines \\n* As Gab): bbieg Hy ea, ; i - \\n~ \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 270}, page_content='Justification \\nPlanning ; \\nBusiness Analysis \\n10 \\nMeta Data \\nRepository \\nDesign \\nUs \\nNe \\nStep 10: Meta Data \\nRepository Design \\nCHAPTER OVERVIEW \\nThis chapter covers the following topics: \\n@ Things to consider when designing a meta data repository \\nor when evaluating meta data repository vendor products \\n@ How the shortcomings of early meta data initiatives con- \\ntributed to failures to effectively manage meta data \\n@ The multitude of meta data sources we now have to man- \\nage in a BI decision-support environment \\nm@ The advantages and disadvantages of three different types \\nof implementation strategies: a centralized meta data \\nrepository, either built or licensed (bought); a decentralized \\nmeta data repository; and a distributed meta data solution \\nenabled through the use of Extensible Markup Language \\n(XML) tags \\nm@ The advantages and disadvantages of two different types \\nof meta data repository designs: an entity-relationship (E-R) \\ndesign and an object-oriented (OO) design \\nm@ Detailed examples of the product and vendor evaluation \\nprocess \\n@ Brief descriptions of the activities involved in meta data \\nrepository design, the deliverables resulting from those \\nactivities, and the roles involved \\n@ The risks of not performing Step 10 \\n237 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 271}, page_content='238 Step 10: Meta Data Repository Design \\nTHINGS TO CONSIDER \\nExisting Meta Data Repository \\nY Do we already have a meta data repository? \\nVv Do we have to expand it? Do we have to add more meta data components? \\nOr expand the functionality? \\n¥V Who is keeping the meta data repository up-to-date? \\n/Y Who is using it? How are they using it? What parts of the meta data reposi- \\ntory are they using? \\nV Do they like it? Are there any complaints? \\nVv If we do not have a meta data repository, how are we coping without one? \\n¥ Why do we not have one? Lack of budget? Lack of resources? Lack of \\nunderstanding? \\nMeta Data Repository Products \\nV Are there meta data repository products that will satisfy our meta data \\nrequirements? Or do we have to build a meta data repository from scratch? \\nY How many of our meta data requirements cannot be satisfied by the meta \\ndata repository products on the market? How important are those meta data \\nrequirements? \\nY Can the meta data repository products be enhanced to meet those specific \\nmeta data requirements? \\n¥ Which meta data repository products have import and export capabilities? \\nInterfaces \\nVY How will we automate the interfaces from the meta data repository to other \\ntools that have their own meta data dictionaries, for example, computer- \\naided software engineering (CASE), extract/transform/load (ETL), and \\nonline analytical processing (OLAP) tools? Will we have to buy additional \\nmiddleware? \\nV Do the other tools from which we have to extract meta data have import and \\nexport capabilities? Are those tools XML-enabled? \\nV How will we deliver the meta data to the business people? Through reports? \\nThrough a help function? Through a Web interface? \\n¥ Will it be hard for the business people to learn how to use the meta data \\nrepository interfaces? What training do we have to develop? \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 272}, page_content='Meta Data Silos 239 \\nStaffing \\nY Will we need more staff to install, enhance, and maintain a licensed meta \\ndata repository product? \\n¥ Will we need more staff to design, build, and maintain our own custom- \\nbuilt meta data repository? \\nThe term meta data is not new, and efforts to manage meta data are not new \\neither. What is new is the increased awareness that meta data is an important \\nextension to business information and that managing meta data is therefore \\nmandatory. Another important recognition is that new tools and techniques for \\nmanaging meta data are needed—and are becoming available. \\nMETA DATA SILOS \\nData administrators have tried to inventory, define, and organize meta data since \\nthe early 1980s. Most data administrators used generic data dictionary products \\n(meta data repositories used to be called data dictionaries); only few tried to \\ndesign and build their own. Some of the generic data dictionary products were \\nrather sophisticated and expandable, and they could store most of the required \\nmeta data components. However, there were multitudes of problems associated \\nwith these early efforts. \\n* Populating these early data dictionaries required a manual effort, which was \\ntime consuming and tedious, as all manual efforts are. \\n* The lack of technical skills on the part of most data administrators prevented \\nthem from expanding the data dictionary products with custom features to \\nmake them more useful. \\n* The reporting capabilities of the early data dictionary products were less than \\ndesirable. Some products did not even have application programming inter- \\nface (API) capabilities that would allow data administrators to generate cus- \\ntomized reports. \\n* The immature technologies used in most early data dictionaries (which were \\nmainframe products) did not provide automated interfaces, easy-to-use \\ngraphical user interface (GUI) displays, or context-sensitive help functions. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 273}, page_content='240 Step 10: Meta Data Repository Design \\n* The lack of standards (or the lack of enforcement of standards) created an \\ninsurmountable burden for the data administrators who had to resolve con- \\nflicting and inconsistent data names, data definitions, and data domains. \\n* No management appreciation for the value of meta data made meta data a low \\npriority in most organizations. Business managers and business executives, as \\nwell as some information technology (IT) managers, viewed meta data as systems \\ndocumentation, which they considered important but could live without. \\n* No cross-organizational initiatives existed in organizations, except depart- \\nmental initiatives usually spearheaded by data administrators in IT. There- \\nfore, many business managers and business executives did not understand the \\nvalue of the effort and did not buy into it. The popularity of data warehouse \\ninitiatives in the 1990s helped raise the understanding of the value of cross- \\norganizational initiatives. \\nBecause of these problems, data administration efforts to manage meta data \\nwere only marginally successful in the past. On many projects, these efforts were \\neven considered project obstructions because of the extra time it took to define \\nand capture the meta data when the technicians were eager to rush into coding. \\nIT managers and business managers often asked, “Why aren’t we coding yet?”— \\nobviously, they perceived writing programs as the only productive project devel- \\nopment activity. \\nSources of Meta Data \\nIt was not until the advent of cross-organizational BI initiatives and the associ- \\nated plethora of BI tools that meta data started to receive its proper recognition. \\nPeople began to realize that these BI tools, with their own sets of meta data in \\ntheir own proprietary dictionary databases, were creating the all-too-familiar \\nproblems of redundancy and inconsistency, only this time with meta data. \\nKnowledge workers, business analysts, managers, and technicians were getting \\nvery frustrated with the tangled web of meta data silos (Figure 10.1). \\nMeta data cannot be avoided, especially technical meta data, because data- \\nbase management systems (DBMSs) and most tools do not function without it. It \\nis their “language.” For example, meta data instructs the DBMS what type of \\ndatabase structures to create, tells the ETL tool what data to transform, and lets \\nthe OLAP tool know how to aggregate and summarize the data. Different meta \\ndata components are stored in different tools, and none of the tools (except a \\nmeta data repository) is designed to store all the other meta data components \\nfrom all the other tools. For example: \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 274}, page_content='Meta Data Silos 241 \\nELIE SATE TEED \\nETL Tool | \\nProprietary \\nDictionary as D> \\nProprietary \\nDictionary \\nProprietary \\nDictionary Le \\nData-Cleansing Tool a \\nhae ae, Proprietary \\nDictionary \\nPLETE ETRE \\nOLAP Tool (| \\nEE ETE ES Proprietary \\nData Mining Tool A Dictionary \\nei: Proprietary \\nDictionary \\nFigure 10.1: Meta Data Silos \\n* CASE tools store the business meta data for the logical data model compo- \\nnents and the technical meta data for the physical data model (logical data- \\nbase design) components. \\nDBMS dictionaries store the technical meta data for the database structure, \\nsuch as databases, tables, columns, indices, and so on. \\nETL tools store the technical meta data about source-to-target data mappings \\nand the transformation specifications, which are used by these tools to per- \\nform their ETL processes. \\n* Data-cleansing tools store the business meta data for data domains and for \\nbusiness rules that allow these tools to identify data quality problems. They \\nalso store the cleansing specifications, which are used by these tools to per- \\nform their data-cleansing functions. \\nOLAP tools store the technical meta data of the tables and columns in the BI \\ntarget databases, the report definitions, and the algorithms for deriving, \\naggregating, summarizing, and in other ways manipulating BI data. \\n* Data mining tools store the technical meta data about the various analytical \\nmodels and the algorithms for the data mining operations. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 275}, page_content='242 Step 10: Meta Data Repository Design \\nAs with vendors of other relatively new software and middleware product \\nlines, the vendors of meta data repository products are competing for dominance, \\nwhich slows down standardization of the product line. As a result, organizations \\nend up with a tangled web of disparate and distributed meta data scattered across \\nthe proprietary dictionaries of their tools. To manage this situation, they now \\nhave to extract, merge, and accurately integrate meta data from these tool dictio- \\nnaries, which can be as much of a challenge as extracting, merging, and accu- \\nrately integrating business data from the operational systems. \\nMETA DATA REPOSITORY SOLUTIONS \\nThe solution to meta data silos is clearly an enterprise-wide meta data repository \\napproach. This can be accomplished in one of three ways: \\n1. One centralized meta data repository database solution \\n2. A decentralized meta data solution that uses one integrated meta model but \\nphysically distributes the meta data across multiple databases \\n3. A distributed XML-enabled solution in which the meta data is XML-tagged \\nand stored (kept) in the different types of proprietary tool dictionaries on \\ndifferent platforms \\nRegardless of which meta data repository solution is chosen, meta data \\nrepository projects and subprojects are large and costly. Therefore, any meta \\ndata repository solution should be built in iterations. \\nCentralized Meta Data Repository \\nA centralized meta data repository is the most popular solution and the easiest to \\nimplement because there is only one database, either relational or object-ori- \\nented, and only one application to maintain (Figure 10.2). \\nUpdating the meta data repository does not have to be coordinated across \\ndatabases, and retrieving the meta data from the repository can easily be accom- \\nplished with a simple GUI front end or Web application. A centralized meta data \\nrepository solution can either be custom built or licensed from a vendor. \\n* Custom-built repository: Designing and building a customized centralized \\nmeta data repository is an alternative that should be considered. Since the \\nmeta data repository solution should be enterprise-wide, the meta models \\n(both logical and physical) will be generalized and not application-specific. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 276}, page_content='Meta Data Repository Solutions 243 \\nFigure 10.2: Centralized Meta Data Repository \\nThis means that there will not be a meta data repository for a marketing \\napplication and another one for a sales application; instead, there will be one \\ncentralized meta data repository for all applications. The advantages and dis- \\nadvantages of building a customized centralized meta data repository are \\nsimilar to those of building a customized business application (Table 10.1). \\nTable 10.1: Advantages and Disadvantages of a Custom-Built Centralized Meta \\nData Repository \\nAdvantages Disadvantages \\n¢ A customized database design ¢ Full-time staff is needed to maintain the \\nincorporates all meta data meta data repository database and the \\nrequirements. meta data reports. \\n¢ The front end for access and the ¢ The front end for access and the \\ninterfaces to tools (ETL, OLAP, and so interfaces to tools must be programmed \\non) are custom designed to meet all and maintained, both of which are time- \\nrequirements. consuming processes. \\n* Reports as well as help functions are * The meta data repository would have to \\ndesigned exactly as desired. be enhanced periodically (sometimes \\nredesigned) because it cannot be built \\nwith all functionality from the start. \\n* Technicians have full control over the * Content may become out of synch with \\ndesign and functionality of the meta the proprietary dictionaries of the tools \\ndata repository. and the DBMS. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 277}, page_content=\"244 Step 10: Meta Data Repository Design \\n* Licensed repository: Licensing (buying) a centralized meta data repository \\nproduct is an attractive alternative to building one. Losing some of the bene- \\nfits inherent in a customized solution is offset by gaining the advantages that \\ncome with licensing a vendor product (Table 10.2). \\nTable 10.2: Advantages and Disadvantages of a Licensed Centralized Meta Data Repository \\nAdvantages Disadvantages \\n* Time is saved by not having to design * The “plain vanilla” version of the licensed \\nand build a meta data repository product will probably not satisfy all meta \\ndatabase, interfaces, front end, and data requirements. Therefore, a full-time \\nreports. administrator is needed to maintain and \\nenhance the licensed product. \\n* Most licensed meta data repository * There will be a learning curve to become \\nproducts come with interfaces, and familiar with the product's architecture, \\nmost come with a full set of APIs. interfaces, and APIs. \\n+ If the meta data repository product is * The more sophisticated the meta data \\ncertified for the tools where the meta repository product is, the more expensive \\ndata resides, it will provide the tool it is, and the more skills the technicians \\ninterfaces. need to maintain it. \\nDecentralized Meta Data Repository \\nAs the term implies, a decentralized meta data repository solution stores the meta \\ndata in multiple databases in multiple locations (Figure 10.3). \\nDBMS Gateway \\neee Be BD Meta Data || Meta Data || Meta Data || Meta Data \\nRepository ) | Repository } | Repository } | Repository \\nFigure 10.3: Decentralized Meta Data Repository \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 278}, page_content='Meta Data Repository Solutions 245 \\nCommonly accessed meta data components could be replicated across multi- \\nple databases, but great care must be taken to keep those components consistent. \\nA gateway directs the meta data access calls to the appropriate database to retrieve \\nthe desired meta data. There are some distinct advantages and disadvantages to \\nthis solution, whether it is built in-house or licensed from a vendor (Table 10.3). \\nTable 10.3: Advantages and Disadvantages of a Decentralized Meta Data Repository \\nAdvantages Disadvantages \\n* Various Owners can maintain and * Controlling redundancy across multiple \\nmanage their own sets of meta data meta data repositories and keeping the \\nseparately. meta data consistent is difficult. \\n¢ Meta data repository databases are It will take longer to maintain and \\nsmaller and easier to use because each manage multiple databases on multiple \\ndatabase contains only those meta data platforms. There could also be \\ncomponents that are of interest to a synchronization problems with new \\nspecific group of business people. DBMS releases. \\n¢ Each meta data repository can have its Communication among the custodians \\nown meta model, that is, its own of the various meta data repositories will \\ncustomized design. have to increase. Plus, it will require \\nmaintaining a meta-meta model, which \\nis an integrated (merged) overall \\narchitecture of multiple meta models. \\n¢ Reports can be customized for each Relating meta data across various \\nindividual meta data repository. databases may be difficult. For example, \\nbusiness meta data is not automatically \\nlinked to technical meta data if they \\nreside on different databases. \\n* A gateway makes the name and location + The architecture of this solution is more \\nof the meta data repository transparent complicated and the learning curve to \\nto the person accessing it. use multiple databases with potentially \\ndifferent designs may be high. \\nDistributed XML-Enabled Meta Data Solution \\nAlthough the most promising meta data repository answer is a distributed XML- \\nenabled meta data solution, it is also the most difficult to implement because it \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 279}, page_content='246 Step 10: Meta Data Repository Design \\nFigure 10.4: Distributed XML-Enabled Meta Data Solution \\ntakes the concept of a decentralized meta data repository to the next level. Rather \\nthan storing meta data across multiple databases, in an XML-enabled solution \\nthe meta data remains at its originating location, that is, in the various tool dic- \\ntionaries (Figure 10.4). \\nA gateway acts as a directory to the various locations where the meta data \\ncomponents are stored (e.g., the DBMS system catalog tables or the ETL tool dic- \\ntionary). Vendors are vigorously exploring this “bleeding-edge” solution because \\nit reduces the necessity for double maintenance of the meta data. Double mainte- \\nnance refers to maintaining the meta data in the originating sources (DBMS and \\ntool dictionaries) as well as maintaining it in the separate meta data repository \\ndatabase. Table 10.4 lists the advantages and disadvantages of this solution. \\nTable 10.4: Advantages and Disadvantages of a Distributed XML-Enabled Meta \\nData Solution \\nAdvantages Disadvantages \\n* XML tags enable access of meta data ¢ The initial tagging of all meta data with \\nacross any type of data storage through XML tags is a manual and laborious \\nstandardized categorization and tagging process. Plus, XML tagging cannot be \\nof meta data components. used for all meta data. \\n* Meta data never has to be duplicated or + XML tags add to the storage \\nmoved from its original source (except requirements for the dictionary \\nfor reporting purposes). databases that store meta data (DBMS \\nand tool dictionaries). \\n(Continued) \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 280}, page_content='Designing a Meta Data Repository 247 \\nTable 10.4: (Continued) \\nAdvantages Disadvantages \\n* A gateway makes the location of the ¢ A meta-meta model has to be created as \\nmeta data transparent to the person a map of all the various types of meta \\naccessing it. data storage, each of which is designed \\naccording to its own unique meta model. \\n* Standard Web search engines should be —_* DBMS and tool vendors must follow \\nable to locate any meta data anywhere. industry standards* for meta data XML \\ntags in order to enable seamless meta \\ndata access across all products. Multiple \\nstandards need to be supported. \\n* Meta data and business data can be * Not all DBMSs and tools are XML- \\ncoupled and transmitted simultaneously. enabled. This is a bleeding-edge and \\nunproven technology. \\n* Meta data standards are being developed by two competing groups: the Meta Data Coalition \\n(MDC, influenced by Microsoft) and the Object Management Group (OMG, influenced by Oracle). \\nThe jury is still out on which meta data standards will be adopted as the industry standards. \\nDESIGNING A META DATA REPOSITORY \\nIf the decision is made to custom build a meta data repository in-house, you have \\nto choose between an E-R design and an OO design. \\nEntity-Relationship Design \\nBecause an E-R design represents the meta data objects and their relationships \\nexplicitly, and because E-R designs are intuitive and easy to understand, many \\norganizations choose this type of database design for their meta data repositories. \\nTo illustrate the intuitiveness of an E-R design, assume that the physical meta \\nmodel contains four objects (Database, Table, Column, and Attribute) and that \\nthese objects are related in a one-to-many cardinality, as shown in Figure 10.5. \\nFigure 10.5: Example of Entity-Relationship Design. (Short vertical lines indicate “one,” and \\nthe crow’s feet indicate “many.”) \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 281}, page_content='248 Step 10: Meta Data Repository Design \\nThis type of database structure is easy enough to understand that technol- \\nogy-savvy business people could write their own ad hoc Structured Query Lan- \\nguage (SQL) queries against it. However, if these ad hoc queries are executed \\nagainst a large centralized meta data repository, performance could be a problem. \\nIt is relatively easy to write poorly performing SQL queries. In addition, since \\neach meta data object is implemented as a separate table, there will be dozens of \\ntables, and some queries will contain very complicated JOINs across many of \\nthese tables. This could also affect performance. \\nTable 10.5 lists the advantages and disadvantages of E-R designs. \\nTable 10.5: Advantages and Disadvantages of Entity-Relationship Designs \\nAdvantages Disadvantages \\n¢ E-R designs are easy to read andeasyto » Changes and enhancements may require \\nunderstand. a database redesign, as well as unload- \\ning and reloading the meta data \\nrepository. \\n* Because of the intuitive and explicit * The physical meta model is fairly large, \\nnature of the design, queries can be with many objects and many relation- \\nwritten with relatively simple SQL ships, which makes the architecture \\nstatements. somewhat complex. \\n* E-R designs are easy to implement as * Meta data objects and their relationships \\nrelational database structures. must be very well defined and under- \\nstood for the physical meta model to be \\naccurate. \\nObject-Oriented Design \\nAs popular as E-R designs may be for meta data repository databases, OO designs \\nare more efficient. Since they are more abstract, they result in fewer tables, run \\nqueries more efficiently, and are much easier to expand. Using the same example \\nas above, the OO model would contain only three objects, but these objects \\nwould be more generic, as shown in Figure 10.6. \\nThis type of database structure is not easy to understand, and business people \\nwill probably not be able to write their own ad hoc SQL queries against it. It is \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 282}, page_content='Designing a Meta Data Repository 249 \\nObject Object \\nType Relationship \\nFigure 10.6: Example of Object-Oriented Design. (Short vertical lines indicate “one,” and the \\ncrow’s feet indicate “many.’) \\nnot intuitively obvious that the object named Object contains the instances \\n(rows) for all meta data objects, such as database instances, table instances, col- \\numn instances, attribute instances, and so on. It is also not obvious that the \\nobject named Object Type differentiates the various meta data object instances by \\nassigning the appropriate label of Database, Table, Column, Attribute, and so on. \\nAnd the untrained eye would have an even more difficult time discerning that all \\nrelationships between these object instances are reflected in the third object \\nnamed Object Relationship. However, it is easy to see that expanding this type of \\ngeneric design is as simple as adding new instances (rows) to these three objects \\n(tables). \\nTable 10.6 lists the advantages and disadvantages of OO designs. \\nTable 10.6: Advantages and Disadvantages of Object-Oriented Designs \\nAdvantages Disadvantages \\n* OO designs are extremely flexible; they * Since the object named Object contains \\nwill not need any database redesigns all instances (rows) of meta data, this \\nwhen changes are necessary. table will become very large. This may \\naffect access performance. \\n* OO designs are simplistic and therefore * Queries are much more difficult to write \\neasy to maintain and to enhance. and will require many recursive JOINS. \\nAdvanced SQL knowledge is required. \\n* OO designs are easy to implement as * OO designs require a high learning \\nobject-oriented database structures. curve. The very abstract physical data \\nmodel is difficult to comprehend, and the \\nextensive rules take time to understand. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 283}, page_content='250 Step 10: Meta Data Repository Design \\nDesigning and building your own meta data repository may not be within the \\nscope of your BI project. There may be no budget and no staff for a separate meta \\ndata repository project. Maybe your organization would prefer to license (buy) a \\nmeta data repository product. As with all off-the-shelf products, a licensed meta \\ndata repository product will probably not be the perfect solution, but it may be \\nthe most cost-effective one. It would certainly be better than ignoring meta data \\naltogether. \\nLICENSING (BUYING) A META DATA REPOSITORY \\nWhen selecting a meta data repository product (or any type of product), you \\nshould never start with the question, “What is the best product of this type on the \\nmarket?” Instead, always start with the following questions: \\n+ What are our requirements? \\n* Which requirements are: \\n— Mandatory (must have) \\n— Important (beneficial to have) \\n— Optional (nice to have) \\n* Which products address our mandatory requirements? \\n* Which products address our important requirements? \\nCompare each vendor’s logical meta model (if one exists) or their physical \\nmeta model (product design) with your logical meta model, and determine \\nwhether the vendor’s model covers all the meta data requirements reflected in \\nyour “requirements meta model.” At a minimum, the vendor’s model must support \\nall your mandatory meta data requirements. If it does, find out if the vendor’s \\nmeta model and software can be expanded so that you can add your own features \\nto support your important meta data requirements. Expansion capabilities of \\nmeta data repository products should include the following: \\n» Adding meta data objects \\n* Adding relationships \\n* Changing inappropriate relationships \\n- Adding meta-meta data attributes to the meta data objects \\n* Changing the size and length of meta-meta data components \\n* Customizing vendor-provided reports \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 284}, page_content='Licensing (Buying) a Meta Data Repository 251 \\n* Creating and storing code for additional reports \\n- Importing meta data from other tools \\n* Exporting meta data to other tools \\nProduct Evaluation \\nUse standard evaluation techniques to select a meta data repository product. For \\nexample, prepare a list of product evaluation criteria for your meta data require- \\nments and assign a weighting factor from 1 to 10 to each criterion (1 being least \\nimportant and 10 being most important), like the sample criteria list shown in \\nTable 10.7. \\nPaw Notice that “Product can satisfy our mandatory meta data requirements” is not \\na weighted criterion. If the product cannot support the mandatory require- \\nments, do not even consider it. \\nRate each product on all product evaluation criteria by assigning a rating on a \\nscale of 0 to 10 (0 means the product does not have that feature, 10 means that \\nthe product feature is outstanding), as illustrated in the example in Table 10.8. \\nMultiply the product ratings by the criteria weighting factors to obtain final \\nscores for each product. Add up all the scores and list the products in the order of \\nhighest total score down to lowest total score, as shown in Table 10.9. \\nTable 10.7: Example of Product Evaluation Criteria with Weights \\nCriterion # Product Evaluation Criteria Weight \\n1 Product closely matches our logical meta model 10 \\nProduct can satisfy our important meta data requirements 6 \\nProduct can satisfy our optional meta data requirements 1 \\nProduct can be expanded \\nProduct has interfaces \\nProduct has a Web front end \\nN 7, OD] SW} RR] WY] N oO] FB] oO] @&© Product has APIs \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 285}, page_content='252 Step 10: Meta Data Repository Design \\nTable 10.8: Example of Product Ratings \\nCriterion # \\nProduct* 1 2 3 4 5 6 7 \\nSi cll me ee ae ee ee \\nHelixor 9 0 2 8 6 0 5 \\nLeeches Repository 6 6 1 6 4 0 7 \\nSpringrep 8 72 0 10 10 2 10 \\nTamroller MDR 7 5 5 0 6 2 7 \\n* The product names presented in this table are fictitious. \\nTable 10.9: Example of Weighted Product Ratings \\nCriterion # \\nProduct* 1 2 3 4 5 6 re Total Score \\nSpringrep 80 12 0 80 90 8 90 360 \\nAutumn Dictionary 30 42 6 0 81 36 90 285 \\nHelixor 90 0 2 64 54 0 45 255 \\nLeeches Repository 60 36 1 48 36 0 63 244 \\nTamroller MDR 70 30 5 0 54 8 63 230 \\n* The product names presented in this table are fictitious. \\nVendor Evaluation \\nMost organizations do not spend enough time, if any, evaluating the vendors in \\naddition to evaluating the products. It is important to understand each vendor’s \\ncompany stability, its commitment to the product, and its level of support. Create \\na list of vendor evaluation criteria and assign a weighting factor to each criterion \\non a scale from 1 to 10 (1 being least important and 10 being most important), \\nsimilar to the sample criteria shown in Table 10.10. Other criteria to consider are \\nreputation for support, vendor integrity, and prior experience with the vendor. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 286}, page_content='Licensing (Buying) a Meta Data Repository 253 \\nTable 10.10: Example of Vendor Evaluation Criteria with Weights \\nCriterion # Vendor Evaluation Criteria Weight \\n1 Vendor has been in business for at least five years 8 \\n2 Vendor has at least five Fortune 1000 clients 6 \\n3 Vendor company is publicly traded and stock is healthy 8 \\n4 Vendor has 24/7 telephone support 10 \\n5 Vendor has an 800 hotline telephone number 9 \\n6 Vendor has at least 50 employees 4 \\n7 Vendor includes at least two weeks of free training 1 \\nRate each vendor on all vendor evaluation criteria by assigning a rating on a \\nscale of 0 to 10 (0 means the vendor cannot meet that criterion, 10 means the \\nvendor excels in that criterion), as illustrated in Table 10.11. \\nMultiply the vendor ratings by the criteria weighting factors to get final scores \\nfor each vendor. Add up all the scores and list the vendors in the order of highest \\ntotal score down to lowest total score, as shown in Table 10.12. \\nFinally, compare the lists for product and vendor ratings and select the top \\ntwo products. Check the vendors’ references, schedule product demos, and \\narrange for a 30-day trial installation before making your final product selection. \\nTable 10.11: Example of Vendor Ratings \\nCriterion # \\nVendor* 1 2 3 4 5 6 7 \\nAutumn, Ltd. 9 7 4 9 10 9 5 \\nHelix Corporation 5 3 0 8 0 1 0 \\nLeeches, LLC 2 2 0 5 0 5 10 \\nSpringer, Inc. 10 9 7 10 10 10 10 \\nTamroller AG 10 10 8 5 0 10 1 \\n* The vendor names presented in this table are fictitious. \\nI ELE I EE \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 287}, page_content='254 Step 10: Meta Data Repository Design \\nTable 10.12: Example of Weighted Vendor Ratings \\nCriterion # \\nVendor* 1 2 3 4 5 6 7 Total Score \\nSpringer, Inc. 80 54 56 100 90 40 10 430 \\nAutumn, Ltd. 72 42 32 90 90 36 5 367 \\nTamroller AG 80 60 64 50 0 40 1 295 \\nHelix Corporation 40 18 0 80 0 4 0 142 \\nLeeches, LLC 16 12 0 50 0 20 10 108 \\n* The vendor names presented in this table are fictitious. \\nMETA DATA REPOSITORY DESIGN ACTIVITIES \\nThe activities for meta data repository design do not need to be performed lin- \\nearly. Figure 10.7 indicates which activities can be performed concurrently. The \\nlist below briefly describes the activities associated with Step 10, Meta Data \\nRepository Design. \\nef 4 \\nDesign meta data Design meta \\nrepository database data application \\n3 \\nInstall and test meta Design meta data \\ndata repository product migration process \\nFigure 10.7: Meta Data Repository Design Activities \\n1. Design the meta data repository database. \\nIf the decision is made to build a meta data repository rather than to license \\n(buy) one, design the meta data repository database. Choose between an E-R \\ndesign and an OO design, and create (or enhance) the physical meta model \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 288}, page_content='Deliverables Resulting from These Activities 255 \\n(database design). Generate the DDL for the database structures. Develop the \\nmeta data repository database maintenance procedures, such as backup and \\nrecovery, and create plans for versioning and archiving. \\n2. Install and test the meta data repository product. \\nIf the decision is made to license a meta data repository rather than to build \\none, evaluate the meta data repository products as well as their vendors. \\nProducts and vendors with the highest scorecard ratings should go on the \\nshort list (top two choices) from which the final product will be selected. \\nInstall and test the meta data repository product. \\n3. Design the meta data migration process. \\nIdentify all tools and DBMSs from which business meta data and technical \\nmeta data will have to be extracted. Determine the import, export, and API \\ncapabilities of those tools and DBMSs as well as of your meta data repository \\nproduct if you licensed one. Design the meta data migration programs, \\nincluding the tool interfaces, and write the programming specifications. \\n4. Design the meta data application. \\nUnless you licensed a meta data repository product, design the meta data \\napplication, which includes access interfaces, Web features, reports, and an online \\nhelp function. Once the reporting medium (e.g., Portable Document Format \\n[PDF], Hypertext Markup Language [HTML]) has been selected, prepare the \\nprogramming specifications for the various types of application programs. \\nDELIVERABLES RESULTING FROM THESE ACTIVITIES \\nIf you are licensing a meta data repository product, your deliverable is an \\ninstalled and tested product. If you are designing your own meta data repository, \\nyou should produce the following design deliverables: \\n1. Physical meta model \\nThe physical meta model is a diagram of the physical database structures for \\nthe meta data repository. Depending on the selected database design schema, \\nthis diagram can be an E-R model or an OO model. It shows tables, columns, \\nprimary keys, foreign keys, cardinality, and referential integrity rules. \\n2. Data definition language for the meta data repository \\nThe data definition language (DDL) is a set of SQL instructions that tells the \\nDBMS what types of physical database structures to create for the meta data \\nrepository, such as databases, table spaces, tables, columns, and indices. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 289}, page_content='256 Step 10: Meta Data Repository Design \\n3. Data control language for the meta data repository \\nThe data control language (DCL) is a set of SQL instructions that tells the \\nDBMS what type of read/write access to the meta data repository to grant. \\nAccess can be granted to a person, a group of persons, a program, or a tool. \\n4. Meta data repository programming specifications \\nFor the meta data migration process, these programming specifications \\nshould define the programming logic for meta data extract, transformation, \\nand load programs, as well as tool interfaces. For the meta data application, \\nthese program specifications should define the programming logic for meta \\ndata reports and queries, access interfaces, and an online help function. \\nROLES INVOLVED IN THESE ACTIVITIES \\n@ BI infrastructure architect \\nSince the BI infrastructure architect has the ultimate architectural responsibil- \\nity over the BI decision-support environment as a whole, he or she needs to \\nreview all design activities. If a meta data repository is licensed, the BI infra- \\nstructure architect may participate in preparing the evaluation criteria and in \\ndeciding the weighting factors for the criteria. He or she will also be involved \\nin the final product selection. \\n® Data administrator \\nThe data administrator will collaborate with the meta data administrator on \\nthe meta data requirements and help the meta data administrator with the \\ndata-modeling activities. The data administrator can also be an effective liai- \\nson between the meta data administrator, the subject matter expert, and the \\nbusiness representative when meta data requirements need to be verified or \\ndesign decisions need to be reviewed or communicated. \\n® Meta data administrator \\nThe meta data administrator holds the primary responsibility over the meta \\ndata and the meta data repository. If the meta data repository is built in- \\nhouse, he or she is responsible for designing and developing it. If a meta data \\nrepository is licensed, he or she is responsible for installing, testing, enhanc- \\ning, and maintaining it. The meta data administrator is also responsible for \\ndesigning the access interfaces as well as the migration programs to the \\nDBMS, CASE tool, ETL tool, OLAP tool, and other tools. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 290}, page_content='Bibliography and Additional Reading 257 \\nRISKS OF NOT PERFORMING STEP 10 \\nProviding a meta data repository solution is not a casual undertaking. The same \\ndisciplines and rigor that apply to building a BI application also apply to develop- \\ning a meta data repository. “Whipping out” a database and a few canned SQL \\nqueries does not equate to a sustainable meta data repository solution. Like every \\nother system, it must be designed with a lot of thought and foresight to assure the \\ndesired level of functionality, performance, scalability, and maintainability over \\ntime. If the decision is to license a meta data repository product, you must give \\nthe same care to the evaluation process as you would give to the purchase of a \\ncritical operational systems package. If you do not take the time to design a \\nrobust and sustainable meta data repository solution, you will have to redo your \\nsolution or end up with an inferior BI decision-support environment. As the say- \\ning goes: “Pay me now or pay me later, but you will pay.” \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nDevlin, Barry. Data Warehouse: From Architecture to Implementation. Reading, MA: \\nAddison-Wesley, 1997. \\nDick, Kevin. XML: A Manager’s Guide. Boston, MA: Addison-Wesley, 2000. \\nMarco, David. Building and Managing the Meta Data Repository: A Full Lifecycle \\nGuide. New York: John Wiley & Sons, 2000. \\nSperley, Eric. The Enterprise Data Warehouse: Planning, Building, and Implemen- \\ntation. Upper Saddle River, NJ: Prentice Hall, 1999. \\nTannenbaum, Adrienne. Metadata Solutions: Using Metamodels, Repositories, \\nXML, and Enterprise Portals to Generate Information on Demand. Boston, MA: \\nAddison-Wesley, 2002. \\nData Management Association: http://www.dama.org \\nEnterprise Warehouse Solutions: http://www.EWSolutions.com \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 291}, page_content='7 \\nNy ees mi Sohgriee ten hb ymaie i: , OL Sa a \\n[a oor Ty pa a e =\" sae \\na \\nmnie WA Orgy arr tins teerpey A Wield 1. ientee tpn hk \\neapa Hed DA ns agar 1aES wee TID Hemp Phe aan GAN TAT 4 \\nDOP alin Wak STAC cniniol logis) (ha EY \\nALD arenes cigen +: sa véap niiwtne awn) af \\nBelt Boras tolyyervtn ber piquant \\\\o tndae climber: \\n“wel itaatnt stom, tht ale sranid mabraty \\niy idee della eros? dll ester ianle \\nee ee oe ee a \\nb Bicone Wehynde dae he map cyeksipye \\norg olive wi ‘sensl flee nrg atatyi fee (haves Rab grees sr bon \\neee eis 6/5 AaAaerP abies LV ye aad LIE erred 1 \\nGietn (aw eh TESS Vey Jud oi sat Oe ee \\n@ Wi uhercume gegen osx \\neither wilbing . cay toy \\nyous Get’ gem pe (ne esspe \\nAidala a ceareinel Aedaog ha tre pebe \\nRy ile MIWADT Ai» Uglies HW: ep \\nBonu [pease Was #4 \\nOAULAY nbd wh prigenianey pagina — == Oi) sate? eal “ \\nBae ary a Sle ‘i \\nt drat \\nFic bee \\na : ue Binie) De daw} “et Le) oe \\nga Sarge eae wt ee Oy, \". ise ~ \\nchenwgilt (id inlocty mm il Ut vy levator! (if Rontnin® oi 7 \\n@ Vis wi rebinpA eit \\nBe opois {ar el \\na 08 Hie Oey dec aeliei anand | pieeiie aa iret IM uy elie la trate ede Bid Bethel balay st : \\njoey  Suphtel, © engin ctapubaltr ine Wate \\nHy ore eliigionty it 110 ihe ia Lo ag os me i fm \\nirene Us iin & mol 7 \\nCHM, CAS? ETA tal aa ftv i i , a} —= \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 292}, page_content='Justification wis \\nBusiness Analysis | \\nDeployment \\nStep 11: Extract/ \\nTransform/Load \\nDevelopment \\nCHAPTER OVERVIEW \\nThis chapter covers the following topics: \\n@ Things to consider about extract/transform/load (ETL) \\ndevelopment \\n@ Common data transformation activities and the chronic \\nunderestimating of data transformation efforts \\n@ Three types of reconciliation totals that should be pro- \\nduced by the ETL process: record counts, domain counts, \\nand amount counts \\n@ Peer reviews \\n@ Six applicable ETL testing procedures: unit testing, integra- \\ntion testing, regression testing, performance testing, quality \\nassurance (QA) testing, and acceptance testing \\n@ How to create a formal test plan \\n@ Brief descriptions of the activities involved in ETL develop- \\nment, the deliverables resulting from those activities, and \\nthe roles involved \\n@ The risks of not performing Step 11 \\n259 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 293}, page_content='260 Step 11: Extract/ Transform/Load Development \\n—————— \\nTHINGS TO CONSIDER ] \\nSource Data Extracts \\n¥Y Who will write the ETL programs? Have those developers written ETL pro- \\ngrams before? Do they understand the ETL process? \\nY Do ETL programs already exist from a previous release or another BI appli- \\ncation? How many of them have to be expanded? \\nY Can we ask the programmers of the operational systems to give us the \\nextract files, or do we have to get the source data ourselves? \\n/¥ What do we need to know about the operational systems before we can get \\nthe data? What operational programs have to finish running before we can \\nextract the data from the source files and source databases? \\nETL Tool \\nV Have we worked with this ETL tool before, or is it new to us? \\nV Has the ETL team been sufficiently trained on the ETL tool? \\nY Can the ETL tool perform all the required transformations, or will we have \\nto write some custom code? In what language (C++, COBOL)? \\nETL Process Dependencies \\n¥ What are the dependencies among program modules? In what sequence do \\nwe have to run our ETL programs (or the ETL tool modules)? \\n/Y How many program modules can we run in parallel? \\n¥ What are the dependencies among the tables? Do some tables have to be \\nloaded before others? \\n¥ How many tables can we load in parallel? \\nTesting \\nVv Will we conduct peer reviews? Are we using extreme programming (XP) \\ntechniques? \\n/Y How many testers will we have on the project? \\n¥ Will the subject matter expert and business representative participate in testing? \\nVY Who will be the testing coordinator? Who will log the test results and main- \\ntain the test log? \\nv What type of testing do we need to perform? Integration or regression test- \\ning? Performance testing? QA testing? Acceptance testing? \\n¥ Which business people will participate in acceptance testing? Only the busi- \\nness representative? The subject matter expert? Other business people? \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 294}, page_content='Source Data Transformation 261 \\nTechnical Considerations \\n¥ What technical platform issues do we have to take into consideration? \\nV How is the staging area set up? On a dedicated server? \\n¥ Will the ETL process be split between the mainframe and one or more servers? \\n¥ What environments does the ETL tool run in? \\nv¥ What type of middleware do we need? \\nThe use of ETL tools has become very widespread, but organizations that use \\nthem discover very quickly that these tools have their limitations. Depending on \\nthe complexity of the required source data transformations and on the age and \\ncondition of the source files, custom code often has to be written to augment the \\nETL tool functionality. \\nSOURCE DATA TRANSFORMATION \\nThe technical rules and the business rules for the required source data transfor- \\nmations were accumulated and defined throughout the steps of project planning, \\nproject requirements definition, data analysis, application prototyping, and meta \\ndata repository analysis. During those steps, the rules were probably extracted \\nfrom old manuals, old memos, e-mails, programs (operational and decision sup- \\nport), and computer-aided software engineering (CASE) tools and provided by \\npeople who remember when and why a business rule was created. These rules are \\nnow reflected as data transformation activities in the ETL process. \\nData Transformation Activities \\nBI projects present the best opportunity to eliminate dead and useless data because \\nit allows the business people to see their information requirements in a different \\nlight. When properly implemented, the data transformation activities of cleansing, \\nsummarization, derivation, aggregation, and integration will produce data that is \\nclean, condensed, new, complete, and standardized, respectively (Figure 11.1). \\nCleansing: ©. Summarization: ~ Derivation: Aggregation: Integration: \\nClean Condensed New Complete Standardized \\nFigure 11.1: Data Transformation Activities \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 295}, page_content='262 Step 11: Extract/ Transform/Load Development \\nea EN SEE TE STE SP RI SET ESE ST A AN LIA CE ET ELE LEELA, \\n* Cleansing: By definition, cleansing is a BI transformation process in which \\nsource data that violates the business rules is changed to conform to those \\nrules. Cleansing is usually accomplished through edits in the ETL programs, \\nwhich use table lookups and program logic to determine or derive the correct \\ndata values and then write those data values into the load files used to popu- \\nlate the BI target databases. \\n* Summarization: Numeric values are summarized to obtain total figures \\n(amounts or counts), which can then be stored as business facts in multidi- \\nmensional fact tables. Summary totals can be calculated and stored at multi- \\nple levels (e.g., departmental summary of sales, regional summary of sales, \\nand total sales by country). \\n* Derivation: During this process, new data is created from existing atomic \\n(detailed) source data. Derivation is typically accomplished by calculations, \\ntable lookups, or program logic. Examples include the following: \\n— Generating a new code for classifying customers based on a certain combi- \\nnation of existing data values \\n— Calculating profit from income and expense items \\n— Appending the last four digits of a ZIP code based on the address in a \\npostal lookup table \\n— Calculating a customer’s age based on his or her date of birth and the cur- \\nrent year \\n* Aggregation: All the data about a business object is brought together. For \\nexample, data elements for a customer may be aggregated from multiple \\nsource files and source databases, such as a Customer Master file, a Prospect \\nfile, a Sales file, and demographic data purchased from a vendor. (In multidi- \\nmensional database design jargon, the term aggregation also refers to the roll- \\nup of data values.) \\n* Integration: Data integration based on normalization rules forces the need to \\nreconcile different data names and different data values for the same data element. \\nThe desired result is to have each unique data element known by one standard \\nname, with one standard definition and an approved domain. Each data ele- \\nment should also be associated with its sources files and source databases as well \\nas its BI target databases. Standardizing the data should be a business objective. \\nUnderestimating Data Transformation Efforts \\nSource data transformation is similar to opening a Russian doll—you open one \\nand there is another inside. It could be an endless process. That is why the time \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 296}, page_content='Reconciliation 263 \\nrequired for the ETL process is chronically underestimated. The original esti- \\nmates are usually based on the amount of technical data conversions required to \\ntransform data types and lengths, and they often do not take into account the \\noverwhelming amount of transformations required to enforce business data \\ndomain rules and business data integrity rules. \\nThe transformation specifications given to the ETL developer should never \\nbe limited to just technical data conversion rules. For some large organizations \\nwith many old file structures, the ratio of a particular data transformation effort \\ncould be as high as 80 percent effort toward enforcing business data domain rules \\nand business data integrity rules and only 20 percent effort toward enforcing \\ntechnical data conversion rules. Therefore, expect to multiply your original esti- \\nmates for your ETL data transformation effort by four. Even if you think you have \\na very realistic timetable for the ETL process, do not be surprised if you still miss \\ndeadlines due to dirty data. If you do not miss deadlines, do not be surprised to \\ndiscover you have not cleansed enough of the data sufficiently. \\nInsist on full-time involvement from the business representative, and insist \\non getting the right business representative—someone who is knowledgeable \\nabout the business and who has authority to make decisions about the business \\nrules. These stipulations are essential for speeding up the ETL process. Furthermore, \\nurge the business sponsor and the business representative to launch a data quality \\ninitiative in the organization, or at least in the departments under their control or \\ninfluence. When business people drive a data quality initiative, they are more \\nlikely to assist with the ETL transformation process. Remind them that while IT \\ntechnicians may know the process semantics, the business people know the data \\ncontents and business semantics. They understand what the data really means. \\nRECONCILIATION \\nOne of the most common complaints about BI applications is that the data in the \\nBI target databases does not match the data in the source systems. As a result, \\nbusiness people often do not trust the BI data. Ironically, most of the time the \\ndata in the BI target databases is more accurate than the data in the operational \\nsource files or source databases because the data has been reformatted, standard- \\nized, and cleansed. However, without proof this trust cannot be restored. Recon- \\nciliation totals provide that proof and must be available as meta data in the meta \\ndata repository. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 297}, page_content='264 Step 11: Extract/ Transform/Load Development \\nSSNS ESE SS SE SE SE A TES EE ES ES SEIDEL LETS ILL DLE IEE ELE, \\nETL reconciliation totals are ETL process control totals, not operational rec- \\nonciliation totals back to the organization’s financial statement or general ledger. \\nThe purpose for ETL reconciliation totals is to ensure that all the data values \\ngoing into the ETL process can be reconciled with all the data values coming out \\nof the ETL process. \\nStoring ETL reconciliation totals, as well as data quality and load statistics, as \\nmeta data highlights the importance of providing a meta data repository. This \\nmeta data is crucial information for the business people who want to see which \\ndata was loaded, which data was rejected and for what reasons, and what the data \\nreliability (cleanliness) factor is for the BI data after each load cycle. For example, \\nsource data from multiple source files and source databases may not have been \\nproperly synchronized (a timeliness error), which may have caused inconsisten- \\ncies in analysis results. With load statistics available as meta data, the business \\nanalysts can quickly recognize and reconcile the problem. \\nCalculating Reconciliation Totals \\nFar too many BI projects do not employ the good IT practices commonly \\nenforced in operational systems. Believing the notion that BI applications are \\n“just” for decision support and are therefore less critical than operational systems \\nis a grave mistake. BI applications are as critical as operational systems because \\nthe decisions that are made based on the data in the BI decision-support environ- \\nment can affect an organization’s strategic direction and vitality. \\nOne time-proven discipline when manipulating data, whether changing the \\ndata in some way or copying it or moving it from one place to another, is to rec- \\noncile every new output to its old input. Every program or program module that \\nreads data and then writes it to a new file, even if only into a temporary file, must \\nproduce reconciliation totals. \\nThere are three types of reconciliation totals: record counts, domain counts, \\nand amount counts. \\nRecord Counts \\nOne of the most fundamental reconciliation totals is a simple count of records \\nread and records written. If records are rejected because they fail an edit check in \\nthe ETL process, the number of records rejected must also be counted. The total \\ncount of records written and records rejected must equal the count of records \\nread (Figure 11.2). \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 298}, page_content='Reconciliation 265 \\nOUTPUT | Number of Output Records RECORDS \\nPROCESS + \\nINPUT l MODULE RECORDS ioe \\nREJECTED | Number of Rejected Records \\nRECORDS Number of Input Records = \\nFigure 11.2: Record Counts \\nDomain Counts \\nDomain counts involve counting the number of records for each unique domain \\n(data value) of an input field and counting the number of records for the same \\nunique domain on the output file. The complication with domain counts enters \\nwhen an “overloaded” source data element must be split into multiple columns. \\nAn overloaded source data element is a data element used for multiple purposes, \\nas many of the one-byte and two-byte code fields are in operational systems. The \\ndomain of an overloaded data element describes not one business object but \\nmany business objects and must therefore be separated into different columns for \\ndifferent tables. (Business objects are usually implemented as dimension tables.) \\nIn that case, the total of the multiple domain counts on the output side must \\nequal the one domain count on the input side. If data values were rejected \\nbecause they did not pass the data quality edits, there would be an additional \\ncount of all the rejected records. Thus, the total of the multiple output domain \\ncounts and the rejected data values count must equal the input domain count \\n(Figure 11.3). \\nAmount Counts \\nEven more important than domain counts are amount counts. They are the pri- \\nmary mechanism for reconciling source files and source databases to the BI target \\ndatabases. Reconciling amounts happens in two ways. One is to summarize every \\namount field in every input file and every corresponding amount field in every \\noutput file. If records were rejected, there would be a third summary for the total \\namount figure rejected. The combined total of the output amount total and the \\nrejected amount total must equal the input amount total. \\nA more complicated amount reconciliation algorithm must be developed if \\nthe incoming amount field is an overloaded source data element that has to be \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 299}, page_content='266 Step 11: Extract/ Transform/Load Development \\nOUTPUT | Number of Records per Output Code \\nCODES for First Domain \\n+ \\nOUTPUT | Number of Records per Output Code \\nCODES for Second Domain \\n+ \\nOUTPUT | Number of Records per Output Code \\nCODES for Third Domain \\n+ \\nREJECTED | Number of Rejected Data Values \\nCODES \\nPROCESS | \\nMODULE \\nNumber of Records per Input Code = = \\nFigure 11.3: Domain Counts \\nseparated into several different amount columns for the BI target databases. In \\nthat case, the selection and edit criteria in the transformation specifications must \\nbe used to create multiple output amount totals. In addition, the same selection \\nand edit criteria must be run against the input file to produce the same multiple \\namount totals for verification (Figure 11.4). \\nStoring Reconciliation Statistics \\nBecause of the extensive amount of transformation and cleansing that typically \\noccurs in the ETL process, the business people should expect the data to be differ- \\nent on the BI target databases than in the original source files and source data- \\nbases. Their desire or need to reconcile the data between source and target is \\nvalid. However, it must be accomplished through using reconciliation totals, not \\nby comparing source data elements to target columns dollar for dollar. \\nOUTPUT | Total $ per Output Amount \\nAMOUNTS for First Domain \\n+ \\nOUTPUT | Total $ per Output Amount \\nAMOUNTS for Second Domain \\nPROCESS }} \\nMODULE } \\nAMOUNTS ] \\nTotal $ Per Input Amount = a \\nTotal $ Input Amount for First Domain + ; \\nTotal $ Input Amount for Second Domain + REJECTED | Total $ Rejected Amounts \\nTotal $ Rejected Amounts AMOUNTS \\nFigure 11.4: Amount Counts \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 300}, page_content='Peer Reviews 267 \\nSR ES SS RS ST TAREE IS PSI SE ST TS \\nTherefore, all reconciliation totals produced by every program module for \\neach BI application load cycle must be stored as meta data in the meta data repos- \\nitory. If possible, additional categorization of rejected records should be consid- \\nered with short descriptions for the rejection reason. These descriptions can be \\ncomposed based on the ETL edit criteria. \\nPEER REVIEWS \\nPeer reviews are similar to the “pair programming” concept of extreme program- \\nming (XP), except that the coding itself does not occur in pairs, the meetings \\noften involve more than two people, and the reviews apply to all types of task \\ndeliverables besides programs. Peer reviews are informal meetings that combine \\nreviewing, testing, and a limited amount of brainstorming about a project task \\ndeliverable. The purpose of peer reviews is to allow the developer of a given piece \\nof project work to present a task deliverable to his or her peers for validation or \\ndiscussion. This is best accomplished in a core team setting, but a peer review can \\nalso involve team members from the extended team who have a vested interest in \\nthat project task. \\nAt the completion of a project task, the developer of the work (or any other \\ncore team member) may decide to ask for a peer review to solicit input to a com- \\nplex problem, get feedback to a creative solution, or ask for opinions on an item \\nthat is uncertain or poorly defined. He or she then determines which team mem- \\nbers should participate in the peer review, schedules the informal peer review \\nmeeting, and distributes copies of documents (e.g., specifications, programs, data \\nmodels, reports) to the invited peers before the meeting. \\nThe developer of the work leads the meeting. The project manager, who \\nshould always participate in peer reviews, ensures that the meeting does not bog \\ndown in disagreements nor stray from the issues at hand. Each attendee should \\nhave reviewed the distributed documents and should be prepared to comment \\nand to brainstorm on the issues. Together, the participants are responsible for \\nuncovering errors or misconceptions in the task deliverable. Discussions are initi- \\nated to help the developer understand the problems uncovered or to allow the \\ndeveloper to justify his or her work to the satisfaction of all in attendance. \\nBrainstorming is usually limited to finding the errors or misconceptions; it \\ndoes not extend to solving them unless a solution is obvious and can be presented or \\ndiscussed within a few minutes. At the conclusion of a peer review the uncovered \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 301}, page_content='268 Step 11: Extract/ Transform/Load Development \\n| RG RSM TRE SI DET ROI ENED RR EEE EEE BE IEE LOOSE EE BEE SS ED CAE NEI GEE BSE EE LO EERE BIEL LEED LEE EELS PLEADED DDD DLO SDI IEEE LEE LLL ED \\nerrors or misconceptions should be documented, and the developer of the deliverable \\nis tasked with correcting them or with creating a new solution to the project task. \\nPeer reviews sound more formal than they really are. They can be best com- \\npared to high-powered, structured brainstorming sessions. Peer review meetings \\nshould be limited to about one hour. \\nETL TESTING \\nUnfortunately, testing, like reconciliation, is often done very poorly on BI \\nprojects, if at all. That is not acceptable—and neither is the excuse that “it can be \\nfixed in the next release.” The next release will be even larger and more compli- \\ncated, and it will require more time to test. In other words, if it takes too long to \\ntest now, it will take even longer to test later, which usually means that adequate \\ntesting is never done. Rushing into deployment at the expense of testing is inex- \\ncusable, especially if it is done to meet some artificial deadline. \\nThe same types of testing that apply to operational systems also apply to BI \\napplications (Figure 11.5). The following sections briefly describe each type. \\nUNIT TESTING \\nDoes the program compile? \\nAre there any compiler \\n7 warnings to heed? REGRESSION TESTING \\nDid the new program \\nfeatures break any of the \\noriginal code? \\nINTEGRATION TESTING \\nDo all programs run \\nwell together? \\n| Does the program do \\n_ what it is supposed \\nto do? Do they pass on the \\nright data to each other? Does the job stream still \\nrun without crashing \\n(abending)? Does the job stream run \\nwithout crashing? \\n| QUALITY ASSURANCE TESTING \\nHow will these programs affect \\nany other programs running in the \\n|, same (production) environment? \\n| PERFORMANCE TESTING \\nHow will the programs \\nperform with huge \\nvolumes of data? ACCEPTANCE TESTING \\nDo the business people \\naccept the results from the \\nexecuted job stream \\n(application)? \\n_ What are the operating instructions \\nWhiat Is the perlormance for the scheduled automated runs? threshold? \\nDoes the application do what \\nthe business people want it \\nto do? \\nFigure 11.5: Types of Testing \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 302}, page_content='ETL Testing 269 \\nUnit Testing \\nUnit testing refers to the testing of discrete program modules and scripts, not to \\ntesting the flow or the links between the programs. Every developer must test his \\nor her program modules and scripts individually (if XP techniques are utilized, \\nthis is done in pairs). There are three components to unit testing: compilation, \\nfunctionality, and edits. \\n* Compilation: Obviously, each program module must compile successfully or \\nit cannot be implemented. There are many testing tools on the market for \\nevery conceivable programming language. These tools allow the developer to \\ntrace every step of the code as it is being executed, displaying the before and \\nafter images of the data for each line of code. \\nFunctionality: Each program module must perform the functions for which \\nit was designed and must produce the expected test results. Therefore, each \\ndeveloper must create a small test file with valid as well as invalid data to test \\nevery function of his or her program modules. He or she must know in \\nadvance what the program modules should do with the valid and the invalid \\ntest data (expected test results). Unit testing is not completed until all pro- \\ngram modules produce all of the expected results. \\nEdits: Each program module must catch errors and, depending on the sever- \\nity of the error, either produce an error message or gracefully end the pro- \\ngram. No program should ever stop abruptly (“crash” or abend) with a \\ncryptic system error message. With the high degree of poor-quality data in \\nthe source files, it is quite common that more lines of code are written for \\nedits than for functionality. \\nPaw Consider allowing someone other than the developer to test any given \\npiece of code. This along with peer reviews should snare most errors that \\nmay not be caught because of pride of ownership and being too close to \\none’s own code. \\nIf an ETL tool is used, unit testing still applies to the individual ETL tool \\nmodules. In that case, you are testing the validity of your ETL instructions, that \\nis, the ETL technical meta data. It is important to note that if an ETL tool does \\nnot meet the standards of your organization, you will have to supplement the \\ntool with your own custom-written code. In that case, unit testing will be a com- \\nbination of testing the ETL technical meta data, testing the custom-written code, \\nand testing the “handshake” between them. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 303}, page_content='270 Step 11: Extract/ Transform/Load Development \\nSE PEELE EO EI II LESION EDI ELE LLL I TE LED EL, \\nIntegration Testing \\nIntegration testing, also known as system testing, is the first complete ETL pro- \\ncess run. This includes all three sets of ETL processes: the initial load, the histori- \\ncal load, and the incremental load. Just because all program modules pass their \\nindividual unit tests, it cannot be assumed that the entire ETL process will run \\nsmoothly. The interactions and flow of all programs, as specified in the ETL process \\nflow diagram, must be observed and validated. \\n- Interactions: Program modules receive data, manipulate it, and hand it off to \\nother program modules. This interaction between the modules must be \\ntested. The test data used for integration testing is different from that used for \\nunit testing. A copy of a relatively large subset of representative operational \\nsource data is used for integration testing. \\n* Flow: The ETL process flow diagram should indicate which programs must \\nrun in which sequence, which programs can run in parallel, and where sort \\nand merge utilities are interjected. This flow must be tested for functionality \\nand efficiency. Testing for functionality ensures that the right process is per- \\nformed on the right data at the right time, that is, that the programs run in \\nthe correct sequence. Testing for efficiency ensures that the entire ETL pro- \\ncess can complete within the expected time frame. If it cannot, the flow must \\nbe redesigned, and the entire ETL process must be retested. \\nIf an ETL tool is used, the entire ETL process must still be tested from begin- \\nning to end, except that you are running the ETL tool processes instead of custom- \\nwritten programs. \\nThe business representative and the subject matter expert should be involved \\nin integration testing. They are the first to know whether a particular run was \\nsuccessful or not. This is also an excellent opportunity for some advanced train- \\ning for them, and it will go a long way toward allaying any future suspicions \\nabout the accuracy and quality of the data in the BI target databases. \\nIntegration testing, like unit testing, requires many test runs to remove all the \\ndefects and to tune the flow. Every time the actual test results do not equal the \\nexpected test results, the program producing the error must be corrected, and all \\nprograms must be rerun. But unlike unit testing, integration testing is far too \\ncomplicated to be performed without a formal test plan, which should include a \\ndescription of the test cases and the sequence in which the programs should be \\nexecuted. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 304}, page_content='ETL Testing 270 \\nRegression Testing \\nThe most complicated and most time-consuming of all types of testing is regres- \\nsion testing. It is similar to integration testing, but this time the programs that are \\nbeing tested are not new. Since the BI decision-support environment is evolving \\nand new BI applications are added to the ETL process continuously, the project \\nteam will have to perform extensive regression testing on all releases except the \\nfirst one. With every new BI release the ETL process has to be modified \\n(enhanced) to extract more data from the operational systems for the new BI \\napplication. The new BI application may have a separate set of data access and \\nanalysis programs, but the ETL process is shared. \\nThe main goal of regression testing is to make sure that the modifications to \\nexisting ETL programs did not inadvertently produce some errors that did not \\nexist before. If new programs were added to the ETL process flow, the new inter- \\nactions between programs must be tested, and any affected subsequent old pro- \\ngrams must be retested. If the ETL process flow had to be enhanced or redesigned \\nto increase efficiency, the entire ETL process has to be retested. \\nPaw To develop a new test plan for every regression test would be much too time- \\nconsuming. Thus, it is advisable to save the original test plan and the original \\ntest data created for integration testing of the first release. Then enhance the \\noriginal test plan for subsequent regression tests with new programs, new \\ndata, and new test cases. \\nPerformance Testing \\nPerformance testing, also known as stress testing, is performed to predict system \\nbehavior and performance. This is very similar to traditional performance testing \\non operational systems, but BI performance testing is more complicated because \\nof the enormous volumes of data in the BI target databases. Since most organiza- \\ntions do not have more than three to four hours left in their nightly batch win- \\ndows, the goal is to find out how much data can be processed during that time \\nand how many nights it will take to complete the entire ETL process. \\nUnlike integration testing or regression testing, performance testing does not \\nhave to be performed on every program module. Performance testing could be \\nlimited to only the most critical program modules with the highest volumes of \\ndata and the longest runtimes. In addition to running physical tests, you can use \\nstress test simulation tools. These simulation tools allow you to describe the pro- \\nduction platform, including other programs running on the same server and \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 305}, page_content='272 Step 11: Extract/ Transform/Load Development \\nsharing the same space. Based on your input, the tools calculate and project esti- \\nmated performance numbers. It is highly recommended to run a simulation \\nprior to actual performance testing with real data. \\nQuality Assurance Testing \\nMost large organizations have strict procedures for moving an application into \\nproduction. These procedures usually include QA testing, and in most cases a sepa- \\nrate QA environment is established for such testing. Operations staff direct the \\ndevelopers in moving databases and programs into the QA environment. Then \\nall operating instructions and scheduled jobs have to be turned over to the opera- \\ntions staff for testing. They will go through a simulated production run before \\nallowing the application components to transfer to the production environment. \\nAcceptance Testing \\nAcceptance testing can be performed in one of two ways, depending on how test- \\ning as a whole is set up. Ideally, there should be a separate acceptance test envi- \\nronment, which could also be used for regression testing of future releases. With \\na separate acceptance test environment, QA testing and acceptance testing could \\nbe done at the same time. However, it may not be feasible or justifiable to main- \\ntain a separate acceptance test environment. A simpler alternative is to perform \\nacceptance testing after QA testing in the same QA environment. \\nIf the business representative actively participated during integration testing \\nor regression testing, there should be very few surprises during acceptance test- \\ning. In fact, if the business representative is comfortable with the integration or \\nregression test results, and barring any unforeseen problems detected during QA \\ntesting, separate acceptance testing may not be necessary at all. However, if a tra- \\nditional approach was followed in which the business representative was not \\ninvolved in any design or testing activities except for occasional reviews, accep- \\ntance testing is the most important test of all. \\nSome project teams limit acceptance testing to the access and analysis portion \\nof the BI application and exclude the business representative from ETL testing. \\nThat is a big mistake. When business analysts and business managers complain \\nabout incorrect data in the BI target databases, the reason may not be that the \\nreport programs do not work properly but that the ETL process is faulty. There- \\nfore, testing how to get the data into the BI target databases correctly is more \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 306}, page_content='Formal Test Plan 273 \\nimportant than testing how to get it out correctly because an error in a report \\nprogram is a lot easier to find and correct than an error in the ETL process. More- \\nover, since the business representative is involved in source data analysis and in \\nproviding the business rules for data cleansing, it is only logical that he or she \\nshould test the ETL process that implements those rules. The business represen- \\ntative should ask some of the following questions. \\n* Is the appropriate data being extracted? \\n* If the source data element is split into multiple columns, is it done correctly \\nduring the transformation process? \\n- If some data elements are merged together, did any integrity problems result \\nfrom this transformation process? \\n* Is the data loaded correctly into the appropriate BI target databases and the \\nappropriate BI tables? \\n* Can the data in the BI target databases be reconciled with the source files and \\nsource databases? Where are the reconciliation totals stored? \\n+ Are data values correctly transformed and cleansed? Is bad data slipping \\nthrough without notice? \\n+ Is the load performance adequate? And is the BI data available to the business \\npeople when they expect it? \\nFORMAL TEST PLAN \\nWith the possible exceptions of unit testing and performance testing, ETL testing \\nsessions are organized events that are guided and controlled by an agenda called a \\ntest plan. Each test plan should specify the information illustrated in Figure 11.6. \\nTest Plan \\nAE \\nEES ASS a \\nPurpose Schedule Test Cases Test Log \\nFigure 11.6: Test Plan Components \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 307}, page_content='274 Step 11: Extract/ Transform/Load Development \\n* Purpose: Describe in general terms what is being tested. For example: \\n“Data is extracted from the Customer Master file, Account Tran file, Sales \\nHistory database, and Product Master database. The extracted data from \\nCustomer Master, Account Tran, and Sales History must be merged under \\nCustomer Number, and the extracted data from Product Master and Sales \\nHistory must be merged under Product Number. The ETL programming \\nspecifications include 28 transformations and 46 cleansing algorithms. We \\nwill run 20 test cases to test the transformations and 42 test cases to test the \\ncleansing algorithms.” \\nSchedule: After reviewing the ETL process flow diagram and determining \\nwhich programs have to run in which sequence and which ones can run in \\nparallel, every program in the job stream must be scheduled to run in exactly \\nthat sequence on certain dates at certain times. \\nTest cases: The bulk of the test plan will be the list of test cases. It is important \\nto have the business representative participate in writing the test cases. Each \\ntest case specifies the input criteria and the expected output results for each \\nrun. It also describes the program logic to be performed and how the result- \\ning data should look. For example: \\n“Submit module ETL3.3 using the T11Customer temporary VSAM file and \\nthe T11Product temporary VSAM file. Both temporary files are sorted in \\ndescending order. Module ETL3.3 merges the two files and rejects records \\nthat do not match on Sale-Tran-Cd and Cust-Num. All rejected records must \\ntrigger the error message: “ETL3.3.e7 No match found on <print out Cust- \\nNum> and <print out Prd-Nbr> <print out system date-time stamp>.” \\nTest log: A detailed audit trail must be kept of all test runs, itemizing the date \\nand time the programs ran, the program or program module numbers, who \\nvalidated them, the expected test results, the actual test results, whether the \\ntest was accepted or not, and any additional comments. Table 11.1 shows a \\nsample test log. \\nRemember that all programs in the ETL process are tested and retested until \\nthe complete ETL process runs from beginning to end as expected. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 308}, page_content=\"PA ho \\n—eeree——————————————— \\n8LL’8z7z \\nD5 \\nVELSCGum \\n1 \\n@ \\naml \\nLZ8‘OZL \\n4g \\n607'1ZL \\n9g \\nSJOPEIEYD \\nPI|eAU! \\n807'86E \\nV \\nO@7'86E \\nV \\n9APY \\nS8PO) \\n996 \\nON \\n-SJ2}O} \\n9I|NOD-duS \\n-SJ2}0} \\n9POD-dusS \\nqd \\nLAC \\nLILA \\nWV \\nOL:6 \\n€002/SZ/8 \\n“€00Z/LO/OL \\nJaye \\npapunj \\nsueo] \\nAl \\nWHY \\nUO \\nsindD0 \\naduejeg \\nueo| \\naduejeg \\nueo| \\nSul}UNOD-3]qnoq \\nON \\nAep \\nLULEz‘s6r‘EE$ \\n Ajjep \\nTE \\nLEL'SSS‘OE$ \\nTVE \\nLALE1LA \\nWY \\nSP:8 \\n€0072/SZ/8 \\n‘paypadxa \\npue \\npljeA \\nue \\nsuoIDalay \\n‘SURO] \\nPayafal \\npaseysind \\n689‘€g6 \\npaseysind \\n[€7‘eg6 \\nSS9'L \\n39M \\nB9YL \\nSEA \\nSURO] \\nPIOS \\n9/8‘0EZ \\nSURO] \\nPJOS \\n687'ZEZ \\naid \\nLAL \\nLILA \\nWY \\nSP:8 \\n€002/SZ/8 \\ns}UauIUuIO) \\n(ON/SAA) \\nSynsay \\nsal \\n[ONY \\n—-synsay \\n}Sal \\npaydadx \\ndaysal \\nJaquinn \\nauiLL \\napa \\npajda2oy \\nwipiboid \\n—eeeeee-? \\n—n \\neee \\nea \\nFormal Test Plan \\nS07] \\n}SaL \\n© Jo \\najdwexq \\n: 111 \\najqey \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 309}, page_content='276 Step 11: Extract/ Transform/Load Development \\nETL DEVELOPMENT ACTIVITIES \\nThe activities for ETL development do not need to be performed linearly. Figure \\n11.7 indicates which activities can be performed concurrently. The list below \\nbriefly describes the activities associated with Step 11, ETL Development. \\nQuality assurance test \\nETL process \\nPerformance test \\nETL process \\nZ 7 Sip \\nIntegration or regression \\ntest ETL process \\nBuild and unit test \\nETL process \\nAcceptance test \\nETL process \\nFigure 11.7: ETL Development Activities \\n1. Build and unit test the ETL process. \\nUnder the direction of the ETL lead developer, the ETL programs must be \\ndeveloped for the three sets of load processes: initial load, historical load, and \\nincremental load. If you plan to use a database management system (DBMS) \\nload utility to populate the BI target databases, then only the extract and \\ntransformation programs need to be written, including the programs that \\ncreate the final load files. If you plan to use an ETL tool, the instructions \\n(technical meta data) for the ETL tool must be created. All custom-written \\nETL programs and all ETL tool modules must be unit tested for compilation, \\nfunctionality, and edits. \\n2. Integration or regression test the ETL process. \\nOnce you have unit tested all the individual ETL programs or program mod- \\nules, the entire ETL process flow must be tested. This is accomplished with \\nintegration testing on the first release and with regression testing on subsequent \\nreleases. Both types of testing must be performed under a formal test plan \\nwith test cases, expected test results, actual test results, and a log of test runs. \\n3. Performance test the ETL process. \\nSince many BI target databases are very large databases (VLDBs), it is important \\nto stress test selected programs or ETL tool modules. Perform stress testing \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 310}, page_content='Deliverables Resulting from These Activities EM fT | \\nwith full volume data on those programs or ETL tool modules that read or \\nwrite to high-volume tables and that perform complicated operations, espe- \\ncially when running in parallel against high-volume tables. Performance tests \\ncan also be simulated with stress test simulation tools. \\n4. Quality assurance test the ETL process. \\nMost organizations do not allow programs to be moved into production until \\nthey have passed through a QA test process. This test is usually run under the \\nsupervision of the operations staff in a separate QA environment. \\n5. Acceptance test the ETL process. \\nIf the business representative and the subject matter expert have been actively \\ninvolved in integration or regression testing activities, then acceptance testing \\nshould be little more than a final, formal certification from the business rep- \\nresentative. If they have not been involved, all functions of the ETL process \\nmust be validated to be complete and correct, especially the reconciliation \\nprocess. \\nDELIVERABLES RESULTING FROM THESE ACTIVITIES \\n1. ETL test plan \\nThe test plan should state the purpose for each test and show a schedule for \\nrunning the tests in a predefined sequence. It should also describe the test \\ncases, including input criteria and expected output results. A test log should \\naccompany the test plan, documenting when the tests were run, who ran the \\ntests, and what the test results were. \\n2. ETL programs \\nAll extract, transformation, and load programs and scripts for the entire ETL \\nprocess should be coded and tested. If an ETL tool is being used, instructions \\nfor the ETL tool modules should be written and the ETL tool modules should \\nbe tested. \\n3. ETL program library \\nAll ETL programs, scripts, and ETL tool modules should reside in a version- \\ncontrolled ETL program library or ETL tool library. These ETL programs, \\nscripts, and ETL tool modules should have been integration or regression \\ntested, performance tested, QA tested, and acceptance tested for the entire \\nELE process: \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 311}, page_content='278 Step 11: Extract/ Transform/Load Development \\nST \\nROLES INVOLVED IN THESE ACTIVITIES \\n@ Business representative \\nThe business representative should be involved in integration or regression \\ntesting and in acceptance testing. With the help of the ETL lead developer, he \\nor she and the subject matter expert write the test cases. \\n@ Database administrator \\nThe database administrator can be very instrumental during the ETL develop- \\nment process. The database administrator assists the ETL lead developer with \\nthe ETL process flow and also reviews all database calls written by the ETL \\ndevelopers. On more than one occasion a database administrator has been \\nable to streamline the ETL process by invoking little-known DBMS utilities at \\nthe appropriate point in the ETL process flow. \\n@ ETL developers \\nOne of the main tasks assigned to ETL developers is to code or enhance the \\nETL programs and to unit test them. If the organization is using an ETL tool, \\nthe ETL developers must write the ETL instructions (technical meta data) for \\nthe ETL tool processes. \\n@ ETL lead developer \\nThe ETL lead developer manages the entire ETL process. He or she reviews the \\nETL process flow diagram and the ETL program design document with the \\nother ETL developers and assigns the programming modules to them. He or \\nshe creates the test plan and works with the business representative and the \\nsubject matter expert on creating the test cases. He or she is also responsible \\nfor coordinating the test runs and keeping the test log current. \\n@ Subject matter expert \\nThe subject matter expert, either alone or with the business representative, \\nwrites or enhances the test cases for the test plan. He or she also suggests what \\nreconciliation totals have to be produced. The subject matter expert should \\nparticipate as a tester during integration or regression testing and during \\nacceptance testing. \\n® Testers \\nTesters can be developers, systems analysts, “power users,” subject matter \\nexperts, and anyone else who has some technical skills and is available to par- \\nticipate in testing. Developers should not test their own code, but they can test \\nthe code written by other developers. Testing is an activity that can easily be \\nmodularized. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 312}, page_content='Bibliography and Additional Reading 279 \\nPaw It is advisable to get as many testers involved as possible to accelerate the \\ntesting process. \\nRISKS OF NOT PERFORMING STEP 11 \\nA well-designed and well-tested ETL process is the backbone of a BI decision- \\nsupport environment. This step is a very time-consuming step, but without it, \\nyou do not have a BI application. End of story. \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nAiken, Peter H. Data Reverse Engineering: Slaying the Legacy Dragon. New York: \\nMcGraw-Hill, 1995. \\nBeck, Kent. Extreme Programming Explained: Embrace Change. Boston, MA: \\nAddison-Wesley, 2000. \\nCockburn, Alistair. Agile Software Development. Boston, MA: Addison-Wesley, 2002. \\nDevlin, Barry, Data Warehouse: From Architecture to Implementation. Reading, MA: \\nAddison-Wesley, 1997. \\nHackney, Douglas. Understanding and Implementing Successful Data Marts. Read- \\ning, MA: Addison-Wesley, 1997. \\nHetzel, William. The Complete Guide to Software Testing, Second Edition. New \\nYork: John Wiley & Sons, 1993. \\nHumphrey, Watts S. Winning with Software: An Executive Strategy. Boston, MA: \\nAddison-Wesley, 2002. \\nImhoff, Claudia, Lisa Loftis, and Jonathan G. Geiger. Building the Customer- \\nCentric Enterprise: Data Warehousing Techniques for Supporting Customer Rela- \\ntionship Management. New York: John Wiley & Sons, 2001. \\nKimball, Ralph, and Richard Merz. The Data Webhouse Toolkit: Building the Web- \\nEnabled Data Warehouse. New York: John Wiley & Sons, 2000. \\nKimball, Ralph, Laura Reeves, Margy Ross, and Warren Thornthwaite. The Data \\nWarehouse Lifecycle Toolkit: Expert Methods for Designing, Developing, and \\nDeploying Data Warehouses. New York: John Wiley & Sons, 1998. \\nPonniah, Paulraj. Data Warehousing Fundamentals: A Comprehensive Guide for IT \\nProfessionals. New York: John Wiley & Sons, 2001. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 313}, page_content='i) Giieedss <a @ eh’ le orn e dpe! OMe la \\\\itegymildeat fa \\n(=a : j “tag at —s eles nf 08 e tit \\ns a4ult > ai oa > 4 Mee \\nSrey efhes Gelinas seit af ae arny D1) fate-linw Latta: \\ni Cher Gad 2a no rera yyy oad peng iT ui \\n(iy i | ob = PEt Debs 6 cra alge : \\nie rr To mbaleie © Niahaw paiem \\nbebts f\\'s;, 1 4 aj svalrmer setae Sh CY eo jibe Nee Din?’ ape: 0 —— a \\nCe fren \\nPuhr dias! ont \" yin? 3 yrs Baie secs ama laa \\nws Gh ‘pp ew leak ; els es ain \\n248, wood St omen, ba yh nee, BF EAS \\n(ie NTE o> Shem nu oGeuiie [tegtie - \\ndakettilnenlbid 7 ry up eae yee ior shyt sient a Alo: Ae \\nka arereenen chanel 16 eri PanbiAook inti) Seaetlse pity = if . \\nlead i i, Sa? nae 7 av< aw eaiet ee a i) 7 \\nhye avcotn sinishibdiiaaitnatnatiead 1S \\\\gtn. gnilennaatoraljuat Riaebgpenentls spil aM. \\nSalat OV by esis aarti wig pls a } = \\nwide \\nq \\nSaal tei nee” rihie: a nalts WY eae gare \\nig we 8 Na 3 nya re i a . ote aah ae o vs iy a ih \\nne =, 8 Ne sare ol aa \\nnae ni\\\\! aehinl tare, ec tat gt a ae nin) \\nYonge oe Sere! cae ‘. Bu a ae \\naa alee iia aye an és} nh \\ndled ade grsbliuld cates rane Pana wr Phiied oy Saed he: \\n+ Sines’ 0G asters B peli tatol anda = \\nwit, Bip t! Grn, 0 5 tt Aaa fl, | \\nMi PRN, ya alg a eae rt ES ea hil \\nbh ed (Leo lerae «oon ad) ie \\n100k onod 7 \\n= \\n“@ P| re! \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 314}, page_content='Justification CHAPTER TWELVE \\nStep 12: Application \\nPlanning a -_ Development \\nCHAPTER OVERVIEW \\nBusiness Analysis i — This chapter covers the following topics: \\nf \\nm@ Things to consider about access and analysis tools \\nm@ The advantages of using online analytical processing \\n(OLAP) tools and some of their popular features \\n@ Multidimensional analysis factors, with emphasis on multi- \\nvariate analysis using both object dimensions and variable \\ndimensions \\n@ Three OLAP architectural layers: presentation services, \\nOLAP services, and database services \\n@ Four common application development environments: \\nprototyping, development, quality assurance (QA), and \\nproduction \\n@ A short discussion of the Web environment \\n@ Brief descriptions of the activities involved in application \\ndevelopment, the deliverables resulting from those activi- \\nties, and the roles involved Application \\nDevelopment \\n@ The risks of not performing Step 12 \\ngulp Deploymer \\n281 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 315}, page_content='282 Step 12: Application Development \\nTHINGS TO CONSIDER \\nPrototyping Results \\n/ Did we prototype the access and analysis components of the BI application? \\nIf so, what did we learn from the prototype? \\nY What portions of the application prototype can we save? What portions have \\nto be redesigned? \\n/ Did we decide to develop the access and analysis components using the oper- \\national prototype as a rapid and iterative development method? Will this be \\nthe final iteration? \\nAccess and Analysis Tools \\n¥ What access and analysis tools do we already have in place? Are we happy \\nwith them? \\n¥ Will the business people use an OLAP tool for multidimensional analysis? \\n¥ In what other ways will they analyze the data? Do we need to acquire another \\nquery or reporting tool? \\nSkills and Training \\n¥ What skill sets (beginning, advanced, expert) do the business people have? \\nWhat type of additional training do they need? \\n¥ How many business people have already been trained on the access and \\nanalysis tools? How many more need training? \\nV Are they familiar with OLAP and multidimensional reporting concepts? \\nVY Do we need to implement a context-sensitive online help function for the \\naccess and analysis components of the BI application? \\nScope and Project Requirements \\nVv Are our project requirements still the same? Or has the scope changed? \\n/Y How many reports and canned queries do we need to develop? Which ones? \\nV Have we validated the necessary number of dimensions needed for those \\nreports and queries? \\nV Do we know how the knowledge workers, business analysts, and business \\nmanagers want to drill down and roll up when working with the data? Are \\ntheir requirements similar or different? \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 316}, page_content='Online Analytical Processing Tools 283 \\nWeb Considerations \\nVY Do we have to include a Web portal with this BI application? \\nVv Have we developed Web portals before? Have we prototyped one? \\n¥ What are the additional security requirements for the Web? Do we have the \\nnecessary firewalls and security packages installed? \\nTechnical Considerations \\nV Are the development and production environments configured the same or \\nare they different? \\n¥ What are the differences? A different database management system (DBMS)? \\nA different operating system? Different hardware? \\nThe main reason for a BI decision-support initiative is to provide fast and \\neasy access to data for business analysis. A high percentage of that access will be \\nby predefined patterns. A predefined pattern means that data has been precalcu- \\nlated (derived, aggregated, summarized) and stored in that fashion for faster \\naccess. This is the reason for the high popularity of multidimensional OLAP \\ntools, and it is the hallmark of BI decision-support applications. \\nONLINE ANALYTICAL PROCESSING TOOLS \\nMultidimensional OLAP tools are a major component of the BI decision-support \\ntool suite. Terms such as OLAP, relational OLAP (ROLAP), multidimensional \\nOLAP (MOLAP), decision support, multidimensional analysis, and executive infor- \\nmation system (EIS) are all used to describe the explosive growth in the field of \\ndata access and data analysis tools. These terms are frequently associated with \\nexpectations of built-in functionality and ease of use. While much of the litera- \\nture uses OLAP to represent all of these terms, each OLAP tool vendor seems to \\nhave its own definition of OLAP. Hence, OLAP tools support only the definitions \\nof their vendors—most of the time. \\nA widely accepted definition of OLAP is the following: OLAP refers to online \\nanalytical processing technology that creates new business information through a \\nrobust set of business transformations and calculations executed upon existing \\ndata. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 317}, page_content='284 Step 12: Application Development \\nAdvantages of OLAP Tools \\nAlthough BI decision-support applications use conventional reporting and que- \\nrying tools as much as multidimensional OLAP tools, the majority of business \\npeople seem to favor OLAP tools because of their additional functionalities. \\nThere are two distinct advantages for business people who use OLAP tools. \\n1. The focus in analytical processing is on the data, specifically the multidimen- \\nsional aspects of the data that are supported by OLAP tools. Business objects \\nare represented as dimensions (e.g., product, customer, department), which \\nare naturally interrelated through functional subject areas (e.g., sales) and are \\noften hierarchical (e.g., products roll up into product categories, departments \\nroll up into divisions). \\n2. Business analysts navigate through these dimensions by drilling down, rolling \\nup, or drilling across. They can drill down to access the detailed level of data, \\nand they can roll up to see the summarized data. They can roll up through \\nthe hierarchy levels of dimensions or to specific characteristics or data ele- \\nments (columns) of the dimensions. They can also drill across dimensions to \\naccess the data of interrelated dimensions. In addition, powerful computa- \\ntional services provide functions such as ranks, averages, return on invest- \\nment (ROJ), and currency conversions. \\nThe OLAP category of software tools makes many business analysts self-sufficient \\nby giving them easy and intuitive access to their data for analysis—and getting \\ndevelopers out of the report-writing business. This is accomplished through the \\nfollowing tool characteristics: \\n* OLAP tools allow business analysts to combine their data in any order they \\ndesire, at any level of summarization, and over several time periods. Business \\nanalysts can design their queries by clicking on the dimensions and by select- \\ning the desired data elements for the analysis they need to perform. \\n- Different OLAP tools support a variety of access and analysis needs. They \\nprovide multiple views for data access, from the senior executive’s desire to \\nbrowse through summarized data to the business analyst’s need to perform \\ncomplex detailed analysis. \\nOLAP tools are a very important component of application development in a \\nBI decision-support environment. While conventional query and reporting tools \\nare used to describe what is in a database, multidimensional OLAP tools are used \\nto answer why certain business events are true. For example, an OLAP tool could \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 318}, page_content='Online Analytical Processing Tools 285 \\nbe used to prove or disprove a hypothesis that a business analyst has formulated \\nabout a correlation among certain data values. Let us assume that a business ana- \\nlyst makes the observation that customers with low income and high debt often \\ndefault on their loans. The business analyst then concludes that this group of cus- \\ntomers should be considered bad credit risks. In order to verify this conclusion, \\nthe business analyst prepares a query against the BI target databases, for example: \\n“Compare write-off amounts for products by product type, by territory, by cus- \\ntomer, by month, where the customer income level is below a certain amount to \\nthose where the customer income level is above a certain amount.” This type of \\nanalysis query would run against a multidimensional database in which summa- \\nrized data is stored as precalculated measures (facts), with one such measure \\nbeing “write-off amount.” \\nOLAP Tool Features \\nOLAP tools are popular not only because they make the business analysts more \\nself-sufficient but also because the tools provide innovative ways to analyze data. \\n* Tools present a multidimensional view of the data, which is intuitive and \\nfamiliar to the business people. For example, organizations always like to set \\ntheir strategies for increasing revenue by: \\n— Introducing new products \\n— Exploring new markets \\n— Increasing price \\nThese three characteristics are based on increases or decreases in revenue that \\ncan be tracked more easily through a multidimensional view of the sales data \\n(by product, by region, by customer). \\nTools provide summarizations and aggregations of the data at every dimen- \\nsional intersection. The terms summarization and aggregation are commonly \\nused interchangeably. Even though both terms refer to “adding up” atomic \\ndata values and both are used in creating measures or facts, their precise defi- \\nnitions are not the same. \\n— Summarization refers to totaling or summing one atomic data value (verti- \\ncally) to produce a total or sum of that value, for example, adding up the \\nannual salaries of all employees to produce the value Total Annual Salary \\nAmount. (In popular multidimensional database design jargon, summari- \\nzation is referred to as aggregation. ) \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 319}, page_content='286 Step 12: Application Development \\na SE SS ST EE SEES L SLE, \\n— Aggregation refers to derived data, which is produced from gathering or \\nadding multiple atomic values (horizontally) to create a new aggregated \\nvalue, for example, adding the annual salary, the bonuses, and the dollar \\nvalue of an employee’s benefits package (health care plan, retirement plan) \\nto produce the value Employee Compensation Plan Amount. \\nTools provide interactive querying and analysis capabilities of the data. \\nBusiness analysts can perform “what if” analysis with the help of OLAP tools, \\nfor example, “What if we lowered the price of the product by $5? How much \\nwould our sales volume increase in the state of Alaska?” Business analysts like \\nto run queries interactively and act upon the query results by changing the \\nvalues of some variables and rerunning the query to produce a new result. \\nTools support business analysts in designing their own analysis queries, in \\ncreating their own custom members within dimensions, and in creating cus- \\ntom measures. \\n— One of the main goals of a BI decision-support environment is to make the \\nbusiness analysts as self-sufficient as possible. This can be done with parame- \\nterized queries, where business analysts can change their assumptions (param- \\neters) and rerun the same queries with new parameters. A prerequisite for \\neffective use of parameterized queries is a well-documented query library. \\n— OLAP tools can also give business analysts the ability to create custom \\nmembers (also called aggregates) within a dimension (e.g., Hot-Car, which \\nwould be defined as any red convertible) that can SUM, AVG, MAX, and \\nMIN a group of member values. \\n— OLAP tools can also provide the ability to create custom measures or facts \\n(e.g., Percent Female, which would be defined by a formula provided by a \\nbusiness analyst). These custom measures can then be picked as a new \\nmeasure from a drop-down menu for a fact table. \\nTools support drill-down, roll-up, and drill-across features of multidimen- \\nsional analysis. For example, a business analyst who wants to find a way to \\nlower the cost of manufactured goods could drill down into the actual \\ndetailed costs of purchased raw materials. He or she could also summarize \\nthese costs by rolling up the raw materials into predefined categories. Then he \\nor she could drill across to another table to include the production costs of \\nthe manufactured goods. \\n* Tools offer analytical modeling capabilities useful to business people. To \\nexpand on the previous example, lowering the cost of manufactured goods \\ncould also be accomplished by reducing the working capital so that the \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 320}, page_content='Multidimensional Analysis Factors 287 \\nborrowing costs are lower. Analytical modeling techniques provided by the \\nOLAP tools could be used to find the optimum amount of working capital. \\n* Tools support functional models for trend analysis and forecasting. OLAP \\ntrend analysis functionality could be used to analyze past data and make pre- \\ndictions about the future. \\n* Tools display data in charts and graphs that offer quick visual summaries. \\nThe saying “A picture is worth a thousand words” has never been so true as \\nwhen analyzing vast amounts of data from BI target databases. Visually \\nappealing, understandable, and useful charts and graphs are important com- \\nponents of every OLAP tool. \\nThere is a diversity of OLAP tools based on different architectures and features. \\nIt is important to know the access and analysis requirements of BI applications in \\norder to make an informed decision about purchasing the right OLAP tools. \\nMULTIDIMENSIONAL ANALYSIS FACTORS \\nOne of the distinguishing factors of multidimensional OLAP tools, as opposed to \\nconventional querying tools, is the way they present the information. Measures \\nor facts are usually presented in a multidimensional format, such as columns in a \\nfact table or cells in a cube. These columns and cells contain precalculated \\nnumeric data about a functional subject area and are related to business objects \\n(dimension tables) associated with the subject area. For example, Sales Amount, \\nNet Profit Amount, Product Cost, and Monthly Account Fee are numeric data \\n(facts) precalculated by account, by purchase, by customer, and by geography, \\nwhich are the associated business objects (dimensions). In contrast, a conven- \\ntional relational table would be a flat matrix of rows and columns, containing \\nnumeric data about one and only one business object (dimension). For example, \\nOpening Account Balance, Daily Account Balance, and Account Interest Rate are \\nnumeric data of only one business object, namely account. \\nFigure 12.1 illustrates multidimensionality through a four-dimensional cube \\nwith the dimensions customer, account, purchase, and geography. The two exam- \\nples of geography in this figure are the regions northeast USA and southeast USA. \\nCustomer profiling and customer profitability are popular multidimensional \\nBI applications. The dimensions of a customer profitability example are listed in \\nFigure 12.2. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 321}, page_content='288 Step 12: Application Development \\n5 5 pa \\ng 8 <q <x \\n> Monthly Sales Amount Customer Customer \\nFigure 12.1: Four-Dimensional Data Representation \\nBuying \\nBehavior \\nCredit \\nRating \\nCustomer \\nProfitability \\nProduct \\nCategory \\nPurchasing \\nHistory Psycho- \\ngraphics \\nFigure 12.2: Multidimensional Customer Profitability \\nThe eight dimensions of customer type, buying behavior, credit rating, \\nregion, demographics, psychographics, purchasing history, and product category \\ncan be used to analyze the various perspectives of customer profitability. \\nSome additional examples of complex multidimensional analysis commonly \\nperformed in the BI decision-support environment include those listed below. \\n* Customer information: Buying patterns by product, geography, time, age, gen- \\nder, number of children, types of cars owned, education level, or income level \\n* Financial planning: Business analysis on profit margins, costs of goods sold, \\ntax codes, or currency exchange rates \\n* Marketing: Impact of promotions and marketing programs, pricing, compet- \\nitors’ initiatives, and market trends \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 322}, page_content='Online Analytical Processing Architecture 289 \\nMultivariate Analysis \\nAnother term for multidimensional analysis is multivariate analysis. This term is \\nderived from a specific aspect of this type of analysis, namely, to analyze measures \\n(facts) from the perspective of multiple variables or characteristics. These vari- \\nables (characteristics) usually describe business objects or dimensions. For exam- \\nple, Product Type describes product and Customer Age describes customer, with \\nproduct and customer being the business objects or dimensions. Occasionally, \\nthe variables can become dimensions in their own right. For example, the vari- \\nables Product Type and Customer Age can be treated as dimensions. In other \\nwords, a dimension can be built for a business object or for a variable of that \\nbusiness object. \\nThese two types of dimensions (the object dimension and the variable \\ndimension) can be illustrated by a simplified example of earthquake analysis. \\nEarthquakes are typically reported by their epicenter, such as the intersection of \\nlatitude and longitude coordinates of a location, and by their intensity, such as \\n7.5 on the Richter scale. Location is normally a business object; thus epicenter \\ncan be used as an object dimension, which may be described by variables such as \\nLocation Name, Location Address, and Population Size. Intensity, on the other \\nhand, is normally not a business object but a variable that describes the business \\nobject earthquake. In this example, however, intensity is treated as an object in its \\nown right and is therefore used as a variable dimension. Another example of a \\nvariable dimension might be Shock Type (foreshock, aftershock), which is nor- \\nmally also a variable of the business object earthquake. \\nVariable dimensions are often “degenerate” dimensions, which means that \\neven though they are being treated as dimensions when precalculating or analyz- \\ning the facts, they are not implemented as physical dimension tables. The main \\nreason is that variable dimensions usually do not have other variables describing \\nthem—or they would not be variable dimensions in the first place. For example, \\nintensity is simply a set of numerical values (numbers on a Richter scale), and \\nthere are no other descriptive characteristics about it. \\nONLINE ANALYTICAL PROCESSING ARCHITECTURE \\nConceptually, OLAP architecture consists of three functional components: pre- \\nsentation services, OLAP services, and database services (Figure 12.3). \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 323}, page_content='290 Step 12: Application Development \\nInformation Display Querying, Reporting, Analyzing Relational, Multidimensional \\nPresentation Services OLAP Services Database Services \\nFigure 12.3: Functional Components of OLAP Architecture \\nPresentation Services \\nOLAP is supposed to provide the link everyone has been looking for between \\ndata and the business. Yet most organizations still seem to be data rich and infor- \\nmation poor because the real world of business exists in bits and pieces, not in \\nbits and bytes. Information is data that can be analyzed, synthesized, and used in \\na valid business context. The people who need this data are knowledge workers, \\nbusiness analysts, business managers, and business executives, not technicians. \\nTherefore, the data needs to be presented in a format that enables the business \\npeople to develop proposals, decide how many widgets to buy, define investment \\nlevels, and set hiring targets. \\nPresentation services have to be easy to use, and ease of use has to be deter- \\nmined by the business people, not by the information technology (IT) staff. For \\nexample, business people want an intuitive graphical user interface (GUI) and \\nthe ability to work with familiar business terms. Therefore, an easy-to-use OLAP \\ntool should hide the underlying structure of the data and hide the processes that \\nrun behind the scenes. Furthermore, ease of use should be expressed in quantifi- \\nable terms. \\n* How much time is needed to learn the OLAP tool? \\n* How fast can a person perform his or her analysis tasks? \\n* Do business people like using the OLAP tool? \\n> Does the OLAP tool have all of the required functionality? \\n* Can the OLAP tool integrate with other desktop tools, such as Microsoft Excel? \\nPresentation services have to be flexible and adaptable because different busi- \\nness people have different preferences and different skill sets. For example, some \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 324}, page_content='Online Analytical Processing Architecture 291 \\nbusiness people like tabular reports; others like graphs and charts. Some business \\npeople have no computer skills at all, some are more advanced, and some are \\nexperts. The menus, icons, and functions should be configured depending on the \\nskill set profile, and they may have to be reconfigured over time. When the begin- \\nners start to become experts, they no longer like the cute messages that were orig- \\ninally provided to them for encouragement. Experts expect better performance \\nand faster responses, and in order to provide that, there should be less clutter on \\ntheir screens. An ideal OLAP tool should be able to adjust to all these different \\nlevels of preferences and skill sets and should be able to provide different levels of \\npresentation. \\nOLAP Services \\nAn OLAP tool should provide a wide range of services. It should be able to sup- \\nport simple querying with just a few dimensions, and at the same time, it should \\nbe able to support powerful querying with many dimensions. In addition, an \\nOLAP tool should be able to integrate all the analytical processing requirements \\nof “What happened?” with those of “Why did this happen?” Querying capabilities \\n(from very simple to complex), reporting capabilities (from very basic to sophis- \\nticated), and multidimensional analysis and presentation of the results are some \\nof the OLAP services that help turn data into useful information. \\nQuerying, reporting, and analyzing are interrelated, interactive, and iterative. \\nFor example, the results of a query might appear in the form of a table, chart, or \\ngraph, presented in several dimensions. While studying these query results, a \\nbusiness analyst may think of a new question, which may lead to a new query. He \\nor she may then want to have the results of the new query printed out as a report. \\nTherefore, OLAP tools should have integrated querying, reporting, and analyzing \\nservices. A person should not have to log off the querying tool to get into a differ- \\nent reporting tool and then log off the reporting tool to get into an analysis tool. \\nQuerying, reporting, and analyzing should be a seamless transition performed by \\nthe tool, not by the person. \\nIn order to leverage these OLAP services, we need to change the way we \\ndevelop applications and the way we present information. BI applications, which \\nemphasize quick delivery of functionality, ease of use, and affordable desktop \\nhardware and software, should be the vehicles for IT to provide OLAP capabili- \\nties to more business people in the organization. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 325}, page_content='292 Step 12: Application Development \\nDatabase Services \\nOLAP architecture supports two types of databases, conventional relational data- \\nbases (e.g., DB2, Oracle), which are accessible with ROLAP tools, and proprietary \\nmultidimensional databases, which are supplied with MOLAP tools. \\n* ROLAP tools can access any of the major relational DBMSs as long as the \\nunderlying application database design is multidimensional, such as star \\nschemas (facts and denormalized dimensions), snowflake schemas (facts and \\nnormalized dimensions), and hybrid schemas (combination of normalized \\nand denormalized dimensions). Depending on the DBMS, the database \\ndesigner would use common physical design techniques such as: \\n— Selecting the most efficient indexing schema for the underlying DBMS \\nproduct in order to improve performance \\n— Partitioning the database into smaller, manageable partitions to improve \\nperformance and to facilitate database maintenance activities \\n— Clustering the data and physically co-locating related tables \\n— Determining the most appropriate data and index placements \\n* MOLAP tools are designed to access their own proprietary databases, which \\nare special data structures (e.g., Essbase), and to perform their OLAP opera- \\ntions on these data structures. MOLAP tools implement their functionality in \\na variety of different ways. \\n— Some products store data in arrays or cubes and therefore have different \\ndata preparation requirements. \\n— Some products require prebuilding dimensions in the staging area before \\nloading them; others build the dimensions from the data at load time. \\n— Some products provide an application programming interface (API); oth- \\ners do not. \\n— Some products offer “turnkey” applications with multidimensional servers \\nand substantial OLAP functionality. \\n— Most products have their own proprietary access methods and front ends. \\nDEVELOPMENT ENVIRONMENTS \\nThe development of vital business applications does not happen ad hoc on some- \\none’s personal computer. Most organizations require some kind of formal or \\nstructured approach for developing these applications, testing them, and deliver- \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 326}, page_content='Development Environments 293 \\ning them. Some organizations (and some projects) require more structure than \\nothers. Also, on BI applications, some application components need more struc- \\nture than others. \\nFor example, an informal and dynamic development approach for building \\nthe front-end access and analysis components is quite appropriate. Front-end \\napplications are usually built with flexible tools that lend themselves quite well to \\nrapid and iterative development cycles. It is quite common for the application \\ntrack to go through several stages of prototyping, especially multiple iterations of \\noperational prototyping, while performing analysis, design, coding, and testing \\nactivities almost all at the same time. However, developing the back-end ETL \\nprocess in such an informal and dynamic way is not appropriate. ETL develop- \\nment requires a more formalized or structured approach because of its size and \\ncomplexity. Even when ETL tools are used, the activities of the ETL development \\ntrack are much more similar to a large operational systems development project \\nthan to the dynamic prototyping activities of the application development track. \\nTo support these different types of activities, organizations usually set up dif- \\nferent development environments for different purposes. While smaller organi- \\nzations may have only two environments (development and production), large \\norganizations usually have at least four different environments: \\n1. The prototyping environment, where the testing of the technology and the \\nsolidifying of the project requirements occur \\n2. The development environment, where the programs and scripts are written \\nand tested by the developers \\n3. The QA environment, where the operations staff tests the final programs and \\nscripts before allowing them to be moved into the production environment \\n4. The production environment, where the programs and scripts run after being \\nrolled out \\nDepending on the overall setup of the environments, early prototyping activ- \\nities (such as creating show-and-tell, mock-up, proof-of-concept, visual-design, \\nand demo prototypes) typically take place in a special-purpose prototyping envi- \\nronment, while development activities (including operational prototyping) are \\nperformed in the development environment. However, it is just as common to \\nperform all prototyping and development activities in the same development \\nenvironment. In either case, the entire BI application should be moved to the QA \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 327}, page_content='294 Step 12: Application Development \\nenvironment for final QA and acceptance testing before being implemented in \\nthe production environment. \\nIf the different development environments are configured differently, moving \\nyour application from one environment to another could have major implica- \\ntions for your BI project. \\nThe prototyping and development environments are usually configured sim- \\nilarly, as are the QA and production environments. The configuration differences \\nare typically between the development and production environments. Key con- \\nsiderations appear below. \\n* If the application works well in the development environment, there is no guar- \\nantee that the application will run equally well in the production environment. \\n* It is conceivable that the migration costs from one environment to another \\ncould be substantial. \\n* New or different tools may be required for differently configured environments. \\nThe Web Environment \\nAnother environment that is becoming more and more popular for BI applica- \\ntions is the Web. Since most OLAP tools are Web-enabled, the data from the BI \\ntarget databases can be and often is published company-wide through the intra- \\nnet. A subset of that data can also be made available through a separate portal to \\nbusiness partners via the extranet or to customers via the Internet. Special secu- \\nrity and authentication measures must be taken in the Web environment. Only \\nqualified persons should be able to access authorized databases, and all access \\nrequests must pass through a firewall. \\nIn addition to being a data delivery platform, the Web environment can also \\nbe a source for BI data. Capturing Web logs is a standard practice on Web sites, \\nand the ability to extract, filter, summarize, and report the log data for click- \\nstream analysis is a popular type of BI application (Web warehouse). Click- \\nstream analysis can help identify customer interest (number of hits), gauge the \\neffectiveness of Internet advertisements, and track the results of promotions. \\nTable 12.1 shows a list of commonly available Web log data. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 328}, page_content='Application Development Activities 295 \\nTable 12.1: Common Web Log Data \\nClick-Stream Data \\nClient IP address \\nUser ID \\nDate and time of server response \\nRequest (GET, POST) \\nStatus from server to browser \\nNumber of bytes sent \\nPrior site information (URL, path, documents, and so on) \\nBrowser name \\nCookie information \\nAPPLICATION DEVELOPMENT ACTIVITIES \\nThe activities for application development do not need to be performed linearly. \\nFigure 12.4 indicates which activities can be performed concurrently. The list below \\nbriefly describes the activities associated with Step 12, Application Development. \\n1 \\nDetermine final \\nproject requirements \\nTest \\napplication programs \\nBuild and unit test \\napplication programs \\n3 RS \\nProvide data access and \\nanalysis training \\n2 \\nDesign \\napplication programs \\nFigure 12.4: Application Development Activities \\n1. Determine the final project requirements. \\nIf you built a prototype, review the prototype results and determine what \\nchanges were requested and what issues were logged during that activity. This \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 329}, page_content='296 Step 12: Application Development \\nwill give you an understanding of the stability of the requirements. In addi- \\ntion, adjust your design or renegotiate the requirements based on what \\nworked and what did not work during the prototype. \\n2. Design the application programs. \\nWhile reviewing the prototype results and the required query and report \\nmock-ups, design the access and analysis components of the BI application, \\nincluding the final reports, queries, front-end interface (GUI, Web), and \\nonline help function. Develop a test plan with detailed test cases. \\n3. Build and unit test the application programs. \\nCreate test data and write the programs and scripts for the reports, queries, \\nfront-end interface, and online help function. Be sure to unit test the pro- \\ngrams and scripts not only to prove that they compile without errors but also \\nto verify that they perform their functions correctly, trap all potential errors, \\nand produce the right results. \\n4, Test the application programs. \\nPerform integration or regression testing on all programs and scripts in the \\nsequence in which they will run in the production environment. Load the \\ndevelopment databases with sample “live” data, and test the programs and \\nscripts against them. Check the actual test results against the expected test \\nresults, then revise and retest the programs and scripts until they perform as \\nexpected. \\nBe sure to performance test some of the more complicated programs that \\nhave many JOINs and that read high-volume tables. A performance test will \\nindicate how the BI application will perform when fully loaded in the pro- \\nduction environment. The easiest way to run a performance test is through a \\nstress test simulation tool. \\nThe final tests should be the QA test with the operations staff and the accep- \\ntance test with the subject matter expert and the business representative. \\nBesides determining whether the access and analysis programs function cor- \\nrectly, acceptance testing should determine the overall usability of the BI \\napplication and the interfaces to the BI application, especially for Web-based \\ndevelopment. \\n5. Provide data access and analysis training. \\nIdentify the training needs of the help desk staff, “power users,” knowledge \\nworkers, business analysts, and business managers. Schedule the training ses- \\nsions, either in-house or with a vendor. If the training is provided internally, \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 330}, page_content='Deliverables Resulting from These Activities 297 \\ncreate the training materials and conduct the training sessions. Be sure to \\nmeasure the effectiveness of the training, including the effectiveness of the \\nstyle in which the training is delivered, the content of the material, the pace \\nwith which the material is covered, and the quality of the workbooks (e.g., \\ntoo much text or not enough explanations). \\nDELIVERABLES RESULTING FROM THESE ACTIVITIES \\ni: Application design document \\nThis document contains the formal design specifications for the access and \\nanalysis components of the BI application. It contains report layouts, screen \\ndesigns, interface designs, calculations for reports and queries, and the design \\nof the online help function. In addition, it contains the programming specifi- \\ncations for every access and analysis component. Portions of this document \\nwill be given to different application developers to code the program modules \\nand query scripts. \\n. Application test plan \\nThe application test plan should include the purpose for each test, a schedule \\nfor running the tests, and the test cases, including input criteria and expected \\noutput results. A test log should accompany the test plan, documenting when \\nthe tests were run, who ran the tests, and what the test results were. \\n. Application programs \\nAll access and analysis programs and scripts for the BI application should be \\ncoded and tested. If an OLAP tool is being used, all of the OLAP functions \\nshould be developed and tested. \\n. Application program library \\nAll access and analysis programs and scripts should reside in the application \\nprogram library or OLAP tool library. All access and analysis programs and \\nscripts should have been integration tested or regression tested, performance \\ntested, QA tested, and acceptance tested. \\n. Training materials \\nTraining materials include presentation slides, instructor notes, student \\nworkbooks, and exercises and their solutions, as well as any additional perti- \\nnent handouts. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 331}, page_content='298 Step 12: Application Development \\nROLES INVOLVED IN THESE ACTIVITIES \\n@ Application developers \\nThe application developers have to code and unit test the access and analysis \\nprograms and scripts. They have to be proficient in the OLAP tool, Structured \\nQuery Language (SQL), and the programming languages used to develop the \\nBI application. \\n@ Application lead developer \\nThe application lead developer should be the “guru” and mentor to the other \\napplication developers. He or she will work closely with the ETL lead devel- \\noper and the database administrator on any design and implementation \\nissues. If internal training is provided, he or she will develop the training \\nmaterials and schedule the training sessions (assisted by the training staff if \\nthe organization has a training department). \\n® Business representative \\nThe business representative must actively participate in integration or regression \\ntesting, as well as acceptance testing. He or she should assist the subject matter \\nexpert in writing the test cases and in validating the test results. In addition, \\nthe business representative must attend the scheduled training sessions. \\n@ Database administrator \\nThe database administrator, who designs and builds the BI target databases, \\nwill assist with accessing these databases. The database administrator should \\nreview all database calls from programs and OLAP tools and write pass- \\nthrough queries where required. \\n@ Subject matter expert \\nThe subject matter expert is a key participant during development and testing \\nbecause he or she is probably the person most familiar with the access and \\nanalysis requirements the BI application is meant to satisfy. The subject matter \\nexpert must provide input and guidance during report and query design. He \\nor she should write (or assist in writing) the test cases and participate in inte- \\ngration or regression testing as well as acceptance testing. In addition, he or \\nshe should assist in preparing and scheduling the training sessions. \\n® Testers \\nThere can never be enough testers. It usually takes three times longer to test an \\napplication than it does to develop it. The business representative and the sub- \\nject matter expert make excellent testers. As an additional benefit, they will \\nlearn the BI application while they are testing it. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 332}, page_content='Bibliography and Additional Reading 299 \\n@ Web developers \\nWeb developers are responsible for designing and building the Web site as well \\nas designing and developing the reports and queries using Web-enabled OLAP \\ntools. They have to be proficient in Web development tools, SQL, and lan- \\nguages such as Java or Perl. \\n® Web master \\nThe Web master is responsible for the administration of the Web environ- \\nment, such as the Web server, the firewall, the Web site, and so on. He or she \\nshould be the “guru” and mentor to the Web developers and may also be the \\nmain designer of the Web site. He or she should be able to interface between \\nthe Web and the OLAP tools and be able to troubleshoot any problem. \\nRISKS OF NOT PERFORMING STEP 12 \\nThe capabilities of a BI application are notably enhanced with OLAP technology. \\nBesides enabling multidimensional analysis, OLAP tools provide additional func- \\ntionality, such as screen painting, “what if” analysis, conversion of data to graphs \\nand charts, and Web displays of query results. By excluding this step, the business \\ncommunity would be missing an important value-added aspect of the BI experi- \\nence for better decision making. \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nBeck, Kent. Extreme Programming Explained: Embrace Change. Boston, MA: \\nAddison-Wesley, 2000. \\nBerson, Alex, and Stephen J. Smith. Data Warehousing, Data Mining, and OLAP. \\nNew York: McGraw-Hill, 1997. \\nBischoff, Joyce, and Ted Alexander. Data Warehouse: Practical Advice from the \\nExperts. Upper Saddle River, NJ: Prentice Hall, 1997. \\nCockburn, Alistair. Agile Software Development. Boston, MA: Addison-Wesley, \\n2002. \\nCorey, Michael J., and Michael Abbey. Oracle Data Warehousing: A Practical \\nGuide to Successful Data Warehouse Analysis, Build, and Roll-out. Berkeley, CA: \\nOsborne McGraw-Hill, 1996. \\nDick, Kevin. XML: A Manager’s Guide. Boston, MA: Addison-Wesley, 2000. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 333}, page_content='300 Step 12: Application Development \\nDyché, Jill. e-Data: Turning Data into Information with Data Warehousing. Boston, \\nMA: Addison-Wesley, 2000. \\nGill, Harjinder S., and Prakash C. Rao. The Official Client/Server Guide to Data \\nWarehousing. Indianapolis, IN: Que Corporation, 1996. \\nHackney, Douglas. Understanding and Implementing Successful Data Marts. Reading, \\nMA: Addison-Wesley, 1997. \\nHumphrey, Watts S. Winning with Software: An Executive Strategy. Boston, MA: \\nAddison-Wesley, 2002. \\nInmon, William H., J. D. Welch, and Katherine L. Glassey. Managing the Data \\nWarehouse: Practical Techniques for Monitoring Operations and Performance, \\nAdministering Data and Tools and Managing Change and Growth. New York: John \\nWiley & Sons, 1997. \\nKimball, Ralph, and Richard Merz. The Data Webhouse Toolkit: Building the Web- \\nEnabled Data Warehouse. New York: John Wiley & Sons, 2000. \\nKimball, Ralph, Laura Reeves, Margy Ross, and Warren Thornthwaite. The Data \\nWarehouse Lifecycle Toolkit: Expert Methods for Designing, Developing, and \\nDeploying Data Warehouses. New York: John Wiley & Sons, 1998. \\nShneiderman, Ben. Designing the User Interface: Strategies for Effective Human- \\nComputer Interaction. Boston, MA: Addison-Wesley, 1998. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 334}, page_content='Construction \\n: Data > \\n~~ Mining aN \\nCHAPTER THIRTEEN \\nStep 13: Data Mining \\nCHAPTER OVERVIEW \\nThis chapter covers the following topics: \\nm@ Things to consider about data mining \\n@ Traditional analysis techniques versus data mining \\n@ The importance of data mining \\n@ Data sources for data mining \\n@ The five most common data mining techniques: associa- \\ntions discovery, sequential pattern discovery, classification, \\nclustering, and forecasting \\nm@ Data mining operations such as predictive and classifica- \\ntion modeling, link analysis, database segmentation, and \\ndeviation detection \\n@ Applications of data mining in the areas of market man- \\nagement, fraud detection, risk management, financial \\nservices, and distribution \\n@ Brief descriptions of the activities involved in data mining, \\nthe deliverables resulting from those activities, and the \\nroles involved \\n@ The risks of not performing Step 13 \\n301 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 335}, page_content='302 Step 13: Data Mining \\nTHINGS TO CONSIDER \\nMarketing Questions \\nY Do we know what general classes of customers we have? \\nY Are there subclasses of customers with similar behavioral patterns? Can we \\nuse targeted marketing messages for these customers? \\nY Do we know what our best customers have in common}? Is there a pattern \\nthat will verify our hunch that if we offer new products or services “just in \\ntime” to our best customers, they will buy them? \\nY Do we know how to retain our best customers? How can we predict which \\ncustomers are more likely to leave us? \\n¥Y How can we sell more to our existing customers? Which of our customers \\nare more likely to buy more products or services from us? \\nV Do we have customers who are costing us money? \\nV Do we suspect fraudulent activities that need to be discovered? \\nData \\nV Is our data clean enough for data mining? \\nV Is the data understood? Will it be used and interpreted correctly? \\nV Is it coded properly for data mining? \\nV Is the data organized correctly for data mining? \\nData Mining Tool \\nv¥ What type of data mining tool is appropriate for our organization? \\nVv What type of criteria should we consider when we evaluate data mining \\ntools? \\nV How will we determine the return on investment (ROI) for a data mining \\ninitiative and a data mining tool? \\nStaffing \\nV Do we have statisticians or skilled analysts who can interpret the data min- \\ning results? \\n¥ Will we need to hire additional statisticians to perform data mining? \\n¥ Will a database administrator be available to create and load the data mining \\ndatabases? Will we need a database administrator full-time? Part-time? \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 336}, page_content='Defining Data Mining 303 \\nMany organizations have accumulated massive amounts of data in their \\noperational systems. This data constitutes a potential source of valuable business \\ninformation that can be mined. Analytical models can be generated to find pat- \\nterns in the data and to allow the information to be used for competitive advan- \\ntage. This gives the business managers and executives the information they need \\nin order to take action, enabling them to increase profits, reduce costs, create \\ninnovative product strategies, and expand market share. \\nDEFINING DATA MINING \\nData mining capability is not something you can buy off the shelf. Data mining \\nrequires building a BI decision-support application, specifically a data mining \\napplication, using a data mining tool. The data mining application can then use a \\nsophisticated blend of classical and advanced components like artificial intelli- \\ngence, pattern recognition, databases, traditional statistics, and graphics to \\npresent hidden relationships and patterns found in the organization’s data pool. \\nData mining is the analysis of data with the intent to discover gems of hidden \\ninformation in the vast quantity of data that has been captured in the normal \\ncourse of running the business. Data mining is different from conventional statis- \\ntical analysis, as indicated in Table 13.1. They both have strengths and weaknesses. \\nTable 13.1: Statistical Analysis versus Data Mining \\nStatistical Analysis Data Mining \\n* Statisticians usually start with a ¢ Data mining does not require a \\nhypothesis. hypothesis. \\n* Statisticians have to develop their own * Data mining algorithms can \\nequations to match their hypothesis. automatically develop the equations. \\n* Statistical analysis uses only numerical ¢ Data mining can use different types of \\ndata. data (e.g., text, voice), not just numerical \\ndata. \\n* Statisticians can find and filter dirty data +* Data mining depends on clean, well- \\nduring their analysis. documented data. \\na TRS 5 SSE I I LS ESTE ES = SRT EE BE EERE IS EE EEE ES EE BS LP I ERLISTE \\n(Continued) \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 337}, page_content='304 Step 13: Data Mining \\na A A RE ETS TE \\nTable 13.1: (Continued) \\nES EST I SE RARE SE SEL BS I PI SI ESE LE OG SER LEI IED TE LE ELOISE SLE IE LES OE, \\nStatistical Analysis Data Mining \\n* Data mining results are not easy to + Statisticians interpret their own results \\nand convey these results to the business \\nmanagers and business executives. \\ninterpret. A statistician must still be \\ninvolved in analyzing the data mining \\nresults and conveying the findings to the \\nbusiness managers and business \\nexecutives. \\nTables 13.2 and 13.3 use specific examples (insurance fraud and market seg- \\nmentation, respectively) to illustrate the differences between traditional analysis \\ntechniques and discovery-driven data mining. \\nTable 13.2: Example of Insurance Fraud Analysis \\nTraditional Analysis Technique \\n¢ An analyst notices a pattern of behavior \\nthat might indicate insurance fraud. \\nBased on this hypothesis, the analyst \\ncreates a set of queries to determine \\nwhether this observed behavior actually \\nconstitutes fraud. If the results are not \\nconclusive, the analyst starts over with a \\nmodified or new hypothesis and more \\nqueries. Not only is this process time- \\nconsuming, but it also depends on the \\nanalyst’s subjective interpretation of the \\nresults. More importantly, this process \\nwill not find any patterns of fraud that \\nthe analyst does not already suspect. \\nDiscovery-Driven Data Mining \\n* An analyst sets up the data mining \\napplication, then “trains” it to find all \\nunusual patterns, trends, or deviations \\nfrom the norm that might constitute \\ninsurance fraud. The data mining results \\nunearth various situations that the \\nanalyst can investigate further. For the \\nfollow-up investigation, the analyst can \\nthen use verification-driven queries. \\nTogether, these efforts can help the \\nanalyst build a model predicting which \\ncustomers or potential customers might \\ncommit fraud. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 338}, page_content='Defining Data Mining 305 \\nTable 13.3: Example of Market Segmentation Analysis \\nTraditional Analysis Technique Discovery-Driven Data Mining \\n* An analyst wants to study the buying * The data mining tool “studies” the \\nbehaviors of known classes of customers database using the clustering technique \\n(e.g., retired school teachers, young to identify all groups of customers with \\nurban professionals) in order to design distinct buying patterns. After the data is \\ntargeted marketing programs. First, the mined and the groupings are presented, \\nanalyst uses known characteristics about the analyst can use various query, \\nthose classes of customers and tries to reporting, and multidimensional analysis \\nsort them into groups. Second, he or she tools to analyze the results. \\nstudies the buying behaviors common to \\neach group. The analyst repeats this \\nprocess until he or she is satisfied with \\nthe final customer groupings. \\nThe Importance of Data Mining \\nDiscovery-driven data mining finds answers to questions that decision-makers \\ndo not know to ask. Because of this powerful capability, data mining is an impor- \\ntant component of business intelligence. One may even say that data mining, also \\ncalled knowledge discovery, is a breakthrough in providing business intelligence to \\nstrategic decision-makers. At first glance, this claim may seem excessive. After all, \\nmany current decision-support applications provide business intelligence and \\ninsights. \\n* Executive information systems (EISs) enable senior managers to monitor, \\nexamine, and change many aspects of their business operations. \\n* Query and reporting tools give business analysts the ability to investigate \\ncompany performance and customer behavior. \\n* Statistical tools enable statisticians to perform sophisticated studies of the \\nbehavior of a business. \\n* New multidimensional online analytical processing (OLAP) tools deliver the \\nability to perform “what if” analysis and to look at a large number of interde- \\npendent factors involved in a business problem. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 339}, page_content='306 Step 13: Data Mining \\nMany of these tools work with BI applications and can sift through vast \\namounts of data. Given this abundance of tools, what is so different about discov- \\nery-driven data mining? The big difference is that traditional analysis techniques, \\neven sophisticated ones, rely on the analyst to know what to look for in the data. \\nThe analyst creates and runs queries based on some hypotheses and guesses \\nabout possible relationships, trends, and correlations thought to be present in the \\ndata. Similarly, the executive relies on the business views built into the EIS tool, \\nwhich can examine only the factors the tool is programmed to review. As prob- \\nlems become more complex and involve more variables to analyze, these tradi- \\ntional analysis techniques can fall short. In contrast, discovery-driven data \\nmining supports very subtle and complex investigations. \\nData Sources for Data Mining \\nBI target databases are popular sources for data mining applications. They con- \\ntain a wealth of internal data that was gathered and consolidated across business \\nboundaries, validated, and cleansed in the extract/transform/load (ETL) process. \\nBI target databases may also contain valuable external data, such as regulations, \\ndemographics, or geographic information. Combining external data with inter- \\nnal organizational data offers a splendid foundation for data mining. \\nThe drawback of multidimensional BI target databases is that since the data \\nhas been summarized, hidden data patterns, data relationships, and data associa- \\ntions are often no longer discernable from that data pool. For example, the data \\nmining tool may not be able to perform the common data mining task of market \\nbasket analysis (also called associations discovery, described in the next section) \\nbased on summarized sales data because some detailed data pattern about each \\nsale may have gotten lost in the summarization. Therefore, operational files and \\ndatabases are also popular sources for data mining applications, especially \\nbecause they contain transaction-level detailed data with a myriad of hidden data \\npatterns, data relationships, and data associations. \\nExercise caution with operational systems extracts because the data could \\ncontain many duplicates, inconsistencies, and errors and could skew the data \\nmining results. \\nData mining tools could theoretically access the operational databases and BI \\ntarget databases directly without building data mining databases first, as long as \\nthe database structures are supported by the tool (e.g., relational like Oracle, \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 340}, page_content='Data Mining Techniques 307 \\nhierarchical like IMS, or even a flat file like VSAM). However, this is not an advis- \\nable practice for several reasons. \\n* The data pool needs to be able to change for different data mining runs, such \\nas dropping a sales region or restricting a product type for a specific mining \\npurpose. Changing the data content of operational or BI target databases is \\nnot possible. \\n* The performance of operational as well as BI target databases would be \\nimpacted by the data mining operations. That is unacceptable for operational \\ndatabases and not desirable for BI target databases. \\n- A data mining operation may need detailed historical data. Operational data- \\nbases do not store historical data, and BI target databases often do not have \\nthe desired level of detail. Archival tapes may have to be restored and merged \\nto extract the desired data. \\nTherefore, organizations often extract data for data mining as needed from \\ntheir BI target databases and from their operational files and databases into special- \\npurpose data mining databases (Figure 13.1). \\nDATA MINING TECHNIQUES \\nData mining techniques are specific implementations of algorithms used in data \\nmining operations. The five most common data mining techniques are described \\nbriefly below. \\nAssociations Discovery \\nThis data mining technique is used to identify the behavior of specific events or \\nprocesses. Associations discovery links occurrences within a single event. An \\nexample might be the discovery that men who purchase premium brands of cof- \\nfee are three times more likely to buy imported cigars than men who buy stan- \\ndard brands of coffee. Associations discovery is based on rules that follow this \\ngeneral form: “If item A is part of an event, then X percent of the time (confi- \\ndence factor), item B is part of the same event.” For example: \\n- If a customer buys snacks, there is an 85 percent probability that the cus- \\ntomer will also buy soft drinks or beer. \\n- If a person buys vacation airline tickets for an entire family, there is a 95 per- \\ncent probability that he or she will rent a full-size car at the vacation location. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 341}, page_content='308 Step 13: Data Mining \\nOperational Databases BI Target Databases \\nEnterprise \\nData Warehouse \\nCustomer \\nData Mart \\ns \\nT \\nAccount \\nMaster \\nSales \\nData Mart \\nDatabases \\nLS Data Mining Applications 5 \\nFigure 13.1: Data Sources for Data Mining Applications \\nWith the help of scanners, retail stores use this data mining technique to find \\nbuying patterns in grocery stores. Because of the context of a grocery store, asso- \\nciations discovery is sometimes called market basket analysis. \\nSequential Pattern Discovery \\nThis data mining technique is similar to associations discovery except that a \\nsequential pattern discovery links events over time and determines how items \\nrelate to each other over time. For example, sequential pattern discovery might \\npredict that a person who buys a washing machine may also buy a clothes dryer \\nwithin six months with a probability of 0.7. To increase the chances above the \\npredicted 70 percent probability, the store may offer each buyer a 10 percent dis- \\ncount on a clothes dryer within four months after purchasing a washing machine. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 342}, page_content='Data Mining Techniques 309 \\nClassification \\nThe classification technique is the most common use of data mining. Classifica- \\ntion looks at the behavior and attributes of predetermined groups. The groups \\nmight include frequent flyers, high spenders, loyal customers, people who \\nrespond to direct mail campaigns, or people with frequent back problems (e.g., \\npeople who drive long distances every day). The data mining tool can assign clas- \\nsifications to new data by examining existing data that has already been classified \\nand by using those results to infer a set of rules. The set of rules is then applied to \\nany new data to be classified. This technique often uses supervised induction, \\nwhich employs a small training set of already classified records to determine \\nadditional classifications. An example of this use is to discover the characteristics \\nof customers who are (or are not) likely to buy a certain type of product. This \\nknowledge would result in reducing the costs of promotions and direct mailings. \\nClustering \\nThe clustering technique is used to discover different groupings within the data. \\nClustering is similar to classification except that no groups have yet been defined \\nat the outset of running the data mining tool. The clustering technique often uses \\nneural networks or statistical methods. Clustering divides items into groups \\nbased on the similarities the data mining tool finds. Within a cluster the members \\nare very similar, but the clusters themselves are very dissimilar. Clustering is used \\nfor problems such as detecting manufacturing defects or finding affinity groups \\nfor credit cards. \\nForecasting \\nThe forecasting data mining technique comes in two flavors: regression analysis \\nand time sequence discovery. \\n* Regression analysis uses known values of data to predict future values or \\nfuture events based on historical trends and statistics. For example, the sales \\nvolume of sports car accessories can be forecasted based on the number of \\nsports cars sold last month. \\n- Time sequence discovery differs from regression analysis in that it forecasts \\nonly time-dependent data values. For example, it determines the rates of acci- \\ndents during a holiday season based on the number of accidents that occurred \\nduring the same holiday season in prior years. The property of time can be: \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 343}, page_content='310 Step 13: Data Mining \\n— Work week versus calendar week \\n— Holidays \\n— Seasons \\n— Date ranges and date intervals \\nDATA MINING OPERATIONS \\nData mining tools enable statisticians to build analytical models, which the tools \\nthen use during data mining operations. A predictive engine asks for a list of \\ninput criteria and follows the steps and relationships from the analytical model to \\ndetermine the most likely predictions. The results of data mining operations are \\ntables and files loaded with analysis data that can be accessed with query and \\nreporting tools. The four main data mining operations are described below. \\nPredictive and Classification Modeling \\nThis data mining operation is used to forecast a particular event. It assumes that \\nthe analyst has a specific question he or she wants to ask. The model provides the \\nanswer by assigning ranks that indicate the likelihood of certain classes. For \\nexample, if a bank analyst wants to predict which customers are likely to leave, he \\nor she has to prepare for predictive modeling by feeding data about two types of \\ncustomers into the data mining tool. \\n1. Customer data that indicates which customers have already left. This data is \\ncalled “bad” data. \\n2. Customer data that indicates which customers stayed and are long-time cus- \\ntomers. This data is called “good” data. \\nThe tool then sifts through the data to uncover the variables that identify \\nclasses of profiles of typical customers who leave and classes of profiles of typical \\ncustomers who stay. The analysis results might be, “A female customer over 40 \\nyears of age who has an income greater than $150,000 per year and owns her own \\nhome has a 35 percent chance of leaving the bank.” \\nTypical probing questions for predictive data mining are those that look for \\nassociations, patterns, trends, and facts in order to make decisions. For example: \\n* Which offers will prompt customers to buy more? (Trend) \\n* Which customers should be targeted for a new product? (Association) \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 344}, page_content='Applications of Data Mining 311 \\n* What are the signs of fraudulent activity? (Pattern) \\n* Which customers are better credit risks? (Fact) \\nLink Analysis \\nThe link analysis data mining operation is a collection of mathematical algo- \\nrithms and visualization techniques that identify and visually present links \\nbetween individual records in a database. It is related to the associations discov- \\nery and sequential pattern discovery data mining techniques. For example, link \\nanalysis can determine which items usually sell together (e.g., cereal and milk). \\nDatabase Segmentation \\nThis data mining operation is a set of algorithms that group similar records into \\nhomogeneous segments. It is related to the clustering data mining technique. \\nThis grouping is often the first step of data selection, before other data mining \\noperations take place. For example, database segmentation may group airline \\npassengers as either frequent flyer passengers or occasional passengers. \\nDeviation Detection \\nThe deviation detection data mining operation is a set of algorithms that look for \\nrecords that fall outside some expectation or norm and then suggest reasons for \\nthe anomalies. While deviation detection is mainly used for fraud detection, \\nother uses include tracing the potential reasons for declines in customer numbers \\nor sales. For example, “Customers who used to make frequent purchases but have \\nnot purchased anything in a long time were either transferred by their companies \\nor have moved away from the area.” \\nAPPLICATIONS OF DATA MINING \\nIt is important to keep in mind that in spite of all the dazzling technologies, data \\nmining has to be driven by strong business needs in order to justify the expendi- \\nture of time and money. One of the common business drivers for engaging in \\ndata mining is to gain market share. This can be accomplished by either intro- \\nducing new products or by taking away market share from competitors. In either \\ncase, a data mining application can help you decide how best to achieve your \\ngoals. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 345}, page_content='312 Step 13: Data Mining \\nThere are many types of data mining applications. The five most common \\nones are briefly described below. \\n* Market management \\n— Cross-selling: Identify cross-selling opportunities among existing custom- \\ners, who are likely to buy as a result of direct mail campaigns and promo- \\ntions (and thus minimize selling costs). \\n— Defecting customers: Determine which customers are likely to switch brands \\nby using vulnerability analysis that creates a predictive model of behavior, \\nso that the company can craft strategies to retain these customers. \\n— Promotions and campaigns: Distinguish natural groupings in the market, \\nsuch as key sales periods for given items, by performing market segmenta- \\ntion analysis as a way to fine-tune promotions and campaigns. \\n— Prospecting: Classify groups of prospects in order to find ways to perform \\ntarget marketing for each group. \\n— Market basket analysis: Evaluate which items people buy together during a \\nvisit to a supermarket or store, using market basket analysis on point-of- \\nsale data. Then use the information to group products in store displays, to \\nadjust inventory, and to price and promote items. \\n¢ Fraud detection \\n— Credit card fraud: Isolate credit card fraud by identifying meaningful pat- \\nterns of transactions as well as deviations from those patterns. Use this \\nmodel to predict an applicant’s trustworthiness. \\n— Calling card fraud: Determine telephone calling card situations that look \\nsuspicious and are likely to indicate fraud. \\n— Insurance fraud: Analyze large data pools of insurance claims to identify \\npossible fraud related to health insurance, car insurance, or property and \\ncasualty insurance. \\n* Risk management \\n— Credit risk: Assess the credit risk of potential loan applicants based on a \\npredictive model of the database that looks for reasons and patterns affect- \\ning risk. \\n— Quality control: Find patterns of quality problems on assembly lines to help \\nreduce the number of products returned due to substandard quality. \\n* Financial services \\n— Customer retention: Identify loyal bank customers who have many high- \\nbalance accounts and provide each of them a personalized fee structure. It \\nis much cheaper to retain existing customers than to acquire new ones. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 346}, page_content='Data Mining Activities 313 \\n— Stock performance: Develop models of stock performance to aid portfolio \\nmanagement. Look for stocks that have performed in ways similar to cer- \\ntain high-performing securities. \\n* Distribution \\n— Inventory control: Improve inventory control and distribution by develop- \\ning predictive models of which products or parts will be needed at various \\ndistribution points at various points in time. \\nOne good indication of the value of data mining is the secrecy that surrounds \\nits implementations. Many of the companies that have implemented data mining \\nhesitate to talk about their successes. Some will not even confirm that they use \\nthis technology. \\nDATA MINING ACTIVITIES \\nThe activities for data mining do not need to be performed linearly. Figure 13.2 \\nindicates which activities can be performed concurrently. The list below briefly \\ndescribes the activities associated with Step 13, Data Mining. \\n1 es ae \\nState \\nbusiness problem \\nPrepare \\ndata \\nCollect \\ndata \\nConsolidate and \\ncleanse data \\nBuild analytical \\ndata model \\nSs 7 Lie \\nPerform external \\nvalidation of results \\nInterpret \\ndata mining results \\nMonitor analytical \\ndata model over time \\nFigure 13.2: Data Mining Activities \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 347}, page_content='314 Step 13: Data Mining \\nrc en SS RL LEE SE ES ES SE SE SES TT I \\n1. State the business problem. \\nSet goals before starting the data mining efforts, and prioritize the goals (such \\nas increase profits, reduce costs, create innovative product strategies, or \\nexpand the market share). Time and money have to be invested in order to \\nreach any of these goals. There also needs to be a commitment from manage- \\nment to implement a data mining solution at the organization. \\n2. Collect the data. \\nOne of the most time-consuming activities of data mining is the collection of \\nthe appropriate types and quantities of data. In order to have correct repre- \\nsentation, first identify all the data needed for analysis. This includes data \\nstored in the operational databases, data from the BI target databases, and \\nany external data that will have to be included. Once you have identified the \\nsource data, extract all pertinent data elements from these various internal \\nand external data sources. \\n3. Consolidate and cleanse the data. \\nRedundantly stored data is more of a norm than an exception in most organi- \\nzations. Therefore, the data from the various sources has to be consolidated and \\ncleansed. If the internal data is to be supplemented by acquired external data, \\nmatch the external data to the internal data, and determine the correct content. \\n4, Prepare the data. \\nBefore building an analytical data model, you need to prepare the data. Part \\nof data preparation is the classification of variables. The variables could be \\ndiscrete or continuous, qualitative or quantitative. Eliminate variables with \\nmissing values or replace them with most likely values. It provides great \\ninsight to know the maximum, minimum, average, mean, median, and mode \\nvalues for quantitative variables. In order to streamline the preparation pro- \\ncess, consider applying data reduction transformations. The objective of data \\nreduction is to combine several variables into one in order to keep the result \\nset manageable for analysis. For example, combine education level, income, \\nmarital status, and ZIP code into one profile variable. \\n5. Build the analytical data model. \\nOne of the most important activities of data mining is to build the analytical \\ndata model. An analytical data model represents a structure of consolidated, \\nintegrated, and time-dependent data that was selected and preprocessed from \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 348}, page_content='Deliverables Resulting from These Activities 315 \\nvarious internal and external data sources. Once implemented, this model \\nmust be able to continue “learning” while it is repeatedly used by the data \\nmining tool and tuned by the data mining expert. \\n6. Interpret the data mining results. \\nOnce the data mining operations are run and results are produced, the next \\nmajor task is to interpret the results. Important things to consider during this \\ninterpretation are how easily the results can be acted upon and whether the \\nresults can be presented to business executives in a convincing, business-ori- \\nented way. \\n7. Perform external validation of the results. \\nCompare your results with published industry statistics. Identify the devia- \\ntions from those statistics and determine the reasons for the deviations. Be \\nsure you are using updated industry statistics since they change from time to \\ntime. Compare the selection criteria of your data to that of the industry sta- \\ntistics, and compare the time frame during which your data was selected to \\nthe time frame covered by the industry statistics. The selection criteria and \\ntime frame of your model and of the industry statistics must be similar. \\n8. Monitor the analytical data model over time. \\nIndustry statistics are usually established by using very large samples. It is \\nimportant to validate your analytical data model against industry statistics at \\nregular intervals. Industry statistics change over time, and some industries \\nhave seasonal changes. In that case, adjust your internal analytical model. \\nDELIVERABLES RESULTING FROM THESE ACTIVITIES \\n1. Data mining database \\nThe data mining database is designed and built for a specific analytical data \\nmodel and a specific set of data mining operations. This database will be pop- \\nulated with data from either an operational system, a BI target database, or a \\ncombination of both. \\n2. Analytical data model \\nThe analytical data model is developed and tested so it can be used by the \\nalgorithms of the data mining operations in the data mining tool. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 349}, page_content='316 Step 13: Data Mining \\nROLES INVOLVED IN THESE ACTIVITIES \\n® Business representative \\nIn the end, it is the business representative (or his or her management) who \\nwill benefit from the results of data mining. Therefore, the business represen- \\ntative has to work very closely with the data mining expert (unless the busi- \\nness representative on this BI application is the data mining expert) in order to \\nunderstand and interpret the data mining results. \\n® Data mining expert \\nThe data mining expert is a statistician who really knows the data and is famil- \\niar with the data mining techniques. He or she is usually responsible for select- \\ning the most appropriate data mining tool for the organization. He or she is \\nalso the primary person who builds the analytical data model and analyzes the \\ndata mining results. \\n@ Database administrator \\nThe database administrator must have a good understanding of the data con- \\ntent in order to design the data mining databases for the data mining activi- \\nties. He or she works very closely with the data mining expert. \\n@ Subject matter expert \\nThe subject matter expert can help analyze, define, cleanse, and prepare the \\nsource data for the data mining databases. He or she will work under the \\ndirection of the data mining expert. \\nRISKS OF NOT PERFORMING STEP 13 \\nMost organizations are sitting on top of a gold mine—the “gold” being all the \\ndata collected about their customers and the products their customers buy. \\nEmbedded in this data is information about their customers’ spending styles, \\nlikes and dislikes, and buying habits. This data is a wasted resource if it is not \\nmined to expose the hidden business intelligence. In addition, executive manage- \\nment must take notice of data mining performed by competitors. If the competi- \\ntors end up increasing their profits, reducing their costs, creating more innovative \\nproduct strategies, and expanding their market shares, the organization may lose \\ncustomers at a very quick rate, which may put its survival in jeopardy. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 350}, page_content='Bibliography and Additional Reading 317 \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nAbramowicz, Witold, and Jozef Zurada. Knowledge Discovery for Business Intelli- \\ngence Systems. Kluwer Academic Publications, 2000. \\nBajaj, Chandrajit. Trends in Software: Data Visualization Techniques. New York: \\nJohn Wiley & Sons, 1999. \\nBashein, Barbara, and M. Lynne Markus. Data Warehouse: More Than Just Min- \\ning. Morristown, NJ: Financial Executives Research Foundation, 2000. \\nBerson, Alex, and Stephen J. Smith. Data Warehousing, Data Mining, and OLAP. \\nNew York: McGraw-Hill, 1997. \\nBerson, Alex, Stephen Smith, and Kurt Thearling. Building Data Mining Applica- \\ntions for CRM. New York: McGraw-Hill, 1999. \\nCabena, Peter, Pablo Hadjinian, Rolf Stadler, Jaap Verhees, and Alessandro \\nZanasi. Discovering Data Mining: From Concept to Implementation. Upper Saddle \\nRiver, NJ: Prentice Hall, 1997. \\nEdelstein, Herb. Introduction to Data Mining and Knowledge Discovery. Potomac, \\nMD: Two Crows Corporation, 1998. \\n. Data Mining: Products and Markets. Potomac, MD: Two Crows Corpora- \\ntion, 1997. \\nKudyba, Stephan, and Richard Hoptroff. Data Mining and Business Intelligence. \\nIdea Group Publishing, 2001. \\nCRoss Industry Standard Process for Data Mining: http://www.crisp-dm.org \\nData Management Association: http://www.dama.org \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 351}, page_content='oe \\nviertarso © ah 6 omit petal uty. with mele git Tip iene ha (eapenndel (y \\neee a \\na \\nWa 9 away we Thom aw a Seana ois aie \\n© hase lenancniny!t Sarewlinitl ight ont? ehetic, Togs Sine sblonet & \\n(Vhs Gab 4 © @> feeb \\\\) MINH emmitileoh chee de \\nvol sist sntauinial santana Vee en Seer whe _ aety writs i ie o Truesirag, rer, \\naOR ae Nie id ty eek ore it area ei URN at rt Naina LUT UA lekaevanetl A aaa \\natt Areniodirenté iat ltt sk tA i | fea See ‘ i\" be i i ae S jie v ae afy « Cid & OF 2) pete 4 ae 104 \\nams feyily em, Fr D @ HN, pees 4“ \\nvin harper) pers a ‘ af oni Mies ion \\nmaak inate) jl, salaliteh horn \\notis ait vl ul > aietnias Luria fond ao \\n~ \\nVivi (BO ikaew «ine inte, | ips SOW ry smu rect postion \\n| MINT Nee ge moh ben and ae!) yt einen Boh, 176 Pie Al dat Wee he 4c ee pissed ivi’ et nite pls Core \\nSOP bt 26) AIM grace ani nid, hie erative t ey — 7 \\n“The mage | Night te expe) ser Be we isha, ih? es, chee mht pr iF \\nsasielwabvasianste bate - nh ey) Pe ee, ae \\nemiGa Dalle @. te! OW? isi Log i PONY, Spa ot “uo \\n: \\n=) - \\n— \\nere ania ves henynnea ane 1? éeoceerrs beraibrset? vane baal a \\nok be RL ae be eiqel wantin areaerveguildl eit a \\nOe ed) | fy. Conantn w Ld isveas “put being a a ats csibligr yee! aw Ow eSiiehieyy OA 4 if pirwe he r wey sealer \\nPevtontel\\' Pr ty (9 pools ree idiepaai I; camry & \\nee J uyene lishite ile are Rb eanel prevopa if \\nTHD 6 WEES 1M Hight aw lite lige iia Ieper, \\nyee Qed Like iler of ad ONY partes ited ey ae sdinets i ep \\noul Vp imatrrving hott. tetlipding GO rerte Seeing, : \\nvale ait Gomd: 0 peeing Geo (Gore cleprm, the \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 352}, page_content='Step 14: Meta Data \\nRepository Development Planning \\nCHAPTER OVERVIEW \\nThis chapter covers the following topics: Business Analysis | \\nm@ Things to consider about meta data repository \\ndevelopment \\nm@ The many potential sources of meta data and the differ- \\nence between active and passive meta data repositories \\n\\\\ m@ The need to develop two types of meta data repository \\nS y | interface processes: a tool interface process and an access \\nDesign We interface process \\nThe four types of testing that apply to meta data repository \\ndevelopment: unit testing, integration testing, regression \\ntesting, and acceptance testing \\n@ Six activities to perform before the meta data repository \\ngoes into production \\n@ How to organize a directory for the meta data repository \\nek \\n14 \\nMeta Data \\nRepository | \\nDevelopment , \\n@ Brief descriptions of the activities involved in meta data \\nrepository development, the deliverables resulting from \\nthose activities, and the roles involved \\n@ The risks of not performing Step 14 \\n319 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 353}, page_content='320 Step 14: Meta Data Repository Development \\nTHINGS TO CONSIDER \\nMeta Data Repository Product Support \\n¥ What interfaces are required for the meta data repository product? \\nY Will we need to contact the meta data repository vendor for assistance with \\nwriting these interfaces? \\nY Do we expect any problems with extracting meta data from the tools that \\noriginate it (e.g., computer-aided software [CASE] tool, extract/transform/ \\nload [ETL] tool, or online analytical processing [OLAP] tool)? Do we know \\nif other companies experienced any problems? \\n¥ Will we need to contact the tool vendors and ask for their assistance? \\n/Y Can we embellish the meta data reports that are provided with the meta data \\nrepository product? \\nVY Does the meta data repository product have a context-sensitive online help \\nfunction? \\nCustom-Built Meta Data Repository \\nV Is our meta data repository design flexible enough to be expanded in the \\nfuture? \\nV Do we need to build a meta data repository directory as part of the access \\ninterface for the business people and for the technicians? \\nY Do we need to build a context-sensitive online help function for the meta \\ndata repository? \\nVY Do we need to write meta data reports? How will we distribute them? On \\npaper? On the intranet? \\n¥ Will meta data be integrated with the queries and reports of the BI applica- \\ntion? What type of process do we have to build to support that? \\nV How can we ensure that the meta data in the meta data repository does not \\nget out of synch with the meta data in the other tools and the database man- \\nagement system (DBMS)? \\nStaffing \\n¥Y How much can we modularize the coding and testing? Do we have enough \\ndevelopers and testers to speed up the development effort? \\n¥ Will the same developers work on the meta data repository online help func- \\ntion? Or can we develop the help function in parallel? \\n¥ Will we have full-time or part-time support from the database administra- \\ntor? Will the same database administrator support the BI target databases? \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 354}, page_content='Populating the Meta Data Repository 321 \\n¥Y Who will continue to maintain the meta data repository? Do we have a full- \\ntime meta data administrator? Is one person enough? \\nV Are there any special training needs we have to consider? For the developers? \\nFor the business people? \\nPreparation for Production \\n¥ Will the production meta data repository be installed on a dedicated pro- \\nduction server? Who will install and test the server? \\nV Do we need to set up any regularly scheduled meta data repository programs \\non the job scheduler? Will the operations staff run and monitor them? \\nVv Do we need to write operating procedures for the operations staff? \\nV Do we need to write a reference guide for the help desk staff and for the busi- \\nness people? \\nTo navigate through the BI decision-support environment more efficiently, \\nbusiness people must have access to a meta data repository. There are only two \\noptions: license (buy) a meta data repository or build one. Once a meta data \\nrepository is implemented, it has to be maintained and expanded over time. It \\nalso has to be populated and updated during each ETL process cycle with load \\nstatistics, reconciliation totals, data reliability metrics, data rejection counts, and \\nthe reasons for the data rejections. \\nPOPULATING THE META DATA REPOSITORY \\nPopulating a meta data repository is usually not a manual effort. A meta data \\nrepository receives most of its meta data from many different meta data sources. \\nThese meta data sources are controlled by people other than the meta data \\nadministrator, as illustrated in Figure 14.1. A meta data migration process has to \\nbe developed to extract the meta data from these sources, associate (link) related \\nmeta data components, and populate the meta data repository. The different \\nsources for the meta data are briefly discussed below. \\n* Word processing files can be manuals, procedures, and other less formal docu- \\nments that contain data definitions and business rules. Embedded in these \\nbusiness rules could be policies about the data, processing rules, data \\ndomains (in code translation manuals), and sundry notes about the history \\nand ownership of the data or the processes performed on the data. Some \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 355}, page_content='322 Step 14: Meta Data Repository Development \\nTechnicians and Business Data Database ETL Lead Application Data Mining \\nBusiness People Analysts Administrator | Administrator Developer Lead Developer Expert \\nData Mining \\nTools DBMS \\nDictionaries — ror \\nMeta Data Migration Process \\n\\\\ \\nMeta Data \\nRepository \\nFigure 14.1: Sources for the Meta Data Repository \\nword processing files also contain valuable technical documentation describ- \\ning data and process rules enforced by programs. \\nPaw Be cautious with word processing files. These files are rarely maintained, \\nand the information contained in them could be out of date and no longer \\napplicable. ; \\nSpreadsheets contain calculations and macros, which are executed on the data \\nin the private spreadsheets of business analysts after they have downloaded \\nthe data from the various operational systems. These calculations and macros \\ncould be the source for transformation rules, cleansing rules, derivations, \\naggregations, and summarizations. \\nCASE tools contain the names, definitions, sizes, lengths, relationships, cardi- \\nnality information, referential integrity rules, and notes about data that has \\nbeen modeled either for an operational system or for a BI application. In \\naddition, CASE tools usually can store the technical names of tables and col- \\numns, as well as primary keys and foreign keys. Some of the more sophisti- \\ncated CASE tools have modules to include meta data for process components, \\nsuch as programs, screen displays, and report layouts. \\n* Internal DBMS dictionaries are an integral part of all DBMSs since the dictio- \\nnaries control the database structures. In relational databases, these are usually \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 356}, page_content='Populating the Meta Data Repository 323 \\ncalled SYSTABLES, and they store the names, definitions, sizes, lengths, rela- \\ntionships, and volumes of database structures, such as storage groups, \\ntablespaces, tables, columns, primary keys, foreign keys, and indices. \\n* ETL tools would not function without instructions (technical meta data) for \\nthe required transformations. The internal dictionaries of ETL tools store the \\nsource-to-target mapping as well as all the transformation algorithms, which \\nare applied to the source data during the ETL process. \\n* OLAP tools store specifications about data derivations (calculations), aggre- \\ngations, and summarizations in their internal directories. These specifica- \\ntions allow the OLAP tool to perform its drill-down and roll-up functions. \\nSome OLAP products have the capability to drill across into another database \\nunder the same DBMS or even into another database under a different DBMS \\nto extract detailed data for a query. \\n* Data mining tools store the descriptions of the analytical data models against \\nwhich the data mining operations are executed. \\nIf any meta data contained in these meta data sources is about to change, the \\nmeta data administrator must be notified before the change occurs. He or she will \\nthen have to determine whether the meta data repository can accommodate that \\nchange or whether the meta data repository has to be modified or enhanced. \\nTherefore, in order to maintain a healthy and useful meta data repository, the \\nmeta data administrator must collaborate with the ETL team, the OLAP team, \\nthe data mining expert, the data administrator, the database administrator, and \\nthe business people on the BI projects. In addition, and more importantly, the \\nmeta data administrator must have full cooperation from the operational systems \\npeople who maintain the operational source files and source databases. \\nChanges made to operational source systems are frequently not communi- \\ncated to the meta data administrator in time to make the necessary changes \\nto the meta data repository. Because these changes also affect the ETL pro- \\ncess, and in some cases the structures of the BI target databases, the ETL team \\nis also impacted. This breakdown in communication between the operational \\nsystems people and the BI decision-support staff can cause severe delays. \\nIdeally, meta data repositories should be active repositories, similar to the \\nDBMS dictionaries. In an active meta data repository, changes would be made \\nonly to the meta data repository, and the meta data repository would propagate \\nthe changes into the appropriate target tool or DBMS. However, currently the \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 357}, page_content='324 Step 14: Meta Data Repository Development \\nmeta data repository products on the market are still passive repositories. That \\nmeans changes must be made both to the meta data repository and to the appro- \\npriate target tool or DBMS, and these changes must be kept synchronized, either \\nmanually or with programs. \\nMETA DATA REPOSITORY INTERFACE PROCESSES \\nEvery meta data repository must have two interfaces in order to function: a tool \\ninterface to accept meta data from other tools and an access interface to interact \\nwith business people and technicians. If the meta data repository is built in-house, \\nthe processes to provide both types of interfaces must be developed (Figure 14.2). \\nIf a meta data repository product is licensed, the access interface will be provided \\nas part of the product, but a tool interface process must still be developed. \\nThe Tool Interface Process \\nMost of the business meta data and the technical meta data is not entered directly \\ninto the meta data repository but is extracted from the tools that capture it and \\nuse it to support their own functionality. In order to exchange this meta data, the \\nmeta data repository and the tools where the meta data originates need to com- \\nInterface S~ im Business Analyst \\nMeta Data \\nRepository \\nAW g | 2 2 \\nTool Interface Process Access Interface Process \\nBusiness Manager \\nFigure 14.2: Meta Data Repository Interface Processes \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 358}, page_content='Meta Data Repository Interface Processes 325 \\nmunicate with each other using common meta data standards. Unfortunately, \\nthese tools do not interact with each other very well outside of rudimentary \\nimport and export capabilities, and common meta data standards have not yet \\nbeen agreed upon and ratified by the meta data repository vendors. Therefore, it \\nis necessary to develop a tool interface process with several interface programs to \\nextract the meta data from the various tools. \\nMeta data repository vendors are recognizing the lack of tool integration as a \\nproblem, and meta data standards are being debated by two authoritative groups: \\nthe Meta Data Coalition (MDC, influenced by Microsoft) and the Object Man- \\nagement Group (OMG, influenced by Oracle). At this time it is unclear which \\nmeta data standards will be adopted as the industry standards. \\nThe Access Interface Process \\nA meta data repository must also have a common access interface for the people \\nwho need to access it. Business people and technicians will want to retrieve infor- \\nmation (meta data) about the business data in the BI target databases, the load \\nstatistics from the ETL processes, and other process-related meta data. Because \\nbusiness people and technicians may have different requirements, some access \\ninterface screens and programs may have to be designed slightly differently for \\nthese two constituencies. Technicians and “power users” may also get authoriza- \\ntion to access the meta data repository directly without going through the access \\ninterface. \\nIf you have only one centralized meta data repository, building a common \\naccess interface process for it seems like an obvious requirement and relatively \\neasy to do. But if you are implementing a decentralized meta data repository \\nsolution, or even a distributed one, building a common access interface process \\nto all meta data repositories or tools may not be such an obvious requirement. It \\nis definitely a lot harder to build a common access interface process for a decen- \\ntralized or distributed meta data repository—with or without the help of Exten- \\nsible Markup Language (XML). However, without that common access interface, \\neverybody who wants to access meta data from multiple meta data repositories or \\ntools would have to learn to use a different access interface for every meta data \\nrepository and tool. To avoid having to use multiple access interfaces, business \\npeople may well end up insisting on duplicating common meta data into their \\nown “preferred” repositories. This can rapidly lead to redundant meta data \\nrepository silos, which is precisely what must be avoided. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 359}, page_content='326 Step 14: Meta Data Repository Development \\nMETA DATA REPOSITORY TESTING \\nDeveloping a meta data repository can be as complicated as developing any other \\napplication. Therefore, the same structured development guidelines should be \\nfollowed, particularly the testing guidelines. \\nWhile most business managers and information technology (IT) managers \\ndemand quality in their applications, they often do not want to spend much time \\non testing. That does not work! In addition, many project managers constantly \\nunderestimate how long testing will take, and they do not allocate sufficient time \\nfor testing in the project plan. What is worse, when milestones are missed, the \\nshort time originally planned for testing is reduced further. \\nThe point is that you must schedule sufficient time for meta data repository \\ntesting and reflect it in the project plan. In addition, plan to have a sufficient \\nnumber of testers available at the appropriate time. Fortunately, testing is one of \\nthe few activities that can easily be modularized, and adding more testers will \\nspeed up the testing effort. \\nExperience has shown that for every day of coding, you should plan three \\ndays of testing. \\nOf the various types of testing discussed in Step 11, ETL Development (unit \\ntesting, integration testing, regression testing, performance testing, quality assur- \\nance [QA] testing, and acceptance testing), only four types of testing are usually \\nrequired for a meta data repository, as shown in Table 14.1. \\n* Unit testing for meta data repository programs is no different from unit test- \\ning for other types of application programs. The programs must compile \\nwithout error; they must perform their functions according to the program \\nspecifications; and they must include the appropriate edit checks. \\nTable 14.1: Required Testing for a Meta Data Repository \\nUnit testing Does the code compile without errors? \\nIntegration testing Do the deliverables meet the requirements? \\nRegression testing Did the changes to the program cause damage to this or any \\nother program? \\nAcceptance testing Are all aspects of the deliverable acceptable? \\nalee \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 360}, page_content='Preparing for the Meta Data Repository Rollout 327 \\nIntegration testing, sometimes referred to as system testing, verifies that the \\noriginal objectives of the meta data application are being met and that all \\nmeta data repository functions perform as expected. Integration testing \\nshould include the initial population of the meta data repository, periodic or \\nintermittent updates to it, the access interface process, the tool interface pro- \\ncess, scheduled reports, canned queries, and the online help function. This \\ntest is carried out according to a test plan (described in Step 11, ETL Develop- \\nment), and the test cases are run by testers rather than by the developers of \\nthe code. (Developers can test other developers’ code, just not their own.) \\nRegression testing is performed on different versions of the same software, \\nwhich can be produced during the development cycle within one project or \\nwhen the same software is revised during different subsequent projects. Each \\ntime changes are made anywhere in the existing programs, a full regression \\ntest cycle should be run to ensure that the changes did not inadvertently \\nbreak some programming logic downstream in the program or somewhere in \\nthe entire stream of programs. Regression testing is a formal test activity and \\nmust be performed with a test plan. Since a complete meta data repository \\nwill probably not be built all at once but over time, regression testing is an \\nimportant part of all projects that enhance the meta data repository. \\nAcceptance testing is even more important than the other forms of testing. \\nThis test determines whether the meta data repository (new or enhanced) is \\nready to be rolled out. This final testing process for the meta data repository \\nusually combines QA testing and acceptance testing. The business people and \\nthe technicians who will be using and supporting the meta data repository \\nare involved in this testing. Similar to integration testing and regression test- \\ning, this test is executed with a test plan, predefined test cases, and expected \\ntest results; all test runs are documented in the test log. \\nPREPARING FOR THE META DATA REPOSITORY ROLLOUT \\nMoving a meta data repository into production requires preparation, as shown in \\nFigure 14.3. This preparation should start early, not when all the coding and test- \\ning have been completed. Novice meta data repository teams often underestimate \\nthe time it takes to prepare the basic aspects of the production environment out- \\nlined below. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 361}, page_content='328 Step 14: Meta Data Repository Development \\nProgram Instruction Guides \\nand Query and Manuals \\nLibraries \\nRepository \\nMeta Data \\nProduction Server Meta Data \\nDBMS Platform Repository Training \\nFigure 14.3: Preparation for Meta Data Repository Rollout \\nServer platform: The meta data repository should reside on a production \\nserver and not on the development server. Therefore, the production server \\nplatform has to be installed and tested, which includes the hardware compo- \\nnents, operating system, monitoring utilities, and network connectivity. \\nProduction DBMS: If the meta data repository is installed on a new produc- \\ntion server, an instance of the DBMS has to be created, and parameters for it \\nhave to be set and tested under the operating system. If a meta data repository \\nproduct is being licensed, all product components including the meta data \\nrepository database have to be installed and tested on the production server. \\nProgram and query libraries: All meta data migration programs (including the \\ntool interface programs) and all meta data application programs (including \\nthe access interface programs, the online help function, the reports, and the \\nqueries) will reside in a version-controlled library. A library management \\nproduct has to be installed and tested before the meta data repository pro- \\ngrams can be moved into production. \\nSecurity: The production server, the DBMS product, the meta data repository \\ndatabase, and all programs need to have the proper levels of security imple- \\nmented. Security levels in a production environment are much stricter than \\nin the development environment. Developers who could change the meta \\ndata repository database structures and its content at will in the development \\nenvironment should not be granted the same authority in the production \\nenvironment. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 362}, page_content='Preparing for the Meta Data Repository Rollout 329 \\n* Instruction guides and manuals: Once the meta data repository is in produc- \\ntion, some of the meta data programs will be scheduled to run automatically \\nwith every ETL process cycle to capture the load statistics and data quality \\nmetrics and to load them into the meta data repository. Certain reports or \\nqueries may also be put on a schedule. \\nOperations staff will monitor the scheduled runs and notify the meta data \\nadministrator if something goes wrong. Operating procedures should be pre- \\npared for them, listing the scheduled jobs, the order in which the jobs should \\nbe run, and what to do if a job fails. The help desk staff will mentor and sup- \\nport the business people with their meta data questions. Therefore, the help \\ndesk staff will need a reference guide to fall back on in case they get inquiries \\nthey need to investigate. This reference guide could also be given to business \\npeople since it contains helpful hints about where to locate specific meta data \\ncomponents and where to get additional help. \\nMeta data repository training: Business people and technicians need to be \\ntrained differently on how to use the meta data repository either through the \\naccess interface or directly and interactively. Business analysts need to know \\nhow to access the meta data repository to help them select BI data for ad hoc \\nqueries. Technicians need to know how to use meta data to help them main- \\ntain the BI applications and how to retrieve meta data in order to deliver it as \\nan integral part of the BI application reports and queries. \\nA best practice is to provide “just enough” training “just in time.” The first \\ntraining session, no longer than one day, should provide a review of the meta data \\nrepository, how it is organized, and how to extract some meta data components, \\nas well as an introduction to one or two basic functions. Tell the trainees that the \\nfirst training session is only an introduction to the meta data repository and that \\nthey will need additional training. After one or two weeks of hands-on practice \\nwhile performing their job duties, the trainees should return for another one- or \\ntwo-day training session to learn about more advanced features of the meta data \\nrepository. \\nUse the training session as an opportunity to introduce the business people to \\nthe help desk staff who will support them. Mention to the business people that \\nthe help desk staff will be mentoring them as they become proficient in navigat- \\ning through the meta data repository and through the entire BI decision-support \\nenvironment. Encourage the business people to establish their own network. In \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 363}, page_content='330 Step 14: Meta Data Repository Development \\nthis network, they could help each other not only with using the meta data repos- \\nitory but also with learning about the business data and the application features \\nof the BI decision-support environment as a whole. \\nMeta Data Repository Directory \\nSome thought should be given to the best way to organize and present the meta \\ndata repository contents to the business people and technicians. The meta data \\nrepository contents could be organized into a directory that serves as a map for \\neasier navigation through the meta data repository. For example, the contents of \\na general meta data repository directory could be organized into three major \\ngroupings: business directory, information navigator, and technical directory, as \\nshown in Table 14.2. These three groupings could list the meta data components \\ncontained within each grouping, or they could show a layer of lower-level sub- \\ngroupings. \\nA meta data repository directory could be designed as fancy as a Web site \\nmap or as simple as a basic context-sensitive matrix. The directory could also be \\nexpanded and included as part of the online help facility of the BI decision-sup- \\nport environment as a whole to serve as a potential entry point into the meta data \\nrepository. If a meta data repository directory is developed, its use should be cov- \\nered during the training sessions. \\nTable 14.2: Example of a Meta Data Repository Directory \\nBusiness Directory Information Navigator Technical Directory \\nAudience Business staff Business staff Technical staff \\nMeta Data Business terms Aggregations Security \\nComponents R f . \\n“iil Funetionsé ource of data Transformations BI target databases \\nCurrency of data Query library Indices \\nOwnership Drill-down functions Data mapping \\nData quality Roll-up functions Quality metrics \\nSS ES a EE ES SE OR \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 364}, page_content='Meta Data Repository Development Activities 331 \\nMETA DATA REPOSITORY DEVELOPMENT ACTIVITIES \\nThe activities for meta data repository development do not need to be performed \\nlinearly. Figure 14.4 indicates which activities can be performed concurrently. \\nThe list below briefly describes the activities associated with Step 14, Meta Data \\nRepository Development. \\nOT eas \\nBuild and unit test \\nmeta data migration \\nPrepare meta \\ndata repository for \\nioduction . \\nBuild meta data \\nrepository database \\nTest meta data \\nrepository programs or \\nproduct functions \\nProvide meta data \\nrepository training \\nBuild and unit test \\nmeta data application \\nFigure 14.4: Meta Data Repository Development Activities \\n1. Build the meta data repository database. \\nIf you are building a meta data repository, regardless of whether it is based on \\nan entity-relationship design or an object-oriented design, generate the data \\ndefinition language (DDL) and run it to create the meta data repository data- \\nbase structures. Also, generate the data control language (DCL) and run it to \\nestablish create, read, update, and delete (CRUD) authority on the meta data \\nrepository database. If you are licensing a meta data repository product, \\ninstall and test all product components, especially the meta data repository \\ndatabase. Set up CRUD authority on the meta data repository product to \\nallow execution of the meta data migration process and the reports and to \\nallow direct access to the meta data repository. \\n2. Build and unit test the meta data migration process. \\nOnce you have created the meta data repository database, you must develop \\nthe meta data migration process, including the tool interface process and the \\nmeta data transformation programs that will prepare the extracted meta data \\nfor the meta data repository. If you licensed a meta data repository product \\nand if the import facility of the product is used to populate the meta data \\nrepository, test it to verify that it functions as expected. \\n3. Build and unit test the meta data application. \\nIf you are building the meta data repository, you must also develop the meta \\ndata application functions, including the access interface process and the \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 365}, page_content='332 Step 14: Meta Data Repository Development \\nonline help function, as well as the meta data reports and queries. If the meta \\ndata repository is a licensed product, you must test its application functions \\n(interfaces, reports, queries). If it is necessary to enhance the product with \\nadditional functionality, write and test the additional code. \\n4. Test the meta data repository programs or product functions. \\nTest all meta data repository programs or product functions from beginning \\nto end through formal integration or regression testing. Every component of \\nthe meta data migration process as well as every component of the meta data \\napplication must be tested vigorously. Perform integration testing or regres- \\nsion testing with a formal test plan; run prepared test cases, log the actual test \\nresults on a test log, and compare them to the expected results. Once the meta \\ndata repository programs or product functions have been thoroughly inte- \\ngration or regression tested, the business people and the technicians can per- \\nform their combination QA/acceptance testing. \\n5. Prepare the meta data repository for production. \\nInstall and test the server platform for the production meta data repository. \\nCreate the DDL and DCL for the production meta data repository database. \\nWrite operating procedures for the operations staff, with instructions for \\nrunning regularly scheduled meta data repository programs. Also write a ref- \\nerence guide for the help desk staff and for the business people with instruc- \\ntions on how to use the meta data repository. Establish other procedures, \\nsuch as monitoring of database performance and meta data usage. \\n6. Provide meta data repository training. \\nSince a meta data application can be as complicated as any business applica- \\ntion, training is an important aspect. Business people and liaison personnel, \\nsuch as “power users” and help desk staff, have to be trained in the use of the \\nmeta data repository database, the online help function, reports, and queries. \\nDevelop and present in-house training sessions or schedule training through \\nthe meta data repository vendor. \\nDELIVERABLES RESULTING FROM THESE ACTIVITIES \\n1. Physical meta data repository database | \\nThis is the physical database of the meta data repository. Its tables, columns, \\nprimary keys, foreign keys, and CRUD authorization are defined to the \\nDBMS with Structured Query Language (SQL) instructions containing DDL \\nand DCL statements. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 366}, page_content='Rol es Involved in These Activities 333 \\n= \\nRo \\n® \\n. Meta data repository test plan \\nThe test plan should state the purpose for each meta data repository test and \\nshow a schedule for running the tests in a predetermined sequence. It should \\nalso describe the test cases, including input criteria and expected output \\nresults. A test log should document when the tests were run, who ran them, \\nand what the test results were. \\nMeta data repository programs \\nAll meta data migration programs, access interface programs, tool interface \\nprograms, report programs, query scripts, and online help function pro- \\ngrams for the meta data repository should be coded and tested. If a meta data \\nrepository product is being used, all of the meta data repository product \\nfunctions should be tested. \\n. Meta data repository program library \\nAll meta data repository programs and scripts should reside in the meta data \\nrepository program library. The entire meta data migration process, as well as \\nthe meta data application functions, should have been integration or regres- \\nsion tested and QA/acceptance tested. \\n. Meta data repository production documentation \\nMeta data repository production documentation includes the following: \\n— Operating procedures for operations staff covering all scheduled meta data \\nrepository jobs \\n— Meta data repository reference guide for the help desk and the business \\npeople with instructions on how to use the meta data repository \\n. Meta data repository training materials \\nThe training materials for internal meta data repository training should \\ninclude presentation slides, instructor notes, student workbooks, exercises \\nand their solutions, and any additional pertinent handouts. \\nLES INVOLVED IN THESE ACTIVITIES \\nBusiness representative \\nThe business representative should participate in acceptance testing the meta \\ndata application functions the same way he or she participates in acceptance \\ntesting the ETL and access and analysis functions of the BI application. The \\nbusiness representative must also take part in the meta data repository training. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 367}, page_content='334 Step 14: Meta Data Repository Development \\n@ Database administrator \\nThe database administrator has to create the database structures (tables, col- \\numns, indices, and so on) for the meta data repository. He or she grants \\nauthority to technicians, business people, tools, and programs for accessing \\nand writing to the meta data repository database. He or she also assists the \\nmeta data administrator with the meta data migration process and the data- \\nbase access calls for the meta data application functions. \\n® Meta data administrator \\nThe meta data administrator must install the meta data repository product, if \\none is being licensed. If a meta data repository is being built from scratch, the \\nmeta data administrator must oversee the development effort. He or she must \\ninstall and test the production server for the meta data repository. He or she \\nalso coordinates the meta data repository development activities with the \\ndatabase administrator, the meta data repository developers, and the testers. \\n® Meta data repository developers \\nThe meta data repository developers should write the code for the meta data \\nmigration process, including the tool interface process, and for the meta data \\napplication, including the access interface process and online help function. \\n@ Testers \\nSince developers should never test their own code, independent testers (other \\ndevelopers) should perform the integration and regression tests. \\nRISKS OF NOT PERFORMING STEP 14 \\nWithout a meta data repository you would have to develop a complicated custom \\nmeta data application to extract meta data from all the tools and DBMSs to pro- \\nduce meta data reports. That would be too difficult, too time consuming, too \\ncoding intensive, too convoluted, and too frustrating. Other meta data \\napproaches, such as expanding the use of a CASE tool, may work as stopgap mea- \\nsures but not as long-term solutions. CASE tools are not equipped to accept meta \\ndata from ETL tools or OLAP tools, just as ETL tools are not equipped to accept \\nmeta data from CASE tools, and so on. A meta data repository is the only solution. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 368}, page_content='Bibliography and Additional Reading 335 \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nAiken, Peter H. Data Reverse Engineering: Slaying the Legacy Dragon. New York: \\nMcGraw-Hill, 1996. \\nBeck, Kent. Extreme Programming Explained: Embrace Change. Boston, MA: \\nAddison-Wesley, 2000. \\nDick, Kevin. XML: A Manager’s Guide. Boston, MA: Addison-Wesley, 2000. \\nHetzel, Bill. The Complete Guide to Software Testing, Second Edition. New York: \\nJohn Wiley & Sons, 1993. \\nHumphrey, Watts S. Winning with Software: An Executive Strategy. Boston, MA: \\nAddison-Wesley, 2002. \\nMarco, David. Building and Managing the Meta Data Repository: A Full Lifecycle \\nGuide. New York: John Wiley & Sons, 2000. \\nTannenbaum, Adrienne. Metadata Solutions: Using Metamodels, Repositories, \\nXML, and Enterprise Portals to Generate Information on Demand. Boston, MA: \\nAddison-Wesley, 2002. \\nEnterprise Warehouse Solutions: http://www.EWSolutions.com \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 369}, page_content='a! lt \\n= \\n- set wap et ia \\n[ @ eee iieQretreyr of i daemibhetrabinn: tetas: \\nvei aehee vB, ag ieanirroi te -_ area \\n7 or he ; a gy achtlinur Pe a Ky ge). alk ie <prigs saree Fa ik 2. ae \\nsees Gala | Ue oar rs ety Acoateil sors, ear oe \\n- Wes Stila apa tt tyn os i de fi ph th! irene wi et : \\n; CSL oth «ii Rraing grieved wun d oi hid — ee \\nY Neal Nate ait s aetrad rain Fe gaptal ils pwte i \" \\n_ * GRE IIe? agra viveneate apo Hee ‘ynemnter! a \\nmies sn nee he \\n7 ahiun to ee Ay ERVIN fLapalOA Yer ae 7 hae ES es Sees ses myers : \\n7 \\n: As Aeannd ei isa nek eens vst K ierusderead? 7 ei \\nrss ol eh nT to chanel weer Tees i Wate 251g Opti. 5 Ge 9449 Gisauld “[svetl ae en eee a, \\nplanet jyseeme:, abate \\'\\\\c. tend sixties pores otal far leur tala int \\n| j ey oe ee ee ee Lone siect cipehiogs he in He \\noe » — = wie» terest A ie M ik d TN antatty led Sano ens \\n. | Cbeaty Asvev Weis iones i cc ee ee 1 T | Pa a \\nJerry 7 “~ i> i ifm © ; pi rl 1 <8 ae 10 7 ‘oo \\n“= Ss —- \\nDe Ti ~S # ; \\na) @ i \\n. \\nos ae Tha Pwee: : yu 14 2 \\n— \\nP - \\n7 7 . \\nae \\nWah. = 4feta ee \" a to) eres ee mA. ia suraind Aubigg”, \\n(wa asi Case as 4) icacl (bebe ier aes  < Jy wesw iil VMs an \\nvee» ‘e Paya vr, | a A he ies is. tee’ time vn > \\n™ ” ® = bee’ wr f ty ejhee & ai \\' 7 fret rely. tiles inet P \\nves, cotmersvanlitg Weum ii el Oe am) Veith Oita : ee _ \\n.] A P = ’ . \\njligny Te Ge 4 lp fei ts mete, CAS dls om! ete: pipped & f . \\n— V3 hele on LL” tte Oe) on 17h ees O08 int & un \\n1A PI OP AGE, OO, BOs) aad OG OS RS eu ppetig Ady \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 370}, page_content='‘Deployment \\n15 \\nImplementation \\nCHAPTER FIFTEEN \\nStep 15: Implementation \\nCHAPTER OVERVIEW \\nThis chapter covers the following topics: \\n@ Things to consider about implementation of BI applications \\nm@ The two types of security implementations: centralized \\nsecurity and decentralized security \\n@ How to perform a security gap analysis \\n@ The three types of backup procedures: incremental backup, \\nhigh-speed mainframe backup, and partial backup \\n@ Monitoring the utilization of computer, network, and per- \\nsonnel resources \\n@ Managing growth in data, growth in usage, and growth in \\nhardware \\n@ Brief descriptions of the activities involved in implementa- \\ntion, the deliverables resulting from those activities, and \\nthe roles involved \\n@ The risks of not performing Step 15 \\n337 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 371}, page_content='338 Step 15: Implementation \\nTHINGS TO CONSIDER \\nPreparing for Production \\nV Have we defined all the production libraries and production databases? \\nVY Are the daily, weekly, and monthly extract/transform/load (ETL) processes \\non the job scheduler? \\nY Are the regularly scheduled application report programs on the job scheduler? \\nVY Are the regularly scheduled meta data repository programs on the job \\nscheduler? \\nV Is the operations staff ready to take over? \\nV Have they approved the quality assurance (QA) test results? Do they have \\nany concerns? \\nY Do we have to write operating procedures for the operations staff? For all \\ncomponents of the BI application? Or just for the ETL process? \\n¥ When will we copy all programs into the production libraries? \\n¥ When will we load the production databases? \\nSecurity Considerations \\nv What types of security measures do we need? What are we securing? \\nY How are we securing the data? The applications? The tools? The interfaces? \\nY Do the security measures have to include encryption and decryption, espe- \\ncially for the Web-enabled access and analysis portion of the BI application? \\nVv Are single-user authentication services of an enterprise information portal \\npart of this BI application? \\nDatabase Maintenance \\n¥ What is our backup and recovery procedure? \\n¥ What is our disaster recovery procedure? \\n¥Y How will database performance monitoring take place? What tools will be \\nused? Who is responsible for monitoring the databases? \\nVY How will we know if we have met the service-level agreement (SLA) for \\nperformance? \\nV How will we monitor growth in usage and growth in data volume? \\nTraining and Support \\nV Have the business people received training on using the BI application? \\nVv Have the business people received training on using the meta data repository? \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 372}, page_content='Incremental Rollout 339 \\nV Have the “power users” received training on writing efficient queries in \\nStructured Query Language (SQL)? \\nV Is the help desk staff geared up to mentor the business people in their use of \\nthe BI application, including the meta data repository? \\nVv Has the help desk staff received sufficient training? \\nV If there is no help desk, who will support the business people? \\nNow that the BI application is built and tested, it is ready to be implemented \\nin the production environment. You can roll out the new BI application in two \\nways, all at once as is done traditionally or in increments as briefly described in \\nthe section below. \\nINCREMENTAL ROLLOUT \\nWhen planning the implementation, use the same iterative approach used when \\ndeveloping the BI application and the meta data repository. The iterative \\napproach, or incremental rollout, works well because it reduces the risk of expos- \\ning potential defects in the BI application to the entire organization. In addition, \\nit gives you the opportunity to informally demonstrate the BI concepts and the BI \\ntool features to the business people who were not directly involved in the BI \\nproject. Here are some suggestions. \\n* Start with a small group of business people. This small group should consist \\nof not only “power users” but also some less technology-savvy knowledge \\nworkers and business analysts, as well as the primary business representative \\nwho was involved in the development work as a member of the core team. \\nTreat the business people as customers—keeping customer care in mind. \\nTrouble-free implementation, interactive training, and ongoing support will help \\nyou get their buy-in. Always ask yourself, “What is in it for the customers?” \\nTake the opportunity to test your implementation approach. You may con- \\nsider adjusting your implementation approach or modifying the BI applica- \\ntion prior to the full rollout (e.g., change cumbersome logon procedures). \\n* It may be necessary to duplicate implementation activities at multiple sites. \\nAdding these sites slowly over time is easier than launching them all at the \\nsame time. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 373}, page_content='340 Step 15: Implementation \\nSECURITY MANAGEMENT \\nSecurity features must be tested early during the first rollout. Security is often \\noverlooked in BI applications or is given superficial attention. Keep in mind that \\nthe data in the BI target databases is the same data contained in the operational \\nsystems. The common argument that security is not an issue for BI applications \\nbecause the data is aggregated and summarized holds true only if detailed data is \\nnot available through drill-down features. In that case, the security measures for \\nthe BI data do not need to be as stringent as the security measures imposed on \\nthe same operational source data. However, most BI target databases store a fair \\namount of detailed data in addition to the summaries. Therefore, the security \\nmeasures may be relaxed for some of the data but not for all. \\nSecurity Measures for BI Applications \\nOrganizations that have strong security umbrellas on their mainframes are more \\nlikely to pay attention to security measures for their BI applications on multi-tier \\nplatforms. Organizations that have very lax security policies for their mainframes \\nare usually prone to treating security casually for their BI applications as well. \\nThese organizations may unwittingly expose themselves to security breaches, espe- \\ncially if they plan to deliver information from the BI target databases over the Web. \\nThe following is an example of a security requirement that may need to be \\nimposed on a BI application. Suppose an organization wants to give its distribu- \\ntors the ability to analyze their orders and shipments via a multidimensional BI \\napplication. To prevent a distributor from searching through other distributors’ \\nsales data, there would have to be a mechanism for restricting each distributor’s \\naccess to only the sales data pertaining to that particular distributor. In other \\nwords, some security lock is required to prevent access to the competitors’ sales \\ndata. This is not as straightforward as it sounds. | \\n- No off-the-shelf umbrella security solutions can impose this kind of security. \\nThis security requirement would have to be implemented through the vari- \\nous security features of the database management system (DBMS) and of the \\naccess and analysis tools used by the BI application. \\n* The solution of imposing security at a table level may not be granular \\nenough. However, one possible way to achieve this type of security is to parti- \\ntion the tables either physically or logically (through VIEWs). Partitioning \\nwill restrict access solely to the appropriate distributor as long as both the fact \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 374}, page_content='Security Management 341 \\ntables and the dimension tables are partitioned. Therefore, this method could \\nbecome too cumbersome. \\n- An alternative may be to enhance the meta data with definitions of data \\nparameters, which could control access to the data. This form of security \\nwould be implemented with appropriate program logic to tell the meta data \\nrepository the distributor’s identity, allowing the application to return the \\nappropriate data for that distributor only. This type of security measure will \\nbe only as good as the program controlling it. \\nThis example illustrates that the required security measures must be well \\nconsidered and that the security features of the DBMS and of the access and anal- \\nysis tools must be well understood and cross-tested. Complete reliance on one \\ncomprehensive security package that has the capability to implement any and all \\ntypes of security measures is not a security solution because such a security pack- \\nage does not exist. \\nTo get the security you need, you will most likely have to implement a num- \\nber of different security measures, including purchased security packages. How- \\never, be sure to minimize the number of security packages you implement \\nbecause one of two things may happen. \\n1. Business people will be logging in through multiple security packages, using \\nmultiple logon identifiers (IDs) and multiple passwords that expire at differ- \\nent times. They will get frustrated very quickly if they have to go through dif- \\nferent logon procedures and remember different IDs and passwords for each \\nprocedure. Complaints will run high. \\n2. Business people will stop using the BI decision-support environment entirely \\nbecause it is too cumbersome. You do not want this to happen. \\nA number of organizations avoid this problem by adopting a single-sign-on \\nscheme, which keeps the frustration level to a minimum but still allows tracking \\nof any security breaches, albeit in a less sophisticated way. \\nSecurity in a Multi-Tier Environment \\nImplementing security measures in a centralized environment is less complicated \\nthan in a multi-tier environment. In a centralized environment, all security mea- \\nsures can be implemented in one location because all the data is in one place. The \\ngoal of centralized security is “one entry point, one guard.” It is much easier to \\nguard a single door than multiple doors. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 375}, page_content='342 Step 15: Implementation \\nIn a BI decision-support environment, keeping all the data in one central \\nplace is not always feasible or desirable. If data needs to be stored in a distributed \\nfashion in a multi-tier environment, implementing security measures becomes \\nmuch more complicated. The list below briefly describes the steps involved. \\n1. Identify the end points in your network architecture and the paths connect- \\ning the end points. Draw a diagram of your physical architecture, similar to \\nFigure 15.1. \\nCLUE wy eS Sail \\nImage = LAN Connector » A Jukebox \\n/ Image Workstations \\nCommunication \\nServer \\nDatabase \\nServers \\nWeb \\nServer \\n Dial-in \\nFigure 15.1: Example of a Physical Architecture Diagram \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 376}, page_content='Security Management 343 \\nCommunication \\nServer \\n| \\nMainframe \\nae \\nRemote Access \\nvs \\nDatabase \\nServer = a \\nLAN File \\nServer \\nFigure 15.2: Example of a Connectivity Path Diagram \\nPersonal Computer \\n2. Determine the connectivity paths (from the entry points) used to get to the \\ndata. Draw a diagram with links and labels for the connectivity paths (Figure \\n5.2). \\n3. Compare the paths with your existing security measures. You may already \\nhave some security packages installed, and some of them may be sufficient to \\nguard a subset of the data. Draw a matrix for security gap analysis purposes \\n(Figure 15.3). \\nThe security gap analysis matrix will help you identify where security is still \\nneeded and what type of security is needed. Keep in mind the following points: \\n- Password security may be the least expensive to implement, but it can be eas- \\nily violated. \\n* DBMS security is the most important component of the security solution \\nand should override all other security measures that may contradict the data \\naccess authority granted by the DBMS. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 377}, page_content='344 Step 15: Implementation \\nMainframe LAN PC Generic \\nConnectivity | Security Security Security Password Encryption DBMS Security \\nPackage Package Package Security Function Security Package \\nSecurity exists \\n[4 No security \\nFigure 15.3: Example of a Security Gap Analysis Matrix \\n* Encryption is not that prevalent in BI decision-support environments \\nbecause of the complicated encryption and decryption algorithms. Encryp- \\ntion and decryption processes also degrade performance considerably. How- \\never, with the frequent use of the Internet as an access and delivery \\nmechanism, encryption should be seriously considered to protect the organi- \\nzation from costly security breaches. \\nSecurity for Internet Access \\nThe Internet enables distribution of information worldwide, and the BI decision- \\nsupport environment provides easy access to organizational data. Combining the \\ntwo capabilities appears to be a giant leap forward for engaging in e-commerce. \\nHowever, carefully consider the implications of combining these technologies \\nbefore you decide to take the risk of potentially exposing sensitive organizational \\ndata (Figure 15.4). \\nMany product vendors are enabling Web access to databases in general, and \\nsome vendors are allowing access to BI target databases in particular. This com- \\nplicates the concerns for: \\n* The security of the BI decision-support environment in general \\n- The security issues associated with allowing Web access to the organization’s data \\nThe bottom line on security is that you need to define your security require- \\nments early in order to have time to consider and weigh all factors. If you opt to \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 378}, page_content='Data Backup and Recovery 345 \\nInternet \\nSecurity \\nOrganizational What is the purpose of \\nData Access providing access to this data? \\nIs it worth the risk? \\nWhat is the cost of minimizing \\nthis risk? \\nDistributed \\nSystem \\nSecurity \\nFigure 15.4: Security Considerations for Internet Access \\ndisplay the data on the Web, spend extra time and money on authentication and \\nauthorization of internal staff and external customers. If you are transmitting \\nsensitive data to and from external customers, consider investing in encryption \\nand decryption software. \\nAuthentication 1s the process of identifying a person, usually based on a logon \\nID and password. This process is meant to ensure that the person is who he \\nor she claims to be. \\nAuthorization is the process of granting or denying a person access to a \\nresource, such as an application or a Web page. In security software, authenti- \\ncation is distinct from authorization, and most security packages implement \\na two-step authentication and authorization process. \\nEncryption is the “translation” of data into a secret code. It is the most effec- \\ntive way to achieve data security. To read an encrypted file, you must have \\naccess to a secret key or password that enables you to decrypt it. Unencrypted \\ndata is usually referred to as plain text, while encrypted data is usually \\nreferred to as cipher text. \\nDATA BACKUP AND RECOVERY \\nAfter spending several million dollars on your BI decision-support environment, \\nyou want to make certain that you will never lose the content of the BI target \\ndatabases and that you will never be deprived of the analytical capabilities of the \\nBI applications for a long period of time. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 379}, page_content='346 Step 15: Implementation \\nThere is a school of thought that says, “Don’t worry about backing up your BI \\ntarget databases because that data is derived from other systems—if the data is \\ndestroyed, simply rebuild it.” This is a careless and expensive attitude when deal- \\ning with a very large database (VLDB). Although backing up a database is time- \\nconsuming and takes the database offline for several hours, the alternative of \\nreloading years’ worth of data into a VLDB will take much longer—if it can be \\ndone at all. Not every organization opts to keep all source extract files for years \\njust in case it needs to reprocess them. \\nIt is mandatory to back up the BI target databases on a regular basis, but the \\nsheer size of VLDBs make this a technological challenge. Many of the hardware \\nplatforms on which BI applications reside often have limitations on the amount \\nof data that can be backed up on a regular basis. These limitations are due to the \\nslow speed of data transfers between the server and the backup device. Several \\nbackup strategies are available to mitigate this problem. \\n* Incremental backup: One strategy is to take advantage of the grow-only \\naspect of BI target databases (no updating of rows) by backing up only the \\nactual changes to a database (new rows) since the last update rather than the \\nentire database. This incremental (“net change”) backup strategy is even pos- \\nsible for most daily backups. However, since there are usually multiple data- \\nbases in the BI decision-support environment, and since the summarized \\ndata must stay synchronized with the detail data, no loads or refreshes can \\noccur to any of these databases until the backups of all databases have com- \\npleted successfully. \\nHigh-speed mainframe backup: Another possibility is to use the mainframe \\ntransfer utilities to pass BI data back to the mainframe for a high-speed \\nbackup, which is supported only on the mainframe. Channel connects on the \\nmainframe allow speeds that cannot yet be approached on most midrange \\nservers. This is an expensive solution, but it is a robust one that usually works. \\nPartial backup: Another strategy relies on partitioning the database tables by \\ndate to support partial backups. While one partition is being backed up, the \\nother partitions can remain available. Considerations about this strategy are \\nlisted below. \\n— Databases, which support parallelization of backups, have a major advantage \\nwith this strategy since multiple partitions can be backed up at the same time. \\n— If your BI target databases are loaded daily, group multiple days into one \\npartition rather than setting up a new partition for each day. During \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 380}, page_content='Monitoring the Utilization of Resources 347 \\nbackup, the data for all days in the partition being backed up would not be \\navailable. \\n— A big drawback of this strategy is that if the table is partitioned by a date \\ncolumn for backup purposes (which means it is clustered by the date col- \\numn), it cannot be clustered in any other way for access purposes. This can \\naffect performance when running the reports and queries, unless database \\nparallelism is used. \\nMONITORING THE UTILIZATION OF RESOURCES \\nYou must continuously monitor the utilization of various resources in a BI deci- \\nsion-support environment, especially the utilization of computers, networks, and \\npersonnel. If any one of these resources is neglected, it may potentially become a \\nbottleneck for the BI applications. \\nComputer Utilization \\nComputer utilization includes the central processing unit (CPU), input/output \\n(I/O) channels, random access memory (RAM), direct access storage devices \\n(DASDs) or disk drives, and other related hardware. These devices should be \\ndedicated for the BI decision-support environment and should not be shared by \\nother applications. Since utilization of these devices increases over time, they \\nshould be monitored. \\nIt is vitally important to use appropriate monitoring and alert utilities that will \\ndetect any resource problem and sound an alarm in case of an actual or \\npending system failure or resource shortfall. Selecting an appropriate monitor- \\ning utility is especially critical in a distributed environment. \\nNetwork Utilization \\nNetwork utilization may be a relatively minor issue for the day-to-day execution \\nof BI applications, but it may be a big issue for the ETL process. One large tele- \\ncommunications organization found out that even with access to the latest and \\ngreatest communications technologies, it had insufficient bandwidth to transmit \\nits source data from the mainframe to the database server to populate its BI target \\ndatabases in a timely fashion. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 381}, page_content='348 Step 15: Implementation \\nWhen monitoring your network utilization, also consider the following \\npoints: \\n- Bandwidth may be a serious problem for BI applications that frequently \\ninvolve several levels of drill-down access into detailed data. Queries after \\nqueries may be executed by many people from many locations, each poten- \\ntially returning huge amounts of data across the network. \\n- If bandwidth is an ongoing problem, one potential solution is to move \\ntoward a distributed BI implementation and away from a centralized strategy. \\nHowever, if a lot of communication and integration among the distributed BI \\ntarget databases is required, this solution could make the situation worse. \\nPersonnel Utilization \\nA BI decision-support environment is a high-maintenance environment. This is \\nespecially true during the initial development and deployment of the first few BI \\napplications. It is also true to the extent that manual processes are used during or \\nafter the ETL cycles to validate and analyze load statistics produced by the ETL \\nruns. A BI decision-support environment requires dedicated support from a \\nnumber of IT personnel, such as: \\n* Application developers \\n+ Data administrators \\n* Database administrators \\n+ Hardware and operating system specialists \\n* Middleware specialists \\n* Network administrators \\nGood technicians are often hard to find. Many technicians want to work on \\nBI applications, especially the multidimensional ones, because these challenging \\napplications involve new technologies (and thus they look good on a résumé). \\nHowever, because the operational systems still need to be supported— since they \\nare more mission-critical than BI applications—a “tug of war” over available staff \\nis often the result. \\nThis is especially true for database administrators who already have a full \\nplate supporting the operational systems. Some senior database administrators \\nhave to be released from those duties to become the chief designers and managers \\nof the BI target databases. These database administrators are responsible for \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 382}, page_content='Growth Management 349 \\ndesigning, building, monitoring, tuning, and maintaining the BI target databases \\nand, to some extent, the database access calls from the BI application programs \\nand access and analysis tools (e.g., writing passthrough queries). In addition, they \\nhave to be concerned with monitoring and managing the increasing data vol- \\numes and increasing database usage, which will require even more of their time. \\nRedistributing the workload of database administrators is a culture shift and an \\nissue in many organizations that perceive the database administrator’s function \\nas nothing more than running DBMS maintenance procedures on production \\ndatabases. \\nGROWTH MANAGEMENT \\nBy conservative estimate, the data in a BI decision-support environment doubles \\nevery two years. The good news is that the cost per query for most BI decision- \\nsupport environments goes down with properly managed growth. The bad news \\nis that the overall cost climbs, assuming that more and more business people use \\nthe BI decision-support environment as time progresses. The three key growth \\nareas to watch are data, usage, and hardware. \\nGrowth in Data \\nGrowth in data means not only adding new rows to the tables but also expanding \\nthe BI target databases with additional columns and new tables. Adding new col- \\numns to a dimension table is not as involved as adding new dimension tables to \\nan existing star or snowflake schema, which usually requires the following: \\n* Unloading the fact table \\n- Adding another foreign key to the fact table to relate to the new dimension \\ntable \\n* Recalculating the facts to a lower granularity (because of the new dimension) \\n* Reloading the fact table \\nBI target databases need a large amount of disk space, with workspace and \\nindices taking up as much as 25 to 40 percent of that space. In the relational \\nworld, the data is only a fraction of the overall database size; a major portion of it \\nis index space. Indexing is required to provide better response time when enor- \\nmous volumes of data are read. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 383}, page_content='350 Step 15: Implementation \\nWhen calculating space requirements, it might be prudent to use the standard \\nengineering maxim: Calculate how large the BI target databases will be \\n(including indices), and then triple those numbers. \\nAs data volumes increase, there needs to be a plan to aggregate and summa- \\nrize the data as it ages. Business analysts rarely require the same level of granular- \\nity for very old data as they do for recent data. Therefore, the level of granularity \\nshould decrease with a moving calendar. For example, assume the business peo- \\nple want to store ten years of historical data. They require monthly summary data \\nby department for two years but are satisfied with monthly summaries by region \\nfor the remaining eight years. Before a new month is loaded into the BI target \\ndatabase, the department-level data for the 24th month is summarized into \\nregional totals and rolled off into another fact table so that the 23rd month \\nbecomes the 24th month, the 22nd month becomes the 23rd month, and so on. \\nThe following list contains some of the new technologies available to support \\nthe massive data volumes and the analysis capabilities of these huge databases: \\n* Parallel technologies \\n* Multidimensional databases \\n* New indexing technologies \\n* Relational online analytical processing (ROLAP) tools \\n* Distributed database maintenance tools and utilities \\nGrowth in Usage \\nAnother key growth area is usage. Organizations that have built successful BI \\napplications have often uncovered a pent-up need for information throughout \\nthe organization. This need translates to more business people using the existing \\nBI applications and asking for new ones. The number of business people access- \\ning the BI target databases can easily double or triple every year, which drives up \\ngrowth in usage exponentially. Since different business people want to see differ- \\nent data and look at it in different ways, they want to slice and dice the data by \\nnew business dimensions, which increases the data volume. Although the data \\nvolume is a far more critical factor in determining processor requirements, the \\nnumber of people accessing the BI target databases is equally important. \\nTechnicians view growth in usage as something negative. Managers, however, \\nthink of growth in usage as something positive, as long as there is a return on \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 384}, page_content='Growth Management 351 \\ninvestment (ROI). Purchasing new hardware or updating existing hardware to \\nhandle the growth may not be a concern if the organization is making a sizable \\nprofit due to better decision-making capabilities with the BI applications. There- \\nfore, growth in usage may mean that the BI strategy is working. \\nPaw BI target databases are by nature read-only and grow-only. Therefore, the key \\nis to stop trying to conserve disk space if the BI applications and BI data are \\nhelping the organization make a profit. \\nGrowth in Hardware \\nGiven the information about the growth in data and the growth in usage, it \\nshould be obvious that scalability of the BI hardware architecture is key. But \\nbefore you plan five years ahead, remember that the hardware cost is only one \\npart of the total BI cost. Look at a planning horizon of 12 to 24 months; it is \\nbest to start small but also plan for long-term growth. Consider the following \\nfactors. \\n* Keep in mind the capacity threshold of your BI platform. If you exceed that \\ncapacity, you have to add more processors, I/O channels, independent disk \\ncontrollers, and other high-speed components to keep the BI decision-support \\nenvironment at an acceptable level of performance. \\nOf all the BI hardware, the BI server platform is the most important. When \\nordering new hardware of any kind, there must be enough lead time to have \\nthe equipment delivered, tested, and prepared for the development and pro- \\nduction environments. \\nParallel technology is an absolute must for VLDBs. The ability to store data \\nacross striped disks and the ability to have multiple independent disk con- \\ntrollers play an enormously important role in the performance of processes \\nrunning against the BI target databases. \\n* The Transmission Control Protocol/Internet Protocol (TCP/IP) is appropri- \\nate for most hardware platforms. TCP/IP is rapidly becoming a standard for \\nscalability, growth considerations, and multiplatform environments. \\nConsider the advantages of a data mart approach with separate BI target \\ndatabases. This approach permits scalability in smaller and less expensive \\nincrements. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 385}, page_content='352 Step 15: Implementation \\nIMPLEMENTATION ACTIVITIES \\nThe activities for implementation do not need to be performed linearly. Figure \\n15.5 indicates which activities can be performed concurrently. The list below \\nbriefly describes the activities associated with Step 15, Implementation. \\nPlan \\nimplementation \\nSet up production \\nenvironment \\nSet up production \\nschedule \\n3 S \\nInstall all Bl \\napplication components \\nJi UG \\nLoad production \\ndatabases \\nPrepare for \\nongoing support \\nFigure 15.5: Implementation Activities \\n1. Plan the implementation. \\nSet the implementation date and make sure that all the resources needed for \\nthe implementation will be available. Depending on the progress you have \\nmade, the lessons you have learned, and the difficulties you have encoun- \\ntered, you may want to roll out the BI application to the business community \\nin phases. Start with a small group of business people, learn from the experi- \\nence, and modify your approach if necessary (e.g., increase the time for train- \\ning or change the security measures) before making the BI application \\navailable to more people. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 386}, page_content='Implementation Activities 353 \\nI EE SE SE IT TE EN a TS I I I SE I ELS OT \\nIf the BI application has any organizational impact, prepare to make those \\norganizational changes (e.g., business process improvement changes or shifted \\nroles and responsibilities). \\n2. Set up the production environment. \\nIn most large organizations, strict procedures have to be followed to prepare \\nthe production environment. \\n— Set up the production program libraries (ETL, application, meta data \\nrepository). \\n— Create the production databases (BI target databases, meta data repository \\ndatabase). \\n— Grant appropriate access authority on the production databases. \\n— Grant appropriate access authority to developers, operations staff, and \\nbusiness people to execute programs from production program libraries. \\n— Write operating procedures for the operations staff with instructions for \\nrunning the ETL process, as well as the regularly scheduled application \\nreport jobs. \\n— Prepare a reference guide for the help desk staff and the business people \\nwith instructions on how to use the BI application. \\n— Determine production security levels for all components of the BI application. \\n3. Install all the BI application components. \\nMove all ETL programs, application programs, and meta data repository pro- \\ngrams to their respective production libraries. \\n4, Set up the production schedule. \\nAll ETL programs, application report programs, and meta data repository \\nprograms that will run on a regular basis have to be set up on the job sched- \\nuler. The ETL job schedule has to include the meta data programs that are \\npart of the ETL process (e.g., capture load statistics, reconciliation totals, data \\nreliability factors). \\n5. Load the production databases. \\nLoad the BI target databases by running the initial load process, followed by \\nthe historical load process. Also load the meta data repository with meta data \\nfrom your various meta data sources such as spreadsheets, computer-aided \\nsoftware engineering (CASE) tool, ETL tool, and online analytical processing \\n(OLAP) tool. \\n6. Prepare for ongoing support. \\nEstablish a schedule for on-call emergency support. Schedule regular backups \\nas well as occasional database reorganizations for all production databases. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 387}, page_content='354 Step 15: Implementation \\nPlan to use the DBMS-provided utilities for these database maintenance \\nactivities. In addition, plan to monitor performance, growth, usage, and \\nquality as part of the ongoing database maintenance activities. Periodically \\nreview and revise capacity plans for processors, disk storage, network, and \\nbandwidth. \\nDELIVERABLES RESULTING FROM THESE ACTIVITIES \\n1. Production ETL program library \\nAll fully functioning ETL programs and scripts should reside in the produc- \\ntion ETL program library. \\n2. Production application program library \\nAll fully functioning access and analysis programs and scripts should reside \\nin the production application program library. \\n3. Production meta data repository program library \\nAll fully functioning meta data repository programs and scripts should reside \\nin the meta data repository program library. \\n4. Production BI target databases \\nThe data definition language (DDL) and data control language (DCL) SQL \\nstatements are run in the production environment to build the production BI \\ntarget databases. The ETL initial load process and the ETL historical load \\nprocess are run to populate these production BI target databases. \\n5. Production meta data repository database \\nThe DDL and DCL statements for the meta data repository are run in the \\nproduction environment to build the production meta data repository data- \\nbase. The meta data migration programs and tool interface programs are run \\nto populate the production meta data repository database with business meta \\ndata, technical meta data, and ETL meta data (load statistics, reconciliation \\ntotals, data quality metrics) from the initial load and historical load processes. \\n6. Production documentation \\nProduction documentation for the BI application includes: \\n— Operating procedures for operations staff covering the ETL process and all \\nscheduled application report jobs \\n— Reference guide for the help desk staff and the business people with instruc- \\ntions on how to use the BI application \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 388}, page_content='Roles Involved in These Activities 355 \\nROLES INVOLVED IN THESE ACTIVITIES \\n@ Application developers \\nThe application developers work with the operations staff to move the report \\nprograms, query scripts, interface programs, and online help function pro- \\ngrams into the production application program library. \\n@ Application lead developer \\nThe application lead developer supervises the implementation activities of the \\naccess and analysis portion of the BI application. He or she is in charge of set- \\nting up the production application program library and writing the access and \\nanalysis portion of the operating procedures and the reference guide. He or \\nshe also has the responsibility of setting up the application report programs \\non the job scheduler. \\n@ Data mining expert \\nThe data mining expert works with the database administrator to create, \\nrevise, and maintain the data mining databases for the planned data mining \\nactivities. Data mining is an iterative and ad hoc endeavor that requires ongo- \\ning changes to the data mining databases, the analytical data models, and the \\ndata mining operations. \\n® Database administrator \\nThe database administrator creates the production BI target databases and the \\nproduction meta data repository database and grants appropriate access \\nauthority for these production databases. He or she must run the initial load \\nprocess and the historical load process to load the BI target databases. He or \\nshe schedules database maintenance activities (backups, reorganizations) as \\nwell as ongoing database monitoring activities (for performance, growth, \\nusage). He or she also reviews the capacity plans for processors, disk storage, \\nand network bandwidth. \\n@ ETL developers \\nThe ETL developers work with the operations staff to move the ETL programs \\ninto the production ETL program library. \\n@ ETL lead developer \\nThe ETL lead developer supervises the implementation activities of the ETL \\nportion of the BI application. He or she works with the operations staff to pre- \\npare the production environment and set up the production ETL program \\nlibrary. He or she should write the ETL portion of the operating procedures \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 389}, page_content='356 Step 15: Implementation \\nand the reference guide. He or she is also responsible for setting up the ETL \\nprocess on the job scheduler. \\n® Meta data administrator \\nThe meta data administrator is responsible for moving all the meta data \\nrepository programs into the production meta data repository program \\nlibrary. He or she also has to run the meta data migration (load) process and \\nschedule ongoing data quality monitoring activities, such as gathering meta \\ndata metrics and performing data quality spot checks. \\n® Meta data repository developers \\nThe meta data repository developers assist the meta data administrator with \\nmoving all the meta data repository programs into the production meta data \\nrepository program library. \\n@ Web developers \\nThe Web developers are responsible for moving their Web pages and scripts \\nfrom their local servers to the production Web server. \\n@ Web master \\nThe Web master is responsible for setting up the production Web server. He or \\nshe also has to work with the staff of security services and network services to \\ninstall and test the firewall and other required security features. \\nRISKS OF NOT PERFORMING STEP 15 \\nIf you got this far, you will obviously deploy your BI application. If you perform \\nthis step with diligence, you can be reasonably assured that the BI decision-support \\nenvironment will be as stable, robust, and secure as any other production envi- \\nronment. If you perform this step hastily, you run the risk that your BI decision- \\nsupport environment will not be the robust and secure environment the business \\npeople expect it to be. \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nBischoff, Joyce, and Ted Alexander. Data Warehouse: Practical Advice from the \\nExperts. Upper Saddle River, NJ: Prentice Hall, 1997. | \\nCorey, Michael J., and Michael Abbey. Oracle Data Warehousing: A Practical \\nGuide to Successful Data Warehouse Analysis, Build, and Roll-out. Berkeley, CA: \\nOsborne McGraw-Hill, 1997. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 390}, page_content='Bibliography and Additional Reading 357 \\nImhoff, Claudia, Lisa Loftis, and Jonathan G. Geiger. Building the Customer-Centric \\nEnterprise: Data Warehousing Techniques for Supporting Customer Relationship \\nManagement. New York: John Wiley & Sons, 2001. \\nInmon, William H. Building the Data Warehouse. New York: John Wiley & Sons, \\n1996. \\nInmon, William H., Claudia Imhoff, and Greg Battas. Building the Operational \\nData Store. New York: John Wiley & Sons, 1996. \\nInmon, William H., Claudia Imhoff, and Ryan Sousa. Corporate Information Fac- \\ntory. New York: John Wiley & Sons, 1998. \\nInmon, William H., J. D. Welch, and Katherine L. Glassey. Managing the Data \\nWarehouse: Practical Techniques for Monitoring Operations and Performance, \\nAdministering Data and Tools and Managing Change and Growth. New York: John \\nWiley & Sons, 1997. \\nKimball, Ralph, and Richard Merz. The Data Webhouse Toolkit: Building the Web- \\nEnabled Data Warehouse. New York: John Wiley & Sons, 2000. \\nKimball, Ralph, Laura Reeves, Margy Ross, and Warren Thornthwaite. The Data \\nWarehouse Lifecycle Toolkit: Expert Methods for Designing, Developing, and \\nDeploying Data Warehouses. New York: John Wiley & Sons, 1998. \\nThe Information Systems Audit and Control Association & Foundation: http:// \\nwww.1saca.org \\nInformation Systems Control Journal: http://www.isaca.com \\nMIS Training Institute: http://www. misti.com \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 391}, page_content='+ \\nthe artheadl ty \\nWena ghoreiem, oat guile srg os? ral barrel dated | \\nieegisinth retell Bgetinieed vb aay/nAwt yi anata Pa \\n@ Wirntades ha iAlnvi, 1 2008 @ ysl nite ala fl Ae \\na ER palin twill werkt s cmyiloniidd wth ec gabhlheallhe 1 eae \\nvayer’ 71D Mig 4 Sa ba @%s its tate wees ate repoultigr) (4 \\nSali Sutra Letin A asda a em ott war ih ‘6 ame ieee TE eh \\nalle ht mai\" t tater ae line SHA nc ania \\nves oi hag ey epee! = ney eaten? wher bat emis a: \\nfeenit WAFS ghia | ra a pelts OE SE lh mt : a ih ay Sait patie: ne res 7 \\nwildy: wk (aa, Tr pelea leeer show) be venereal \\noe Viidnigsn: “> \\nbal’ ae AT Cr ii Aer nina (ait y el ac artlat \\n(ROE LEA TA lil sede ited Nein \\nFen Mire nae A010 bon paostvron Meee gil ome a \\nIBeviestartt geet wit Theta nek oa ait \\nmae race adil nf wt 6 Nee yea TL wie hea, Ut ies ast Aas | Y lenis HY (ja \\nWage wudiahhaent @ ie : SOMA }aMV IC Linke deals ~~ larger = 3s \\nParca 1 (ores Pimper. S? et \\ni eb / fy ella’ hh< i Vs \\\\ey) \\njets OP hs fy ° y om \\nie Veo ws ha Apoeta Seal Pa. iy \\n;wHMVe <= bef Oy 2 piers 1G al gp fb? oe. ce \\nNea, 19 & ie Cee sap Lule, pe oni og Se pa ma, \\noy ee a 0 eb A page \\n[era eo! |e a \\nes en \\nFLA RAIYTY Ani) | ee TER se EA Cge ’ \\nNM we bare én Adin (Mm Lido Vebperp’ Prurtn al Ai \\ni vA. qe Get)! ‘Vouns, YY TS hibe Hal, ty \\nre, hori a 4 Mle inal AM y | Craide. J \\ni i Mire eian 1) \\nCideyg ee wh tap Gam Of ae \\noa Q ae Oe = opt \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 392}, page_content='Step 16: Release \\nCHAPTER OVERVIEW \\nThis chapter covers the following topics: \\nm@ Things to consider about release evaluation \\nae @ Guidelines for using the application release concept when \\n> aa \\\\/ developing BI applications \\n@ How to organize a post-implementation review meeting, \\nincluding when and where to schedule the session, who to \\ninvite, and what to discuss \\nm@ The process flow of a post-implementation review session, \\nincluding responsibilities for conducting the meeting \\n@ Brief descriptions of the activities involved in release evalu- \\n: ation, the deliverables resulting from those activities, and \\n1 the roles involved \\n@ The risks of not performing Step 16 \\nCons \\n\\\\ J 7 N \\n16 _ \\nRelease \\nEvaluation ~~. \\n359 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 393}, page_content='360 Step 16: Release Evaluation \\nTHINGS TO CONSIDER \\nPost-Implementation Review \\nY How soon after the rollout should we schedule a formal project review? \\n/ Should the business sponsor or the project manager run the review session? \\nOr should we ask a trained facilitator who was not involved with the BI \\nproject to facilitate the review session? \\nY Who should attend the review session? \\n¥ Should it be held offsite? Where? \\nY¥ Who will prepare and distribute the agenda? \\n¥ What topics should appear on the agenda? \\n¥ Who will be responsible for taking notes? \\n¥ Will we invite stakeholders from other departments? \\nV Will we invite the data owners? \\n¥ Who will track the assigned action items? The project manager? \\n¥Y How will we communicate to other teams and stakeholders the lessons we \\nlearned from the review? Who else can benefit from this review? \\nMeasures of Success \\nV Is the business sponsor satisfied with the BI application? \\n¥ Do the business people like the BI application? Is it easy to use? \\n¥ What do they like? What do they dislike? Why? \\nVv Are they using the meta data repository? Do they find it helpful? \\nVv Is the business sponsor willing to support another BI application? \\nPlans for the Next Release \\nVY Do we have leftover requirements that did not get implemented due to time \\nconstraints or other project constraints? \\n¥ Do we know how we want to address these requirements? Will they go into \\nthe next release? Will they be reprioritized? \\nVv Are we planning another release of this BI application for the same business \\narea? \\nVv Are we switching to a different department and a different business sponsor? \\n¥ Do we want to invite the new business sponsor to the review session as one \\nof the stakeholders? \\nVv Are we prepared to split the core team into two groups the next time so we \\ncan work on two BI projects at the same time? \\n¥Y Who will continue with the next release of this BI application? \\n¥ Who will lead the new BI project for the new business sponsor? \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 394}, page_content='The Application Release Concept 361 \\nBuilding a BI decision-support environment is a never-ending process. \\nUnlike most operational systems, which have sharply defined functionalities, BI \\napplications must evolve to handle emerging information needs. As the needs \\nand goals of your organization change, so must the BI decision-support environ- \\nment. There is no practical way to anticipate all possible questions in the initial \\ndesign of the BI decision-support environment or of any BI application. The best \\nyou can do at any given time is to have an environment that supports the current \\norganizational goals and that can be easily adapted to new goals. Plan to design \\nflexible and easy-to-change BI applications so that you have the ability to modify \\nthem when the organization’s goals change. This applies to all BI initiatives, from \\nsmall departmental data marts to large industrial-strength enterprise data ware- \\nhouses. Be prepared to modify all BI applications and BI target databases in future \\nreleases in order to provide new query and reporting capabilities and more data. \\nTHE APPLICATION RELEASE CONCEPT \\nBI projects introduce many new practices: new techniques for business analytics, \\nnew prototyping techniques, new design techniques, new architectures, and new \\ntechnologies. These practices are relatively new not only to organizations but also \\nto the information technology (IT) industry as a whole. In addition, BI projects \\nusually involve a significant level of capital investment. All of these factors add up \\nto make IT managers and business executives quite anxious. When a BI applica- \\ntion does not turn out flawless or is not complete on its initial implementation, \\nsome IT managers and business executives get very unnerved. \\nA major shift must occur in how IT managers and business executives \\napproach BI projects. The approach of “get it right the first time” has never \\nworked, even though people have pretended for years that it does—or that it \\nshould. That misconception should have been put to rest long ago. No major \\ninvention or significant endeavor has ever worked right the first time. Usually, \\ngood things evolve over time. Nature evolves. This fact is generally accepted. \\nTechnology evolves (Figure 16.1), and this fact is also accepted. But the truth that \\nsoftware evolves as well is usually not accepted, at least not when the software is \\ndeveloped in-house. \\nWhen software is purchased from a vendor, it seems to be more palatable to \\naccept an imperfect and evolving product because a software vendor never prom- \\nises that the first product release will be the last. Vendors also never claim that \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 395}, page_content='362 Step 16: Release Evaluation \\nMainframe Midrange Client/Server Internet \\nFigure 16.1: Evolving Technologies \\ntheir software products will not have to be enhanced; on the contrary, we want \\nthem to be enhanced. Why, then, do we have exact opposite expectations of inter- \\nnally developed software? \\nFor example, when vendors publish a new release of their products, they \\ninclude new functionality, new screens, new modules—and of course some fixes \\nto defective parts of the prior release. Sometimes, the new software release is \\ncompletely redesigned and is not even compatible with the previous release. We \\ndo not hesitate to pay good money to upgrade purchased software products \\nunder those conditions. But when the in-house IT technicians have to redesign a \\nBI target database or portions of a BI application after the third or fourth release, \\nthe situation is treated like a disaster. Organizations must accept the fact that \\ninternally developed applications evolve over time, just as vendor software prod- \\nucts do. Hence, it is high time to embrace the application release concept. \\nGuidelines for Using the Release Concept \\nWhen developing BI applications under the release concept, IT and business \\nmanagement must agree on and follow some basic guidelines (Table 16.1). When \\nfollowing these guidelines, there should never be any concern about the com- \\npleteness of a BI application on its initial release. Any incomplete functionality \\nthat was negotiated out of the scope due to unforeseen roadblocks will be bun- \\ndled with new functionality in the next release or some future release. Business \\nmanagement gets to decide how long to defer the functionality, and the decision \\nwill probably be based on the priorities of outstanding requirements. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 396}, page_content=\"The Application Release Concept 363 \\nTable 16.1: BI Application Release Guidelines \\nDos and Don'ts of Application Releases \\n* Releases should be delivered every three to six months (the first release will \\ntake longer). \\n* Releases must have very small and manageable deliverables. \\n* Expectations regarding deliverables must be managed continuously and must \\nremain realistic. \\n* A release does not have to equal a completed BI application. It may take \\nseveral releases to complete a BI application. \\n* The first release of a BI application should deliver only the basics. \\n* Business management must be willing to accept a partial delivery of a BI \\napplication (e. g., the basics). \\n* Nothing is cast in concrete. Everything is negotiable. That includes scope, \\nschedule, budget, resources, and quality. \\n¢ The enterprise infrastructure, both technical and nontechnical, must be robust. \\n¢ Meta data must be an integral part of each release; otherwise, the releases will \\nnot be manageable. \\n¢ The development process must be sound and flexible. Developing releases \\nfeels like prototyping, but the effort is more disciplined and controlled because \\nthe results are treated as production-worthy deliverables. \\n* Designs, programs, and tools must be flexible to allow for occasional redesigns \\nof BI target databases and BI applications. \\n¢ New requirements must be triaged and prioritized; scope is strictly controlled \\nand kept small for every BI release. \\n¢ Small errors or defects are addressed under strict change-control procedures \\nduring the development of the release. \\n¢ Large errors or defects are deferred to another release by removing the \\nfunction or data associated with the problem. \\n* When deferred functions or data are implemented in a future release, business \\nmanagement must prioritize the sequence of delivering the deferred \\nrequirements. \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 397}, page_content='364 Step 16: Release Evaluation \\nPaw If time is a critical project constraint, using the release concept to deliver a par- \\ntial application of high quality is much better than delivering a completed \\napplication with many defects and dirty data. \\nPOST-IMPLEMENTATION REVIEWS \\nA post-implementation review should be conducted after every BI project, \\nregardless of whether the BI application runs perfectly or has problems. It is \\nimperative to learn from each project in order to improve the quality as well as \\nthe speed of the development process for future BI applications. \\nA post-implementation review session is also an excellent forum for IT man- \\nagers and business executives to become comfortable with the dynamic develop- \\nment process and the release concept of BI applications. In addition, the review \\nsession is an ideal venue for sharing the lessons learned with other project teams \\nas well as with other business managers in the organization. This goes a long way \\ntoward making the necessary culture shift more natural and acceptable. \\nTopics to be reviewed can include schedule, budget, satisfaction, scope, nego- \\ntiation skills, staffing, skills and training, project planning and reporting, and \\ndevelopment approach (methodology), as well as contractors, consultants, and \\nvendors or any other general topic. Table 16.2 lists some suggested review ques- \\ntions for those topics. \\nTable 16.2: Suggested Post-Implementation Review Questions \\nPost-Implementation Review Topics \\nSchedule \\n¢ Did the project come in on time? \\n* If not, why not? Was the schedule realistic? What slowed us down? \\n* How can we prevent delays next time? \\nBudget \\n* Did the project come in within budget? \\n* If not, why not? Was the budget realistic? \\n* How can we prevent cost overruns next time? \\nSE SASS PRA ET RS SES SESE SS STS FT STS SE EST TF TS A TEESE \\n(Continued) \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 398}, page_content='Post-Implementation Reviews 365 \\nSE ES \\nTable 16.2: (Continued) \\nPost-Implementation Review Topics \\nSatisfaction \\n* Are we achieving the benefits we expected in terms of the return on investment (ROI)? \\n* Are the online analytical processing (OLAP) tool and other access and analysis tools \\nsatisfying the analytical business needs? \\nScope \\n¢ Were scope changes requested during the project? Were scope changes made as a \\nresult of prototyping? \\n* Was the impact analyzed and measured? What was the impact? Could it have been \\navoided? \\n* What did we learn about scope changes and the existing change-control procedure? \\nNegotiation Skills \\n* Were all requested functions and data implemented? Did the scope have to be \\nrenegotiated? \\n* Did other project constraints have to be renegotiated (time, quality, resources, budget)? \\n* Was the renegotiating process painless, or did it create friction between the business \\npeople and IT staff? \\n* What needs to be done to improve the renegotiating process? \\nStaffing \\n* Did we lose any key people during the project? \\n¢ Why did they leave? What was the impact of their departure? \\n* How can we avoid that type of loss in the future? \\n* Was the core team staffed properly? Were there too few or too many team members? \\n* Were the roles and responsibilities assigned appropriately? \\n* Did the team members work well together? Was there friction? If so, what was the \\nreason for the friction? \\n* How can we increase team spirit and team morale in the future? \\nSkills and Training \\n* Were the skills of the team members sufficient? Was “just enough and just in time’ \\ntraining provided or was “emergency training’ required during the project? \\n* Was the provided training effective? What should be done differently next time? \\n(Continued) \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 399}, page_content='366 Step 16: Release Evaluation \\nene I EE RI I RD \\nTable 16.2: (Continued) \\nSe el \\nPost-Implementation Review Topics \\nProject Planning and Reporting \\n* Did the team report “actual time’ truthfully? If not, why not? \\n« Were the activities estimated correctly? If not, do we know why they were \\noverestimated or underestimated? \\n* Does our procedure for tracking time and reporting project status work? How can we \\nimprove it? \\n* What other lessons did we learn about project planning, tracking, and reporting? \\nDevelopment Approach \\n¢ Did we select the appropriate steps, activities, and tasks from Business Intelligence \\nRoadmap? If not, why not? \\n¢ Were important tasks left out? Were unnecessary tasks included? \\n* Did we use the operational prototype approach for application development? Did it \\nwork? What were the benefits? \\nContractors, Consultants, and Vendors \\n* Did we effectively use outside consultants or contractors? \\n¢ Did they transfer their knowledge to our staff? \\n* What lessons did we learn from negotiating with vendors? \\n* Did the vendors follow the rules or try to go around them? How can we control that \\nsituation in the future? \\nGeneral \\n* Was communication effective? \\n* Were business people available when needed? \\n¢ What other lessons did we learn? What should be done differently next time? \\nOrganizing a Post-Implementation Review \\nConsider the following items when organizing a project review. \\n* How to prepare for the review: The project manager has to take some time to \\nprepare for the review by: \\n— Examining the issues log to see which issues were effectively resolved and \\nwhich were not \\n— Assessing the change-control procedure for its effectiveness \\n— Reviewing the project plan to determine whether all the appropriate tasks \\nwere included \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 400}, page_content='Post-Implementation Reviews 367 \\n— Studying the estimated and actual task completion times on the project plan \\nto determine which tasks were underestimated and which were overestimated \\n— Noting any problems with the technology platform, such as problems with \\ntools or their vendors, hardware, network, and so on \\n— Reviewing the budget to see if the actual expenditures came close to the \\nestimated ones \\n— Assessing the effectiveness of the training sessions \\nAll of these items are potential topics for discussion at the review. \\nWhen to schedule the review: It is advisable to wait for two months after \\ngoing into production before holding a formal review of the BI application. \\nThis will give the project team time to iron out all the glitches that are com- \\nmon during the first few weeks after “going live.” It will also give the project \\nmanager and the business sponsor time to: \\n— Review the project charter, project plan, project reports, project activities, \\nand budget \\n— Collect information and metrics about the usage of the BI application, the \\nBI target databases, and the meta data repository \\n— Organize the meeting \\nWhere to hold the review: The review session should be held offsite. Pagers \\nand cell phones should be used for emergencies only; they should not ring dur- \\ning the session. The room should be set up as a conference room supplied with: \\n— Several flipcharts \\n— An overhead or data projector \\n— Markers and masking tape \\n— Two laptops, one for the facilitator and one for the scribe \\n— Coffee—lots of strong coffee \\nHow long the review should last: A well-organized, thorough review usually \\nlasts two full days, especially for the first release of a new BI application. \\nHowever, if time is in short supply, or if the release was small in scope and \\neffort with no significant hurdles, one full day could be scheduled with the \\noption of a follow-up session within two weeks if necessary. \\nWho should attend the review: All team members from the core team and \\nthe extended team should be invited to participate in the review. They must \\nbe prepared to contribute. That means they must review the agenda and pre- \\npare to discuss the topics listed on it. They must also review any documents \\nsent to them ahead of time and be prepared to discuss them. In short, every \\nproject team member should be an active participant! \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 401}, page_content='368 Step 16: Release Evaluation \\n- What to discuss during the review: A preliminary agenda should be pub- \\nlished about four weeks before the scheduled review session. \\n— The preliminary agenda should list all topics, including introduction and \\nwrap-up, with estimated time allocations for each topic. \\n— The time estimates must take into account the complexity of the topic and \\nthe number of people participating. \\n— Everyone who is invited should be given the opportunity to add to the \\nagenda and submit any pertinent documents to be reviewed. \\n— About two weeks before the review session, the final agenda and all docu- \\nments should be sent to the attendees. \\nPost-Implementation Review Session Flow \\nPost-implementation reviews are very structured and follow a prescribed proce- \\ndure by which the group must abide. Figure 16.2 illustrates the typical flow of a \\nreview session. \\nFaciliator \\nBusiness Sponsor Project Manager Facilitate Business Sponsor Discussions Nee \\nOpen Session Be a! Close Session and Rules \\nDocument \\nDiscussions \\nScribe \\nFigure 16.2: Post-Implementation Review Session Flow \\nCertain people conduct certain parts of the meeting (Figure 16.3), as \\ndescribed briefly below. \\n+ The business sponsor should open the meeting and give an introduction \\nbefore turning the meeting over to the project manager. At the end of the ses- \\nsion, the business sponsor should close the meeting. \\nThe project manager should discuss the flow, the rules, and the expectations \\nof the review, then turn the meeting over to a skilled facilitator. \\nThe facilitator should lead the group through the topics on the agenda. The \\nfacilitator’s responsibilities include the following: \\n— Asking the person who owns a topic on the agenda to introduce the topic \\n— Soliciting comments and feedback from the other participants \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 402}, page_content='Release Evaluation Activities 369 \\nFacilitator \\nFacilitates the \\nProject Manager entire session \\nSets the rules \\nand expectations \\nfor the session \\nBusiness Sponsor \\nOpens and closes \\nthe session \\nScribe \\nDocuments the session \\nand the action items \\nFigure 16.3: Conducting a Post-Implementation Review \\n— Assuring that the meeting does not get bogged down on any given topic \\n— Monitoring the allocated time for each topic and interrupting the discus- \\nsion when the time limit has been reached, at which point the facilitator \\nmust temporarily turn the meeting over to the project manager for a deci- \\nsion (see below) \\nThe “scribe” is a person who was not involved with the BI project. The main \\npurpose for having a third-party scribe is to have a knowledgeable but neu- \\ntral note taker who: \\n— Documents the highlights of all conversations and comments \\n— Documents identified action items and to whom they were assigned \\nIf more time is required for a topic, the project manager and the business \\nsponsor must decide whether to continue the discussion beyond its allocated \\ntime or to cut the topic short and discuss the remaining topics on the agenda. In \\neither case, a second meeting has to be called to either finish the discussion on the \\ninterrupted topic or to cover the other topics that had to be dropped from the \\nagenda during this meeting. \\nAt the end of the review session, all action items are reviewed, and the person \\nto whom an action item was assigned estimates a completion date or a reply date \\n(the date on which an estimate will be provided for the effort to complete the \\naction item). The group must decide who will get the task to follow up on the \\naction items and whether another meeting is necessary (and if so, how soon). \\nRELEASE EVALUATION ACTIVITIES \\nThe activities for release evaluation do not need to be performed linearly. Figure \\n16.4 indicates which activities can be performed concurrently. The list below \\nbriefly describes the activities associated with Step 16, Release Evaluation. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 403}, page_content='Step 16: Release Evaluation \\na a \\npost-implementation \\npost-implementation \\nPrepare for \\nConduct \\npost-implementation \\ni eeting | \\nFollow up on \\npost-implementation \\nOrganize \\nreview meeting \\nFigure 16.4: Release Evaluation Activities \\n1. \\na \\nPrepare for the post-implementation review. \\nAll aspects of the completed project are subject to review. That includes strat- \\negies, plans, documents, designs, deliverables, procedures, and infrastructure. \\nThe goal of the review is to get an accounting of what worked well on the \\nproject and what did not, and to produce a list of action items to implement \\nchanges to the development process. \\n. Organize the post-implementation review meeting. \\nPrepare a list of discussion topics and an agenda, and distribute them to all \\nattendees. The agenda should list the date, time, place, attendees, and topics \\nto be discussed. Appoint a facilitator and scribe, and find a venue for the session. \\nConduct the post-implementation review meeting. \\nThe business sponsor should open and close the review session. The project \\nmanager should explain the agenda, the rules of the meeting, and the roles of \\nthe facilitator and the scribe. The scribe should document all discussion \\npoints, which must be reviewed at the end of the session. Assign any action \\nitems that come up during the session. \\nFollow up on the post-implementation review. \\nAction items are usually assigned to the attendees, but they can occasionally \\nbe delegated to staff other than the attendees. In either case, someone must \\nfollow up on the action items to ensure that they are performed. Action items \\ncan include updating the standards or the methodology, revising estimating \\nguidelines, seeking resolution to a business problem, or repairing an urgent \\nproblem that cannot wait for the next release. Prioritize functions or data \\ndropped from the scope due to constraints on the BI project so you can bun- \\ndle them with future releases. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 404}, page_content='Roles Involved in These Activities 371 \\nDELIVERABLES RESULTING FROM THESE ACTIVITIES \\n1. Post-implementation review agenda \\nThe agenda is the “program” for the review session. It lists the date, time, and \\nplace of the meeting; invited attendees; topics for review; and questions to be \\ndiscussed. \\n2. Post-implementation review meeting minutes \\nThis short document highlights all the discussions, suggestions, and resolu- \\ntions regarding the topics and questions on the agenda. \\n3. Action item list \\nThe action item list briefly describes each action item, noting to whom an \\naction item was assigned and showing a projected completion date (or \\nresponse date) for each action item. \\nROLES INVOLVED IN THESE ACTIVITIES \\n@ Application lead developer \\nThe application lead developer should be prepared to discuss access and analysis \\nissues on the review agenda. He or she may also actively participate in discus- \\nsions regarding database design, tool selection, and technical infrastructure. \\nTopics such as OLAP tools, ease of use, reports, and the extraction of data into \\nprivate data sets require input from the application lead developer as well. \\n® BI infrastructure architect \\nThe BI infrastructure architect should be prepared to discuss the technical \\ninfrastructure components, such as servers, network, the database manage- \\nment system (DBMS), and the various tools. In addition, the BI infrastructure \\narchitect should be able to address the scalability of the current platform and \\nthe plans for expanding the platform for future BI application releases. \\n@ Business representative \\nThe business representative who was involved in the BI project provides his or \\nher opinions—from a business person’s perspective—about the development \\nprocess. He or she may comment on budgetary issues, the project plan, the \\noverall management of the project, the effectiveness of his or her own contri- \\nbution to the project, testing activities, or on any other topic he or she feels \\ncould be improved. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 405}, page_content='372 Step 16: Release Evaluation \\n® Business sponsor \\nThe business sponsor spearheads the BI project from its inception to its \\nimplementation and initiates the post-implementation review. He or she \\nsends the invitation to the attendees, prepares opening remarks for the review, \\nand closes the session. \\n® Data administrator \\nThe data administrator must be prepared to discuss the data requirements and \\nthe business decisions made during the requirements and analysis activities. \\nThe data administrator should review the procedure used for resolving data \\ndisputes and make recommendations for improving it. He or she can also con- \\ntribute to discussions about the nontechnical infrastructure. \\n@ Data mining expert \\nThe data mining expert should be prepared to suggest any necessary improve- \\nments to the BI application (or the BI decision-support environment as a \\nwhole) that could enhance the use of the data mining tool. These suggestions \\ncould involve discussions about the extract/transform/load (ETL) process, the \\ncleanliness of the data, and the completeness of the data, as well as any limita- \\ntions the current technologies impose on data mining activities. \\n@ Data quality analyst \\nThe data quality analyst should be a very active participant on the topics of \\nsource data analysis and data cleansing. He or she must be prepared to present \\na summary of data quality problems. This summary should include the \\nimpact of the bad data on the BI application as well as on the operational sys- \\ntems. The data quality analyst must also explain what type of cleansing is \\nbeing performed in the ETL process. He or she should send out a document \\nbefore the meeting that lists the data elements not being cleansed, indicating \\nwhether they are being rejected or moved into the BI target databases as is. He \\nor she should also be able to discuss the current triage procedure for prioritiz- \\ning the source data for cleansing. \\n@ Database administrator \\nThe database administrator must be prepared to discuss the design and con- \\ntent of the BI target databases and how to navigate through them. If one of the \\nsession topics is database design or database performance, it is the database \\nadministrator’s responsibility to explain the database design decisions made \\nduring the project. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 406}, page_content='Roles Involved in These Activities 373 \\n@ Developers \\nAll developers, whether ETL developers, application developers, meta data \\nrepository developers, or Web developers, should be encouraged to share their \\nexperiences with the development process. This could include discussions \\nabout methodology, status reporting, technical infrastructure components, \\ntesting procedures, and any other topics directly related to their development \\nactivities. \\n@ ETL lead developer \\nThe ETL lead developer should be prepared to discuss the data transforma- \\ntions being performed in the ETL process. He or she must be able to explain \\nhow the data from the source systems is being reconciled to the BI target data- \\nbases and where the reconciliation totals can be viewed. On the technical side, \\nthe ETL lead developer may actively participate in platform scalability and \\ntool discussions. \\n® Facilitator (not on the BI project team) \\nThe facilitator must be someone who was not directly involved with the \\nproject. This person must have training in facilitation. His or her responsibili- \\nties include time-boxing questions and discussion topics, halting runaway dis- \\ncussions, keeping on schedule with the agenda, giving turns to attendees to \\nspeak, and in general “directing traffic” at the review meeting. \\n® Meta data administrator \\nThe meta data administrator must be prepared to discuss what meta data is \\navailable and how to access it. He or she should send out a document with \\nmeta data examples prior to the meeting. The meta data administrator should \\nalso walk through the ETL load metrics that are being captured in the meta \\ndata repository, such as ETL reconciliation totals, trapped data error totals, \\nand data quality (reliability) statistics. \\n@ Project manager \\nThe project manager is primarily responsible for organizing the review ses- \\nsion. This includes finding a venue, creating the agenda, shipping documents \\nto be reviewed during the session, scheduling the session, arranging for a facil- \\nitator and a scribe, and following up on action items. \\n@ Scribe (not on the BI project team) \\nThe scribe’s main responsibility is to document the review discussions. The \\nscribe writes and distributes the minutes of the meeting, prepares and distrib- \\nutes the action item list, and helps with other administrative activities. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 407}, page_content='374 Step 16: Release Evaluation \\n@ Stakeholders (including data owners) \\nOccasionally other stakeholders may want to participate in the post-imple- \\nmentation review. Stakeholders could be business people from other depart- \\nments, the data owners of the operational source data, or IT staff from other \\nBI applications who want to benefit from the lessons learned. Stakeholders \\ncould also be staff from operations, technical support, or the help desk. In \\ngeneral, stakeholders (with the exception of the data owners) do not actively \\nparticipate in the review discussions. \\n@ Subject matter expert \\nThe subject matter expert is an active participant who represents the business \\nview during the review discussions. Topics of data quality, meta data, ease of \\nuse, and problem resolution procedures should be of particular interest to this \\nperson. The subject matter expert may also contribute to the discussions \\nregarding cost justification, the measurement of ROI, the impact on opera- \\ntional systems, and potential improvements to business processes. \\n@ Web master \\nThe Web master must be prepared to review the Web application issues and to \\nanswer questions regarding data access capabilities through the Web, as well as \\ndata security on the Web server. If some data is accessible globally through the \\nInternet, the Web master should invite the security officer to the meeting to \\nanswer global security and privacy questions raised during the review session. \\nRISKS OF NOT PERFORMING STEP 16 \\nAs George Santayana once said, “Those who cannot remember the past are con- \\ndemned to repeat it.”! This statement applies to BI projects as much as it does to \\nlife and politics. In order to know how to improve the next project, you have to \\nlearn from the mistakes made on the last project. The post-implementation \\nreview is the vehicle for discovering the mistakes and correcting them. Excluding \\nthis step would result in repeating the same mistakes in a rapidly growing envi- \\nronment that affects more people with each release. We have learned from experi- \\nence that correcting mistakes on small systems is much easier than correcting \\nmistakes on large systems. The BI decision-support environment can nae \\nbecome a very large system! \\n1. Santayana, George. Life of Reason, Reason in Common Sense. Scribner’s, 1905, p. 284. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 408}, page_content='Bibliography and Additional Reading 375 \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nAdelman, Sid, and Larissa Terpeluk Moss. Data Warehouse Project Management. \\nBoston, MA: Addison-Wesley, 2000. \\nBeck, Kent. Extreme Programming Explained: Embrace Change. Boston, MA: \\nAddison-Wesley, 2000. \\nCockburn, Alistair. Agile Software Development. Boston, MA: Addison-Wesley, \\n2002. \\nDeMarco, Tom. Slack: Getting Past Burnout, Busywork, and the Myth of Total Effi- \\nciency. New York: Broadway Books, 2001. \\nEnglish, Larry P. Improving Data Warehouse and Business Information Quality: \\nMethods for Reducing Costs and Increasing Profits. New York: John Wiley & Sons, 1999. \\nHumphrey, Watts S. Winning with Software: An Executive Strategy. Boston, MA: \\nAddison-Wesley, 2002. \\nInmon, William H., J. D. Welch, and Katherine L. Glassey. Managing the Data \\nWarehouse: Practical Techniques for Monitoring Operations and Performance, \\nAdministering Data and Tools and Managing Change and Growth. New York: John \\nWiley & Sons, 1997. \\nKuan-Tsae, Huang, Yang W. Lee, and Richard Y. Wang. Quality Information and \\nKnowledge. Upper Saddle River, NJ: Prentice Hall, 1999. \\nYourdon, Edward. Death March. Upper Saddle River, NJ: Prentice Hall, 1997. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 409}, page_content='anne 7 guano reat ire \\nSS x aria pak A, goers H \\n+, awe pew: ‘ \\nsak nial drecagbaeid aot Rpataly \\n>] —e - = \\nSeater xigte: Wine A Me Stina’ wt ping eae \\nage 4 eet) planets tog pro san eacrTIe \\npital nee ) a tn i ptr \\naedhe? sng awe apt wee hes i \\nal <i Mt ticle ir \\noe hi at ae dhs ny Ty ie watts, 2 E \\nTaye cs quested! a) bad orate That “Tees \\n’ ee aad Tear squats AEN 1M e ne \\ntien wie Sgt ain \\nmor ccies f forge { aol ie \\nGeis  o-o: ae es § \\nMele site a @ . wer iw yaetas tha yee WE aie \\nSe O86 eet 6.\" reek ws ) Des woul fA © \\nBR «od pede « = . => 06> fi Te se see? ning. is 4 \\nRae HO) Os AM | we D> pp ini Sus pew \\nmeses ® i” ele ie posites petra \\na SI) > “ewby a win fly re 9 yb \\nwh bine) Ga aie > 6% ORRe Ode “Ssh en | i nce 7 \\nHO @® SPOSY (sho de onli eee Woh eke Oe rae \\noe w hie liad rise Me \\' pointe, i wlomamsume / i \\n—— | oa \\niy ee “th --- [aa \\ni. Vopumpes | ree. 1 uf Abide aie we ne Y : \\n7 * \\n_ \\n=p eh = gin \\n- \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 410}, page_content='PART II \\nAt a Glance \\n377 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 411}, page_content='~~ FF \\nate \\nNS \\nae a \\né \\nsansios tA \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 412}, page_content='\"XUU}EWW \\nSIY} \\nUl \\nPa}Sl] \\nJOU \\naie \\nUO \\nOS \\npuke \\n‘WOddns \\n|ed1UYII} \\n‘SadIAaS \\nYIOMJOU \\n“AOUPNe \\n[| \\n‘JIQUMO \\nP}ep \\nSe \\nUNS \\n‘sajo1 \\nSuNOddns \\n‘pajsi| \\naie \\nYIOM \\nJUdLUdOJaAaP \\nJeYA \\nWUOJJad \\nyeU} \\nSajo! \\nay} \\nAJUO \\n“Gg ‘(uosiad auwies \\n3U} \\nO} \\npausisse \\naie \\nsajoi \\nBulddepiaro \\nUaayIp \\n1) \\nPAUBIsse \\naie \\nsajos \\naU} \\nMOU \\nUO \\nSulpuadap \\n‘sadinosal \\nJO \\nUOHEIO|JEJ9AO \\njeNUI}Od \\n9}e31PU! \\n0} \\n184}930} \\npaxog \\naie \\njajjesed \\nul \\npawUOLed \\naq \\nued \\ney} \\nsdais \\n‘e \\nSa \\na \\nSS \\nSEE \\nJOVEAJSIUILUIPE \\ne}ep \\nLIB \\nysAjeue \\nAyyjenb \\nejeq \\nJO}eJ}SIUIWUpe \\ne}eQ \\nuolenjeaq \\nposyPYe \\nanpnyjseyul \\n|g \\n@ \\ndINPNMYSesju] \\n[EdUYDI}UON\\'g \\nUOIPIS \\nJO}VEA}SIUILUPe \\noseqejeq \\nuoljenjeaq \\npPoPYIe \\nDINPNAJSeAUI \\n|G \\nAINNAJSeAU] \\nJEDNUYDIAL\\' \\nVW \\nUODIS \\nuolenjeaq \\nainyonsysesu] \\nasudiaj}uy \\n*Z \\nyYedxea \\nJayew \\npalqns \\nJOsCURW \\nPdlOld \\nysAjeue \\nAyjenb \\neleg \\nJosuods \\nssauisng \\n@ \\ndAI}E}UISIIdas \\nSSouISNG \\n@ \\nJUDLUSSASSY \\nASD \\nSsauIsng \\n‘| \\na \\nda}s \\nay} \\nUI \\nPaAJOAU] \\nSajOY \\nJOUA \\np \\nda}s \\njuauidojanaq \\n‘SJENPIAIPUI \\najdiyjNW \\n0} \\npausisse \\naq \\nAew \\najoJ \\nauo \\n‘Ajjeuols \\nSaji \\nadn \\niajdoad \\nyou \\n‘sayos \\nae \\nXLyeUW \\nSIy} \\nUl \\npays] \\nAve \\nXIIJVJ \\nUOTLIOT[Y \\ndd1NOsoy \\nUPUIN;T \\nNASI \\nNANSS \\nGaldveo \\n379 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 413}, page_content='Human Resource Allocation Matrix 380 \\nyYodxea \\nsayew \\npealqns \\nJO}EASIUILUPE e}eP ja \\nysAjeue \\nAyjenb \\neyeq \\nJO}eASIUILUpe \\ne}eq \\ndA}e}UaSaidal \\nssauisng \\nJadojaAap \\npea] \\nuonediddy \\nyodxa sayew pafqns Jaseuew palold JO}eASIUIWIpe yep ej} Jadojanap pea] 14 Jo}yess|ulpe aseqej}eq ysAjeue Ayyenb eyeq JO}eMSIUILUpe e}eq \\ndAl}e}UaSaIdaJ \\nssauIsng \\nJadojaaap \\npea] \\nuonediddy \\n$¢¢ +H HF OH1% OH OO O da}s ay} UJ PanfOAUu] SafoYy [DHA \\nUOIMUYaG \\nS}UsWaINbay \\nPaloid \\n‘y \\nSuljuueld \\npaloid \\n*€ \\ndajs juauidojanag \\nXL}e] \\nUOHeIO}|]|Y \\n324JNosay \\nULLUN} \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 414}, page_content='381 is Data Analys Development Step 5 \\nYadxa \\nJayew \\npalqns \\nJO}EASIUILUPe \\neyep \\neI \\nJo}yeJ}SIUILUpe \\neyeEq \\nJa}sew \\nGam \\nYedxa \\nJayew \\npalqns \\nSJOP|OYOHL}S \\nJO}eNSIUIWpe \\naseqejyeq \\ndAl}e}UaSaidaJ \\nssauisng \\nJadojaaap \\npea] \\nuonedijddy \\nyYedxe \\nsayew \\npalqns \\n(SI9UMO \\nJEP \\nBUIPN|DUl) \\nSJapjoydye}s \\nJO}eJ}SIUIWUpe \\ne}ep \\neI \\nJadojaaap \\npes} \\n1.14 \\nysAjeue \\nAyyenb \\neyeq \\nJO}e1}S|UIpe \\ne}eq \\ndAI}e}UISIIdas \\nsSauIsng \\n$+ 66% HF © @ \\nsiskjeuy \\nAuoysoday \\nejeq \\nela \\n7 \\nSuidA}o}01g \\nUOHed|ddy \\n-9 \\nsisAjeuy \\ne}eq \\n‘Ss \\nSS \\nSa \\na \\nES \\ndays \\nay} \\nUI \\nPaAjOAuT \\nSajoy \\n[DUA \\nSSS \\nSSS \\na \\na \\na \\ndajs \\njuauidojanag \\nXL}eW \\nUOHeIO]|Y \\nIDANOsSoY \\nUPLUNH \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 415}, page_content='Human Resource Allocation Matrix 382 \\n‘sdajs \\nyjog \\nul \\nayedidiyed \\nAjaAie \\nJsNW \\nOYUM \\nUO}eJ}SIUILUPe \\naseqe}ep \\ndU} \\nJO} \\nUOH}EIO||e \\nSWI} \\nJU} \\nspaye \\nAjUIeW \\nSIUL \\n‘pa}ajdwod \\naq \\nued \\nssad0/d \\n71.J \\nBU} \\nJO \\nUBISAap \\naU} \\na1OJaq \\npazIjeuly \\naq \\n}sNW \\nSaseqe}ep \\n9312} \\n|g \\nGU} \\nJO \\nUBISap \\nau} \\n‘Jajjesed \\nUl \\nPoaUUOpad \\npue \\npayie}s \\naq \\nUPD \\nSaI}IAIDe \\nUsISAp \\n[Je \\nYSNOUIy \\n*D \\nJO}EASIUILUPe e}ep e}dI/ JO}eISIUILUpe e}eq payyoe sinponyseyul 1g yYadxa Jayew palqns \\nJadojaaap \\npee] \\n14 \\nJo}eJ}SIUILUpe \\naseqe}eq \\nysAjeue Ayyenb eyeq \\nJadojaaap \\nped} \\n114 \\nJO}eASIUILUPe aseqej}eq JO}eASIUILUpe e}eq \\nJadojaAap \\npea \\nuonedddy \\n¢-¢ ee © OF © O% % \\nusisaqg \\nAioyisoday \\ne}eq \\nPW \\n‘OL ,UZISAq peOT/WWOJsUeIL/DENXI ‘6 \\nusisoq \\naseqe}eq \\n‘8 \\ndajs ay} UI PaAJOAUT Sajoy JOYA \\ndajs Juauidojanag \\nXLJeI] \\nUONSIO]/V \\nBANOSOY \\nUPLINH \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 416}, page_content='383 Extract/Transform/Load Development Development Step 11 \\nS1O}SOL \\nsladojaAap \\nAloysodai \\ne}ep \\nea \\nJo}eJjSIuWpe \\ne}ep \\neI \\nJO}ENSIUIWUpe \\naseqej}eq \\ndAl}e}UaSaidas \\nssauisng \\nYedxe \\nJayew \\npalqns \\nJO}eASIUILUPe \\naseqe}eq \\nYadxa \\nSuIuIW \\ne}eEq \\ndAl}e}UaSaidas \\nssauisng \\nJa}SeW Gam \\nsladojanap \\ngam \\nSJO}SAL \\nyYedxe \\nJayewW \\npalqns \\nJO}eNSIUIIpe \\naseqe}eq \\naAl}e}UaSaidas \\nssauisng \\nJadojaAap \\npea \\nuonediddy \\nsiadojaAap \\nuo}edddy \\nSJO}SOL \\nyadxa Jayew palqns \\nJadojaaap \\npes] \\n113 \\nSIadOJaAIP \\nLF \\nJo}ye}S|UIUpe \\nasegeieq \\ndAl}e}UASaJdad \\nSsauIsng \\noft 6H HHH HHH 6H HH 6H \\njUawdojanaq \\nAuoysoday \\neleg \\neIBW \\n‘vL \\nSUIUII \\nB}eQ \\n“EL \\nyUawudojaaaq \\nuoHediddy \\n‘z1 \\nJUIWO|aAVq \\nPeOT/WWOJSURIL/PeNXI \\n“LL \\nSSS \\naL \\na \\nda}s \\nay} \\nUl \\nPaAjOAU| \\nSafOY \\n[DHA \\nSS \\na \\na \\nEES \\ndajs \\njuauidojanag \\nXH}e \\nUORedIO]V \\n9DANOSOY \\nUPLUNH \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 417}, page_content='Human Resource Allocation Matri 384 \\nJa}SeW Gam \\nSiadojanAap \\nGam \\nsiadojanap Auopsodai eyep eyo JO}JEASIUILUPe e}ep ja Jadojaaap pea] 719 siadojaAap 114 \\nJo}eAS|UILUpe \\naseqe}eq \\nYedxa Sulullw ejyeq \\nJadojanap \\npea] \\nuonedijddy \\nsiadojaAap \\nuonediddy \\nS A A A A A A A A \\nuOol}e}USWs|dWwy] \\n“SL \\nda}s \\nay} \\nUI \\nPAAJOAU] \\nSafoy \\n[DIA \\ndajs \\njuauidojanag \\nXLJEJA] \\nUONSIO]/V \\nBANOSoyY \\nUPLINH \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 418}, page_content='385 ion Release Evaluat ° \\n° Development Step 16 \\nJa}SeW \\nGam \\nYadxa sayew pafqns \\n(SIQUMO \\nB}eP \\nBUIPN|DU!) \\nSIapjOyaxe}s \\n(wiea} \\nafoid \\n|g \\nBY} \\nUO \\n}0U) \\nAqUIS \\nJaseuew palold \\nJO}eJ}S|UIWUpe \\neyep \\neI \\n(wiea} \\nPafoid \\n|g \\nay} \\nUO \\n}OU) \\nJO}e}|IDe4 \\nJadojaaap \\nped] \\n114 \\n(qaM \\npue \\n‘Auoysodas \\neyep \\neyo \\n‘UO!}ed1|dde \\n“71 \\n4) \\nsiadojanaq \\nJO}e1}SIUIWUpe \\naseqeyeq \\nysAjeue \\nAyyjenb \\neyeq \\nYedxa \\nSulullu \\nejyeq \\nJO}eNSIUILUpe e}eq \\nJosuods \\nssauisng \\naAl}eyUasaidad \\nssauisng \\npoyyoie \\nainynsjsedul \\n1g \\nJadojaaap \\npea] \\nuonediddy \\n¢¢¢ $$ % O @ $e? ¢ $e %¢ OO O \\nda}s \\nay} \\nUI PanjoAu \\nSajoY \\n[DA \\nuolyeNI|eAF \\nVsevjoy \\n“OL \\na \\na \\nEES \\ndajs \\nJuauidojanaq \\nSSS \\nSSS \\nSSS \\na \\na \\na \\nSS \\nXL}eIA] \\nUOHeIO]]y \\n841nNOsay \\nUeLINY \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 419}, page_content='> \\naie \\n> - - : es “en si an \\na , 2 . > Pe\" LES \\n_ \\naaa” \\nte \\nmee \\nso \\n6 \\nines, \\neae \\nnih \\nean \\nea \\nota wate ase \\ntl \\nJy \\n(rare \\nceed \\n9G? \\nno \\ntee \\nKiet \\n« \\n: \\no \\nA \\n7 \\nator \\nch \\n—— \\n— \\net \\n| \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 420}, page_content='Pn \\na \\nra \\na \\nes \\nlh \\nge \\nee \\neee \\ni \\nwood \\nSUONEPUSLWILUODI9Y \\n— jUawWssasse ysIY — \\nsynsai \\nsisAjeue \\nWjauag-}soD \\n— \\nUOI}NjOS \\nIg \\npasodoid \\nay} \\n0} \\nBulyIWwWod \\nJOU \\npuke \\npaauU \\nssauisng \\n3u} \\nSUISSAIPPe \\nJOU \\nJOJ \\nSUOI}EIYIWEY \\n— \\npaau \\n}eUu} \\nAjsizes \\n[JIM \\nUOIed1|dde \\n1q@ \\n9U} \\nMOY \\njo \\nUO!}eUR|dxyW \\n— \\n(Aywunyoddo \\nssauisng \\nJO \\nWajqoid \\nssauisnq) \\n(JED1IUYII}UOU \\nSe \\n[JAM \\nse \\njed1UYI9}) \\nSasueUD \\n3s0U} \\nJO \\nsjuatauINbal \\naINJINYSeIUI \\nJOJ \\nSaNbay \\n“9 \\nMau) \\naSeajoJ \\n}XoU \\naseajas \\n10d \\nJU} \\nJO} \\nSJUaWaINbaY \\n“py \\ne WO \\nS}UaWasINbas \\nLua} \\n3109 \\nuoneridde \\npayyinsun \\n“s \\n9U} \\nJO} \\ndAI}E}UaSaIdaJ \\nAyunyoddo \\nssauisng \\n(aseajol \\nJoud \\n& \\nWO \\npauajap \\n387 \\nPdaU \\nSSIUISNG \\ndy} \\nJO \\nJUBW}e}S \\n— \\nssoulsng \\npaljijuap] \\n“€ \\nJO \\nWajqoid \\nssauisng \\n‘p \\nuoledijdde \\n(ajqissod \\nuo}jeddde \\nIg \\npasodoid \\nay} \\nJo \\nsaandealqo \\n— \\nyl \\n“osuods \\nayeulaye \\n1d \\n84} \\nJO \\nSAAIDaIGO \\n“€ \\nuoleziuesiO \\nue \\npuke) \\nJosuods \\ndAlyelyul \\nYoddns \\naU} \\nJO \\nsjeos \\nssaulsng \\nd1Sa}e4}5 \\n— \\nSSaUIsSng \\npaljijuap] \\n°Z \\n-UOISIDAP \\n|g \\n||eJBAO \\nAsewiwins aaiyndaxq — (JUaWaseUeW aANIaxa BY} JO} Ueld IIda}eI}S °Z \\n‘SuNUaWNDOp \\nssaulsng \\npue \\n|| \\nWoOds) \\nUOIJEZIULSBIO \\nJU} \\nJO \\nJUBLUSSASSY \\nyoda \\n}Uawssasse \\nase) \\nssauisng \\n‘| \\nJUBWASJOPUS \\nPalold \\n‘1 \\nsjeos \\nssauisng \\ndIsa}e41S \\n“1 \\nase) \\nssauisng \\n‘| \\nSa/qDsaAljaq \\nDUAyD \\nXJ \\npuayD \\nAuyuq \\ndajs \\njuauidojanaqg \\nXIIJRY] \\nSOTQeIIATIIG \\npue \\ne1IdyIT) \\nyxy \\n9 \\nAU \\nNAALHDIA \\nYALd \\nVHD) \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 421}, page_content='Entry & Exit Criteria and Deliverables Matrix 388 \\nspnpoid \\npayajas \\nJO \\nUO!}E]/e}SU \\n(aseysind) SulsuadI] \\npnpoid 10} suopepuawwosay — SdJ09S UOHeENJeAd JOPUDA — SalOdS UOH}eN|eAS JNpOld — Auoysodai eyep ea — \\n(dV10 \\n‘1L4) \\nS}O0} \\nJUBWUdOjaAaq \\n— (ZuLOPUOW sdUeWWOJJed ‘AlaA0da1 pue dnydeq) \\nsalpiiyn \\npue \\nAyjeuonouns \\nSWAG \\n— \\nujpimpueg \\n— S}JUQUOdWIOD YIOMIAN — Sade}9}U] WO}SND — \\n(sAemajes \\nSINE \\nAjjeidadsa) \\na1emalpplIW \\n— SUOI}E}SYIOM JWal|D — swajsAs Sul}eJado puke SIaAlas — \\n‘BULAAO0D \\n‘44OdaJ \\nJUBLUSSaSsSe \\nINPMYSeYU! \\n[ENUYIAL \\n* \\nsajqosanijaq \\nsapeisdn Jo spnpoid \\n(paseysind) pasuadi] ‘€ \\nsuolenjeAd \\nJOPUDA puke yNPOld *Z \\nWU} \\nJO} \\nSUOINIOS \\npue \\nsanss! \\nAyjiqiedwo) \\n‘1 \\nDIO) \\nHXF \\nuol}Njos |g pasodold “9 \\nSasUeUD diN}oNJ}sejyUul \\nJEdIUUII} JO} Jsanbay “¢ \\n(a1qissod 41 ‘““osuods \\n9}eUJa}e \\nUe \\npuke) \\nJOSUOdS \\nssauisng \\npayiuep| \\n‘y (JUaWaseURW aAI}Ndaxa ssaulsng pue || WO) \\njUaWasIOpUa Palold *€ \\nAyunyoddo \\nssaulsng JO Wa|qojd \\nSSOUISNG JU} JO JUDWI}E}S *Z \\nuoljed1|dde \\nId 84} JO sanoalqo ‘1 \\npisayly \\nAsyuz \\nuolenjeaq aunpMiysesuy JeEd1UUDAL \\n‘VW \\nUO!DIIS \\nuolenjeaq \\naunpnsyseyu] \\nasudia}uq ‘7 \\ndajs \\njuawdojanag \\nuonenjeng \\nainynsyseajuy \\nasiidia}zuq \\n:Z \\ndays \\nyuauIdojaAaq \\n=— \\nXL}eIA \\nSajqeJaAljaq \\npue \\neLayWD \\nWxy \\nBANU \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 422}, page_content='389 \\n—_—_ee_e_eeee—————— \\nssad0id \\nuoledIUNWWOD \\n— \\nainpadoJd \\nuoljnjosas \\nayndsig \\n— \\nuolunj \\nyoddns \\n— \\nSJUILUDIIBE \\n[BAIJ-IDIAVS \\n— \\nsainpasoid \\npue \\nspiepuejs \\nSuljsay \\n— \\nssad0id \\nase} \\npue \\nsoinseaw \\nAyjenb \\neyeg \\n— \\nSs \\nMOIA \\n3 \\nISUdia}Ua \\na/BUIS \\ne \\nOJU! \\nS|apOW \\n£ \\nej}ep \\njed1B0| \\nSUISJAW \\nJO} \\nssad01g \\n— \\n5 \\n(eyep \\ne}owW \\ne \\nJ2>!UYIa} \\npue \\nssaulsngq) \\nssadoid \\nUOlNJOs \\n|g \\npasodoid \\n“9 \\nie \\nAJaAljap \\npue \\nainyded \\nelep \\nejay \\n— \\nS8BUPY) \\ndINPNAYseyul \\ns \\nssad0id \\nAyindas \\n— \\nJED1UYII}UOU \\nJO} \\nsanbay \\n*s \\n8 \\nSalt \\n|Iqisuodsad \\npue \\nsajoy \\n— \\n(a1GQISssod \\nj1 \\n“osuods \\na \\nainpadoid \\njusawaseuew \\nsanss| \\n— \\n9}lUJa}e \\nUe \\npuke) \\n1OsSUOds \\n5 \\nainpadoid \\n(jou,U09 \\nSsaulsng \\npeayi}Uap| \\n“y \\ng \\nasuey)) \\nJuawaseuew \\nadods \\n— \\n(juUswWaseUeW \\ndAIINDaxa \\n7 \\nsauljapins \\nSuljewnysy \\n— \\nssaulsng \\npue \\n{| \\nWOds) \\nP= \\nAZojopouyawt \\nJUaWasJOpUa \\nDalold \\n“€ \\n= \\nJUSWdOJaAap \\neC jo \\nasp \\n— \\nAytunyioddo \\ng \\nsplepueys \\n— \\nWed} \\n3109 \\naloud \\n404 \\nssaulsng \\n40 \\nwajqoid \\nUOHEN[EAF \\nhe \\n2. \\n:0} \\nS}UBWIAAOICUUI \\nsauljapins \\njuawdojanaq \\n*z \\nSSOUISNG \\nJY} \\nJO \\nJUDW}E}S \\n* \\ndINPNA}SeAU] \\n= \\npasodoid \\nyym \\nYoda \\njuawssasse \\nainpnsjsedjul \\nuoljed1|dde \\nJBED1UYI9}UON \\ntad \\nONJINAISEAJUI! \\n[ENUYIA}UON \\n“1 \\nJed1UYd9}UO0U \\nPsAoIdU] \\n*L \\n1d \\n94} \\nJO \\nSAAIPAIGO \\n‘1 \\n‘g \\nUOIDAS \\nN \\ni \\n(panujuod) \\na \\nuonenjeaq \\n5 \\naunynyseUy \\n= \\ndsUdia}uy \\n*Z \\na \\n-_ \\nses \\n2 \\n$a/qDsaAlaq \\nDIA}LD \\nIXY \\nDuUaywD \\nAjuz \\ndays \\nJuauidojanaq \\n> \\n————_—_—_—_—_—_—nkn \\nee... \\nee \\na \\n(PanuUOd) \\nUoHeNjeAg \\nainynyseyuy \\nasiidisyuq \\n:7 \\ndays \\nyuauidojanaq \\n— \\nxujeW \\nSa|qe1aAljaq \\npue \\nela} \\nUx \\nRB \\nAnUy \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 423}, page_content='Entry & Exit Criteria and Deliverables Matrix 390 \\nuejd pafloig °Z \\nSIOPP} \\nSSadINS \\nJeINUD \\n— \\njUdLUSSasse \\nYysIYy \\n— S}UIEI}SUOD — suolduinssy — uejd uonjediunwwo, — \\naunponys \\nweal \\n— \\nSal}|Iqisuodsai \\npue \\nsajoy \\n— \\ns}UaWasINbal \\n[O0} \\nssaddy \\n— s}uaWadInbal \\nAyundas \\npue \\nAyiqejeay \\n— \\n(eseajaJ \\nsaseqejep \\nJoud \\n& \\nWO \\npauajap \\npue \\nsail \\nadunos \\nyo \\nUOIIpUOD \\n— \\n3SOU} \\nJO \\nS}UaWaIINbal \\n(papnpxa \\nMau) \\ndSea]jaJ \\n}XOU \\nAjyuanbasqns \\nyng \\npaysanbai \\naU} \\nJO} \\nsjuawasinbay \\n°g Ajjeulsu0) adods ul you sway — jUaussasse siskjeue \\nJapOW \\ne}ep \\n[ed1ZO] \\njaAaj-UZIH \\n— \\ndes \\naunjonijseiyul \\nPalaAljap \\naq \\n0} \\nease \\npalqns \\n— \\neet \\nenuaN \\n2 \\nsjuawalinbal \\njedUO}sIH \\n— \\nyuauussasse \\nsiskjeue \\ndes \\nsa|qeJaAljap \\nafoid \\nyeuoNduNy \\n— \\nSEIU \\nSE \\nAS \\nhehe \\nae \\nee, \\n(je>1UYDa}UOU \\nJUALUSSASSE \\nYSIY \\n“S \\npue \\njeu \\ne}) \\nsisAjeue \\ndes \\nsisA}eue \\nWauaq-}SOD \\n“fv \\nQINPNASCIJU! \\nOY} \\nWOAJ \\nSPNSOY \\n— \\n(a1q!Issod \\n1 \\n“osuods \\nsiskjeue \\nyespnq \\nparoiddy \\n“Sy \\npyaye \\nUe \\npue) \\nJosuods \\n1QUIg-}SOD \\nBU} \\nWO \\nsyNsay \\n— \\npeloud \\n1g \\npanouddy \\n“y \\nssauisng \\npayiuap] \\n“€ \\nuOlINJOS \\n|g \\npasodold \\n— \\nSSQDINS \\nJO \\nSOINSeI|| \\n“E \\nAyunyoddo \\nwajqoid \\nSIOPL} \\nSS9IINS \\n[eIIUD \\n°Z \\nssaulsng \\nJO \\nWajqold \\nSSOUISNG \\nBU} \\nJO \\nJUDW}E}S \\n— \\nuoljediniyied \\nJo \\nsjano] \\nSSOUISNG \\nJU} \\nJO \\nJUSWI}E}S \\n°Z \\nSaAlpe{go \\npue \\nsjeoy \\n— \\nJay} \\npuke \\nSJaquIdW \\nuoljyed1|dde \\n‘SUOIPDAS \\n9U} \\nUUM \\nJaWeUD \\nPalold \\n‘| \\nwea} \\npaloid \\npaynuap] \\n‘| \\n1g \\n9Y} \\nJO \\nSAAIDAGO \\n‘1 \\nSUIUU]d \\nPalold \\n“€ \\nsa[qnJanijaq \\nDUayAD \\nyg \\npiaywsD \\nAuyuqz \\ndays \\njuauidojanaq \\nSulUuUe]d \\nPalOid \\n:¢ \\ndajs \\nwUatUdOjaAag \\n— \\nXL}eW \\nSa|qesdAljaq \\npue \\neLayWD \\nWxq \\nB \\nAuUy \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 424}, page_content='391 inition ts Def: Iremen Project Requi ° \\n° Development Step 4 \\nS}UDW9AISe \\nJQAQ]-9dIAas AEUIWNIId — s}UdWadInbas Ayundas — s}UdWaJINbas Sulsuea}D-e}eq — jaPpOW eyep jed1So] JaAa|-YSIH — \\nAuoysiy Sulpn|dul \\n‘eyep \\n3dINOS \\nJO} \\nSJUBWAIINbay \\n— s}UdWaJINbal \\nAuanb pauued pue d0y py — s}UdWaJINbas SUIOday — \\n(saseqej}ep \\npue \\nsajlj \\n|euOeJado) \\nSadiNOs eyep |eUsa}xa \\nSSaDINS JO SaINSea| ‘OL SIO} SSADINS [LINUD 6 \\n(jed1UYd9}UOU \\nSe \\n||aM \\nse jed1UYd9}) \\nSasueud \\nJANPNASCAJUI \\nJOJ \\nysonbay \\n43} \\ns}UdWalINbal \\nMAN \\n7 \\npefoid \\n|g \\nsnoiAoid \\nwold \\nsjuaWalInbas \\npay|yinjun \\n“9 \\npauyap \\ndiysisumo \\nsjuoswauinbal \\npue \\nJeUJa}U! \\nPspejes \\n‘€ \\n(ssad0Jd) \\nssauisng \\n°s \\nJINJINASCAJU! \\n[EDUYDIO}UON \\n— \\n(Jed1|UYD9}UOU \\nse \\n[Jam \\nse \\n(aiqissod \\n41 \\n‘;osuods \\nsjuawasinbal \\njed1UYyd9}) \\ns}JUaWaUINbaL \\nayeusa}e \\nue \\npuke) \\n10suods \\naINPNMYSeU! \\n[EDNUYIAL \\n— \\ndIINPNASeIU! \\npale}aq \\n*Z \\nssaulsng \\npaljiuep| \\n“7 \\n:SUOI}IAS \\n(ssadoid \\nueld \\n~alold \\n“€ \\nTomuioe \\nSUIMO]|O} \\nJY} \\nUM \\n‘4UdWUNDOP \\npue \\ne}ep) \\nsjuaweauinbel \\nJayey \\nPalold \\n“7 \\ns}uaWasINbay \\nsyuawasnbas \\nuonesiddy \\n“1 \\npafoid \\npaylejed \\n‘1 \\npeloid \\n1g \\npanouddy \\n*1 \\npalold \\n“p \\naed \\nDOHA) \\nHXA \\nDiayD \\nAuz \\ndays \\njuauidojanaq \\nUOI}HUIag \\nS}JUaWaINbay \\nPaloid \\n:7 \\ndays \\nyUsWdojanaqg \\nXL}eW \\nSaiqesanljaq \\npue \\nevay1D \\nWxq-B \\nAquy \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 425}, page_content='SS \\nESE \\nEI \\nSAT \\nRR \\nAES \\nEEE \\nESSE \\nSD \\nSS \\nSRI \\nSE \\nA \\nCS \\nBE \\ngE \\nSR \\nET \\n‘paloid \\n[@ \\naU} \\nfO \\nsauads \\nay} \\nPulyaq \\nUOND.}SIUILUPD \\nD}DP \\nAq \\npajoa2 \\nAyjor1d \\nfq \\nsi \\najqosanljap \\nSIUL \\n:2}0N, \\nEntry & Exit Criteria and Deliverables Matrix \\n«|9POW \\nSosegeyep dd1NnOs \\neyep \\njed130] \\nasudsajzua \\npapuedxy \\n“pv \\npue \\nsajlj \\nad4nNOs \\nse \\n||aM \\nsuoljedyioads \\nSulsueajd-eyeq \\n“€ \\nse \\nS}UdWA]a \\nPep \\nJO \\nSIT \\n“OL \\ndiysiaumo \\neyeg \\n— \\ndiusiaumo \\nejeg \\n— \\n(a1qe]!eAe \\n41) \\nj|apow \\nsaljod \\npue \\nsajni \\nssauisng \\n— \\nsapijod \\neyeq \\n— \\nBYeP \\n[eI1BO] \\n|PA2I-USIH \\n6 \\nsulewog \\n— \\nsain \\neyeq \\n— \\nsjuawasInbas \\npafoid \\nsu}sua] \\npue \\nsadA} \\nejeq \\n— \\n(uleWOp) \\n}U9}U09 \\ne}eq \\n— \\nPajle}ep \\nYM \\nJUsWINIOp \\nsiayiuap! \\nanbiun \\n— \\nsuySua] \\neeq \\n— \\nsjuaWasINbas \\nuoIedI\\\\ddy \\n°g \\nSdiysuo}ejas \\neyeq \\n— \\nsadh} \\neyeq \\n— \\nJajapOW \\neyep \\npauled, \\nZ \\nSUO}IUOPp \\nPUL \\nSOWEU \\nP}eq \\n— \\nSJOIUSp!I \\neyeq \\n— \\nSJOUMO \\nbB}ep \\nAjjeidadsa \\n‘e}ep \\nPJOW \\nssauisng \\n*z \\nsdiysuonejas \\neyeq \\n— \\n‘aidoad \\nssauisng \\nJayj}0 \\nsainquny — SUOHUYap e}eq — 30 Ayiiqeiene awip-yed siaynuap! anbiun — sawieu e1eq — ‘QAlve}Uasaidas ssauisng \\nAyjeuondo \\npue \\nAyjeuipsey \\n— \\nJO} \\nEYEP \\neJOW \\nJo \\nIGEN \\nEM \\nSi) \\n9 \\nsaiua \\ndsuapeseyD \\n— \\nssaulsng \\npazipsepueis \\n° \\nPauyyep \\ndiysioumo \\neyed“ \\nsalua \\naanepossy \\n— \\nUaUssasse \\npauyap \\ndiyssaumo \\nsaliua \\njauay \\n— \\nAyjenb \\neyep \\nadinos \\n- \\n(ssad0d) \\nssaulsng \\n“y \\n“UUM \\n(21dads \\naalpedsiad \\nssauisnq \\nue|d \\npalold \\n“€ \\n-pefoid) \\njapow \\neyep \\njed/80| \\ne \\nWO \\nMaIA \\ne}ep \\nJayeyp \\npalo \\n*Z \\npeainquye \\nAjjn} \\npue \\npazijeUON \\n‘1 \\npezes1sajzUl \\nAljed1307 \\npefoid \\npanoiddy \\n‘| \\nsishjeuy \\nbeg \\n“Ss \\n392 \\nNe \\nSSS \\na \\na \\na \\nSSE \\nsa]qnsaAljaq \\nDIUA}LD \\nHXY \\nDay \\nAuyuq \\ndays \\njuauidojanag \\nSee \\nee \\nSS \\nES \\nSE \\nsisKjeuy \\ne}eq \\n:¢ \\ndajs \\n}uaWdojanaq \\n— \\nXL}eIA \\nSa|qeJanljag \\npue \\neLiayD \\nWxq \\nBANU \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 426}, page_content='393 ing ° \\nPrototyp . \\nication Appl Development Step 6 \\nSO] \\nSanss| \\n° \\nXi}eW \\nABAINS \\nSIIIHS \\n° \\n(suoldUN} \\npue \\ne}ep) \\ns}UaWaINbas \\npaloid payieyap uM JUaUNDOp s}UdWaJINbas UOI}EDI|dde pasiAdy ° adAjo}01d payajdwo ° \\n(asn JO asea ‘S|I[I4S ‘Spsepue}s) \\nJUIWIIIBe adepa}u! UOHedI\\\\ddy — \\n(1 \\nYOM \\nSEM \\n}! MOUY \\n[II \\n(19}UM \\nYOd~aI \\nJO) \\n100} \\ndV10 \\nJ0 \\nUOH}e]/E}SU] \\n© uolyen|eAd \\najdoad ssauisng Jay} \\njo \\nAyiqejfeae \\nawiy-yed \\n‘QAI}E}USSAIdad SSaUISNg \\njo \\nAyyiqeyeae \\nawi-IN4 \\n“8 \\nnoA \\nMOU) \\nssadINs \\nJO \\nsainsea \\n— \\npe \\nhacr \\nseth \\nyonpoid \\n(5100) \\nJ91UM Yoda 10 ; \\nadAjoyoid ay} 10} suuope|d ( i +e path ) yee Auanb pue siayim yodal) \\ndIeEMYOS \\npuke \\nJIEMPJEH \\n— \\n(19}UM \\n} \\ndV10) \\n5100} \\nSUNSIXe \\n10 \\nMEN \\n‘Z \\nadAjojoid JOO} sisAjeue pue ssadde \\ni \\nsUOdas \\nMAU \\nJO} \\nS}NOAR| \\n3} \\nJO} \\npasn \\nag \\n0} \\ne1eq \\n— \\nMau \\ne (Ang) \\nasuad)| \\nLodsrdnoseitadhiee \\n* \\n(aidoad \\nssauisnq \\n0} Jay}YM \\nUOISIIaG \\nFe) \\ni \\na \\npue \\nJ]) \\ns}juediyued \\nadAjo}0ld \\n— \\nAypeuolDduN} \\n|OO} \\nsone \\nEee) \\nSas \\n(paysa} \\n10 \\nuanoid \\naq \\n|IIM \\npayaA \\npue \\nOWap \\n[OO \\n° \\npoems), \\n. \\nyeu} \\nSOdas \\najdwies \\n*s \\nJLYM \\n‘pasn \\naq \\n|IIM \\nadAjo}ONd \\nJo \\nuoljed|dde \\nadA} \\nyeYyM) \\nsannpal{qo \\nadAjo}O1g \\n— \\nIq \\n104 \\nAytjigiseay \\npue \\nSuldAj}o}01d \\n10} \\njenoiddy \\n“p \\n(AyM \\npue \\npadAjo}o1d \\nSulaq \\n‘Syjauag \\n‘UOHe \\nWISN \\n° \\nsjuaWadInbas \\npaloid \\ns] \\nJuawauInbas \\nyeym) \\nadAjo}01d \\nsanigedes \\nPelleyeP \\nUNM \\nFUSWUNIOP \\nau} \\n10} \\nasodind \\nAuewid \\n— \\nSuniodas \\nquaun> \\nsjuatuasinbas \\nuoneriddy \\n“¢ \\n‘SUOIPAS \\nSUIMO]JO} \\npue \\nspaou \\nSuloda \\nueld \\npalold \\n°Z \\nSUIGA}O}O1d \\n3} \\nUUM \\nJayeyud \\nadA}0}01d \\n‘| \\njo \\nsisAjeue \\ndey \\n° \\nJayeud \\npoeloidg \\n‘| \\nuonerijddy \\n9 \\nsajqpJsanljaqd \\nDLUA}LD \\nHIXY \\npia) \\nAnuqz \\ndajs \\njuauidojanaq \\nSuidA}0}01g \\nuoneriddy \\n:9 \\ndays \\nJuawidojanag \\n=— \\nXL}e\\\\ \\nSa|qeJaAljaq \\npue \\neLazD \\nWxq \\nBANU \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 427}, page_content='Entry & Exit Criteria and Deliverables Matrix 394 \\ndiysiduMoO \\ne}ep \\neI \\n— \\nsaldljod \\npue \\nsajni \\nssauisng \\n— suIeLUOG — \\nsuj}sua] \\npue \\nsadA| \\n— \\nSJaluUap! \\nanbiun \\n— Sdiysuoljejas e}ep eI — \\nSUOHULAP \\nP}eP \\neja|I \\n— SOWEeU EJP LY — \\ns}UaWaJINbas \\nAloysodas \\najqejiene \\nyou \\npue \\npapaau \\ne}ep \\nJB \\nSNSIVA \\najqejiene \\nApeayje \\neyep \\n/2}EP \\nCJOW-L}o[| \\n“Z \\nejep \\nejau \\npayiejap \\ne}owW \\nJo \\nsisAjeue \\ndey \\n‘y \\nSOINGUAY \\n— \\nYUM \\nJUBWNDOP \\nS}USW \\nS}UQUOdWOD \\ne}ep \\ne}JOW \\nsiayiuap! \\nanbiun \\n— \\n-aiinbas \\nuoied|dde \\nMAU \\nJO} \\nS}JUdWAIINbaY \\n“¢ \\nAyjeuondo \\npue \\nAyyeuipsey \\n— \\nPaSIAal \\nJY} \\nO} \\nSa}epdn \\n- \\nAuousoda \\nsdiysuojejay \\n— \\nP}EP \\nCJL \\n[EDIUUIE} \\ne}ep \\nP}AW \\nBSUI}SIXS \\n9U} \\nSaljUa \\nISUs}eIeUD \\n— \\npue \\ne}ep \\nejyaw \\nssauisng \\njo \\nAyyeuoNouny \\nMau \\nJO} \\nSal}}Ue \\nBAeIOsSsy \\n— \\nusamjog \\nsulddey; \\n° \\nJo \\nAioysodas \\neyep \\ne}OW \\nSol}US \\nJAUEyY \\n— \\nAyyeuonpouny \\nMAU \\nB \\nJO} \\nSjUaWaIINbaY \\n*Z \\nsisAjeuy \\n:“8ulmoUs (padueyUa \\nAioysodai eyep \\npefoid \\nAsoysodai \\nAioysoday \\nJO \\nMAU) \\n|APOW \\nJAW \\n[eII3O7 \\n“1 \\nP}JALW \\nMAU \\nPalji}Uap| \\neyep \\neyowW \\npanoiddy \\n‘1 \\nejeq \\nePW \\n7 \\nSS \\nSSS \\nSa/qDJaAljaq \\nDUA} \\nHIXF \\nDiaywsD \\nAuyuz \\ndajs \\njuauidojanaq \\nee \\nsiskjeuy \\nAioyisoday \\n&}eq \\ne}aI| \\n:Z \\ndays \\nyUaWdojanag \\n— \\nXL}eW \\nsajqesantag \\npue \\neLiayD \\nWxq \\nB \\nAnuy \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 428}, page_content='395 \\nSess \\nmnEETEIEEETEEEREEEEEEREEEEREREEEEE \\ne}yep \\nweal}s \\n-YydI[2 \\npazuewuNs \\nUUM \\nasnoyalem \\ngam \\n— \\n(Sulpodas \\nsainpadod \\npaulayed \\n10} \\nsew \\naoueUaIUIEW \\naseqe}eq \\n‘9 \\ne}ep \\njeuoijesado) \\nsaseqejyep \\njosie} \\n1g \\njedISAUd \\n*S \\nseul \\nJado \\n— \\n(1Dq) \\na8ensue] \\njoUOD \\ne}eq \\n‘fy \\n: eerie \\nage \\nBeer \\nue SUO! \\n(aq) \\nssensuey \\nhe \\nes \\neer \\n© \\nUUM \\nsew \\ne}eg \\n— \\nssaulsng \\npazipsepueys \\n*S \\nepnltees \\n10} \\nUSIsap \\njapow \\neyep \\n[e>130| \\nsuyaysn|D \\n— \\nJPUOISUaWIPHINW \\nasuiduajua \\npapuedxy \\n‘y \\n& \\nSulUoNHed \\n— \\nSulyiodai \\n20yu \\n(ayI9ads-}afoud) \\njapow \\n3 \\nMeine \\nAe \\npe \\n10} \\neyep \\npalleyap \\neyep \\n[e180] \\npainquye \\na \\nquauare|d \\nyaseyeq \\n— \\nYUM \\nspew \\ne}eq \\n— \\nAyny \\npue \\npazijewuon \\n“¢ \\ng \\n:saseqeyep \\n(maa) \\nasnoyasem \\nS \\njasJe} \\n|g \\nJO \\nUBISap \\njedISAUd \\n‘Z \\neel \\nPeedi \\nS \\n‘ \\n: \\neyep \\nasuidiayuq \\n— \\npuke \\nSajlJ \\nIDINOS \\nSe \\n[JOM \\nPS \\nSeIPu] \\n— \\n(Sao) \\nse \\nSJUaWaja \\ne1eP \\nJO \\n}SI] \\n*Z \\ne \\nsajm \\nAyi8ajzu! \\n[eUsajoY \\n— \\naJO}s \\nEyep \\neuoiesadoO \\n— \\n(suonoun} \\na. \\nAyyeulpsey \\n— \\n10} \\nUSISap \\npue \\ne}ep) \\nsyuatwauinbas \\nAr \\nsKay \\nUsI9d10} \\npue \\nAuewid \\n— \\ndiysuonejas-A}}Uy \\npafoid \\npayieyap \\nuM \\n= \\nSULUNIJOD \\npuke \\nsajqeL \\n— \\n“BLUUIS \\nyUaWNdOp \\ns}UawasInbad \\nusIsaq \\n= \\n‘JaPOW \\neyep \\njedIsAUd \\n‘1 \\nuSisap \\naseqeieq \\n‘1 \\nuonedidde \\npasiaay \\n‘1 \\naseqeieg \\n‘8 \\na \\nee \\n= \\nsafqDsanjaq \\nDIAYAD \\nXY \\nDuUayiD \\nAjuq \\ndajs \\njuauidojanaq \\n> a SSS ST TY \\nra \\nuSisaq \\naseqe}eq \\n:g \\ndajs \\nyuaudojanag \\n=— \\nXe \\nSajqesantjeag \\npue \\neLia}yD \\nWxq4 \\nB \\nANUy \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 429}, page_content='Entry & Exit Criteria and Deliverables Matrix \\nSajqe} \\nPur \\nSajlj \\nyJOM \\nJUdUReLUAad \\npue \\nAuesodwa} \\nJO} \\nadeds \\nysIp \\npa}ed0]|V \\n— SaUeIG)| WeISOld — \\n‘UUM \\nBae \\nSUIZeIS \\n“py peo] je}UsWAaIU] — \\npeo] \\n[EdUO0}SIH \\n— \\npeo] \\njeuy \\n— \\n‘SWeIBOId \\nLJ \\nJO \\nS}aS \\nJos} \\nJO} \\nJUBLUNIOP \\nUBISAap \\nWeIBOId \\nFLW \\n“E \\nSalyiyn \\npeo] \\npue \\n‘Asia \\n‘Wos \\n— \\nSa|qe} \\nPUe \\nSajl} \\nYIOM \\njUaueUad \\npue \\nAiesodway \\n— \\nSa|NDOW \\nWeIsOld \\n— \\nsaseqe}ep \\n‘suowe \\n[00} \\n11d \\nJO \\nUORe|TeysU \\n“Ss \\nyodse} \\n1g \\n[ed1SAUd \\n°S \\nsalduapuadap \\nssad0id \\nSulmous \\nuoHen|ered \\nsuojedyioads \\nWweiseIp \\nMOY \\nssad0I/d \\n114 \\n‘7 \\nJOpuad \\npue \\ny~npoid \\n114 \\n“7 \\nSulsueal-e}eq \\n‘p \\nsuonezuewuuins \\npue \\n|00} \\n11] \\nue \\n(Anq) \\nasuad}| \\nejep \\nJaw \\nssauisng \\n“¢€ \\nsuOoH}eSaisse \\nJO} \\nSWUWOS|Y \\n— \\n0} \\nJBYJOYM \\nUOISID9G \\n‘€ \\n(jewua}xa \\npue \\njeUsayUI \\nSul|puey \\nS]E}O} \\nUOHEIINUOIOY \\n— \\ny}Oq) \\nsaseqeyep \\nadinos \\nJOM9 \\nPUL \\nUO!HPI[IDNUDIOY \\n— \\nsoujaw \\nAyyjenb \\neyeq \\n— \\npue \\nSaji \\nDINOS \\nSe \\n[JOM \\nSulydayD \\nAyZajzu! \\njeHUdaJaJaY \\n— \\nSd}SI}e}S \\nPROT \\n— \\nse \\nsjuaWala \\ne}ep \\nJO \\nIs] \\n“Z \\nSulsueal> \\nejeq \\n— \\n:SSa001d \\n(suonduny \\nSUOIJELUOJSULI} \\nEEG \\n— \\n11d \\nau} \\nAq \\npadnpoid \\naq \\npue \\ne}ep) \\nsyuawasinbas \\nJO} \\nSUOIPEIYINIdS \\nO} \\nB}ep \\nL}JOW \\nPalji}USP] \\n*Z \\npafoid \\npayieyap \\nYUM \\nusIsoq \\nUO!}EWUOJSULI} \\nUM \\nJUSWINDOP \\nssad0jd \\nT1J \\nJO \\nyUaWUNDOP \\ns}UdWaJINbal \\npeoy/Wuojsuely \\nSulddew \\n3a8Je}-0}-3dINOS \\n‘| \\nadUeUOPed \\npayadxXJ \\n‘1 \\nuoledijdde \\npasiasy \\n‘1 \\n/PeNXI \\n6 \\nSa{qD4s2Alaq \\nDLAI \\nXY \\npia) \\nAnuqz \\ndajs \\njuauidojanaq \\n396 \\nusIsag \\npeOT/WHOJsueIL/e1Xq \\n:6 \\ndajs \\n}UadOjanaqg \\n— \\nXL}eWW \\nSajqeJaAljaqg \\npuke \\neLiayLD \\nWxq \\nBANU \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 430}, page_content='397 ign Meta Data Repository Des Development Step 10 \\nuolunN} djay auljuO — \\nSadepa}Ul \\nSSaDdYy \\n— \\nsauianb \\npue \\nsoda \\nejep \\nejay \\n— SaDLP9}UI JOOL — sweis0jd peo] e}ep eI — \\nSWeISOId \\nUOIEWUOJSULI} \\npue \\neJ}Xa \\ne}eP \\nLIA \\n— \\nJO} \\nSUOIPEIYIOads \\nSulwwweiso01d \\nAioysodal \\ne}ep \\neyo \\nAsoysodai e}ep e}JOW 9} JO} TDA * Aioysodai e}ep &}aW ay} JO} 1d ° \\nsol \\nAySojzUul \\nJeUdajoY \\n— Ayyeuipsey — \\nskoy \\nUsIa10} \\npue \\nAJeWLd \\n— \\nSULUNJOD \\npuke \\nsage \\n— \\n‘JopOW \\neyowW \\njedISsAUd \\nmM a: \\npnpoid Auoysoda \\neyep \\nCJOW \\nJO \\nUOl}E]/C}SU] \\n* uolyenjerd JOPUSA pue ~Npod Auoysodai eyep eyo ° Aisoysodas eyep e}awW e pjing 40 (Anq) asuad|| 0} JOUJBYM UOISIDIG * usisap Asoysodai eyep PJ PAdULYUS JO MON \\ne}ep P}IW |eIUYII} pue eyep e}Jaw ssauisng usamjeq (4ul|) Suidde; * Ayyeuonpuny Auoysodas \\ne}ep \\nP}OLW \\nMAU \\nPaljijuap| \\n° Aisoysodai eyep \\n2}JIW \\n9U} \\nJO} \\nJaPOW \\nCOW \\nJed130] \\nP9dUeYUD \\nJO \\nMAN \\n* \\ns}UdWaIINbas \\nAloysodai \\neyep \\nPOW \\npaylejap \\nYM \\n}UBLUNDOP s}UdWaJINbas \\nuonedi|dde \\npasiaay \\n‘L \\nusIsoq \\nAuoysoday eyed \\nPW \\nOL \\nsajqpsanijaq \\nDIAYWAD \\nWXA \\npuayD \\nAuyuqz \\ndajs \\njuauidojanaq \\nusisaq \\nAioysoday \\ne}eq \\nBIW \\n:O1 \\ndajs \\n}UatdojaAsg \\n— \\nXL}e \\nSa]qeJaAljag \\npue \\neLaywD \\nWxyW \\nB \\nANUA \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 431}, page_content=\"Entry & Exit Criteria and Deliverables Matrix 398 \\n(sajnpow \\n100} \\n714 \\nSuluoNouny \\nAjjny \\nUUM \\nAleiqi| \\n{00} \\n7.19 \\n410) \\ns}duds \\npaj}so} \\nadue}daady \\n— \\npue \\nsuieisoid \\n714 \\nSuluo!DUN} \\npajsa} \\nAqiny \\nym \\nAseiql| \\nweisoid \\n114 \\n“€ \\naoueinsse \\nAyyjend \\n— \\n(pasn \\ns} \\nPd}S9} \\nSDUCULOJJad \\n— \\nease \\nSUIse}S \\n‘p \\nAyan \\nSWIG \\n& \\nssajun) \\nsaseqe}yep \\npa}S9} \\nUOISSAsOI \\nJUSWINDOP \\n39312} \\n|g \\nO}U! \\ne}ep \\npeoq \\n— \\nJO \\npajsa} \\nuoTe13a}U] \\n— \\nusisap \\nweis0ld \\n1LJ \\n“€ \\nP}YEP \\nBdUNOS \\nWAOJsSueI] \\n— \\n‘sojNnpOW \\nSalduapuaedap \\ne}yep \\nadinos \\n~eIpXq \\n— \\nJ00} \\n14 \\n40 \\nswessoid \\nssad0jd \\nSulmous \\n:0} \\n{00} \\n114 \\nOU} \\nILA \\npaysay \\nAlin \\n*Z \\n= \\nWesBeIp \\nMo} \\nssad04d \\n119 \\n°Z \\njuawdojanaq \\nJO} \\nSUOHINAYSU! \\nJO \\nSweISOId \\nTLJ \\n'Z \\nSSad01d \\nyUSWUNDOp \\npeo \\n]/WWOjsuelL \\nSaSPD \\n}S9} \\nUM \\nUPd \\n3S9} \\nLJ \\n'L \\n11] \\nsujuonDuny \\nAyjn4 \\n“1 \\nSUIddew \\n}98J2}-0}-3DINOS \\n*| \\n/PeRINXA \\n‘LL \\nSaiqDsanljaq \\nDUA} \\nHX \\nDiayD \\nAujyuq \\ndajs \\njuauidojanaq \\nJUBWUdOJaNaq \\nPeOT/ULOJsues] \\n/PeXA \\n: \\n11 dais \\nwuatudojanaq \\n— \\nXL}eI \\nSajqeJaAljaq \\npue \\neLa}D \\nWxq-B \\nANUy \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 432}, page_content='399 \\ns}nopuey \\nJUdUIPed \\nJaUIO \\n— SUOI}NIJOS JI9Y} PUL SaSIDJaXq — SyOOqyJOM JUapnis — Sa}0U JOPNISU] — Sapl|S UONL}UISAId — \\n:sjeuayeu SUIUIeLL “Ss \\n(Sa]npOW \\n|00} \\nd¥10 \\nSujuolpuny \\nAjjny \\nYM \\nAseqi] \\n[00} \\ndV10 JO) s}duds pue sweisoid \\nsaseqeyep \\nuonedijdde \\nSuiuonsuny \\nAjjny \\nya31e} \\n1g \\nJedISKUd \\n°9 \\nuum \\nAseigi| \\nweisoid \\nuonediddy \\n‘py \\n(5100) \\nuonedijdde 1g dy} JO S}UBUOdWOD sisAjeue pue ssad0e ay} JO} SUO!}DUNY \\ndV10 \\n10 \\nswessoid \\nuonediddy \\n‘¢ Sose) \\nAuanb pue sia}UM Yoda) \\npajso} \\nadueydady \\n— \\nS|OO} \\nSUI}SIX9 \\nJO \\nMAN \\n‘S \\npo}so} \\nsyodas \\nMau \\nJO} \\ns}noAe| \\nadueinsse \\nAyyjend \\n— \\nyoda \\ndn-yoow \\najdwes \\n“y \\nDevelopment ication Appl Development Step 12 \\n}S9} \\nUUM \\nUeR]d \\n3s9} \\nUOHedI|ddy \\n° \\nPd}S9} DDURWOPIad — \\nPp9}S9} UOISSAIBO/ \\npasn \\nAJaaipe \\nae \\npue \\nysixa \\nAjjuauNd \\nuo} \\nuN} \\ndjay \\naulluO \\n— \\nJO \\nuonesZayu] \\n— \\nye} \\nSodas \\najdwes \\n‘¢ \\nsaianb \\nsuoluUN \\n(suolpuny \\npue \\nsyiodad \\n10} \\nsuonejndje> \\n— \\ndV10 \\n10 \\nsweisoid \\npue \\ne}ep) \\nsyuawauinbas \\nsdeds \\nSulWWeIsOld \\n— \\nuoleddde \\npaysa} \\nAjjnj \\n° \\npoloid \\npayleyap \\nUUM \\nSUBISAP \\nBde}a}U] \\n— \\n(sweiZoud \\nyuaUNdOp \\ns}uaWasNbas \\nSUSISAP \\nUBS \\n— \\nuonedijdde) \\nuonedijdde \\nuojeridde \\npasaay \\n*Z synoAe] Woday — 1g 94} JO s}UaUOdWIOD (leuondo) AyjeuoNduNy \\n“SUIUIE}UOD \\nsisAjeue \\npue \\nuonedijdde \\njened \\num \\njUdWdojsANq \\n}UBWUNDOP \\nUsISap \\nUOHedI|ddy \\n* \\nssaade \\nSuluolDuNY \\nAjjn4 \\nadAjoj}oO1d \\npajyajdwoy \\n‘| \\nuoledddy \\n‘Z1 \\nsa[qDJanljaq \\nDIA}LD \\nIXY \\npiay) \\nAujuq \\ndays \\njuauidojanaq \\nquauidojanag \\nuoneriddy \\n:z1, \\ndays \\nyuatidojanaq \\n=— \\nXxLj}eIA \\nSa|qeJsaAljaq \\npuke \\neLayLID \\nWXxy \\nRB \\nANUA \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 433}, page_content='Entry & Exit Criteria and Deliverables Matrix 400 \\nAlaAoosip aspa|Mouy UO paseq \\nSalsa}eljs SSOUISNG MON ‘9 \\nuo]pDejsies \\nJAWO}SND \\naseaJDU] \\n— \\nJOO} \\nSujUuIL \\ne}eEQ \\n7 \\nJIeUS \\nJOYIEW \\nISedIDU| \\n— \\ns}Nsol \\nS}SOD \\naseaideq \\n— \\nSUIUIL \\ne}ep \\nau} \\n}aAdJ94UuI \\nyoud aseaidu| — 0} (UBIDIISIVe}S) adxe \\nanudAal \\naseaidU] \\n— \\nSUJUILW \\ne}ep \\npayedipaq \\n“9 :0} Saisa}e1}s UOI}}adWOD 3u} \\nSUIJAYILL MON ‘S JO SAIPAIDe SululwW eyeq “s \\nSUIUIW e}yep WO} (a|qIssod 41 ‘tosuods AJBAODSIP BSPa|MOUyY “v a}yeUJa}e Ue pue) JOSUOdS \\nSOIAIDe \\nSSQUISNG \\nPolfl}Usp] \\n“7 \\nSUIUIW \\nyep \\nJO \\nS}NsaJ \\nAywunyoddo \\n3} \\nSULINSCAW \\nJO} \\nUP} \\n“€ \\nssaulsng \\n40 \\nWajqoid \\nsuolj}ejado \\npue \\nSSOUIsng \\n94} \\nJO \\nJUBWaI}e}s \\n“€ \\nswUWOs|e \\nSulUlwW \\ne}yeq \\n°Z \\nuoHed|dde \\nejep \\nId \\na4} \\n$0 \\nsannda{qo \\n°Z \\nJapow \\nejep \\njedAjeuy \\n°Z \\n3y} \\nul \\nAlaAOdsSIP \\nWayed \\nSACU! \\nasegej}ep \\nSUIUIW \\ne}yeq \\n‘| \\nJO} \\nSJUQWAIINbaY \\n‘1 \\nSululw \\neyep \\npanoiddy \\n‘1 \\nSUIUI \\nb}eq \\n“EL \\nSa/qDJaAljaq \\nDIJA}AD \\nHX\" \\npDiayD \\nAuyuq \\ndajs \\njuauidojanaq \\nSUIUI \\n8}eq \\n:€1 \\ndais \\n}UaWidojanaqg \\n— \\nXLRI \\nSajqeJaAljaq \\npue \\neLazLD \\nWxq \\nBANU \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 434}, page_content='401 Meta Data Repository Development Development Step 14 \\n4 \\nSS \\nSS \\nI \\nsinopuey \\nJUdsUI \\nYad \\nJaUIO \\n— \\nSUOIJNJOS \\nJIdU} \\nPUL \\nSASIDJaXJ \\n— \\nSYOOGyJOM \\njUapN}s \\n— Sd}0U JOPNISU] — \\nSaPl|S \\nUOI}E}UASAId \\n— sjeua}yew \\nSuiules} \\nAsoysodas \\neyep \\nejay \\n“9 \\napins \\naduasajoy \\n— \\nainpasojd \\nBuljesado \\n— \\n‘UO}}e}UBWINIOP \\nuonanpoid \\nAuoysodai \\neyep \\nejay \\n“S \\n(sajnpow \\nynpoid \\nAuoysodas \\neyep \\nejaw \\nSulUo}DUN} \\nAjjn} \\n40) \\ns}duds \\npue \\nsuueisoid \\nAloysodai \\neyep \\nKioysodai \\neal \\nBulUOHDUNY \\nAlin} \\nUM \\nAyes \\nPJP \\nPBL \\naU} \\nJO} \\nweisoid \\nAiopsodai \\ne}ep \\nePW \\n‘7 \\nuonouny \\ndjay \\nauyjuC \\n— \\nuonouny \\ndjay \\nAiousodai \\neyep \\ne}aW \\nauljuo \\nAloysodas \\neyep \\nea \\n— \\nau} \\nWo \\nSuoday \\n— \\n(Sadej49}U! \\nssadde \\n(p9}s9} \\nAjsoysodas \\ne}yep \\nSulpnjdul) \\nuojyed1|dde \\nejyep \\ney \\n— \\naoueinsse \\nAyjenb \\npur) \\nJBL \\nJU} \\n0} \\nSadeLaIUI \\n(Sadej49}U! 00} SUIPN|dul) pa}sa} adue}daddy — JOO} pue ssaddy — \\nssad0id \\nUOHeISIW \\ne}ep \\nJIA \\n— \\npa}sa} \\nUOISSAISOs \\nAuoysodai \\neyep \\nJO} SUO!PUN} JO UO}}eISa}U] — P}JalwW ay} Suleindog — \\npnpoid \\nAuo}ysodai \\neyep \\neyo \\n:sajnpow \\njnpoud \\nJO} \\nJo \\nswiessoid \\nAsopsodad \\neyep \\neyIN \\n“€ \\nAuoyisodas \\neyep \\ne}ow \\nsuojeosyioeds \\nwessoid \\nSdSeD \\n1S3} \\nUUM \\nJo \\nswieisojd \\nAloysodas \\nAloysodas \\neyep \\neI \\n‘Z \\nueld \\njsa} \\nAsopisodai \\neyep \\nea \\n“Z \\neyep \\nPJaW \\npa}sa} \\nAljn4 \\n°Z \\nAuoysodai \\neyep \\nejaw \\njuawdojarAaq \\naseqej}ep \\nAsoysodas \\ne}ep \\n9} \\nJO} \\n(USISap \\naseqeyep) \\nAuoysoday \\nAioysodas \\neyep \\neyow \\njedisAud \\n‘L \\nejowW \\nSuluolDUNY \\nAng \\n“1 \\njapowW \\neyowW \\njedISAUd \\n‘1 \\ne1eq \\nEW \\n‘VL \\nSajqDJsanljaq \\nDLUA}D \\nIXY \\npiayD \\nAujuz \\ndajs \\nJuawidojanaqg \\nquawdojanag \\nAioyisoday \\ne}eq \\nPAW \\n:vL \\ndajs \\n}uauidojaneq \\n— \\nXL}e] \\nSA|qeJaAljaq \\npue \\neLa}UD \\nWxXq \\nB \\nAuyuy \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 435}, page_content='Entry & Exit Criteria and Deliverables Matrix \\nsapins \\naduasjajoy \\n— \\nsainpadoid \\nSuneiodo \\n— \\n:UO]e}UBWUNIOP \\nUOHDNpold \\n° \\n(SDUJOW \\nAyyenb \\neyxep \\n‘sje}o} \\nUO}eIIDU0IIL \\n‘SDI}SI}E}S \\nPeO}) \\ne}ep \\nejalW \\n71 \\nJ pue \\n‘eJEP \\nSOW \\n[LIIUYII} \\n‘eyep \\neJoW \\nssaulsng \\nYM \\npajejndod \\naseqejep \\nAioysodas \\neyep \\neyaw \\nUONNpOld \\n° \\nP}EP \\nBd1NOS \\n|PdUO}SIY \\npue \\njeu! \\nYM \\npazejndod \\nAjjny \\nsaseqej}ep \\njasJe} \\n|g \\nUOIDNpold \\n* \\nsweisojd \\nAuoysodas \\neyep \\neyaw \\nSUIUONUNY \\nAyiny \\nuyim \\nAsesqi \\nwessoid \\nAsoysodai \\neyep \\ne}aW \\nUOIDNpOld \\n* \\n(sisAjeue \\npue \\nssade) \\nsweisoid \\nuojjed;dde \\nsujuol}uny \\nAjjn} \\nYM \\nAyes) \\nweisoid \\nuonedijdde \\nuon \\nsnpoid \\n° \\nS}dids \\npue \\nsweisold \\nLd \\nSuluo;ouny \\nAjjny \\nYM \\nAseiqi \\nwessojd \\n719 \\nuolpnpold \\nSS9D9NS \\nSULINSESW \\nJO} \\nSIO \\n* \\nssav0id \\nAsoysodai \\ne}ep \\ne}awW \\nUODNpold \\nSuluonouny \\nAjjn4 \\n° \\nuonedijdde \\n{gq \\nuonDNpoid \\nSuluolpuny \\nAqjn4 \\n° \\nssad0jd \\n714 \\nuolpnpoid \\nsuluolpuny \\nAjjn4 \\naseqeyep \\nAloysodas \\neyep \\neyo \\njedisAud \\n° \\nsaseqejep \\n}o31e} \\n1g \\nJed1SAUd \\n° \\nsuolpun} \\npnpoid \\nAuoysodai \\neyep \\ne}yaw \\nJO \\nsweisoid \\nAsoysodai \\nejep \\neyo \\n° \\nsuolpun} \\ndV1O \\nJO \\n(sisAjeue \\npue \\nssadde) \\nsweisoijd \\nuonediddy \\n° \\n]OO} \\nLJ \\n2} \\n10} \\nsuOHNIYsSUI \\nJO \\nswiessO1d \\n714 \\nNN \\nUO}}e}USW|dW] \\n“S| \\n402 \\nCCC \\ncnn \\nnnn \\nSSS \\nSSS \\nSSS \\nSa/qDJaAl[aq \\nDIA \\nWD \\nHXY \\nbuUay) \\nAujuq \\ndays \\njuauidojanaq \\nEEE \\nEn \\nnnn \\nnn \\neSNG \\nuone}UsIWa|duy] \\n:¢1 \\ndays \\nyuawidojanaq \\n— \\nXL}eWW \\nSajqesanljag \\npue \\nPL9}UD \\nUXq \\nB \\nAUy \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 436}, page_content='403 ion Release Evaluat Development Step 16 \\nSS \\nSSS \\nSSS \\nSSS \\nJUSWdAO0IdWUI \\nJO} \\nSUONSaBsns \\n7 \\nyseoidde \\n}uawdojanap \\npefoid \\njo \\nsjyuawssasse \\npue \\nSUO}}eAIaSgO \\n}SOUOH \\n‘9 \\n}SI] \\nWo} \\nUOIDY \\n“€ \\nsido} \\nepuase \\nJO \\nSUON}N|OSaJ \\npue \\nsuOIsassns \\n— \\nSUOISSNDSID \\nJO \\nS}YSI|USIH \\n— \\n“SUIPJOIAJ \\nSO}NUILW \\nSUNIOW \\nMAIA9J \\nUOI}E}UIWA|AWI-}SOd \\n*Z \\nPassndsIp \\naq \\nO} \\nSUOH}SaNH \\n— \\nJUBWYSSAU! \\nUO \\nUIN}OY \\n— \\nQJIUCUWO}dd \\n— \\nuolpejsizes \\nssauisng \\n— \\nSSOUDAIPaHo \\nSUIUIEI \\n— \\nasn \\njo \\naseq \\n— \\nAyyenb \\neyeq \\n— \\nMalAaJ \\nJO} \\nSIIdOL \\n— \\nssadons \\najqeyeaday \\n“y \\n40} \\nS}UStONSEeWN \\nFS \\nSaapuaye \\npaiAu| \\n— \\nSW} \\nSJOQWISWW \\nWES} \\nSUNIIU \\nBU} \\nJO \\nadeId \\n— \\n}UdWAAOIdUI \\nssad0Id \\n*E \\npafoid \\njje \\njo \\nAyiqepeay \\n“y \\nSulaawW \\nau} \\nJO \\ndw} \\npue \\nayeq \\n— \\npausea] \\nSUOSSa] \\n*Z \\n30] \\nsanss| \\n“€ \\n‘Suljsl] \\nepuase \\nuolpeRjsies \\nueld \\npalold \\n°Z \\nuojenjeaq \\nMAIAaJ \\nUOH}L}UIWI|CWI-SOd \\n“1 \\nssaulsng \\nJo \\nuonenjeaq \\n‘1 \\nJUD \\nPalold \\n‘1 \\naseajay \\n‘OL \\n— \\nSSS \\nSa/qDJAAl[aqd \\nDIO}AD \\nWIXF \\nDia} \\nAnjuq \\ndajs \\n}uauidojanaq \\nSSE \\nuoHenjeAq \\naseajay \\n:91 \\ndajs \\n}uaWdojanag \\nXHIeW \\nSaiqesaatjag \\npue \\nevayiD \\nWxq \\n-B AnUy \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 437}, page_content='wre \\n‘ot \\nLa \\ni \\n7 \\n: Daas \\nune \\n: >)? \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 438}, page_content='aINJONASEIJU! jeo|uyoa}uoU \\n801d] \\n€ \\nyoda: \\nJuswssesse \\naunjon4jsesjul \\nJEO|UYD9]UOU \\nSLU \\nrd \\njueund \\npuedxy \\nWoe \\nv \\nyoda \\nJuswssesse \\nSINJONAJSEIU! \\n[EOIUYDS} \\nOY \\n€ \\nsjuauodwoo \\naiNjonsysesjul \\nfeEO!IUyYOe}UOU \\nJO \\nSSQUBAI}OA}JO \\nSSassy \\nL \\nsjonpoid \\nmau \\njoajas \\npue ayenjeag \\nc \\n—— \\nWwojje|d \\nBuljsixe \\nssessy L \\nuonenjeaq \\naInpNMjsesu] JED1IUUD9}]UON \\n“d \\nUOlDIS \\nuolyenjeaq \\naunyoNyseu| \\nJEdIUUDAL ‘VW \\nUOlDIS \\nuolenjeaq \\naINPNISeIU| \\nasldsa}uq \\n*Z \\nyoda \\nJUSWSSASSE \\nA}A\\\\ \\n6 \\nJUSWSSesse ySI \\nWOLad \\nsishjeue \\nyauaq \\n-]SOOD \\nWJOL8q Z \\nbo \\nUO!N|OS \\n|g asodolg \\n9 \\nIg \\neulWaleq \\nsenijeliul \\noddns-uoisioe! \\nIg \\n,S1oWWedwWoo \\nssassy \\n—- \\nv \\np J \\nseinpeooid \\npue \\nseoinos \\njeuoleiado \\nssassy \\n& \\npaeu \\nsseuisnq \\nBUIWE}18q \\nL \\nsuolnjos \\nssq \\njuauno \\nssassy é \\nSaMMAIDY \\nxIyepy \\nAsuspusdag \\nAWAY \\nNAALANIN \\nYalLdWHD \\nJUdLUSSasSsY \\nase) \\nssauisng \\n‘1 \\ndajs \\n}uauidojanaq \\n405 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 439}, page_content='Activity Dependency Matrix 406 \\nsalouedasosip eyep \\nanjosay \\nS \\nsuoneoyioeds \\nHulsueajo-eyep \\nay \\n9 \\njapow \\neyep \\njeoiHo} \\nasidiajue \\npuedxy v \\nAyyenb eyep \\ngoinos \\nazAjeuy € \\nsaounos \\neyep \\nfeoiBo) \\nauyoy \\njeusa}xe \\nazAjeuy L \\njapow \\neyep é \\nsiskjeuy \\ne1eq \\n°“s \\nsjuswaeaibe \\njanaj-ao1nes \\n| \\nAseuiwjaid \\nauyaq \\neyep \\n9ONOS \\n10} \\nSjuaWalINbes \\nauaq \\nv \\nsjuawasINbas Buljiodas \\nauyeag \\njusWWNDOP \\nsjusWaJINbe \\nMb \\nadoos \\njoaloid \\ng \\nuoyeaidde \\nayA, \\nMOIAOY \\n9 \\nSees \\nS \\nsjuawaoueyuS \\nah \\njeo160| \\npuedx3 \\naunjons|seju! \\n|2d|UYyd9]UOU \\n: \\n9 \\nJO} \\nS}usWaJINbas \\nauijaq \\nJ \\nC \\ns}uawaoueYyUS \\n‘| \\nauNJONISedju! feEd!UYoE} UO}IULNOG \\nJO} \\nsjuaWaJINbas \\naullEg \\ns}UdWalINbay \\nt \\n= \\npelold \\n‘bp \\naaa \\nae \\nue|d \\njoaloud \\njuauussesse \\njag|-uBiy \\nayean \\nYSU \\nASIAaY \\nseseqejep \\npue \\njo~aloud \\nZ \\ns10}0e} \\nssaoons \\nv \\n$9 \\n2oiNos \\na \\nas \\naie \\nJO \\n4OIy \\nfeono \\nApuap| \\nJO \\nUOI}I|PUOD \\nBuea \\n8 \\nJayeyo \\njoelfoid \\nS \\nsa]euiyse \\nSUILUI9}9q \\n; \\n| \\naredaid \\n}SOO \\n9SIABI \\nc \\n9 \\nJO \\naulWal|eq \\nSuluue|d \\né \\npaloid \\n“€ \\nSOIHAIDY \\ndajs \\njuauidojanaq \\nxijeW \\nAduapuadag \\nAyANDy \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 440}, page_content='407 \\nsjuawaiinbes \\nnie \\nAyenb \\nuolezuewuns \\nae \\nnotte.) \\nseinpasoid \\nsainjonijs \\nponece \\nae \\ng \\naoueuaqulew \\nrete \\naseqejep \\nee \\nel \\nmean \\naseqejyep \\nyebue} \\n1d \\njeoisAud \\n} \\nia \\né \\ndojansq \\nPung \\nubisaq \\neae \\nmer \\nenn \\n9 \\nS \\n’ \\n€ \\nsjuawasinbas \\nJOWUOW \\nee \\neo \\nee, \\naK: \\nusIisoq \\nL \\naseqejieq \\n‘8 \\nsjuawasinbes \\nBurjiodai \\npue \\nssaooe \\nAojisodas \\neyep \\nejow \\nazAjeuy € \\nAsoysodas \\neyep \\neyaw \\neyep \\nejaw-e}9W \\njapow \\nejaw \\n10} \\nsjuawiasinbay \\nayeal9 \\njealHo| \\nayeaig \\naoRyalul \\nazhreuy \\nS \\nv \\n; é \\non \\n£ \\nsjuawalinbas \\nAiojyisodas \\nsisAjeuy \\na \\n! \\n5 \\neyep \\nia \\nazAjeuy \\nKuousoday \\ng \\neyed \\neyo \\nZ \\ntee a \\nc \\nadAjojoid \\n40} \\n2 \\n$]00} \\n108}8S \\nhet \\nMf \\nadAjojoid \\ng \\n= \\npling \\na \\nadAjojoid \\n9 \\nJeyeyo \\naedhjojoid \\nadAjoj}oid \\nJo \\n<x \\na}elJSUOWaG \\nasedald \\nadoos \\naulwse}9q \\no \\nZ \\nsolianb \\npue \\nv \\né \\n& \\nsyodai \\nubiseq \\na \\nS \\nsjuewasinba \\nFs \\nsseo0e \\nao \\nSuidAyo\\\\o1g \\nE \\nuonedtiddy \\n9 \\nQa ie) \\n3 \\nsanlAny \\ndajs \\n}uauidojanaq \\n> (7) \\nra \\nxi}eW \\nAduapuadag \\nApAnoy \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 441}, page_content='Activity Dependency Matrix 408 \\nHulures} \\nsisAyeue \\npue \\n$sa00e \\nB}ep \\napiAdig \\nG \\nsuueiBoid \\nuolyeodde \\nise, \\nv \\nswes6oid \\nuoleoydde \\nubiseq \\nc \\nsuwes6oid \\nuoneoidde \\n}s9} \\nUN \\npue \\npling \\n€ \\nsjuawadnbad \\njoafoud \\njeuly BUILWa}Eq \\njUaWdojanaq \\nuoneriddy ‘Z1 \\nsseo0id \\n719 \\nS98} \\naouR}da00y \\nS \\nsseo0id \\n719 \\nSe] \\naoueINsse \\nAENO \\nv \\nsseo0id \\n719 \\n}S9] \\nSOURWIOLag \\n€ \\nsseooid \\n715 \\n1S9} \\nuoisseJ6aJ \\n10 \\nuol}es69}u| é \\nsseo0id \\n719 \\n}S9} \\nuN \\npue \\npling \\nL \\njUdWdojaAeq \\npeOT/WWO}SUeLL \\n/PRIX”ZA \\nLL \\nssadoid \\nuones6iw \\neyep \\nejow \\nubiseq € \\nyonpoid \\nAsoyisodai \\neyep \\nBOW \\nSO} \\nPur \\n|/e}SU] \\nZ \\nuoljeojdde \\neyep \\nejow \\nubiseq v \\naseqejep \\nAioysodas \\nusIsaq \\neyep \\nejow \\nubiseq \\nKiousoday \\nl \\neyed \\nPOW \\n‘OL \\nease \\nHulbe\\\\s \\n114 \\ndn \\njas \\noa suesBoid \\n43 \\nubisaq \\nv \\nsuojjoun} \\nJOO} \\n115 \\n}SeL \\nMO|} \\nSS8001d \\né \\n113 \\nubiseg € \\njuawinoop \\nBuiddew \\nusIsoq \\nPoe \\nae \\nayealo \\npeoT/WWOJsUeLL \\n/PeXF \\n6 \\nSATAY \\ndajs \\njuauidojanaq \\nxHieW \\nAduapuadag \\nAyAny \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 442}, page_content='409 \\najnpayos \\nuononpoid \\nsaseqejep \\naie \\nJUSWUOLIAUS \\nyoddns \\nBulobuo \\nuononpoid \\nv \\nuononpoud \\nuonejuawejdut \\n40} \\naedaig \\nUPd \\npeo7 \\ndn \\njas \\n9 \\ns}uguodwoo \\nL \\nS \\nZ \\nuolyeodde \\njg \\nI \\n|yeysuy \\n€ \\nee \\nee) \\nuoHe}UsWajdwy \\n“SL \\nBuiures} \\nAsojyisodas \\nuoyeodde \\neyep \\nejow \\neyep \\neJaW \\napiAoig \\n}S9} \\nUN \\npue \\npying \\n9 \\nsuonouny \\nJonpoid \\n410 \\nsweisBod \\n€ \\naseqeyep \\nAlojisode \\nAiousoda \\neyep \\nejaw \\nJsay \\neyep \\nejow \\npling \\nuononpoid \\n10} \\nAioyisodes \\nv \\nsseoojd \\nuonesbiw \\neyep \\nL \\njUdWdojaAIq \\neyep \\nejaw \\naiedaig \\ne]aW \\nSa} \\nUN \\npue \\npjing \\nKioysoday \\nS \\nZ \\n: \\nF \\nb}eq \\nejoW \\n‘VL \\non \\nMine \\n=A.) \\n£ \\neyep \\n= \\naledaid \\n= \\nS}INSOJ \\nJO \\nUOHEpIeA \\nv \\n= \\nJEUIO}X9 \\nWIOLad \\n= Lares \\nQ \\nOWI} \\nJBAO \\njJapowW \\neyep \\ni \\nZ \\njapow \\neyep \\neyep \\nasueajo \\nwajqoid \\n5S \\njeonAyeue \\nsoyUO/y \\njeonAjeue \\npjing \\npue \\nayepijosuo9 \\nssoulsng \\na}e}S \\nal \\n8 \\nsyjnses \\nBuruiw \\nS \\n€ \\nL \\n* \\neyep \\njaidiajuy \\nA \\n¢) \\neyep \\n= \\n103109 \\no \\nZ \\n= \\nSa \\nSUIUII \\nE}EQ \\n“EL \\nQa. \\ner \\nSSS \\n© 2 \\nSanIAROY \\nda}s \\njuauidojanaq \\n> \\n————————— \\nVv \\n5 \\nxljeW \\nAduapuadag \\nAyAnoy \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 443}, page_content='Activity Dependency Matrix \\n[ \\nHuljeew \\nMalAel \\nuolyejuawajdul-}sod \\nMAIAG4 \\nBuyjeaaw \\nMales \\noe) \\nuolye}UsW9|dUI-}sod \\nuolyejuawajdul-}sod \\né \\nuo \\ndn \\nmojo \\nyonpuog \\ni \\n© \\nMAIA2I \\nuolejuawe|dwi-jsod \\nJO} \\nuedaig \\nIL \\nuolenjeaq \\naseajay \\n“OL \\nSIAIDY \\ndaj}s \\njuauidojanag \\n410 \\nxl}eIW \\nAduapuadag \\nAWAY \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 444}, page_content='EN \\nSSS \\nSuIUIes} \\nJO \\nye] \\n— \\n3pod \\nWeIsOld \\nSAIpPajaq \\n— \\nSyDIYD \\nHpa \\nJO \\nye] \\n— \\nsaoeid \\nAljua \\neyep \\n100g \\n— \\n:JO \\nSWW9} \\nUl \\nSainpadoid \\nJeuoHesado \\nJUaIND \\nssassy \\n« \\nuoledijdnp \\neyeg \\n— \\nuojeindiuew \\neyeq \\n— \\nUOIPeI}Xa \\ne}eEG \\n— \\nAyjua \\neyeg \\n— \\n:}O \\nSUL} \\nUl \\nJUBLUDAOLWW \\n}EP \\n}UIIIND \\nJU} \\nSSaSSY \\n« \\nsaunpadoid \\nS}JUDWAJa \\nEJP \\nJDINOS \\n$0 \\n(UIELWOP) \\n}Ua}U0D \\n— \\npue \\nsadJnos \\nsain}jomjs \\naseqeyep \\npuke \\nsainyonjs \\naji4 \\n— \\njeuoneiado \\n‘JO \\nSUJ9} \\nUI \\nSWa}sAs \\nJeuOH}eJadoO \\nJo \\nAyjenb \\neyep \\nau} \\nssassy \\n« \\nOU} \\nssassy \\n“€ \\n}OU \\nae \\nS9UO \\nUDIYM \\npue \\nSsq \\nB8uUl}sIxa \\nay} \\nAg \\npajamsue \\nBulag \\nase \\nsuolsanb \\nssauisng \\nydiyM \\nBulAyUap! \\n‘siskjeue \\ndeS \\nWwuojlag \\n« \\nsuolnjos \\n(ssa) \\n(Ssadde \\n0} \\nYNDIWYIP \\n‘Saidua}sisuOdU! \\n‘ADUepUNpal \\nwaysAs \\nyoddns \\nBye \\n‘shay \\nJUBJAYIP) \\nSSC \\nSUNSIXa \\naU} \\nJO \\nSBUILUOILOYS \\na4} \\nSUIWWA}AG \\n= \\n—_yo|si>ap \\nyUaLIND \\nSSC \\nBUI}SIXd \\nBU} \\nJO \\naSeSN \\nJUaIND \\nssassy \\n» \\ndU} \\nSSassy \\n‘7 \\n(UN.UBAO \\n}SOD \\n‘adUaISaJOSgO \\n‘UOIadWODd \\n‘AyUNyOoddo \\njso] \\n‘QNUDAAI \\n}SO]) \\nPIBU \\nSSaUISNg \\nay} \\nJO \\nSodUaNbasuUOd \\n|e|DULULY \\nJUILIND \\nSUILUA}Aq \\n« \\npau \\nssauisng \\njuawssassy \\n(Ayjunyioddo \\nssaulsng \\n10 \\nWajgoid \\nssauisng) \\npaau \\nssauisng \\nay} \\nAjuapy \\n« \\nOU} \\nSUIW9}9Q \\n*| \\nase) \\nssauisng \\n‘1 \\nSYSD}GNS/SYSDL \\nSanIAIDY \\nda}s \\njuauidojanaq \\nXITIEW \\nYSeIGNS \\nse]. \\nALNAML \\nYUALdWHD \\n411 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 445}, page_content='a \\na \\na \\ned \\nPE \\n(IOY) \\n}JUBWSSAU! \\nUO \\nWUNJas \\npaypafoid \\nau} \\na}ejNd]eD \\n« \\nUOHLZIULBIO \\nJU} \\n0} \\nS}JaUdq \\nWa}-3uo] \\nAyUap] \\n— \\nUOHEZIULBIO \\nJU} \\nO} \\nS}JaUdg \\nWa}-OUS \\nAynuUapy \\n— \\ns}jauaq \\najqisuejzu! \\nAynuap] \\n— \\ns}yauaq \\najqisue} \\nAynuap| \\n— \\n-SHJOUS \\nUILUJ9}0Q \\nsisAjeue \\nyauaq \\nS}SOD \\nSUIWWI}Aq \\n« \\n-}SOD \\nCe WWO}ad \\n7 \\nTask/Subtask Matrix \\nJaPpOW \\nezep \\n[ed130| \\n(jen}daduOd) \\nJaAa]-YSIY \\ne \\na}eaID \\n» \\ns}udWalINbed \\nMU \\nYUM \\nspafoid \\n|g \\nsnoiAaid \\nwo \\nsjuawasinbas \\npayyinjun \\nazyuoud \\npue \\nayepyjosuoz \\n« \\nUOI}NJOS \\n[g \\npasodoid \\n9uy} \\n10} \\nainy~aPYDIe \\n[aAa|-YSIY \\ne \\na}eaID \\n- \\nuled \\nssauisng \\nay} \\nuassa] \\n{JJM \\nUOI}ed1|dde \\ng \\nau} \\nMOY \\naUIWA}aQ \\n« \\nsisAjeue \\ndeB \\nSSq \\nMa!Ady \\n« \\nuonnjos \\nSUOIINJOS \\nSSC \\n}USND \\nMAIADY \\n« \\nIg \\ne asodold \\n“9 \\nsjeo3 \\nSSOUISN \\n3!89}e1}S \\nBY} \\n0} \\nSAAIIA[qo \\nUOHeDI|dde \\n|g \\nDyIDads-afoud \\naU} \\nUdIEW \\n+ \\nsjeO8 \\nssaulsng \\n3189}e1}s \\nBY} \\n0} \\nSAAalqo \\nYoddns-uolsidap \\n|g \\n|J219AO \\nBY} \\nYdILY\\\\ \\n« \\nSaApPelgo \\nuoNedidde \\n|g \\nd4IDeds-}Dafo1d \\nay} \\naUuaq \\n- \\nSaAIPalgo \\nSaAefgo \\nYoddns-uols|ap \\n|g \\n||eJ2AO \\nJY} \\nBUaq \\nuoneridde \\n1g \\nUO}}EZIULBIO \\nBY} \\nJO \\nsjeOs \\nssauisng \\nIISa}eN}s \\nay} \\nAjUAp] \\n« \\n9U} \\nBUILUI9IOG \\n*S \\nsynpold \\nSAeAOUU! \\nJO \\n‘SJaWO}SND \\nMau \\n‘Sayes \\nSOAI}LNIU! \\nJJOW \\nSe \\nYONs \\n‘Sase}UeAPe \\nJaye \\nPaUles \\nSIO}JIdWOD \\nINOA \\nJAYIOUM \\nSUIWW}IQ \\n« \\noddns-uoispap \\nSOAEIU! \\nSUIUILU \\neYep \\nWay} \\nAjjeldadsea \\n‘saneniul \\nWoddns \\n1g \\n.SJo}}edWod \\n-UOISIDEP \\n|g \\nAAU} \\nYPM \\nSasNjle} \\npue \\nSassaddNs \\nS10}1}adWOdD \\naU} \\nSUILUAa}Oq \\n« \\n9U} \\nSSOSSY \\n“Py \\n————————_—————————————————————————— \\na \\nEE \\nSYSD}GNS/SY¥SDL \\nSATAY \\ndajs \\njuauidojanaq \\nES \\nJUDUISSISSY \\nBSED \\nSSOUISNG \\n:] \\ndais \\njUIWdojaAaqg \\n— \\nXiH}eW \\n¥se1qns/yseLl \\n412 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 446}, page_content='413 Case Assessment Business Development Step 1 \\nSSS \\nSSS \\nSSS \\n(s}UaWaAOIdUU| \\nssad01d \\nssaulsng \\njeuoHeJado \\napnjdul) \\nSuoMepUdaLULUODaY \\n— \\njUassasse \\nySIYy \\n— \\n10Y¥ \\npapedxa \\npue \\nuonedynsnf \\nysop \\n— \\n(SUOH}INJOS \\nBAeUJI}Ye \\nPue) \\nUONNIJOS \\n1g \\npasodolg \\n— \\n(paau \\nssaulsng \\nau} \\nSUIssaippe \\nJOU \\nJO \\nSUOH}EDYILWeJ) \\nSaIUN \\nOddo \\n3s07 \\n— \\nyoda \\n(Ayjunyoddo \\nssaulsng \\n10 \\nWajqoid \\nssauisng) \\npaau \\nssauisng \\n— \\njUawssasse \\n‘9QUISap \\n0} \\nWOdas \\nJUBLUSSASSE \\nJY} \\nJIM \\n« \\n3U} \\nIUM \\n‘6 \\nuOolNjoOs \\n|g \\ne SuNnuUsWwejdwI \\n}OU \\nPU \\nP|aU \\nSsaUlsng \\n3Y} \\nSUISSAIPPe \\n}OU \\nJO \\n(SUOHEIYILWULJ) \\nSYS \\nJU} \\nBUIWA}aQ \\n« \\nYsIY \\nJO \\n‘WINIPalW \\n‘MO| \\n:SySU \\nay} \\nyUeY \\n« \\nSYS \\nSY} \\nO} \\nS}USIOM \\nUBISSY \\n« \\n}USLWYSIAUI \\njelnueuy \\npue \\n‘Wea; \\npafoid \\n‘uoHeziUesi0 \\n‘UOe1B9}UI \\n‘AyXa]dWODd \\n‘AZojouUDa} \\njUawssasse \\nJO \\nSUU9} \\nUl \\nS¥SU \\nPafoid \\n|g \\najqissod \\n|je \\nSusi] \\n‘xUpewW \\nJUdLUSSasse \\nYSU \\ne \\n3}eAID \\n« \\nYSU \\n& \\nWUOJdd \\n‘g \\n— \\nSSS \\nSYSD]QNS/SYSDL \\nSAMA \\ndajs \\nJuauuidojanaq \\n_ \\nSSE \\nJUBLUSSassy \\nase) \\nssauisng \\n:| \\ndaj}s}uawdojanaq \\n— \\nxL}eW \\nyse}qns/yseL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 447}, page_content='EEE \\nSS \\nSSS \\nSSS \\nSSS \\nSSS \\nJOPE} \\nJYUSI9M \\nJUaWUINbal \\nau} \\nAq \\nyued \\nau} \\nBulA|dinw \\nAq \\nsOpUuaA \\nYdea \\nJO} \\n91S \\n[2}0} \\nBU} \\nBUIW}AQ \\n« \\nQUaWauINbas \\nay} \\nAysizes \\nJOUULD \\nJOPUBA \\naU} \\nSUPA \\n0) \\nOL \\n0} \\n0 \\nJO \\na]e9s \\ne \\nUO \\nS}yUdWaUINba! \\npa}Yysiam \\nay} \\nJsSUIese \\nJOPUDA \\nYea \\nYUeY \\n- \\nOL \\n0} \\n| JO \\naJeds \\ne \\nUO \\nJUDWAINbal \\nJOPUSA \\nYI \\nUSI9M \\n« \\nSIOPUDA \\nJU} \\nJO} \\nSJUBWIIINbaJ \\nANOA \\nJZIWA}| \\n« spnpoid |e JO SIOPUDA IIe 3ST] « \\nJ0}3E} \\nJUSIOM \\nJUBWaJINbal \\nau} \\nAq \\nyues \\nay} \\nSulAjdiyjnwu \\nAq \\nynpoid \\nYydea \\n10} \\nB10Ds \\n]2}0} \\nBY} \\nSUILLIA}AQ \\n« \\nQUaWasINbas \\nay} \\nAysi}es \\nJOUULD \\nNpoOJd \\noy} \\nsueawW \\nO) \\nOL \\n0} \\n0 \\nJo \\najeIs \\n& \\nUO \\nS}UdWAUINbal \\npa}Yyslam \\nau} \\nJsulese \\nyNpoid \\nyea \\nyUeY \\n- \\nOL \\nO} \\n| JO \\nayeds \\n& \\nUO \\nJUBWALINbaJ \\n}ONpoJd \\nUDded \\nUSIaM \\n« \\nspnpoid \\nay} \\n10} \\ns}uaWasINbas \\nINO \\n3ZIWa}| \\n« \\nAiosaye) \\nydea \\n10} \\npasapisuod \\nSulaq \\nsynpoid \\n|e \\n3sI7 \\n- \\nsjpnpoid \\n(sjoo} \\n‘SWIG \\n‘asema|ppiwi \\nMAU \\nPajas \\n‘quempiey \\n‘a]dwexa \\nJ0J) \\nayenjeAa \\n0} \\npaau \\nNOK \\nsauo8ayed \\npnposd \\nay} \\nAynuapy \\n« \\npue \\noyenjeaq \\n‘7 \\nTask/Subtask Matrix \\nayenbapeul \\nwes \\nsauO \\nYdIYM \\npue \\nayenbape \\nWaeas \\ns}uauodWo) \\nWoyye|d \\nYydIyM \\nSuIAyQUApI \\n‘siskjeue \\ndeS \\nWola \\n« \\n(S}sIxa \\naUO \\n}1) \\nAloySodas \\nEyep \\nEJaW \\nJU} \\nMaIAayY \\n- \\n(J00} \\nSujujW \\neyep \\n‘Sia}UM \\nOda \\n‘dV10 \\n“Ld \\n‘ASVD) \\nS100} \\nMalAay \\n« \\nSINAC \\n2} \\nMdIAdY \\n« \\nUIPIMPUe \\nPUL \\nS}UBUOGWOD \\nYIOMJOU \\nMAIADY \\n« \\nSODEJJI}U! \\nLUO}SND \\nMAIADY \\n« \\nuolyenjeaq \\nsAemayes \\nSING \\nAjjeladsa \\n‘aiemajppiW \\nMaIAay \\n« \\nwuoneld \\noIN}IN}SeAsU] \\nswa}sAs \\nSul}e19dO \\nMAIAaY \\n« \\nSunsixe \\nJEdIUYDIL \\nDIEMPILY \\nMAIAdy \\n« \\nQU} \\nSSASSY \\n‘L \\n\"Y \\nUOIDAS \\nuolenjeag \\nauNyON}SesU] \\nasudia}uy \\n*Z \\n—____ \\nSSS \\nSSS \\nSYSD}IQNS/SYSDL \\nsaniAnoy \\ndajs \\ndajs \\njuauidojanaq \\n—_—__—_—— \\nSSS \\nuoHenjeng \\nainyonaysejjuy \\nasiiduayuq \\n:z \\ndays \\nyuawidojanaqg \\n~=— \\nxi}eW \\nySeIqNS/yseL \\n414 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 448}, page_content=\"415 \\nSSS \\ns}npoid \\nMaU \\nUO \\nJes \\n[eEd!UYI9} \\nUIEAL \\n« \\nspnpojd \\nMau \\n}SaL \\n« \\nspnpoid \\nMau \\n|IP}SUl \\n> \\n wWoeid \\njuaund \\nsjnpoid \\nMau \\nJapsO \\n« \\nau} \\npuedxy \\n‘v \\nPla} \\nUO!Pa]as \\nJeUll \\n— \\nspnpoid \\nSulya{es \\n10 \\nSuIDajas \\n10} \\naJeEUOHeY \\n— \\n}SI] \\nYOUS \\nBY} \\nUO \\nSPNpPOld \\n— \\nS}SOD \\nPNpPOld \\n— \\nS3J09S \\nJOPUSA \\n— \\nSdJODS \\nONPOld \\n— \\ns}UaWaJINbad \\npa}ysiam \\nJO \\n3st] \\n— \\nyoda \\nAioysodai \\neyep \\neye \\npure \\n‘S}OO} \\n‘SING \\n‘UIpIMpueg \\npue \\nJUdLUSSasse \\nIOMIaU \\n‘SadejJazU! \\n‘AJeMa|ppIWW \\n‘sWIa}SAs \\nZuUNeJadoO \\n‘siaAlas \\nynoge \\nSSUIPUI \\n— \\naunyonNsj}Sesjul \\nAuewiuwins \\ndAiyndexq \\n— \\nJED1UYIE} \\n‘yodas \\nJUALUSSASSE \\nBU} \\nJO \\nSUO!}DIS \\nSUIMOJ|O} \\nJU} \\nU! \\n|II4 \\n3U} \\nSIUM \\n'E \\nEnterprise Infrastructure Evaluation \\ns}npoid \\nay} \\nasuad|| \\n0} \\njeAoJdde \\ns0suods \\nssauisng \\nule}qO \\n« \\nN \\n2 \\nnf \\nKio8aye) \\nJNpod \\nYdea \\nUl \\nPNpold \\njeuly \\nay} \\nBsSoOYD \\nponunee) \\n& \\ns1OpuaA \\nau} \\nAg \\npayes}sUOWaP \\nS}NpOJd \\n3y} \\nBACH \\n- \\nsionpoud \\n= \\nKio8aye) \\nUdea \\nUl \\nSIOPUBA \\nPUL \\nS}INPOJA \\njo \\njsI] \\nWOYS \\n& \\n9}e9/D \\n» \\nMaU \\nalas \\n= \\nSQ10DS \\nJOPUSA \\nPUR \\nSa10S \\nPNPOJd \\nay} \\na}eNnjeAq \\n« \\npue \\najenjeaq \\n‘Zz \\na. \\nerrr \\nLL \\n< \\nSYSD}GNS/SYSDL \\nsamHAnoy \\ndajs \\nda}s \\njuawidojanaq \\n> \\nTE \\nA \\nuonenjenq \\nainjponyseauy \\nasiiduayuq \\n:7 \\ndays \\nyuaudojanaq \\n— \\nXI}eIN \\nySe}qGns/AseL \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 449}, page_content='Task/Subtask Matrix 416 \\nee \\nee \\npefosd \\n|g \\nau} \\napisino \\npo}Uswa}duu! \\naq \\n0} \\ns}uUsWadUeYUA \\naINJNYSeU! \\n[ed1UYI9}UOU \\nPazWOLd \\n— \\npafoid \\n|g \\nay} \\nUUM \\npa}uawa|du! \\naq \\n0} \\nsjuaWasINbas \\nainyonyseyul \\n[ed1UYI9}U0U \\nPaZWOLd \\n— \\nyoda \\nS9BSULLP \\nJINIONAJSEAJU! \\n[EIIUYI}UOU \\nJO} \\nSUOT}EPUSLUWOD9Y \\n— \\njUalussasse \\nSassad01d \\npue \\n‘sainpadoid \\n‘sauljapin3 \\n‘spsepuejs \\na}enbapeul \\nynoge \\ns8ulpul4 \\n— \\nainpnsjseyul \\nAuewiuwins \\ndAiyndaxq \\n— \\njed1UYda}U0U \\n‘HOdaJ \\n}UALISSASSE \\nBY} \\nJO \\nSUOIPDAS \\nSUIMO][OJ \\nJU} \\nUI \\nIII4 \\n9U} \\nSWUM \\n*Z \\na}enbapeul \\nase \\nsduO \\nYdIUM \\npue \\najenbape \\naie \\nsainpadoid \\npue \\n‘sauljaping \\n‘spiepueys \\nydI4UM \\nBuIA \\nUap! \\n‘siskjeue \\ndeS \\nwWuojlad \\nSS9001d \\nUOH}EDIUNWILWOD \\n3U} \\nMaIAdY \\nssa00Jd \\nuolNjosad \\nayndsip \\nau} \\nMalAaY \\nuonduny \\nyoddns \\n|g \\nay} \\nMalAay \\nSS9D0J1d \\n(W1S) \\nJUBLWBIISE \\n[AAV]-adIABS \\nJU} \\nMIIANY \\nssad0id \\nadel} \\nSulsuea|d \\nay} \\npue \\nsaunseaw \\nAyjenb \\neyep \\nmalAay jepow \\nBJP \\nasiids9}Ud \\nJU} \\nOU! \\nSJBPOW \\neyep \\n|ed/30] \\nSULSIIW \\n104 \\nssad01d \\nBUY \\nMAIADY \\n« \\nAyjeuonsuny \\nAsoysodas \\neyep \\neJaW \\nMAIAdY \\n« \\ne}JEp \\n}AIW \\n[EDIUYII} \\nSe \\n[Jam \\nse \\nB}ep \\nPJalU \\nssaulsng \\nJOJ \\nsassad0id \\nAJaAljap \\npue \\nainyded \\neyep \\nea \\nMaIAdY \\n« \\nsauljapind \\npue \\nsassadojd \\nAyundas \\nMAIADY \\n« \\nSAI} \\n[IGISUOdS3J \\nPUL \\nS2lO1 \\nMAIAQY \\nSaJNpad0Jd \\nJUBWIASEULCL \\nSANSSI \\nMAIADY \\n« \\nSdINPIdO1d \\n[01}UOD-BSULUD \\nMAIADY \\n« \\nlisted \\nSOUIJAPINS \\nSUI}EWI}SS \\nMAIADY \\n« \\nainpnAseyut \\nuoHenjeAg \\nASojOpoy}awW \\nJUadojanap \\nau} \\nJO \\nasn \\nay} \\nMAaIAaY \\n« \\nje21UY3}UOU \\nSu! \\ndiNPNAsesJU] \\nuo}}el]INUODI1 \\nPuke \\n“SUI}Sd} \\n-]SIX9 \\nJO \\nSSOUSAI} \\nJED1UYIOJUON \\n‘SUI[aPOW \\ne}ep \\njed/3o] \\n‘SuOHeIAaqge \\n‘BUIWWEU \\ne}ep \\nJO} \\nSPAePUL}S \\nMAIADY \\n» \\n— \\n-DayJo \\n9} \\nSSASSY \\n‘1 \\n‘g \\nUOIDAS \\nSSS \\nSYSDIQNS/SYSDL \\nSaIAH \\noY \\ndais \\ndajs \\njuauidojanag \\nSSS \\nSSS! \\nuoHeNeAq \\na1nynJ}se4ju] \\nasiidiayuy \\n:7 \\ndays \\nyuauidojanaqg \\n~— \\nxLU}eA \\nyseIGNS/yseL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 450}, page_content='417 Ion Infrastructure Evaluat ise Enterpr Development Step 2 \\nSSS \\nB3UI4JOM \\n}0U \\nJO \\nayenbapeul \\naq \\n0} \\nsieadde \\nyeu} \\nssadoid \\nAue \\nAjipow \\nJo \\n‘papaau \\nse \\nsassad0id \\nMAU \\na}eaID \\n« \\nAiessadau \\nJ! \\n‘sulgaq \\nPafosd \\n|g \\nay} \\nalojaq \\nsalyiqisuodsas \\npue \\nsajos \\nau} \\nAJIPOW \\n« \\nAuessadau \\nJ} \\n‘Sulgaq \\nyaloid \\nId \\n84} \\na10jaq \\nASojopoyujaw \\nyUawdojanap \\nay} \\nSulsn \\n410} \\nsauljapins \\nau} \\naSueyD \\n« \\nainjNyseyuI \\nsainpadoid \\njed1Uyd9}U0U \\npue \\n‘sauljapins \\n‘spuepue}s \\nMau \\nBUIAJIPOLW \\nJO \\nBUI}CIID \\nJO} \\nS9}EWUI}SA \\nUI} \\n9}eID \\n« \\n9} \\nSAOIdWY \\n“¢ \\nSSS \\nSYSDIQNS/SYSDL \\nSalIAQ \\nIY \\nda}s \\ndays \\njuauidojanaq \\n_ \\nSS \\nuoHenjenq \\nainjonjjsedju] \\naslidiayuq \\n:7 \\ndays \\nyuauidojanaq \\n= — \\nxe \\nyse}qns/yseL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 451}, page_content='Aiessadau \\nJI \\n‘Sd}EWI}SA \\nJSOD \\n[EUISUO \\nJU} \\nISIADY \\n« \\nSulUuled} \\nPUe \\n“BUI}IEIJUOD \\n‘BUI}[NSUOD \\nJO} \\nPIdU \\nJU} \\nMAIAIY \\n« \\n(Ayjjenb \\n‘sadunosai \\n‘aspnq \\n‘adods \\n‘au}) \\ns}ules}SUOD \\nPafoid \\nBU} \\nMAIADY \\n« \\nsjualWadInbas \\nPafoid \\nau} \\nMaIAaY \\nOda \\nJUALUSSASSE \\nBINJDNIJSEAJU! \\n[EDIUYDI}UOU \\nJY} \\nMAIAdY \\nOda \\nJUILUSSASSE \\nSINISE! \\n[ED!UYII} \\nJY} \\nMalAdY \\nTask/Subtask Matrix \\nNEE \\nSSS \\nSSS \\nSSS \\nSSS \\nSS \\nSa}eWI}SO \\n}SOD \\nJU} \\nASIAII \\nJO \\nJUIWA}9q \\n*€ \\nOe \\nSulsuea]d \\nay} \\naziyUOUd \\nJOsuods \\nssaulsnq \\n94} \\nBAeY \\nPuke \\nJOSUOdS \\nssauUIsng \\ndy} \\nUUM \\nsa}zeUU|}sa \\nSuIsU||D-e}EP \\nMAIAY \\n« \\ns}UdWa]a \\ne}ep \\nBdiNOS \\nJUeYOdUWI \\n94} \\nSUISULI]D \\nJO} \\n(SSaN3 \\npajyeInpa \\nue \\nayeW) \\na}ew}sa \\nUe \\najejodes}xa \\npue \\nSJUIWJa \\nE}LP \\nIDINOS \\nJEDI} \\nBY} \\nVBSUL]D \\nO} \\nBYE} \\nP|NOM \\n}! \\nSUC] \\nMOY \\n3}eWI}SF \\nJULDIJIUSISU! \\nBe \\nYDIYM \\npue \\n“(jed}9 \\nJOU \\nyng) \\nJUeYOdUI \\nAJP \\nYIIYM \\n‘SSSUISNG \\nJY} \\nO} \\nJIU \\nJie \\nS}JUBLWa]a \\nE}YEP \\nULDIUM \\nSUIWaIaq \\n- \\nsain \\nAysajul \\neyep \\nssouisng \\n— \\nSa] \\nUIEWOp \\ne}ep \\nssauisng \\n— \\nSoM \\nUOISIQAUOD \\ne}ep \\n[edUUDI] \\n— \\n:9U} \\nO} \\nSUONEJOIA \\ne}LP \\nDINOS \\nSsassy \\n- \\n(JeUJe}xe \\npue \\nJEUJa}Ul) \\naseqe}ep \\nJdiNOS \\nPue \\najlj \\nDINOS \\nJe1}U9}0d \\nYIEd \\nJO \\nJUd}UOD \\nJU} \\nMAIADY \\n« \\nsaseqe}ep \\npue \\nsajlj \\nad1nos \\n9U} \\nJO \\nUO!|PUod \\nJU} \\nDUIUAIAq \\n*Z \\ns}UdWAaJINDaJ \\nBU} \\n10} \\n|eAOIdde \\nsosuods \\nulelqGo \\n- \\najdoad \\nssaulsng \\n484}0 \\nYM \\ns}UaWasINbad \\nay} \\nayepIeA \\n« \\nJaPOW \\neyep \\n[ed130] \\n|@Aa]-USIY \\ndy} \\na}ea19 \\n10 \\npuedxy \\n« \\n(29}UYyd9}UOU \\nPue \\nJed/UYIe}) \\ns}UaWaIINbas \\nainpNsyseyUl \\nUIQ \\n« \\n(uolDuNy \\ndjay \\nauljuo \\n‘salanb \\n‘syoda) \\nsjuawasnbas \\njeuonduNy \\nauyaq \\n« \\nsjUdWaJINbas \\neyep \\naujaq \\n- \\nsjuUdWaJINbal \\npoloid \\n9Y} \\nSUIUAI9G \\n“| \\nBuluUeIg \\nPalolg \\n‘¢€ \\n———_ \\nSSS \\nSYSD}IGNS/SYSDL \\n418 \\nSaIHAIY \\ndaj}s \\ndajs \\njuauidojanaq \\nSS \\nsuluurid \\nPaloid \\n:¢ \\ndays \\njuawidojanag \\n= — \\nXL}eI \\nyse}qNS/yseL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 452}, page_content='419 ing Project Planni Development Step 3 \\nSSS \\nSS \\nSS \\n(QDefoid \\nau} \\n104} \\naAle}Uasesdas \\nssauisng \\naul}-|IN} \\nUO \\napiAoid \\n‘ajdwexa \\n404) \\nJosuods \\nssauisng \\n9} \\nWO \\nS1OJLJ \\nSS9DINS \\n[LID \\nBY} \\nUO \\nUO!}EJ9d00) \\npuke \\nJUaWaaIZe \\nUle}gGO \\n« \\nJosuOds \\nssaulsng \\ndy} \\nYM \\n$10}De} \\nSSADINS \\n[LID \\nMAIAY \\n« \\n(2L9}U9 \\nSSaddNs \\ndU} \\nJOOW \\nO} \\npefoid \\nay} \\n104 \\nJaps \\nu! \\nade/d \\nUI \\naq \\nJsNWW \\n}eYM) \\nS10;De} \\nSSadINS \\n[eID \\nBUIWWA}aq \\n« \\n(,ssadons, \\nSIO}DE} \\nSSadINs \\n& \\nPAHaPISUOD \\n3q \\nP|NOM \\nyeYM) \\nPalo \\n|g \\nay} \\n410} \\nEL9}19 \\nssaddNs \\naU} \\nAUG \\n« \\njean \\nAynuapy \\n“s \\nYSU \\nO} \\n9}e] \\n91 \\nAauy \\nse \\n(Ayjenb \\n‘sadunosas \\n‘yaspnq \\n‘adods \\n‘awu!}) \\ns}Ules}SUOD \\nyDa{oid \\nauy \\nMAlAQY \\n« \\n(SOAHeUIA}e \\n3SI|) \\nUejd \\nAQUasuUNUOD \\n3y} \\nUl \\nSUONdUUNsse \\napn}dU| \\n« \\nSys \\nawWodeq \\nAew \\nAay} \\nasnedag \\nsuoljduinsse \\nsnoA \\nAyuapy \\n« \\nSOZI|CWO}EW \\nYSU \\n© \\nUIYM \\ndye} \\nO} \\nSUO]}I \\nBAH}EUJa}ye \\nSuNsl] \\n‘Uejd \\nAQUaSUUOD \\ne \\ndUIJaQq \\n« \\nYSU \\nYd \\nJUBALUNIAID \\nJO \\nJUSASId \\n0} \\nSUID \\nBuNsl| \\n‘Uejd \\nUOHeSHIW \\nYSU \\ne \\naUaq \\n« \\n(9ZIJEUa}eW \\nO} \\n}NOGe \\nSI \\n¥SH \\ne \\nJEU} \\nSUONEDIPU!) \\nSiaBBLUy \\naUYaq \\n« \\nysly \\n‘WnIpaw \\n‘moj \\n:¥sU \\nAlaAa \\nJO \\nedu \\naU} \\naUIWIA}aq \\n« \\nYsly \\n‘Win|paw \\n‘MO] \\n:SUIZI|eUa}ewW \\n3 \\nJO \\nPOOU!|9y!] \\n9Y} \\nBUILWA}ap \\n“YSU \\nAUBAd \\n104 \\n« \\nJUSWSSesse \\nXU}EWW \\nJUBLUSSASSE \\nYSH \\n|EUISUO \\n9Y} \\nASIAII \\nPUL \\nMAIADY \\n« \\nYSU \\nBUY} \\nASIANY \\n‘yp \\n— \\nSSS \\nSYSD}QNS/SY¥SDL \\nSATAY \\ndays \\ndajs \\nJuauidojanaq \\n_ \\nSS \\nsujuueld \\nPafoid \\n:¢ \\ndays \\n}uauidojanaqg \\n= — \\nXL}eIW \\n¥Se}GNs/yse \\n1 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 453}, page_content='Task/Subtask Matrix 420 \\nYeYD \\nHuey \\ne a}edID \\n- \\nHUD \\nMad \\nJO \\n(dD) \\nPOYJEW \\nY}ed \\nJed1}9 \\ne \\nd}eaID \\n- \\n(SUI|9A] \\n3D1NOSaJ) \\nSa{DUaPUadap \\nadINOSaJ \\nAJUAp] \\n« \\nSIIMAIDE \\nPd}ejas-yYJOM-UON \\n— \\nSOIPAHIE \\nOAHEJ}SIUILUpe \\n|EUONIpPpY \\n— \\nasiedxa \\nJayHew \\npalqns \\n— \\nJSAP] \\n[IPAS \\n— \\n(UO \\npase \\n‘Sdd1NOSAJ \\nPAUSISSe \\nJO} \\nSd}EWI}SA \\nVSeg \\nJU} \\nASIADY \\n« \\nSaldUapUadap \\nySe} \\nAjI}Uap] \\n« \\n(440M \\n3U} \\nOP \\n|JIM \\nOYM \\nSJaquUioW \\nuejd \\nwea} \\nay} \\nAg \\npaplAoid \\nsayeUl}sa \\nBuUISN) \\nSySe} \\n[|e \\nJO} \\nSa}EUUI}Sa \\naSeg \\nSUILWA}IQ \\n« \\npaloud \\njana} \\n(syse} \\nayeLdoidde \\njo \\n3sI]) \\naunjon4j3s \\nUMOpyealg \\nYOM \\nBC a}PdID \\n« \\n-UsIY \\ne a}eaID \\n7 \\nSIO} \\nSSBDINS \\n[EdD \\n— \\nSjU!e1}SUOD \\npuke \\n‘SUOI}dLUNSSe \\n‘sysIYy \\n— \\nSalj{iqisuodsas \\npue \\n‘Ssajos \\n‘Qunyonys \\nWeal \\n— \\nyYoddns \\nSulosuo \\n‘ssauljuea}) \\neyep \\n‘(adueWOJJad) \\naw} \\nasuodsas \\n‘ANDAs \\n‘ApIge|leAe \\nJO \\nSLUJa} \\nUl \\naj}doad \\nssauisng \\nay} \\nWo \\nsuoTe~adxq \\n— \\n(adods \\nau} \\nwoJ} \\npapn|axa \\nAjjuanbasqns \\nyng \\npaysanbas \\nAjjeulso) \\nadods \\nay} \\nul \\nJOU \\nsway \\n— \\n(SuolauUN} \\npue \\ne}ep) \\nadods \\nJaAa|-USIH \\n— \\nS}JUDWAAOICLUI \\nSSad0Jd \\nSsauIsNg \\npuke \\nsinyNyses4yU] \\n— \\nS}IJQUaq \\nPUL \\nS}sOD \\n— \\nyeafloid \\n|g \\nau} \\n10} \\nUOSeal \\npuke \\nasoding \\n— \\n:JUIOd \\nSIU} \\nJayeyud \\npofoid \\n0} \\ndn \\npayayjod \\nyafoid \\n|g \\nay} \\nNOge \\nUOHeWWOJU \\nYM \\nJayeYUd \\npaloid \\nOU} \\nSIUM \\n« \\n3} \\naedaldg \\n9 \\nnnn \\nnnn \\nnnn \\nnnn \\nSSS \\nSSS \\nSYSD}GNS/SYSDL \\nsalAnpy \\ndays \\nda}s \\njuauidojanaq \\nnnn \\nnn \\nnnn \\nnn \\nSSS \\nsujuueid \\nPafoidg \\n:¢ \\ndays \\nyuauidojanaq \\n— \\nxiIeW \\nyseiqns/yse \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 454}, page_content='421 t Planning Projec Development Step 3 \\nSSS \\n(DeEO}4JOM \\nAlay} \\n[SuLeYs] \\nSUyNQUIsIpas \\npue \\nBULOYUOW \\nSIdqWAW \\nLL} \\n3409) \\nSued} \\nSUIZIULSIO-J]as \\nJO \\n}dadUOD \\naU} \\nssnosiq \\n« \\nuejd \\npafoid \\nau} \\nYSnosU} \\nyyeM \\n« \\nJayey) \\nPefoid \\nau} \\nssndsiq \\n« \\nSOIIGISUOdSaJ \\n1194} \\nMAIAad \\nPU \\nSIBQUIdLU \\nLUR|} \\npapuayxa \\nAjUAap] \\n« \\nSJBQUIDLU \\nLULD} \\n90D \\nO} \\nSal}|IqisuOdsal \\npue \\nSajO/ \\nUBISSY \\n« \\n(eAne}UISaIdas \\nssaulsng \\nay} \\npue \\nJOsuOds \\nssaulsng \\nau} \\napn|rul) \\nSUIeW \\nJOyDIy \\ne \\n[JED \\n« \\npeafoid \\nSU!}IOWW \\nJJOYIIY \\nBY} \\n10} \\nEpuage \\nue \\naiedaig \\n« \\n3U} \\nHO \\nYIN \\n“8 \\n— \\nSYSD}QNS/SY¥SDL \\nSanAoyY \\ndais \\ndajs \\njuauidojanaq \\n-_ \\na \\nsuluueld \\nPafoig \\n:¢ \\ndays \\n}uauidojanaq \\n~— \\nxe! \\nyseiqns/yseL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 455}, page_content='Task/Subtask Matrix 422 \\nSS \\nES \\nES \\na \\nSSS \\nSF \\nBPSD \\nEES \\nSSad01d \\nUOI}EDIUNWIWOD \\n— \\nssad0jd \\nuoljnjosas \\nayndsiq \\n— \\nsuolpunj \\nWoddns \\n— \\nssa00id \\nW1S \\n— \\nssa00l/d \\nSUl}sal \\n— \\nssad0jd \\nase} \\npue \\nsainseaw \\nAyyjenb \\neyeg \\n— \\nSuljapOwW \\ne}ep \\n[ed1307 \\n— \\nssa0oid \\nAuaAljap \\npuke \\nainjded \\nejyep \\neyo \\n— \\nssad0id \\nAyndas \\n— \\nSalp|iqisuodsas \\npue \\nsajoy \\n— \\nssad0jd \\njUaWaseUeW \\nSanss] \\n— \\nS$sad0Jd \\n(|01}U0) \\nasueYD) \\nJUsWaseUeW \\nadods \\n— \\nsauljapins \\nSulyewiysy \\n— \\nAZojopoyjaw \\nJUdWdoO|anap \\nau} \\nJO \\nasp \\n— \\ns}UaWadUeYUS \\n(e1ep \\ne}aW \\n‘e}ep \\n‘SUOI}DUNJ) \\nSa|qeJaAIap \\nainyoniyseyul \\npue \\ns}uawWadinbas \\nSulzyUOd \\n10} \\nsainpadoid \\npue \\nspuepuels \\nadUeUIaAOD \\n— \\njed1UYyd9}UOU \\nJO} \\nSaInpado1d \\nJO} \\ns}UaWAIINbaL \\npue \\n‘sauljapins \\n‘spiepuejs \\nSulsueY) \\nJO \\nSUI}ed1D \\nJO} \\nS}JUaWauINbas \\nay} \\naUaq \\n- \\n9} \\nBUYaq \\n‘Z \\n}! \\nADUCYUS \\nO} \\nMOY \\nJUIWWa}ap \\n‘s}SIxa \\nApeasje \\nAuoysodas \\neyep \\neJaW \\nke \\nJ] \\n« \\nAioyisodai \\neyep \\ne}aW \\ne \\nPjINg \\nWoOjsnd \\nJo \\n(Ang) \\nasuad!] \\n0} \\nJ9YJAUM \\nSUILWAIIQ \\n« \\nJOO} \\nSUIUIW \\neye \\nMAU \\ne \\nJO} \\nS}JUaWAJINbas \\nay} \\naUaq \\n« \\n(S197 \\nUM \\nYoda \\n‘d¥10) \\n$}00} \\n8uljJodaJ \\npuke \\nssadde \\neyep \\n10} \\nsyUaWasINbad \\nay} \\naUIJaq \\n- \\n(114 \\n‘JSVD) \\nS]00} \\nJUaLUdOJaAap \\nJO} \\ns}UaWaUINbad \\nBU} \\naUIJaq \\n« aseyped \\nAyundas \\ne Ang \\n0} \\nJay}aYM \\nap|dap \\npuke \\nsyUaWaINba \\nAyNdas \\nay} \\naULaq \\n« \\n1] 0} \\nSapesiSdn \\nJO \\nYOMJaU \\naU} \\nJO} \\nS}UatasINbal \\naU} \\naUaq \\n« \\nacre \\nSINEG \\nSunsixa \\nay} \\n0} \\nsapei8dn \\nJo \\nSWad \\nMau \\ne 40} \\nsyuaWasINbas \\nau} \\nauyaq \\n« \\njed]UUD91 \\nJEMa|PPIW \\nJEUO!Ppe \\nJO} \\nSJUaWaJINbaJ \\nBY} \\nBUIJ9q \\n+ \\nJO} \\nS}UaWaJINbal \\naJeMpJey \\nJCUOI}IPpe \\n10} \\nS}JUaWAaIND|J \\nJY} \\nBUA \\n« \\n9U} \\nGUYS \\n‘L \\nUO! UYaq \\ns}JUaWaIINbay \\npalold \\n‘y \\nEen \\nen \\nnnn \\nnnn \\nSSS \\nSSS \\nS¥SD}QNS/SY4SDI \\nsamianoy \\ndays \\nnnn \\nnnn \\nnn \\nrenner \\nnn \\nnner \\nSS \\nSSS \\nSSS \\nSS \\nUuOIUIZag \\nS}JUBWIAaIINb|Y \\nWaf01d \\n:7 \\nda}s \\nJUaWIdOjaAag \\ndajs \\n}uauidojanag \\nXH}e \\nIA] \\n¥Se}GNS/y4se_L \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 456}, page_content='423 inition ect Requirements Defi Proj Development Step 4 \\nne \\nsanss! \\nSUIAJOSAJ \\nPUe \\nBULLI} \\n10} \\nSO] \\nSanss! \\nUL \\n9}eAID \\n+ \\ns}uawasInbad \\nay} \\n0} \\nsasueyd \\nSulseuewW \\nJ0j \\nJUBUNIOP \\njO1}U0D-BSULUD \\nP \\na}edJD \\n» \\nAuessadau \\nJI \\n‘adods \\nay} \\nayeNOBIUdy \\nS}UIEIJSUOD \\nBSOU} \\nJOPUN \\nIISHEAL \\n[I]}S \\nS| \\nPdOIs \\nBY} \\nJOYJOYUM \\nSUILUI9}0Q \\n+ \\n(Ayenb \\n‘sadsnosad \\n‘yaspnq \\n‘adods \\n‘atu!}) \\ns}UJes}SUOD \\npafoid \\ndy} \\nMAIAOY \\n« \\nJayeyo \\npefoid \\nadoos \\npafoid \\nay} \\nUl \\nadods \\nJana|-YSIY \\naU} \\nO} \\nsyUaWasINbal \\npafoid \\npayleyap \\nay} \\na1edwiod \\n- \\n3U} \\nMAlAaY \\n*S \\n(paemio} \\nyulOd \\nsiy} \\nWoy \\nA1O}sIY \\na}ye|NWINdDe \\n4O \\n“YIeq \\nsieaA \\nAuew \\nMOU \\nwOdJ \\npue \\npeo] \\n0} \\nAlo}siy \\nYONW \\nMOU) \\nsjualaliInbas \\ne}yep \\n[EdUO}SIY \\nBY} \\nBUOC \\n«+ \\nsjuawasinbas \\nSulsuea|d-e}ep \\nJUILLID}IP \\nO} \\n[!2}aP \\nBIOW \\nUI! \\nSaseqe}ep \\nBdANOS \\nPUP \\nSejlJ \\n9IINOS \\nOU} \\nazAjeuy \\ne}ep \\nIY} \\nJO} \\nSajni \\nssaulsng \\nsno|Ago \\npue \\nJURDIJIUSIS \\nBY} \\nDUI \\n« \\n(sanjea \\najqemoyjje) \\nSUJELUOP \\ne}ep \\nJU} \\nSUIJoq \\nUeDIIUZISUI \\n‘JUeYOULUI \\n‘JeEd}U9 \\nSe \\ns}UdWaJa \\ne}ep \\nAjisse|D \\n« \\neyep \\naaunos \\n(Zuiujw \\neyep \\n40} \\n‘saanb \\nJO} \\nsJUaWadINbal \\n10} \\n‘Spjaly \\nYodad \\n10} \\n‘SUOISUBIP \\nSUIPOdad \\n410J) \\nS}UBLAJa \\nB}EP \\n9I4NOS \\n|e \\nSUIo \\n« \\ndU} \\nJUNE \\n‘PV \\n(jeyiod \\n‘Aejdsip \\nqam \\n‘pua \\n}UOsJ \\n1D) \\nSAde}J9}U! \\nSS8dde \\nBULJOC \\n* \\n3M \\n0} \\nJUeM \\nAew \\ns}sAjeue \\nssaulsng \\ndU} \\nsauianb \\ndou \\npe \\nJo \\nsadA} \\nau} \\nJo \\nsajdwies \\n325 \\n« \\nSALIPII| \\nBU} \\nJO \\nSPuemay}s \\nAj}}Uap] \\n« \\nsaueiqi| \\nAuanb \\nauyed \\n« \\nSUOISUBWIP \\nBUIPOdas \\nUOQ \\n+ \\nsajni \\nuoHezUeWLuNs \\npue \\nuonesalsse \\nduyaq \\n« \\nsoda \\nay} \\n40} \\nSajm \\nssauisng \\nauyaq \\n« \\nsjuauiasinbau \\nsalianb \\najdwes \\n3}eaJ9 \\n10 \\nPal|OD \\nSurodas \\nsjnoAe| \\nWoda \\najdwes \\n332919 \\nJO \\n}aI|OD \\n+ \\ndU} \\nDUed \\n“€ \\nSYSD}GNS/SYSDL \\nsalpHAnoy \\ndajs \\nda}s \\njuauidojanaq \\nuoUyad \\nsyuawasinbay \\nWaloi1d \\n:7 \\nda1s \\nyuawidojaneq \\n— \\nX}eIW \\n¥se}qNSs/yseL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 457}, page_content='Task/Subtask Matrix 424 \\nSW1S \\nAleuIWiI|ald \\n— \\nS}UdWaINba \\nAyundas \\n— \\ns}udaWalInbas \\nSulsuea}o-e}eq \\n— (j|apow eyep \\nJed180] \\n|9AV]-YSIY \\nBy} \\napnjdul) \\nAyo}s!y \\nSulpN|ou! \\n‘eyep \\nadinOs \\n10} \\ns}UaWaINbay \\n— \\nsjuawatinbas \\nAianb \\npauued \\npue \\nd0Y \\npy \\n— \\nsjudWalInbas \\nSuljoday \\n— \\njUawNndOp \\nS}UdWAINbas \\nJNINA}SeIU! \\n[|ED1UYDI}UON \\n— \\ns}UdWaJINba \\nSjUdWadINbas \\nsuNnpNsseUl \\nJedNIUUIL \\n— \\nuolyed1|dde \\n‘JUBLUNIOP \\nS}UdWaJINbas \\nUOHedI|dde \\nay} \\nJO \\nSUOIIDAS \\nSUIMO]IO} \\nJU} \\nUI \\n|II4 \\n« \\n2} \\nSIUM \\n‘8 \\nyoddns \\nsulosuo \\n— \\nssouljueap> \\ne}eq \\n— \\nWl} \\nasuodsay \\n— \\nAyundeas \\n— \\nS}UDWIIIBE \\nAyjiqeyieay \\n— \\nJQAQ]-3d1Aas \\n‘JO \\nSWJ9} \\nUl \\naj|doad \\nAueutuuijasd \\nSSOUISNG \\nJU} \\nJO \\n(SHWI] \\n3]Ge}dadde \\nJSOWA}NO) \\nSUOI}EPadx—a \\ndu} \\nasiAad \\nJO \\nAjUAp] \\n« \\nauyeqd \\n7 \\nS}JUIWA]a E}EP [CIPD YUM [aPOW e}ep [ed130] aU} aINqUNY - Ayua yoed 0} Suali}Uap! anbiun ppy - \\nsdiysuonejas \\nAuew-o}-Auew \\nay} \\nSUIAjOSad \\nAg \\n[aPOW \\nL}ep \\n[ed!30] \\n9y} \\nBUOY \\n« \\nlapow \\nJapow \\neyep \\njed180] \\n(jen}dadu0d) \\neyep \\njed180} \\nJOA2]-YSIY \\nJU} \\nO} \\nSdIYSUO}eJaJ \\nAB} \\nPUL \\nSdI}1}Ud \\nPaJaAOdsIp \\nAJMaU \\nPpY \\n« \\n94} \\npuedxq \\n‘9 \\nNeen \\nnnn \\nnner \\nnner \\nSSS \\nSSS \\nS¥SD}QNS/SY¥SDL \\nsanianoy \\ndays \\nnner \\nn nnn \\nnennnrnnnnnnnnnnnncencnnnncnenncenncee \\nrene \\neeeeceeeeeereee \\nreser \\nSSS \\nSSS \\nUOIULId \\nS}UIWAIINbaY \\nPeloig \\n:y7 \\ndays \\n}UaWIdOjansq \\ndajs \\njuauidojanaq \\nXHze \\nI \\n4Se}GNs/y¥se \\n| \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 458}, page_content=\"425 is Data Analys Development Step 5 \\n———————OOOO \\n(P9}D9109 \\n}OU \\n4! \\nUOIeD1;dde \\nId \\n94} \\nPoye \\n[JIM \\ne}yep \\nApp \\nay} \\nMoU) \\nWajqoud \\n3U} \\nJO \\nAjJEIUD \\ndy} \\nBUILUA}Aq \\n+ \\nZ80'6€v'Z \\n$0 \\nINO \\nSpl0da1 \\n72/609 \\nPue \\n09Z \\n40 \\n}nO \\nS}JUSWA]a \\nEP \\nOvL \\n‘ajdwexa \\nJO} \\n‘payaye \\nase \\nspsoda1 \\nAUew \\nMOY \\npue \\nSUIeELUOD \\nPIJEAU! \\nBABY \\nS}UaWa|a \\neyep \\nAuewW \\nMOY \\n:Wa|qgold \\nay} \\nJO \\nAyaAasS \\naU} \\nBUILAIAG \\nsKay \\nArewiud \\nayedijdng \\n— \\nsKay \\nArewud \\nSulssi, \\n— \\nS9|NJ \\nSSOUISN \\nJU} \\nd}LIOIA \\nJEU} \\nSaNjeA \\n— \\n(s}UaWa]a \\ne}ep \\nJUaPUadap \\nOM} \\nUBamMjaq) \\nsanjeA \\nSulDdIPeUOD \\n— \\nsanjea \\nd1dAuD \\n— \\nSaNnjeA \\nBUISsI \\n— \\nSanjeA \\nyNejaq \\n— \\nAyyenb \\n:se \\nYONS \\n‘SUIELUOP \\nPIJEAU! \\nYIM \\nS}UaWa|a \\neyep \\nadinos \\nB}eP \\nPUlJ \\nO} \\nSain \\nAjSaju! \\neyep \\nssauisng \\npue \\nsajni \\nuleWoOp \\ne}ep \\nssauisng \\nAiddy \\n« \\n9U} \\nazAjeuy \\n“€ \\n(uo \\nOs \\npue \\n‘adA} \\n‘y}Bua] \\n‘UleWOp \\n‘UOMIUNap \\n‘aWeU \\n2}ep) \\nsaynqlyye \\n|Je \\n10} \\ns}UBUOdWOD \\ne}ep \\neJaW \\nssauIsng \\ndYIDads-eyep \\naU} \\nayealy \\n« \\nsasodind \\n3]diyinu \\n40} \\npasn \\nsi \\n}UuaWaja \\neyep \\ne \\nUayM \\n‘ajdwexa \\nJO} \\n‘pauyapas \\nAjqioyduu \\ndB \\nYDIYM \\n‘s}UBW]a \\nBJP \\nPasMaao \\nazZI|/eWUOU \\npuke \\n‘sasege}ep \\nadiNOs \\npue \\nS9]l} \\n9INOS \\nJU} \\nU! \\nS}UDWA]a \\nJEP \\nBdiNOS \\npaljijUap! \\n||e \\nJO \\nJUa}UOD \\nau} \\nazAjeuy \\n« \\nweisoJd \\n& \\nUl \\naSNe|D \\n,SINddO, \\nUL \\n40 \\naSNeID \\n,sauyapa, \\ne \\n‘ajduiexa \\n40} \\n‘pauyapai \\nApoiidxa \\naie \\nUdIYM \\n‘sjuaaja \\neyep \\npasniano \\n9ZI|EWOU \\npue \\n‘saseqejep \\nadinOs \\npue \\nsajly \\nad1nOs \\npayijuap! \\n[Je \\nJO \\n;NOAD] \\nayy \\nazAjeuy \\n« \\n(s}UdWaja \\ne}ep) \\nSOINGUYE \\nMSU \\nBU} \\n910}s \\n0} \\npapaau \\n319M \\nSdiysuO!ejad \\npUe \\nSal}}Ua \\nMAU \\na}ealD \\n« \\njapow \\nS9DJNOS \\nB}eP \\n|CUI9}Xa \\nSe \\n[JaM \\nSe \\n[EUJd}U! \\nWO’ \\ns}UaWa|a \\neyep \\n[e180] \\n}ep \\nadunos \\npauinbad \\nje \\napnjdu! \\n0} \\njapow \\neyep \\njed13o] \\nau} \\nainquyye \\nAng \\ndU} \\nBUOY \\n*Z \\nJ9POW \\ne}yep \\njed130] \\nau} \\nS30JNOS \\nOU! \\nSBDANOS \\nBp \\n[EUJa}X9 \\n9} \\nWO \\nSdIYSUO!}LJaJ \\nPU \\nSaI}I}Ua \\nMAU \\naU} \\naSJay \\n« \\neyep \\njeusaixa \\n224NOs \\ne}ep \\n[UJa}X9 \\nYee \\nWO \\nSdiysuOHejas \\npue \\nsaiyUa \\nay} \\nAyUAp \\n« \\nOU} \\nazAjeuy \\n‘1 \\nsisAjeuy \\ne}eq \\n“Ss \\nSe \\nees \\nSYSD}QNS/SY¥SDL \\nSamAn \\nIY \\ndais \\ndajs \\njuauidojanaq \\nTE \\nes \\nsishjeuy \\ne}eq \\n:¢ \\ndays \\nyuaudojanag \\n— \\nXL}eW \\n¥se}qns/yseL \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 459}, page_content='Task/Subtask Matrix 426 \\nS}UBWIJa \\nE}eP \\nJULDIJIUBISUI \\ndU} \\nJO} \\nSUONEIYINads \\nSulsuea|d-e}ep \\n3}UM \\nJOU \\nOP \\n‘41 \\nS}sanbas \\nAjjedyI9ads \\ndAI}L}UISIIdaJ \\nSSaUISNg \\nay} \\npue \\nPafoid \\nay} \\nUO \\nSUI} \\nJUBIDIJNS \\nSI \\nJ1dY} \\nSSalUN \\n- \\n(UOPa]VS \\nBY} \\n9XeW \\nSAI}E}UASdAdas \\nSsaUISNg \\nJu} \\n}9]) \\nSJUdW]Ja \\nE}ep \\nJURPOdUUI \\nPaypalas \\n410} \\nSUOH}EDIJIDads \\nSuIsuea|D-e}eP \\nILM \\n« \\nsuoneoyioads \\nS}UIW]J9 \\nE}JLP \\nJEIUD \\n[Je \\nJOJ \\nSUOIWEIIJID9ds \\nSulsuea|I-E}eEP \\nJIM \\n« \\nSuisuea|> \\nJUBIIIUSISU! \\n‘JUEYOAU! \\n‘[EI}UD \\n:s}JUWAIa \\nE}EP \\nJO \\nUO!}EDIJISSE]D \\nJY} \\nMAIAaY \\n« \\n-E}EP \\nJU} \\nBUM \\n9 \\npo}UdWa]dwI \\naq \\n0} \\nsasueY) \\n3y} \\nJO} \\nBWI} \\ne ajnpaUds \\npue \\n‘e}ep \\neJaW \\nse \\nsaiduUa} \\n-SISUODU! \\nPUL \\nSdIDULddIDSIP \\nBY} \\nJUSWINDOP \\n‘pa}UaWa|dwI \\nag \\nJoUULD \\nSasUeLD \\nJ] \\n« \\nsasuey) \\nay} \\nAg \\npapaye \\nase \\nyeu} \\nSWea} \\nPafoid \\nJay} \\nAJNON \\n- \\nayeudouidde \\nse \\n‘jJapow \\neyep \\nJED130| \\ndsUdsiajUa \\nJy} \\nJO \\nJapOW \\neyep \\n[ed13O] \\nDyI9ads-pafoid \\nau} \\nJayye \\nIsn{py \\n- \\nSUOISIDaP \\nSSAUISN \\nJIdU} \\nJO} \\nUOSanb \\nul \\ne}yep \\n3y} \\nASN \\nOYM \\nSAaAINIaxa \\nSSaUISNG \\naU} \\npuke \\n‘SIMUMO \\ne}eP \\nsalduedaisip \\n3} \\n‘Wea} \\nPafoid \\n|g \\n3Yy} \\nYM \\nSaldUa}sISUOIU! \\nPUL \\nSsaldUedaJDSIP \\ndU} \\nSSNDSIQ \\n« \\nP}JEP \\nBAJOSIY \\n“SG \\n‘payaff{o \\naq \\nApw \\najnpayps \\naloud \\n1g \\nQU} \\n“J0}DA}SIUILUPD \\nDLOp \\nasudiajua \\nou} \\nfo \\n[O01 \\nal} \\nAvjd \\nos|p \\nJsnus \\n40}0.4)51 \\n-UJWIpD \\nDyDp \\nWaloid \\nau} \\nfo \\najo \\nay} \\nsAvjd \\nOUM \\nJaqulaWl \\nUID2a} \\nAOD \\nau} \\nff \\nWanamoy \\n‘Waloid \\n[g \\nay} \\nfo \\nsauads \\nay} \\nPulYoq \\nUO}}D4J}sIU|LUpD \\npop \\nAq \\npauuofiad \\nAor} \\ns1 AWANIO \\nSIUL \\nS[SpOW :a}0N \\neyep \\n[e130] \\n9Y} \\nUaMjaq \\nSAa!IDUd}sSISUODU! \\nPU \\nSaldUedaIDSIP \\ne}ep \\nAjnUAp] \\n- \\nljapow \\neyep \\njapow \\nJeEd130] \\nasidiajue \\neyep \\n[ed130] \\nasidia}Ua \\ndU} \\nO}U! \\nJaPOW \\neyep \\n[ed130} \\nDiJId9ds-pafoid \\nay} \\nasia \\n« \\n9U} \\npuedxy \\n‘py \\nSSS \\nSc \\nSYSD}IGNS/SHSDL \\nSATAN \\nY \\ndajs \\ndajs \\njuauidojanaq \\neee \\nnena \\nence \\neece \\nee \\na \\na \\nOBIE \\nIE \\nEE \\nSE \\nI \\nAS \\nsisAjeuy \\ne}eq \\n:¢ \\ndays \\n}uawidojanaq \\n— \\nxXx} \\nySeIqNs/yseL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 460}, page_content='427 ing Prototyp ication Appl Development Step 6 \\n—eeeee——————————— \\nsuo}je1a}! \\nadAjo}O1d \\nJo \\nJaquNU \\nay} \\ndUILLIA}aq \\n« \\nadAjo}01d \\nay} \\nSuinp \\nsanss! \\nSulajosas \\npue \\nSury>e} \\nJO} \\nSO] \\nSanssi \\nue \\na}eadJ> \\n« \\nadfjo}01d \\n24} \\nSuLnp \\nsasueyd \\nadods \\nZulseuew \\n10} \\nJuUaWINDOp \\nJO1}U0D-3SULYD \\n& \\n3}edID \\n« \\nSOSEGE}LP \\nBDINOS \\nPuke \\nSaji} \\n3DINOS \\n94} \\nWO \\neyep \\najduues \\njo \\nJasqns \\ne \\npajas \\n« \\n(edeJ19}U! \\n“1LJ \\n‘Sauanb \\n‘syiodai) \\nsuoiauny \\nJo \\nJasqns \\ne pajas \\n« \\njeuo}esado \\n— \\nowaq \\n— \\nusISap-|eENsiA \\n— \\n}d39U0)-J0-JOOIg \\n— \\ndn-yd0w \\n— \\n[|9}-Pue-MoUs \\n— \\nadAjo}o1d \\n‘pling \\n0} \\nadAjo}01d \\nJo \\nadAy \\nYydIYM \\napidaq \\n+ \\nau} \\nJO \\nadods \\nadA}0}01d \\nay} \\nJo \\nasn \\nAuewuid \\nay} \\npue \\naandafgo \\nayy \\nJUILL9}OQ \\ndU} \\nDUILA}IQ \\n*Z \\nYadxe \\n‘paduenpe \\n‘Buluulsaq \\nse \\naSpajmouy \\nuoNedI\\\\dde \\n3}ed1PU] \\n— \\nyedxa \\n‘paouenpe \\n‘SuUIUUIZaq \\nSe \\n[andj \\n[|}4S \\nJa}NdwWOD \\n3}e>1pUT \\n— \\n‘SOIHANDe \\nSuldAyo10O1d \\n94} \\nUl \\nSuljed|>1ed \\nUOsJad \\nssauisng \\nYea \\nJO} \\nXUJELW \\nJas \\nIIIS \\nB \\na}ealD \\n« \\nJO}ej}S|UILUpe \\naseqezep \\nau} \\n0} \\nSsulpuy \\nINOA \\njJe \\na}eD1UNWIWOD \\n- \\nJeyiod \\ngam \\ne \\n40 \\npua \\nUO \\n[5 \\ne \\n‘aj|dwexa \\nJ04 \\n‘sjuawasnbas \\nadepa}U] \\n— \\nyse \\nAj}UauInd \\nAau} \\nsuonsanb \\n0 \\nsadAy \\nyeym \\nuO \\npaseg \\nyse \\n0} \\nJUeM \\nKew \\najdoad \\nssauisng \\nau} \\nsuolysanb \\n2OY \\npe \\nJo \\nadA} \\nyeYyM \\naulWWa}p \\n0} \\nAuy \\n‘a|qISsod \\n41 \\n‘sjuaWasINbad \\nJoy \\npy \\n- \\nAseigi) \\nAuanb \\nay} \\nuyeyusew \\njim \\nOUM \\npue \\nSa|qeHeA \\npaZiajawuesed \\nay} \\naie \\nJEM \\n‘OS \\n}] \\nue \\nsalianb \\npazuajaweied \\naldnynus \\npees \\njUeM \\najdoad \\nssauisng \\nau} \\nop \\n‘ajdwexa \\n104 \\n‘sjuawasinbal \\nAland \\n— \\nIIIM \\ndays \\nsty} \\nul \\nsaniAgoD \\nSUOISUSLUIP \\nPuke \\n$}de} \\npup \\n‘ssazoid \\nannp.a} \\nales \\nBY} \\nJO \\nasn \\n10 \\nsHOdaJ \\nay} \\nU! \\nWiayed \\ne \\n0} \\nANP \\npaulqWiOd \\naq \\na10ja19U} \\nup \\ns} buidhjo,01g \\nUBD \\nPUP \\nJ|ILUIS \\nYOO] \\nsodas \\nAuew \\nMoy \\n‘ajdwiexa \\n10} \\n‘s}uawauinbas \\nyoday \\n— \\ns}UaWadINba \\n:3J0N \\n:azAjeue \\nJayjaso} \\npue \\n‘aatjeyUasaidas \\nssauisng \\nau} \\npue \\nssan0e \\nSuUIdA}0}01d \\nYedxe \\nJayew \\n~palgns \\nay} \\nuM \\nJUaWINIOp \\ns}uaWauINbas \\nUOHeDII}dde \\nUY} \\nMIIAQY \\n« \\n9U} \\nazAjeuy \\n‘1 \\nuonesiddy \\n‘9 \\n—_—_—_—_—_—:::?. \\nkxphjReeoo_—_—_—_—_—_—— \\nSYSD}GNS/SY¥SDL \\nSalAoy \\ndais \\ndajs \\njuaudojanaq \\nes \\nSuldA}0}01q \\nuoNerddy \\n:9 \\ndays \\nyuawidojanaqg \\n— \\nXL}eI \\n¥Se}qns/yse \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 461}, page_content='Task/Subtask Matrix 428 \\nSSODINS \\nJO \\nBdisap \\nANOA \\naunseaw \\n[JIM \\nNOA \\nMOH \\n— \\n(SuO}}e19} \\n‘AWUI} \\n‘AdoOds) \\nase \\nsajni \\nau} \\n}eUM \\n— \\n(a1doad \\nssauisng \\npue \\nJ}) \\nayedioyed \\njim \\nOUM \\n— \\n(Jeuoneiado \\n‘Owap \\n‘UsISap-jensiA \\n‘4Wda.u0d \\n-J0-J0O1d \\n‘dn-yo0u \\n‘|ja}-pue-MOYs) \\npapajas \\nNOK \\nadAjojoid \\njo \\nadA} \\nyeUM \\n— \\nJayeud \\n(asodind) \\nadAjojo1d \\nay} \\nSuipying \\naie \\nNOA \\nAum \\n— \\nadAjo}o1d \\n‘NOG \\nUOHEWUOJU! \\nYUM \\nJayeYD \\n3dAjoO}Od \\nBuy} \\ndM \\n«+ \\naU} \\naedald \\n‘v \\naiqissod \\nse \\nUOOS \\nSE \\nSUOISSAS \\nSUIUILJ} \\nJ[NDAUIS \\n« \\nS[OO} \\nMAU \\n3U} \\nJO} \\nSP9dU \\nBUIUIEI} \\nQUILI}IQ \\n« \\nS[00} \\nMAU \\nJO \\nBUI}SIXA \\nJIOW \\nJO \\nDUO \\nWAI—aS \\n« \\nSSINEC \\nPa}se} \\npue \\npajje}SU! \\n3Y} \\nJO \\nBUO \\nPal—as \\n« \\npadojanap \\naq \\n||IM \\nadA}o}01d \\nay} \\nYIYM \\nUO \\nWIO}}e]d \\naU} \\nPalas \\n« adAjo}01d ay} 10} sUOHdO SWC BUIISIXS MOIADY + \\nS$]OO} \\nUOINUISID \\nWOd31 \\nMAU \\nJO \\nBUI}SIXS \\nMAIADY \\n« \\nS]OO} \\nJed14des3 \\nMAU \\nJO \\nBUIISIXS \\nMAIADY \\n« \\ns]00} BulAuanb pue suljjodas Mau JO ApIGeyleAe SU} MAIAaY « adhyojo1d au} \\nLU} \\nS8SN \\nOYM \\n}NO \\nPUY \\nPUe \\nS[OO} \\nASNOU-U! \\nBUI}SIXS \\nMAIADY \\n« \\nJO} \\nSJOO} \\nPaas \\n“€ \\nYOYs SuldAjo}O1d au} JO} SUINJO4 BUIYSIUILUIP JO JUIOd JY} SUILA}Iq - \\n(panunuod) \\nuo}}e19}! \\n9dA}O}Od \\nYDS \\nJO} \\nWJoUaq \\nPUP \\n}SOD \\nJU} \\na}eWIISJ \\n« \\nadfoioid \\n(xOqg-aWI}) \\nUOI}E19}! \\n3dA}O}Od \\nYDeA \\nJO} \\nSHUI] \\nSLU} \\nJY} \\nDUILUA}IQ \\nau} \\njo \\nadoos \\n(a1doad \\nssauisng \\npue \\nJ}) \\ns}uedioaed \\nadAjo}01d \\njo \\nJaquINU \\nay} \\nJUIWA}9q \\n« \\n9U} \\nQUILUII}BQ \\n*Z \\nmmm \\nSYSDIQNS/SYSDL \\nSanyIAn \\noy \\ndajs \\ndajs \\njuauidojanag \\neee \\namma \\nSuidA}0}01g \\nuoneriddy \\n:9 \\ndajs}uauidojaaaq \\n=— \\nxXxiU}eW \\n¥se}GNs/yseL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 462}, page_content='429 ing Prototyp ication Appl Development Step 6 \\n_—_—_—_—_— \\nSSS \\nSSS \\nuonedidde \\n|g \\n24} \\n10} \\nSA}EWI}SO \\n}SOD \\nPUL \\nSLI} \\nJY} \\naJEpIEA \\n‘yDISpieA \\ne \\nse \\nadAjo}01d \\nay} \\nSuIsN \\n« \\n(uolDUNy \\n7Lq \\nUe \\nBuIdA}O}ONd \\nae \\nNOA \\nssajun \\nWY} \\nBUIA[OSAJ \\nALI} \\n3}SEM \\nJOU \\nOP) \\nB}ep \\nadinos \\nAYP \\nYM \\nsanss| \\nAue \\n}USWWINDOG \\nSUO!IUNJ \\n19U}O \\nJO \\nSadeJ19}U! \\nJY} \\nYM \\nSanssi \\nAue \\n}uaWINDOG \\n« \\nsauianb \\n10 \\nsyiodai \\nay} \\nUM \\nsanss! \\nAue \\nJUaWUNDOG \\n+ \\nJOO} \\n94} \\nYUM \\nswWajqoid \\nAue \\n}UaWINdOG \\n« \\nSUO!PUNJ \\nJBUJO \\nJO \\n‘SadeJJ9}UI \\n‘SaUaNnb \\n‘syodai \\nysay \\n- \\nSUO!}IUNJ \\n19Y}O \\nJO \\nSAILJJa}U! \\nJO \\nJaSqns \\npaypajas \\ne \\ndILIM \\n« \\nSauianb \\njo \\nJasqns \\npapajas \\n& \\naM \\n« \\nSUOdad \\nJO \\nJasqns \\npapayas \\ne \\naM \\n« \\nb}ep \\nsa} \\najdtues \\nJO \\ne}ep \\nadinos \\najdwes \\nYM \\naseqgejep \\nadhjolo1d \\nau} \\npeoq \\n« \\n(2}e€p \\nMAU \\n9}€3J9 \\n1O \\ne}ep \\nadiNOs \\najdwes \\ne1}X~a) \\ne}ep \\n}Sa} \\najduues \\nayeasD \\n- \\nadhyojo1d \\n(sed1pul \\n‘SULUNIOD \\n‘sajqe}) \\naseqeyep \\nadAjo}0/d \\nJed1sAyd \\naU} \\na}eaID \\n« \\n3} \\npling \\n“9 \\naseqeyep \\nadA}0}01d \\nay} \\nO}U! \\neyep \\nSa} \\nMau \\nJO \\ne}ep \\nadINOs \\najdwes \\ndey \\n« \\n2}ep \\n}Sa} \\nMAU \\nJO \\ne}eP \\n3D1NOS \\nJO \\naides \\nanyejuasaidal \\n& \\nJayya \\n:adAyo}01d \\nau} \\n40} \\npasn \\naq \\n0} \\neyep \\nau} \\nAjiquapy \\n« \\naseqejep \\n3dA}0}01d \\nay} \\n10} \\n(USISap \\naseqeyep) \\njapow \\neyep \\njedIsAud \\ne \\nayealD \\n« \\nPua \\n}JUOIY \\nGaN \\nJO \\n[MD \\n:sadejsa}U! \\nBy} \\nUBISAq \\n« \\nsajdwes \\nsauianb \\ndn-yD0W \\nUO \\n40 \\nsyiodal \\nJo \\nsyaayspeaids \\nSulsixa \\nUO \\npaseq \\nSauianb \\nay} \\nUsISaq \\n« \\npue \\nsyodai \\nsynoAe| \\nYodas \\ndn-yoow \\nJo \\nsoda \\nBuNsIxa \\nUO \\npaseg \\nsyiodal \\n9} \\nUBISAq \\ne \\n9U} \\nUSISAG \\n°S \\nSs \\nSYSD}GNS/SYSDL \\nsania \\ny \\ndajs \\ndajs \\njuauidojanaq \\n_ \\nCee \\nSE \\nSuldA}o}01g \\nuoneriddy \\n:9 \\ndais \\n}uauidojanaqg \\n— \\nXL}eW \\n¥se}qns/yseL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 463}, page_content='Task/Subtask Matrix 430 \\naiqeaijdde 41 ‘uoesay! adA}O}Od }x9U BU} WUO}Iad « \\nuo}ed1dde \\n|g \\nay} \\na}0WOJd \\n0} \\nsuOHesSUOWAP \\nadAjo10/d \\nasf \\n- \\nWed} \\n3109 \\ndajs \\n714 \\n9u} \\nUUM \\nJejndWed \\nul \\npue \\nWes} \\n3109 \\nPafosd \\n311}Ua \\nJU} \\nYYWM \\nPIUea] \\nSUOSS2] \\nMAIADY \\n« \\nsasuey) \\npadoidde \\napnjdu! \\n0} \\n}UaWINIOp \\nsyUaWasINbas \\nUOHedI|dde \\nau} \\naSIAaY \\n« \\ndAlve}Uasaidas \\nssauisng \\n3} \\npue \\nJOSUOdS \\nssauUIsng \\nau} \\nYM \\nSasueYD \\npaysanbai \\njo \\nedu! \\nay} \\nMaIAaY \\n« \\npauinbas \\nsadinosal \\nJO \\nSi[I4s \\n[eUONIPpY \\n— \\nSO) \\n— \\nAyyend \\n— \\nout \\n— \\n:JO SU9} UI SASUeYD paysanbai jo edu! ay} azAjeuy - \\nJUBLUNDIOP \\n[01}UOD-2sUeLD \\n3U} \\nUl \\nSASUeYD \\npaysanbaJ \\n}JUaWINIOG \\n« \\ndAI}e}UaSaIdaJ \\nssouIsng \\n9Y} \\npue \\nYadxea \\nJayew \\npafqns \\nau} \\nYyyM \\ns}UaWa.Nbas \\nafoid \\nJy} \\nMAIAIY \\n« \\nWed} \\n3109 \\nJU} \\nUO \\ndAIL}UaSaIdas \\nssaulsng \\nay} \\npue \\nJOsuOds \\nssaulsng \\n3y} \\nYM \\nSanss! \\npuke \\nSWajgolJd \\nMaIAay \\n« \\nadfyojo1d \\nau; \\najdoad \\nssauisng \\n34} \\nuM \\nSalianb \\npue \\nsyiodas \\nMaIAdY \\n« \\nd}eNJSUOWIG \\n7 \\nnnn \\nnn \\nnn \\nnnn \\nnnn \\nnnn \\nnn \\nnn \\nnnn \\nnner \\nnnnnnnnnnnnnnnnnn \\nnnn \\nSSS \\nSSS \\nSYSDIQNS/SYSDL \\nsamiAnoy \\nda}s \\ndajs \\n}uauidojanaq \\neee \\nn nnn \\nnnnnnnnnnnnnnnnnnenen \\nSS \\nSSS \\nSSS \\nSSS \\nSSS \\nSSS \\nSuIdA}0}01dg \\nUOHeIIIddy \\n:9 \\ndais \\nyuauidojanag \\n— \\nxXL}eIW \\nySeIqns/yseL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 464}, page_content='431 \\n—_—_—_—_——_—erereeeeeeeeeeeee \\nMoysodai \\neyep \\ne}aW \\na4} \\nWO4 \\npadnpoid \\naq \\npinous \\nsyodas \\neum \\nSUILLD}IQ \\n° \\n: \\nUO!}UNJ \\ndjay \\naAl}ISUas-}x9}UOD \\n& JO \\nAyIqiseay \\naU}Y \\nazAyeuy \\n« \\nsoe \\neae. \\nsulyoda \\n(IWLH \\n‘4dd \\n‘a|dwexa \\nJoj) \\nsynsau \\npue \\nssa02e \\nAianb \\ndoy \\npe \\nejep \\neyawi \\n8ulAejdsip \\n10} \\nelpaw \\nadej1a}U! \\nssadde \\nou} \\nAjiquapy] \\n« \\nArousodas \\nsjuaWadinba \\nAyndas \\neyep \\neJIW \\nJY} \\nMAaIAay \\n« \\neyep \\ne}aw \\ns}uaWiasInbad \\n3ulodas \\npue \\nssad.e \\nAuoysodas \\ne}ep \\neyalU \\n|eUISLO \\n9U} \\nMAIAdY \\n« \\n9U} \\nazAjeuy \\n“¢€ \\nynpod \\nAsoysodai \\neyep \\nejyaw \\nay} \\nul \\nse \\n[]OM \\nSe \\ns]OO} \\naSay} \\nUl \\nBJge|IeAe \\naie \\nSainjzeay \\nYOdxe \\npue \\nWOduI \\n}eUM \\nduUILUa}aq \\n« \\nJOO} \\nSUIUILU \\ne}eEg \\n— \\n5}00} \\nAlanb \\npue \\nsiaqumM \\nYWoday \\n— \\n$100} \\ndV10 \\n“1L4 \\n‘ASWD \\n— \\nMioysodas \\na \\nSUEUOIDIP \\nSWAG \\n— \\neyep \\nPOW \\ndy} \\n= \\nsjaayspeaids \\npue \\nsail \\nSulssadoid \\nprom \\n— \\nJO} \\nS}UaWaINba \\n= \\n:payde1}xa \\nDEJO}! \\n> \\n2q \\n[IM \\ns}UsUOdWOD \\ne}ep \\nBJAW \\nBY} \\nYIYM \\nWO \\nSadINOS \\neyep \\neJaW \\naU} \\nazAjeuy \\n« \\ndU} \\nazAjeuy \\n‘*Z \\n: \\nsasueyp \\nAue \\nPaljaJ \\n0} \\nJUBWINIOP \\ns}uatWasINnbas \\nUuoNer1;dde \\n3} \\na}epdyp \\n« \\n2. \\njeuondo \\n10 \\n‘yueYOduI \\n‘Aioyepuew \\naie \\ns}UaUOdWIOD \\ne}ep \\n= \\nBJOW \\nJY} \\nJBYJOYM \\nBUI}EIIPU! \\n‘Sa|qeJaAljap \\nAuoysodas \\neyep \\neyaW \\nBU} \\nAZO \\n« \\n6 \\nSa|GeJaAl|ap \\nA1oysodas \\neyep \\neJaW \\nay} \\nJO \\n3dods \\nau} \\naUILUIA}aq \\n« \\nfe \\n(JE>1UYd9} \\npue \\nssauisnq) \\nsyuatasinbas \\n= \\nBJP \\nPJIWW \\nMOU \\n10} \\nHOdas \\nJUSUUSSaSsSe \\naiN}DN\\\\SeJJU! \\n[2|UYD9}UOU \\nJY} \\nMAlAdy \\n« \\n“ \\nMioysodai \\neyep \\neJaW \\ne \\nPjINg \\n10 \\nasuad|| \\n0} \\nUOISIDap \\nay} \\naye \\n« \\n= \\nMoysodas \\nsjuawiasinbad \\nOr \\ne}ep \\nPjalU \\nB BUIPIING \\nsNsJaA \\nBUIsUad|| \\n104 \\nsIsAJeUL \\n}JaUAG-}SOD \\nBP \\nUOLIad \\n« \\nAiousodas \\nsiskjeuy \\n= \\nMuoysodas \\neyep \\ne}aW \\ne \\nadUeYUA \\nJO \\n‘pjIng \\n‘(Ang) \\nasuad|| \\ne}ep \\nblow \\nAioysoday \\n= \\n0} \\ns}UaWaJINbad \\n10} \\nWOdaJ \\nJUAaLUSSASSE \\nJ1N}DNASEAUI \\n[ED|UYI9} \\nJU} \\nMAlAay \\n« \\n9} \\nazAjeuy \\n‘1 \\nejeq \\nePW \\n7 \\na. \\nSSS \\ng \\nSYSDIGNS/SY¥SDL \\nSalIAn \\nDY \\nda}s \\ndajs \\njuawuidojanaq \\na \\nsishjeuy \\nAioysoday \\neyeq \\ne}aW \\n:Z \\nda}syuauidojanag \\n— \\nXL}eW \\n4se}qns/yse \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 465}, page_content='Task/Subtask Matrix 432 \\na \\nee el \\nSdiysuonjejas \\npue \\n‘Saynquyye \\n‘sal}}WUa \\neyep \\ne}aW \\nJO} \\nSajNJ \\nSsaUISNg \\nay} \\naUIjaq \\n» diysiauMO — Ayundas — \\n(}U9}U0D) \\nUleWOg \\n— u}Sua] pue adAy — UOIMUYaq — aWeN — “UUM Sa}Nquye e}yep yaw [Je aqudsaq - \\nIWNIOA \\n— \\nSSOUIJOWIL \\n— \\nuol}ed0] \\nJed1SAUd \\n— \\nAyundas \\n— Sdiysuonejay — UOHUJaq — \\naWeN \\n— \\neyep \\neyoOwW \\nYUM \\nSaly}Ud \\ne}ep \\ne}OW \\n[Je \\naqUdSaq \\n» \\n= -eJALW \\nBU} \\na}RaID \\n°S \\nWweiseIp diysuoiejas-AyUa Ue MeIG « \\nSal}jUa \\neyep \\nJAW \\n|eEdUUI2} \\nPue \\nSSdUISNG \\nJO} \\nSajnquye \\na}eaD \\n« \\nSal}}UI \\nPJEP \\nEJOW \\nJY} \\nUIBMjaq \\nSCIYSUO!}E]3J \\nJY} \\nDUILWIIQ \\n« \\njapow \\nSOHI}US \\nE}EP \\nCOW \\n|LIIULYI} \\n}eaID \\n«+ \\ne}9W \\n[eDd130} \\nSal}IJUa \\ne}EP \\nE}OW \\nSsauIsng \\no}eaJD \\n« \\nUY} \\na}e3ID \\n‘py \\nnen \\nnn \\nen \\nee \\nnn \\nener \\ncnncn \\nnnn \\nSSS \\nSSS \\nSSS \\nSYSDIGNS/SYSDL \\nSATAN \\nY \\ndajs \\ndajs \\njuauidojanaq \\nNeen \\nen \\nnnn \\nnnn \\nenn \\nnnnncnnnnncnnnnnnnnnnnnnn \\nSSS \\nSS \\nsishjeuy \\nAuoysoday \\neyeq \\nea \\n:Z \\ndays \\nyUatdojanaq \\n= — \\nxLeW \\nyseIqns/yseL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 466}, page_content='433 ign Database Desi Development Step 8 \\n-———— \\nSSS \\nAue \\n}1 \\n‘papaau \\naq \\n||IM \\neyep \\npajleyap \\nsuowe \\n(sdiysuonjejas \\nAyyUa) \\nsdiysuonejas \\nssauisng \\nAuew \\nMou \\nSUIWUD}AQ \\n« \\n(20Y \\npe \\n10 \\nUMOP-||LIP) \\npassadde \\naq \\n[JIM \\ne}ep \\npajiejap \\nay} \\nMOY \\ndUILUA}aQ \\n« \\npapseu \\n(Ayejnuedss) \\n[1e}ap \\nJO \\n[aAa] \\nBU} \\nDUILLIA}IQ \\n« \\nJojes}SIUILUPe \\nB}ep \\nJU} \\nUUM \\nJaPOW \\nyep \\n[eI13O| \\n9Y} \\nMAIADY \\n+ \\nSUOISUALUIP \\nSUI}Odal \\npasn \\nAjjuanbay \\nSOW \\naU} \\nSUIWA}AQ \\n« \\nsjuawpedap \\nsnoueA \\nWold \\najdoad \\nssauisng \\ns8uowe \\npuke \\nspyodas \\nSuNsixa \\nBuowe \\nsuaHed \\nSuliodas \\nUOWLWOD \\nMAIAdY \\n« \\nadAjojod \\nay} \\nJo \\nsuonduny \\ndn-jjo1 \\npue \\nUMOP-||LIP \\nYU} \\nMaIAay \\n« \\nsjuawasinbas \\nadfjo}o1d \\nay} \\nAq \\npasn \\nsuoisuawiIp \\nay} \\nMaIAay \\n« \\nuONeZI \\nyewiuwuns \\n(uoHezZUeWWuNs \\npue \\nUOHesaisse \\nYsnoiy} \\npue \\nuonesaisse \\nPaALap \\n34am \\nAay} \\nMOY) \\nadAjo}01d \\nay} \\nAq \\npasn \\n(s}eJ) \\nsaINseaLU \\nBY} \\nMAIADY \\n« \\nOU} \\nQUIWI}AQ \\n*Z \\n(S19}UM \\nOda \\n‘dV10 \\n“1L9) \\nSUOHE}LUI] \\nJOO} \\nAUIWA}aq \\n« \\nSUOH}EUWI] \\nWU0j}e]d \\nSUIWAIaq \\n« \\nspoued \\nSulyiodai \\njeuoseas \\npue \\nyead \\nau} \\naUIWA}aq \\n« \\nsuolyndexe \\nAuanb \\npue \\nyoda \\njo \\nAduanbayy \\nay} \\nauIWa}aq \\n« \\na|doad \\nssauisng \\nJO \\nUO!}Ed0] \\nJU} \\nSUILA}aq \\n« \\nSasesn \\naseqgejep \\nJUaLINIUOD \\nJO \\nJaquunu \\npayeloid \\nay} \\naUIWa}aq \\n« \\nS10}DE} \\nY}MOIS \\nPUe \\nSALUNIOA \\ne}yep \\npayafoid \\nauIWajaq \\n« \\nsjuaWadinbas \\nAyUNdas \\neYLP \\nMAIADY \\n« \\nsjuawadinbai \\n8ulAsanb \\ndoy \\npy \\n— \\nsjudWadInbas \\nSulAJano \\n— \\nsjuaWalnbas \\nSuloday \\n— \\n‘2Al}e}Uasaidad \\nssauisng \\n410 \\nYadxa \\nJa}j}eW \\nYafqns \\nay} \\npue \\nJadojanap \\npeg] \\nuojedijdde \\n3y} \\nyyM \\ns}uawiasinba \\nsiskjeue \\npue \\nssadde \\npaylej}ap \\nMaIAaY \\n« \\nsjuawaunbas \\nJadojaaap \\npea] \\nuoed)|dde \\nay} \\nym \\nsynsas \\nSuidAjojo1d \\nay} \\nMalAay \\n« \\nssande \\nuSisaq \\nsuonedyioads \\nSulsueajd-e}ep \\ndy} \\nMAIAdY \\n» \\n—-e}eP \\nBY} \\nMAIADY \\n‘| \\nasegejeq \\n‘9 \\n—_— \\naa \\nSYSD}IGNS/SY¥SDL \\nsania \\noy \\ndais \\ndajs \\njuauidojanaq \\n_ \\na \\nusisaq \\naseqej}eq \\n:gdajs}uauidojanag \\n— \\nXH}eI \\n4Se}GNS/yse \\n1 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 467}, page_content='a \\nSadIPU| \\n— \\nshady \\nUBSI9IO4 \\n— \\nshay \\nAiewid \\n— \\nsuUNIOD \\n— so|qgel — \\nsaoedsajqel \\n— \\nSUOI \\nPed \\n— saseqejeq — \\nsdnoi3 \\na3e10}5 \\n— \\nsaseqe}ep \\njadje} \\n‘3U|UYaP \\n(10q) \\nadensue] \\nuoH!UYap \\neyep \\nay} \\nayeasD \\n« \\nIg \\nau} \\npjing \\n‘s \\nTask/Subtask Matrix \\nsweisold \\n114 \\nau} \\nAq \\n10 \\nSIG \\nay} \\nAq \\npadiojua \\nag \\n| [IM \\nAqZaquI \\n[eUaJaJoJ \\nJAUJBYM \\nSUIWA}AQ \\n« \\nA8ayeis \\nSurxapul \\nayeudoidde \\njsow \\nau} \\naUuIWa}aq \\n« \\nIZISYIO|G \\nIU} \\n9S \\nO} \\nBB1L] \\nMOU \\nSUIWI}9q \\n« \\naJejdap \\n0} \\nadeds \\nJajyjnq \\nYINW \\nMOY \\ndUIWa}9q \\n« \\n9SOOY) \\n0} \\nadeds \\n391} \\nYONW \\nMOY \\nIUIWJIIIQG \\n« \\nSYSIP \\na]dijjNW \\nssoide \\nSajqe} \\nay} \\nUOIed \\n0} \\nMOY \\ndUIWWA}aQ \\n« \\nsaunyonys \\nSYSID \\n9dL}S \\n0} \\nMOU \\nSUILA19Qq \\n» \\naseqeiep \\nS}aSe}ep \\nJO \\nJUBWAIe|d \\n3} \\nSUIWAIaq \\n« \\nreaiskud \\nS3]GE} \\nBU} \\nJA}SN|D \\nO} \\nMOY \\nSUILUIA}IQ \\n° \\n3U} \\nUSISAQ \\n‘Pp \\nJaPOW \\neyep \\n[ed130] \\nBU} \\n0} \\nsjapow \\ne}ep \\njedIsAyd \\nau} \\ndew \\n- \\n(sadipul \\n‘SAay \\n‘SULUNJOD \\n‘Sajqe} \\n10} \\nSUOIUYap \\npue \\nsalueU \\n‘a]dwexa \\nJ0J) \\nsj|apow \\neyep \\njed1isAyd \\nay} \\nJO} \\nE}EP \\nEJB \\nJed1UYI9} \\nJY} \\na}eaI> \\n« \\n(sweiseIp \\nUSISap \\naseqe}ep) \\nsjapow \\ne}ep \\njedIsAyd \\nau} \\na}eaID \\n» \\n(aun}xIW) \\nEWeaLds \\nUSISAap \\nPUGAH \\n— \\nBWAY)s \\nJEUO!}eJa1 \\npaseq-diysuolejas-AjUy \\n— \\nPLWWAYIS \\nIYE|JMOUS \\n|EUOISUSWIPIINA \\n— \\nPWAY)S \\nJe}S \\n|EUOISUSWIPHIN|A \\n— \\nSaseqejep \\njosie} \\n“SPELUBUDS \\nUSISap \\naseqeyep \\najeudoidde \\nau} \\naulWajaq \\n« \\n1g \\n9U} \\nUBISAGg \\n“¢ \\nSYSD}GNS/SYSDL \\nsanAnoy \\ndays \\ndaj}s \\njuauidojanaq \\nSSS \\nusIsaq \\naseqe}eq \\n:g \\ndais \\n}uauidojaaaq \\n=— \\nxXxL}eW \\nySseIqns/yseL \\n434 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 468}, page_content='wn \\nfoal \\nSS \\nSSS \\nSS \\n+t \\n“AYANID \\nuoND}Uawajdui| \\n-jsod \\nbulobuo \\nup \\nsI \\nSiu \\n-3JON \\nuolndexe \\nAuanb \\njayjesed \\n3zi13n \\n0} \\nUe} \\n« \\nsugisap \\nAiessadau \\nJI \\n‘S{00} \\nd¥10 \\n10} \\nsaanb \\nySnolu}-ssed \\nayM \\n0} \\nUe} \\n« \\nAuanb \\nauy \\naun} \\nswieisoid \\npue \\nJoWUOW \\nuoledi|dde \\npue \\nsuiesgoid \\n713 \\nul \\nsijed \\nTOS \\n|e \\nauljwiea|ds \\npue \\nMaiAai \\n0} \\nUeId \\n0} \\naiedald \\n*g \\n‘AYARID \\nuo/D}Uawa|du| \\n-jsod \\nbulobuo \\nup \\nsi \\nsi \\n-dJ0ON \\nAiessadau \\nJI \\n‘Sad1pul \\n|euOHIppe \\nppe \\n0} \\nUe}d \\n« \\nsliscan \\nSEWWAUS \\nUBISA9P \\naSeqe}ep \\nJU} \\nSUIJA \\nO} \\nULI \\n» \\naseqeiep \\nuonepeisap \\nay} \\naun} \\naUeUOJJad \\nasouseIp \\noO} \\nAj|IIN \\nSULOPUOW-adUeWUOJJad \\n& \\nasN \\n0} \\nULI \\n« \\npue \\nJoWUOW \\nalujuNJ \\nye \\nsalianb \\npue \\n‘syodai \\n‘speo] \\n7.19 \\nJO \\nadUeWOJJad \\nBU} \\nJ0UOW \\n0} \\nUe} \\n« \\n0} \\nsiedald \\n‘7 \\nSAIPHANIE \\nBULOPUOW \\nSULWUOJIad \\n410j \\nainpad0Id \\npue \\nJo \\nAdUanbay \\nau} \\nDUIaQ \\n« \\nSajqe} \\npa}yuawises \\n410) \\nsainpadoid \\nuoNeziueZioay \\n— \\nsainpadoid \\nSainpadoid \\nAlaAodaJ \\nJaysesiq \\n— \\ndUCUSUIEW \\n. \\n(sdnypeq \\nJe}UaWaJDU! \\npue \\nsdnyDeq \\n||ny) \\nsdnydeq \\naseqejeq \\n— \\naseqej}ep \\nDp \\nJO} \\nSAIPAN \\nBdUeUd}UJEW \\naseqeyep \\nauljaq \\n« \\ndojanaq \\n°9 \\n~”n Vv \\ne \\nS22|PUI \\naU} \\npling \\n- \\npa \\nsainjonijs \\naseqgejyep \\njedisAyd \\nau} \\n0} \\nAyoujne \\nGnyD \\n}UeIs \\n0} \\n1Dq \\nau} \\nUNY \\n- \\nOo \\nic \\nsainjonijs \\naseqeyep \\njedisAyd \\nay} \\n3}e319 \\n0} \\n1qq \\nau} \\nUNY \\n- \\n4 \\nsal \\ndnois \\nés \\na}eldoidde \\nay} \\n0} \\nswessoid \\npue \\n‘s}sAjeue \\nssauisng \\n‘siadojanap \\nuSissy \\n— \\no \\nSCI \\ndnois \\nay} \\n0} \\nAyouzne \\n(ajajap \\n‘ajyepdn \\n‘peas \\n‘ay919) \\nGNUD \\n}UeIDH \\n— \\naA \\nsq| \\ndnoi3 \\ndn \\njas \\n— \\n(panujuod) \\nE \\nFTAVLSAS \\nAndes \\n3y} \\n10} \\nsiajawesed \\nauyaq \\n— \\nsaseqejep \\njase} \\n= \\n:0} \\n(19d) \\nasensue] \\n}013U0) \\neyep \\nayy \\nayeasD \\n- \\nIg \\na4} \\nping \\n*s \\na. \\na \\nSS \\n2 \\nSYSD}GNS/SYSDL \\nSarMIAnY \\ndais \\ndajs \\nJuauidojanaq \\n> \\n_-.SSl \\nEe \\na \\nusIsaq \\naseqeieq \\n:g \\ndays \\n}uawdojanag \\n— \\nXL}eI \\n4Se}qNs/yseL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 469}, page_content='ssad0/d \\n714 \\ndu} \\nUl \\nSda}s \\naBsaW \\nPUue \\nLOS \\nJY} \\nJUILWa}aq \\n« \\npapeo| \\npue \\n‘pasueald \\n‘pawiojsues \\nag \\nUBD \\nB}EP \\nBdi1NOS \\npa}eJ}X9 \\n94} \\nYDIYM \\nU! \\nBdUaNbas \\nJUAIDIJJa \\nJSOW \\nJU} \\nDUILAIVQ \\n« \\nsaseqe}yep \\nad1NOs \\nPUe \\nSaji} \\n9dINOS \\naU} \\nWO \\nMO}j \\nSSad01d \\nPpapel}x9 \\naq \\nUBD \\nP}EP \\nBdINOS \\nYDIYM \\nUl] \\nadUaNbaS \\n}UAIDIJJa \\nJSOW \\nJU} \\nJUILUIAIAQ \\n« \\nLJ \\nau} \\nusIsag \\n*¢€ \\n100} \\n1.19 \\n94} \\nAq \\npaypuey \\naq \\nyoUUeD \\nyey} \\nSUOHeWWOJSUeL} \\nJO} \\nUBWYUM \\naq \\n}SNW \\napod \\nWo} \\nsnd \\nAieyUaWajddns \\nyeYyM \\nIUIWA}IG \\n« \\nIIZO] \\nUOIEWWOJSULI} \\npouinbas \\nay} \\nWOJJed \\nUPD \\nSUO!DUN} \\nJOO} \\n119 \\nBY} \\nJOYJOYM \\nJUIUWA}aQq \\n« \\nyUawUNDOp \\nsuolpun} \\nSulddew \\n}931e}-0}-391NOS \\nay} \\nUl \\nSUOHEIYIDI9dsS \\nUOHPUOJSULI} \\nJU} \\nMAIADY \\n» \\n— JOO}. \\n1. LJ \\nBUI \\nISAL \\n“Z \\nTask/Subtask Matrix \\n(sjunod \\njUNOWe \\n‘S}UNOD \\nUIEWOP \\n‘S}UNOD \\np1Oda4) \\nS]e}O} \\nUOHLI[IDUOIAI \\nJO} \\nIISO] \\napnjouy \\n— \\nS}UNOD \\nUONDefe1 \\nPlOIa1 \\nPUL \\nSABeSSALW \\nJOM \\nJO} \\nDIZO] \\napnjouy \\n— \\n(SWaG \\n2u} \\nAg \\npawuoyiad \\nyou \\n$1) \\nAySazu! \\njeyUdJaJa1 \\nSUNayYD \\n104 \\nDIO] \\napnpou] \\n— \\nULWUNJOD \\nYded \\nJO} \\nSUO}}EdJIDads \\nSulsuead-e}yep \\napnpu| \\n— \\nSWYJOS]e \\nUOHEZLEWLUNS \\npue \\nUOHeSoIsse \\napnjou] \\n— \\nsasodind \\najdijjnw \\n10} \\npasn \\nsem \\neyep \\n9DJNOS \\nJ! \\nSULUNIJOD \\na]dyjnW \\nssoide \\nJUaWA]a \\nL}eEp \\nBUO \\nWO \\nJUd}UOD \\ne}ep \\nIds \\n— \\n(Papaau \\n1) \\nSadINOs \\najdiyNwW \\nWO \\n}Ud}UOD \\ne}ep \\nBUIGUIOD \\n— \\n“SULUNJOD \\n9Y} \\nSulyeiNdod \\n40} \\nsuoedyIads \\nUONeWIOJSULI} \\nJIU \\n« \\nJUBWaja \\neyep \\nad1nNOS \\nAJaAd \\nJO} \\nYYSUs] \\nPue \\n3d} \\neyep \\njsI7 \\n« \\nULUNJOD \\njJos1e} \\nAlaAa \\nJO} \\nUSUI] \\npue \\nadA} \\ne}ep \\nIsIq \\n« \\nULUNJOD \\nJasse} \\nAlBA \\nJO} \\nSJUBLUAJa \\nEYP \\n3dINOS \\n}ULAaIAI \\n|] \\nISIT \\n« \\n3/ge} \\n39312} \\nAlana \\nJO} \\nSaseqeyep \\n3d1NOS \\npuke \\nsajly \\nadINOs \\na]qedi|dde \\n|e \\n3sIq \\n- \\nSULUNOD \\nJOSIE} \\nPUL \\nS3]qe} \\n}ASJe} \\n[Je \\nJO} \\nXUJEW \\ne \\na}eaID \\n» \\naAl}e}Uasasdas \\nSsauisng \\nay} \\npue \\n‘Wadxa \\nJa}7eW \\nPalqns \\nau} \\n‘IsAjeue \\nAyjenb \\neyep \\nyUaWNdOp \\n9U} \\nYUM \\nS}UIWaja \\ne}ep \\ndiNOs \\nJO} \\nSUOHedJIDads \\nSulsued|d-e}ep \\nJU} \\nMAIADY \\n» \\nsmidaeut \\nuSisaq \\npeot \\nSASEqe}eP \\nJd1NOS \\nJY} \\nJO} \\nSYIO]|G \\nUOdDSap \\nyep \\n9U} \\nMAIADY \\n+ \\n1931e}-0}-aD1N0s \\n/WUOJsUeL \\nIL \\nSII} \\nIDINOS \\nBU} \\n10} \\nS]NOAe] \\nP1OI91 \\nBU} \\nMAIADY \\n« \\nOU} \\nB}eIID \\n‘1 \\n/PeNXI \\n‘6 \\nSSS \\nSSS \\nSYSDIQNS/SYSDL \\nSAA \\nIY \\nda}s \\ndajs \\njuauidojanaq \\nSSS \\nSSS \\nUSISAq \\npeoT \\n/WHOJsUeA] \\n/}eXq \\n6 \\ndays \\nyUadojanaq \\n=— \\nxUIeW \\nySeIGNS/yseL \\n436 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 470}, page_content='437 \\nNNN \\nSainpadoid \\nSuluolssaA-WeISOId \\nUSI|qejsq \\n« \\nSdUeIqI| \\nWeIZOIJd \\na}eaID \\n- \\nSa]qe} \\npue \\nsajlj \\n¥JOM \\nJUaUeWWAd \\npue \\nAlesOdWa} \\n10} \\nadeds \\na}ed0}I¥ \\n« \\n(Pasn \\nS| \\nJaAJaS \\npo}edipap \\neC \\n41) \\nJaAIAS \\n119 \\naU} \\ndn \\njas \\n- \\n(J9MU9S \\n7LF \\n9Y} \\nUO \\naWOS \\n‘aWeYyUIeL \\n24} \\nUO \\nSujUUNA \\nSWUesSOId \\n79 \\nBWOS) \\npaynquisip \\naq \\n0} \\nsey \\npW \\nJayI@yM \\n10 \\nPeale \\nSuIse}s \\nPale \\nZUIZe}s \\n[21}U9D \\nBUO \\nUI! \\nUNJ \\nUD \\nSsad0J1d \\n74 \\nad}Ua \\nay} \\nJaUJaYM \\ndUILUalaq \\n« \\n1.1] \\n9u} \\ndn \\njas \\n‘sg \\n(2]NPOW \\nJOO} \\n19 \\nYydea \\nJO} \\nJO) \\najnpow \\nwesso1d \\n714 \\nYea \\n10} \\nsuoHedyI9ads \\nSulWWeIZOId \\nOW! \\nJUaLUNDOD \\nBulddew \\n3a31e}-0}-991NOs \\nay} \\nWOY \\nsUOHeIYI9ads \\nUOHeWUOJSUeL} \\naU} \\nd}e|SURL] \\n« \\najqissod \\nse \\nyonw \\nse \\nswessoid \\n714 \\nay} \\naZUeINpO| \\n« \\npeo] \\nje}Uawai \\nUy \\n— \\npeo] \\n|edU0}sIH \\n— \\npeo] \\njeiuy \\n— \\nswieisoid \\n10} \\nSWeISOId \\n11J \\nJO \\nS}as \\nJasy} \\nUBISaq \\n- \\n11] \\n9} \\nUsIsag \\n‘y \\nign \\nSolP[IIN \\nPeo] \\npue \\nsajly \\npeo7 \\n— \\nSUodas \\nJO.Ua \\npuke \\nSaji} \\nUOIDa{ad \\n104 \\n— \\n(sajnpow \\nWwessoid) \\nsueisoid \\nuoNeUUOJsUeL] \\n— \\nsajqe} \\npue \\nSal} \\n44OM \\nJUBUeLUAad \\npue \\nAyeJOodwia} \\nay} \\nUO \\npauUojad \\nSulZiaw \\npue \\nSuNsos \\n— \\nS9/qe} \\npue \\nsail} \\nYJOM \\nJUBUeULIAd \\npue \\nAyesodway] \\n— \\nsaseqej}ep \\nadinOs \\npue \\nsajlj \\n3dunOs \\nWO \\nspeIXxy \\n— \\n10} \\nSalIUapuadap \\nssad01d \\npue \\naduanbas \\nssad01d \\n3uImoys \\nWeZeIp \\nMO} \\nssad0J/d \\nau} \\nMe \\n« \\njajjesed \\nul \\npapeo] \\naq \\nued \\nsajqe} \\n}eUM \\ndUILWIA}aq \\n« \\n(panujuos) \\njayesed \\nul \\nuns \\nued \\nssad0id \\nFJ \\nay} \\nJO \\nS}UBUOdWOD \\nJeYM \\naUIWA}aq \\n« \\nMO|y \\nssanoid \\nS9]ge} \\npue \\nSaji} \\nYJOM \\nJUBULWWAad \\npue \\nAiesOdW9} \\nJe \\nAyUap] \\n« \\n11] \\n94} \\nusIsag \\n‘¢ \\nSSS \\nSYSD}IQNS/SY¥SDL \\nSAAN \\nIY \\ndais \\ndajs \\njuauidojanaq \\nCC \\nUSISaq \\npeoy \\n/WUOJsue.L/}e}Xq \\n:6 \\nda}s}UaUdojanaqg \\n= — \\nXL}eI \\nYSe}qns/yseL \\nExtract/Transform/ Load Des Development Step 9 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 471}, page_content='Task/Subtask Matrix \\nNN \\n~npold \\nAuojsodai \\neyep \\ne}aW \\nBU} \\n}S9} \\nPuke \\n|]eISU \\n- \\npnpoid \\nAuoysodas \\neyep \\nea \\nay} \\n(Anq) \\nasuadry \\n« S9DUIIIJOJ JUI]D SJOPUIA JY} YDIUD « \\nsOwap \\n~npoid \\nAuoysodas \\neyep \\ne}JOW \\n10} \\naSULLIY \\n« \\n}SI| \\nHOUS \\n& \\nO} \\nSIOPUBA \\nPuke \\nsPNpoOd \\nAuOYSOdal \\ne}eEp \\nJ@W \\nJO \\n}SI] \\nJY} \\nMOEN \\n« \\nJopua \\nAloysodad \\neyep \\ne}aW \\npayenjeAa \\nYea \\nJO} \\nP1eddIOIS \\n© 9}L9ID \\n« \\npnpoid \\nAuojsodas \\nyep \\ne}aW \\nPayenjera \\nYea \\nJO} \\npslLddIOIS \\n& a}eAID \\n« \\nJaPOW \\nBOW \\n[e180] \\npnpoid \\n94} \\nUl \\npue \\nJUBWINDOP \\ns}udWaJINbas \\nUOHeDd1|dde \\npasiAas \\nau} \\nUI \\nS}UaWasINbaL \\nAioysodas \\nAioysodas \\neyep \\neat \\n3Y} \\n0} \\nSPNpod \\nAuoysodai \\ne}ep \\nea \\nay} \\naIedWOD \\n« \\nelep \\neal \\nay} \\nSIOPUSA \\npuke \\ns}nNpold \\nAloysodas \\neyep \\ne}dW \\nJO \\njsI| \\ne \\nafIdWOD \\n- \\n}S9} \\nPuke \\n|Je}sU] \\n*Z \\nsainpadoid \\njeAiydie \\npue \\nSUIUOISI3A \\nUZISaq \\n« \\nsainpadoid \\nAlaAodaJ1 \\npue \\ndnydeqg \\nusisaq \\n« \\naseqejep \\nAloysodas \\neyep \\n&}BW \\nJU} \\nJO} \\n7D \\nay} \\na}eaID \\n« \\naseqejep \\nAloysodas \\neyep \\n&}BW \\nJU} \\nJO} \\nTGC \\nay} \\na}eaID \\n- \\nJOPOW \\neJoW \\nJed1BO| \\ndy} \\nO} \\nJaPOW \\ne}aW \\nJedISAUd \\nayy \\ndey \\n- \\n(pa}yUsHO-Palgo \\n410 \\ndiysuonejas-AjUa) \\nWeIseIp \\njapow \\neyo \\n[edISAyd \\nay} \\nMeg \\n« \\n(pa}uaO \\naseqelep \\nuSisaq \\n-~pafgo \\n10 \\ndiysuo}ejas-Ayjua) \\naseqeyep \\nAuoysodai \\neyep \\neat \\nay} \\nUSISaq \\n» \\nKiousodas \\neyep \\nKiousoday \\nAioysodai \\ne}ep \\ne}aW \\nJU} \\nJO} \\nJBPOW \\ne}aW \\nJeI130] \\nBY} \\nMaIAaY \\n+ \\n—EJBW \\nBY}. \\nUSISAq \\n*| \\ne1eq \\nPW \\n‘OL \\nSSS \\nSY¥SD}IGNS/SYSDL \\nSAMA \\nY \\nda}s \\ndajs \\njuauidojanag \\nSSS \\nusisaq \\nAuopsoday \\ne}eq \\nIa \\n:O1 \\ndais \\n}Uawidojanaqg \\n— \\nxe \\nyseIgns/yseL \\n438 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 472}, page_content='439 ign Meta Data Repository Des Development Step 10 \\nSSS \\nSS \\nuolpuny \\ndjay \\nauljuoO \\n— \\nSSad01d \\nadeLJa}UI \\nSSaDdy \\n— \\nSavando \\n— \\nsuoday \\n— \\n‘uoHed||\\\\dde \\neyep \\neyatW \\nay} \\n10} \\nSUOHeIYIDads \\nSulwWeISOId \\naU} \\naM \\n« \\n(Auopasp \\nAsoysodas \\nB}ep \\nP}OW \\n‘Pua \\nJUOJJ \\n[M.D \\n‘Ae|dsip \\nqam) \\nssad0Jd \\nadejJa}U! \\nSsadde \\naU} \\nUBISaq \\n« \\n(IWLLH \\n‘4dd \\n‘ajduuexa \\n404) \\ns}nsai \\nAuanb \\ndoy \\npe \\neyep \\neyo \\nSulAejdsip \\n40) \\neipaw \\nau} \\nUsISAq \\n« \\nuolpUNJ \\ndjay \\ndUl|UO \\nBAISUaS-}X3}U0D \\nay} \\nUSISaq \\n« \\nuoneridde \\neyep \\nsueldoid \\nOda \\nAso}sodas \\neyep \\neJaW \\nay} \\nUZIsaq \\nea \\naU} \\nUSISaq \\n“fp \\nssad0id \\npeoy \\n— \\nssad0/d \\nUOleUUOJSUeL] \\n— \\nSSad0Jd \\nBDELJd}U! \\nJOO] \\n— \\n:$S990Jd \\nUO}EIZ|W \\ne}ep \\neJaW \\ndU} \\nJO} \\nSUOHEIYID9ds \\nSulWeIZO1d \\nay} \\naM \\n« \\nAioysodad \\neyep \\ne}9W \\nBY} \\n10} \\nsWeIZOId \\npeo] \\nay} \\nUBISAq \\n« \\nBJEP \\nE}OW \\nPI}ILJ}X9 \\nJY} \\nJO} \\nSUOHEWWOJSUeJ} \\nJY} \\nUZISaq \\n« \\nSS9DOId \\nBDEJJ9}U! \\n[OO} \\nJU} \\nUZISAq \\n« \\n(J00} \\nSujuIW \\ne}ep \\n‘}00} \\ndv1O \\n‘]00} \\n7.1] \\n‘a]dwexa \\n404) \\neyep \\neat \\nJed1UYII} \\nSUNDeI}Xa \\nJO} \\nSadINOS \\n|Je \\naZAjeUY \\n« \\nssanold \\n(sjeayspeaids \\n‘s}uauNdOp \\nSulssaz01d \\npom \\nuO}eISILU \\neyep \\n‘J00} \\nASV) \\n‘ajdwiexa \\n10J) \\neyep \\neyawW \\nSsauIsng \\nSul}de1}X—a \\n104 \\nSadinOs \\n|Je \\nazAJeuy \\n+ \\neJaW \\naU} \\nusISeq \\n“€ \\n_ \\nee \\nSYSD}QNS/SYSDL \\nSaIA \\nIY \\ndais \\ndajs \\nJuauidojanaq \\nEE \\nusisaq \\nA1oysoday \\ne}eq \\nBI9W \\n:OL \\ndais \\n}uauidojanaq \\n— \\nXL}eW \\n4Se}qns/yse \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 473}, page_content='Ce \\nSe \\nMee \\nA \\nee \\nee \\nes \\nhe \\nee \\nre \\ne}JLP \\nSWINJOA-|[N} \\nYUM \\nBUI}S9} \\nJ1OJaq \\n}S9} \\nUOTE;NUWIS \\n© \\nUN \\nPUP \\n[OO} \\nUO!}E|NWIS \\nBY} \\n0} \\n(UO \\nOS \\npuke \\n‘SAaWINIOA \\n‘sajqe} \\n‘saseqej}ep \\n‘SWUeIBO1d) \\nS}UDUOALUOD \\n}S9} \\nJY} \\nBUIAP \\n‘JO0} \\nUOHL|NWIS \\n}sa} \\nSsai}s \\ne SuISN \\nJ] \\n« \\nSUl}S9} \\nIURWOJJad \\nJO} \\ne}YLP \\nAWUINJOA-||NJ \\nasfF \\n- \\nsuol}esado \\npayed!|dwo2 \\nWiojiad \\nyey} \\nSajnpOwW \\n00} \\n714 \\npue \\nswesod \\nTJ \\nau} \\n}sal \\n« \\nSo]ge} \\nJUINJOA \\nTask/Subtask Matrix \\n-Ysly \\nJsulese \\nSajnpOwW \\n[00} \\n714 \\npue \\nswesZO1d \\n79 \\nJO \\nUONNDaxa \\n|Jajjesed \\nay} \\nysay \\n+ \\nssanoid \\nSo]qe} \\nQUIN|OA \\nTLA \\n9U} \\n}So} \\n-Y31Y \\n0} \\n3}1M \\nJO \\npead \\n}eU} \\nSajNpOW \\nJOO} \\n114 \\npue \\nswesZosd \\n71] \\nJenpIAIpul \\nysay \\n« \\nBIUCWUIOLJad \\n“€ \\ns}[NSal \\npapadxa \\nau} \\nSAdNpold \\n} \\nUN \\nPua \\n0} \\nSUlUUIZaq \\nWO \\nSsad0JId \\n719 \\nal]Ua \\ndy} \\nJsa}ay \\n« \\n(|00} \\nT.LF \\nAY} \\n40} \\nSUOIINAYSU! \\nBY} \\nJO) \\nSWeISOId \\nTJ \\nBY} \\naSIADY \\n« \\nS}NSOJ \\n1S9} \\npayadxa \\nYM \\nS}Nsau \\n}sa} \\nJenjoe \\naledwiod \\n- \\nsanss! \\n}Sa} \\nAue \\n}UaWNdOp \\npue \\ns}NsaJ \\n}Sa} \\nJeN}De \\ndU} \\n807 \\n- \\nuejd \\n}s9} \\nay} \\nSuisn \\npua \\n0} \\nSuluuIgaqg \\nWd \\nssad0id \\n714 \\nauUa \\ndU} \\n}S9} \\nUOISSAa1Z9I \\nJO \\nUONeISa}U \\n« \\nssavoid \\n1.4 \\naun \\nSWeISOId \\n1LJ \\nBU} \\nJO} \\n(2}P \\nBDINOS \\nJo \\nyasqns \\naAHeUasaidal \\nke) \\nEYP \\n3S9} \\n3}e9/5 \\n» \\n153} \\nUOISSa13a4 \\n$S9901d \\n119 \\nIY} \\n10} \\nSASeD \\n3S} \\nUUM \\nUe] \\n}sa} \\ne \\na}edID \\n- \\nJO \\nuOH}e1Sa}U] \\n*Z \\naduanbas \\nJadojd \\nau} \\nul \\nsaiiyiin \\npeoj \\npue \\n‘asiawi \\n‘YOs \\nay} \\npue \\nswessold \\n714 \\n9y} \\nayNdaxa \\n0} \\nS}dUDS \\naU} \\nJIM \\n« \\n3|NPOW \\n[O0} \\n7LJ \\nYea \\n}S9} \\nPUN \\n‘}OO} \\nTLJ \\nUe \\nBuisn \\nJ \\n« \\naINPOW \\nWeIZOJd \\n|ENPIAIPU! \\nUDA \\n4Sa} \\nUN \\n- \\nSD1}SI}E}S \\nPO} \\nPue \\n‘SdU}OW \\nAyyenb \\neyep \\n‘sje}0} \\nUOHeI|IDUODa4 \\nBdNposd \\n0} \\nswesOId \\n79 \\nBY} \\nUl \\nBPOd \\naz \\n« \\nAioysodas \\neyep \\neo \\nJU} \\nJO} \\nYEP \\nPOW \\n[eI!UYI9} \\n7.LJ \\nay} \\naunjdez \\n« \\nS9|NPOW \\nJOO} \\n7LJ \\nBY} \\n40} \\n(2}ep \\neyW \\n[EI1UYI9}) \\nSUOHDMSU! \\nBUM \\n{OO} \\n1] \\nUL \\nBuISsN \\nJ] \\n« \\nssad0id \\nyUaWdojaAeq \\n}UBLUNDOP \\nUSIsap \\nWeigold \\n1.1] \\n94} \\n}S9} \\npeo \\n/wuojsuely \\nLJ \\n94} \\nUl \\nsuOHedYI9ads \\nSulUWeIsOId \\nay} \\nSUIMO]|O} \\nAg \\nSwieISOJd \\n719 \\nBU} \\napOD \\n- \\nyun \\npue \\nping \\n°1 \\n/Pe!NXA \\nLL \\na \\nSYSDIQNS/SYSDL \\nSAMA \\nIY \\ndajs \\ndajs \\nJuauidojanaq \\nSSS! \\njuawidojanaq \\npeo \\nT/wuojsuesL/eXA \\n:LL \\ndais \\nyuatudojaneq \\n— \\nxiIeW \\nyseIqns/yseL \\n440 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 474}, page_content='441 Extract/Transform/Load Development . \\ne Development Step 11 \\nSSS \\nSSS \\naAlyejUasaida \\nssaulsng \\nay} \\nWO \\nSsad0Jd \\n714 \\nBuy} \\n40} \\nUOEDIJIAD \\nUIeIGO \\n» \\nS]€10} \\nUOHeIINUODIJ \\na}epIjeA \\n— \\nSOUIINOI \\nSUl|PUCU-JOMA \\na}epleA \\n— \\nSUOIELUIOJSULI} \\nSUISUBZ)D \\n[Je \\na}JepeA \\n— \\n‘dAle}UaSaJdad \\nSSaUISNg \\nau} \\npue \\nYadxa \\nJayWeW \\nSsa201d \\nTL \\n3u} \\npealqns \\nay} \\nYUM \\nPua \\n0} \\nBuJUUIsaqg \\nWO \\nssad0J/d \\n71] \\nau}Ua \\naU} \\n3S} \\naUe\\\\daDD.y~ \\n—jsa} \\naoue}dandy \\n‘s \\nuoyonpoid \\nssad0id \\nOU! \\nSsad01d \\n714 \\nBY} \\nAAOW \\n0} \\nye}S \\nSUOHeJadO \\nay} \\nWOY \\n|eroidde \\nuleIgGO \\n- \\nLA \\nau} \\n3sa} \\njye}s \\nSUOT}e39dO \\nay} \\nYM \\nPua \\n0} \\nBUIULIBIq \\nWOY \\nssad01d \\n1,9 \\na1NUS \\ndU} \\n159} \\nYO \\n« \\n(vO) \\naoueinsse \\nJUBWUOIAUS \\nYO \\nJU} \\nOJU! \\nSWUeISOId \\n7LJ \\n[Je \\nSAO \\n« \\nAyend \\n‘py \\n_ \\nSYSD}QNS/SYSDL \\nsanianoy \\ndazs \\ndas \\njuaudojanaq \\nSS \\nyUalUdojaAaq \\npeoy/WHOjsUueIL/}DeAYXA \\n:1 \\n| dais \\nwuauidojaneq \\n— \\nXLW}eW \\nyseIqns/yseL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 475}, page_content='Task/Subtask Matrix 442 \\nSSS \\nSSS \\nSSS \\nSSS \\nSSS \\nSSS \\najnpow \\nwessold \\njeNpIAIPU! \\nDea \\n3S9} \\nHUN \\nsweidoid \\nuOlUN} \\ndjay \\naul[UO \\nJU} \\napOD \\nSWIEIZOId \\nIDEL9}U! \\nPUD-}UOJJ \\n[EULJ \\nJY} \\nIPOD \\n« \\ns}duos \\nAuanb \\njeul \\nay} \\napod \\n- \\nsweisojd \\nyoda: \\nJeu \\n9U} \\nAPOD \\n« \\ns}duds \\npue \\nswieisoid \\nSuidAyo}o1d \\nadUeYUA \\nJO \\nJIIMAY \\n« \\nnee \\na a \\nP}ep \\n}S9} \\naj]dwies \\nYM \\nsaseqe}yep \\nyUaWdoOjanap \\nau} \\npeoT \\n- \\n3U} \\n159} \\ne}ep \\n}S9} \\najdwes \\no}eaID \\n« \\nyun \\npue \\npjing \\n‘¢ \\n30] \\n}S9} \\n© \\nue \\nSased \\nsa} \\nYM \\nUe|d \\n}Sa} \\neB \\na}eaID \\n« \\nuolpUN} \\ndjay \\nauljuO \\n— \\nssad0Jd \\nadejJa}U! \\npud-}UO14 \\n— SaUandy — syoday — \\nJO} \\nsuoHeIyDads \\nSulwwWessO1d \\ndy} \\ndM \\n- uO}}UNJ djay auljuo au} UBISaq « \\n(leyOd \\ngam \\n‘1ND) \\na>ejJa}U! \\npua-}UO1 \\nay} \\nUBISAaq \\n- \\nsweiSoid \\nsalianb \\njeuy \\nay} \\nud|saq \\n+ \\nuojedijdde \\nswoda \\n|euly \\ndy} \\nUSISag \\n- \\n9} \\nUBISAG \\n‘Z \\nsasueyp \\nAue \\n}a|Jd/ \\n0} \\nJUaLUNIOP \\nSjUaWaJINbas \\nUOHedI|dde \\nau} \\nayepdyp \\n- \\nAuessadau \\n}1 \\nadods \\njeulj \\nay} \\na}eNOBaua \\n‘syUaWaLINbas \\npafod \\nJeul, \\ndy} \\nUO \\naaISy \\n« \\n}USWINDOP \\ns}UdWaJINbas \\nUOHEDI|dde \\nau} \\nJO \\nUOISI9A \\n}S9}L] \\nJU} \\nMAIADY \\n« \\nSjaayspeaids \\nSUNSIXS \\nMAIADY \\n« \\nsynoAe| \\nWoda \\ndn-ydoW \\npuke \\nSUNSIXd \\nMAIADy \\n« SO] SANSSI BU} MAIADY « \\nJUDLUNDIOP \\n|[O1J}UOD-9SULUD \\nJY} \\nMAIADY \\n« \\nsiloweinbel \\ns}duos \\npue \\nswieiso1d \\nSuidAjo}o1d \\nay} \\nMaIAdy \\n« \\npefoid \\nyeuy \\njuaudojanaq \\n3dA}0}01d \\nBu} \\nJO \\nS}/NS3J \\nBY} \\nMAIADY \\n« \\n9U} \\nSUIWLS}I9Q \\n*| \\nuonediddy \\n‘ZL \\na \\nSYSDIQNS/SY¥SDL \\nSAHA \\nIY \\ndajs \\ndajs \\njuauidojanag \\nEEE \\njuaudojanaq \\nuoHed|ddy \\n:z1 \\ndays \\n}uauidojanaq \\n— \\nxe \\nyseiqns/yse \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 476}, page_content='443 \\na \\ndAl}e}UaSaidal \\nSsauisng \\na4} \\nWO \\nUOHedI|dde \\nay} \\n410} \\nUONedINIaD \\nUIeIGO \\n« \\ndAl}e}UISaJdal \\nssauisng \\npue \\nYiedxa \\nJayeW \\npealqns \\nay} \\nYM \\npusa \\n0} \\nBuJUUIsaq \\nWo \\nUOHed!|dde \\na4Ua \\naU} \\nsa} \\naDUe}daDddy \\n« \\nuolanpoid \\no}UI \\nsweisojd \\nuo}ed1}dde \\nay} \\naAOW \\n0} \\nJye}s \\nSUOI}EJdO \\nBU} \\nWO \\nJeAoidde \\nUle}GO \\n+ \\nyes \\nSUO!}e19dO \\nJY} \\nYUM \\nPua \\nO} \\nSUIUUISaq \\nWO \\nUO!}eD!|dde \\naud \\nJU} \\n3S9} \\nWO \\n« \\nJUBLUUOIMIAUS \\nYO \\nJY} \\nOU! \\nS}dUds \\npuke \\n‘Sweisoid \\n‘saseqeiep \\ndAOW\\\\ \\n« \\nB}eP \\nIWNIOA-|[N} \\nYUM \\nBUI}S9} \\nJ1OJaq \\nsa} \\nUOIE|NUWIS \\n@ \\nUNI \\nPUe \\n{OO} \\nUOF}E;NWIS \\nJY} \\n0} \\n(UO \\nOS \\nPUe \\n‘SAaLUNIOA \\n‘sajqe} \\n‘saseqeiep \\n‘SWISOId) \\nS}UIUOAWOD \\n359} \\nJY} \\nBUYAP \\n‘|OO} \\nUO!E|NUWIS \\n}S9} \\nSsaujs \\ne \\nSulsn \\nJ] \\n« \\nBUI}S9} \\nIDURUOJJAad \\n10} \\nE}LP \\nBWINIOA-||NJ \\nas \\n« \\n5 \\nSa]ge} \\nswWINjOA-Yysiy \\npeas \\npue \\n‘suoHejnzjed \\nE \\npayedi|dwod \\nauinbai \\n‘sNiof \\nAuew \\naney \\n}ey} \\nswWeIZO1d \\nasOU} \\nSa} \\nDUPLO} \\nIdd \\n« \\n2 \\npayedxe \\nse \\nwuopied \\na \\nAay} \\n|WUN \\npus \\n0} \\nBUIUUISaq \\nWO \\ns}dlds \\npue \\nswesZOJd \\nUOHedI|dde \\nay} \\njsajay \\n« \\na \\ns}duds \\npue \\nswiessoid \\nuoedi|dde \\nau} \\nasiAay \\n- \\n= \\nS}[NSaJ \\n}S9} \\npa}Iadxa \\nYUM \\nS}NsaJ \\nsa} \\n[en}oe \\nasedwod \\n- \\nA; \\nsanss| \\n}So} \\nAue \\n}USLUNDOP \\npuke \\nS}[NSaJ \\nsa} \\nJeN}De \\nay} \\n307 \\n- \\n= \\nsweisoid \\nUOlDuUN} \\ndjay \\nauljuO \\n— \\n= \\nsweis0ld \\nade}J9}U! \\npua-jUOl4 \\n— \\nSe \\ns}duds \\nAuand \\n— \\nsweisold \\nyoday \\n— \\naH \\n‘uejd \\nsweisoid \\n= \\n}S9} \\nBU} \\nWO} \\nSASeD \\n}S9} \\nJY} \\nBuUISN \\n‘pUa \\n0} \\nSUIUUIS9qg \\nWO \\ns}duds \\npue \\nswesSoid \\nuonedijdde \\n= \\n\\\\J2 \\n(Saseajas \\nJuUaNbasgns) \\n}sa} \\nUOIssaIBaI \\nJO \\n(aSeajas \\n}SJIJ) \\n}SO} \\nUO}EIS9}U \\n« \\nQU} \\nSOL \\n‘Pp \\nCall \\nSe \\nSSS \\ns \\nSYSDIQNS/SY¥SDL \\nSaAn \\nDY \\nda}s \\ndajs \\njuauidojanag \\n> \\nee \\nees \\nO \\nyualwdojanag \\nuoneriddy \\n:z71 \\ndais \\n}uauidojanaq \\n~— \\nXL}eWW \\n4se}qGNs/yse_L \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 477}, page_content='Task/Subtask Matrix \\nSSOUDAIPAYO \\nSUIUILI} \\nBINSed|| \\n« \\nSUOISSAS \\nSUIUIEJ} \\nNPUOD \\n« \\nSUOISSAS \\nSUIUIEJ} \\nJ[NPILS \\n« \\ns}nopuey \\n}UdUIPad \\nJay}JO \\npuke \\nSUOIINJOS \\nasidiaxq \\n— \\nSdSIDJOX9 \\nYUM \\nSYOOGYJOM \\nJUapn}s \\n— \\nS3}0U \\nJOPNJIJSUI \\nPUL \\nSapl|s \\nUOI}E}UASald \\n— \\n‘SJEW9}EW \\nBUIUIe} \\nB}eaID \\n« \\npaules} \\naq \\n0} \\najdoad \\nssauisng \\nAjiuap] \\n« \\nuiuren \\nsiskjeue \\nPaUules} \\n3g \\nO} \\n[BUUOSJad \\nUOSIel] \\nSSauIsNg \\n49U}O \\nJO \\n,SJasn \\nJamod, \\nAjiuapy] \\n« \\npue \\nssa22e \\npauled} \\naq \\n0} \\n4e}s \\nySap \\ndjay \\nAyyuap] \\n« \\nJEP \\nBPIAOId \\n*S \\nSYSDIQNS/SY¥SDL \\nSAAN \\nda}s \\nda}s \\nJuauidojanaq \\n444 \\nqualdojanaq \\nuoNneriddy \\n:z1 \\ndays \\nyuauidojanaq \\n— \\nxi}eW \\nySe}Gqns/yseL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 478}, page_content='445 ining Data Mi Development Step 13 \\n6 \\nee \\neee \\nee \\najeldoidde \\naiaym \\n‘uo \\nnpai \\neyep \\nAjddy \\n- SQd|Mas puke SPNpOJd YYWM SJAWO}SND d}eJdy « \\nSJOWO}SN) \\nP9}ejaJ \\nO} \\nJaquINU \\npjoyasnoy \\ne \\nBulUsIsse \\nAg \\nSIQWO}sNd \\nd}epI|OSUOD \\n« \\na}eldoidde \\naiaym \\n‘e}yep \\nyndul \\njeulsUO \\nWO \\nSa|qeUeA \\nMAU \\ndALIAQ \\n« \\npasn \\nwyyWosje \\nSululw \\neyep \\nsejyndipyed \\nay} \\nyNs \\n0} \\ns}EWOJ \\nEJEP \\nWd9AUOD \\n« \\nsanjen \\n,Ajayl] \\nJSOW, \\nYUM \\nSanjeA \\nBUISSILU \\n34} \\nade|daJ1 \\nJO \\nSAaNjeA \\nSUISSILU \\nYM \\nS2|QeUeA \\nd}eUILUI|A \\n« \\n2}JEP \\nJY} \\nUl \\nASIOU \\nJa}y \\nO} \\nSsJoWUeIed \\nUO!}NL}sIP \\nJedNSIVe}S \\nOSA \\n- Sa|qeuen \\naAeyjUuenb \\n10} \\nuelpaw \\npue \\n‘APOW \\n‘UBdW \\n‘WINWIUIW \\n‘LUNLUIXeLU \\nMaIAay \\n« \\nSa|GeUeA \\n[ed1089}e) \\nJo \\nUONNqUIsSIP \\nADUanbad \\ndy} \\nMaIADY \\n« \\n~~ \\ne}ep \\nay} \\naledaid \\n‘yp \\nSA]GeUPA \\nJAIDe \\nssosde \\nAjpJiqeuoseas \\nUIeEWOP \\naj}epl|e, \\n- \\nSaNnjeA \\ne}ep \\nau} \\njo \\nAj|iqeuoseas \\npue \\nAyyjenb \\nay} \\nainseaw \\npue \\n(jUa}U0D) \\nSUIEWOP \\ne}ep \\ndy} \\nMAaIAdy \\n« \\nAsoysodas \\neyep \\ne}BW \\nJY} \\nWO4 \\ne}EP \\nLBW \\nPajLjas \\nyajas \\n« \\nJOPOW \\nezep \\njedj}Ayeue \\nYea \\nJO} \\neyep \\njo \\najdwes \\ne pajas \\n- B}eP PasJaW JU} JO BINNS BU} MAIADY « \\nBJep \\n[PUa}Xo \\nYM \\neyep \\n[eUJa}U] \\nABi9W \\nPUe \\nYL \\n+ \\n—pyep \\nay} \\nasuea|D \\nS9DINOS \\nE}eP \\n|PUJA}U! \\nSNOWEA \\nWO4 \\neyep \\nassay» \\n= puke \\nayepljosuoD \\n‘¢ \\nSadiNOS \\nP}ep \\nJeUsA}X9 \\nWO \\ne}ep \\nJUaUIad \\n(aseydind) \\nauinboy \\n- \\nSODINOS \\n}ep \\n[CUJA}U! \\nSNOWEA \\nWO \\neyep \\nJUdUIAd \\neX \\n(Ig \\nse \\njJam \\nse \\nJeuOHesado) \\nsadinos \\ne}ep \\najgejiene \\nAyuap] \\nEJeP \\nBY} \\nPojJOD \\n*Z \\nWa|qoid \\nssaulsng \\nau} \\n0} \\nJUeASIa \\nSWIYyWOSje \\nAseulwujaid \\nAyuapy \\n- \\nJOO} \\nSUIUILU \\nJEP \\nJU} \\nJO} \\nSUOI}EPadx~a \\nINISI}eaI \\n39S \\n« \\nlWajqgoid \\nUOHNJOS \\nBUIUILU \\nEye \\n& \\nJO} \\nJUSWPILUWOD \\nUle}GO \\n» \\nssauisng \\nWa|qold \\nssaulsng \\nau} \\ndulaq \\n« \\n9U} \\n3}e1S \\n‘1 \\nSUIUI \\ne}eq \\n“EL \\nNNEC \\nEn \\nCC \\nnnn \\nnnn \\nnn \\nnn \\nnnn \\nnnn \\nnn \\nnnn \\nnnn \\nSSS \\nSSS \\nSYSDIGNS/SYSDL \\nSAMA \\nIY \\ndais \\ndajs \\njuauidojanag \\nEn, \\nSS \\nSUIUIW \\ne}eq \\n:€1 \\ndajs \\nyuawidojanaq \\n— \\nXLU}eW \\nyseIqNS/yseL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 479}, page_content='rr \\né \\nAjsuipsoroe \\nSs \\nJ9POW \\ne}yep \\njedIAjeue \\nINOA \\nysn{[pe \\npue \\naieys \\nJOyJeW \\nS1OWJIdWOD \\nANOA \\nJO}UOW \\n+ \\nfae \\n% \\ns1oy}adwod \\nANOA \\njo \\nsatpyiqeded \\nSuluiw \\neyep \\nay} \\nYDeasay \\n- \\n6ulobuo \\nup \\n5| SIU \\n3S \\nH \\nUIeI}OI \\n:210N \\na \\npue \\njapow \\nezep \\njedAjeue \\nsNoA \\nasueyp \\n‘asueyp \\nsoi}siye}s \\nAYJSMpUl \\nUZUM \\n* \\n— ay \\nJAAO \\nJaPOW \\n2 \\nSJEAJa}U! \\nUU} \\neyep \\njedijAjeue \\na \\nJejnSai \\nye \\nsoNsHeIs \\nAsnpul \\nysulese \\njapow \\neyep \\njedyAjeue \\nANoA \\nSunjepljea \\ndaay \\n+ \\n3U} \\nJOWUOW \\n*8 \\nSUOIJELLA \\nBU} \\n10} \\nSUDSEAJ \\nBU} \\nAUILWA}Aq \\n« \\npete \\nses \\nsoisie}s \\nAusnpul \\nau} \\npue \\ns}nsaJ \\nsiskjeue \\nINOA \\nUasaMjaq \\nSUO}ELEA \\nay} \\nAj}UAP] \\n« \\n:210N \\nsoisizeys \\nAujsnpul \\nau} \\nJO \\nawed \\nSUI} \\npul \\nSa|qeleA \\nsynsai \\nau} \\nJsulese \\nejep \\nINOA \\nJo \\nSWI \\nSLU} \\nPUL \\nSA|GeLA \\nJO \\nUO!}IaIaS \\nBY} \\nB}2PI/EA \\n+ \\nay} \\nJo \\nUONEPIeA \\nsonsieis \\nAsnpul \\npausijqnd \\n0} \\ns}jnsai \\nSulu \\neyep \\naledwioD \\n» \\n= JUJa}X9 \\nWUO}8d \\nZ \\npayio|dxa \\naq \\n}sag \\nUPD \\nUONPWUOJU! \\nMAU \\n34} \\nYDIYM \\nUl \\nSACM \\na}e|NUWOL \\n+ \\nPpa \\nee \\nBoy \\nAZojouyr9} \\nUOHeZIENSIA \\n:2]0N \\nSuisn \\nAem \\npayUualo-ssaulsng \\n‘BUIDUIAUOD \\ne \\nUl! \\nSSUIPUIJ \\nMAU \\n3U} \\n}UaSadd \\n« \\nsyinsau \\na]qeuolde \\npue \\n‘pljeA \\n‘BUI}SA49}U! \\nJe \\nJEU} \\nS}NSO1 \\nJO} \\nYOOT \\n+ \\nZuiuiw \\neyep \\nS][NSO1 \\nSUIUILU \\nE}EP \\n9U} \\nMAIADY \\n« \\n3U} \\nJoUda}U] \\n“9 \\n(J|APOW \\nBY} \\nSUIUTEJIIAO \\nJO \\na4eMadq) \\n|aPOW \\nay} \\nUleJJa1 \\nPUL \\nUe} \\nO} \\n(AJeSSadaU \\n}1) \\nSdays \\n4OLId \\nyeaday \\n« \\nsasAjeue \\nAVAIISUaS \\nyndul \\npue \\nsadujeW \\nUOISNJUOD \\nSuIsN \\njapow \\neyep \\njed1Ajeue \\nau} \\n4O \\nADeundde \\n}sal \\n« \\nlapoul \\nsu \\nOS]e \\nayeUdoidde \\nau} \\nYM \\nSUOHeJadO \\nSuUIUIW \\neyep \\nPalas \\n« \\neyep \\njerAjeue \\nJapOW \\neyep \\n([EUOHeEWUOJU!) \\nJeEdAJeUe \\nBU} \\nB}eaID \\nau} \\npling \\n‘s \\nYIOMJU \\n[eJNIU \\ne \\nO} \\nyNdUI \\n10} \\nUOe}USSaIda1 \\nUBWINU \\n& \\nO} \\naJGeULA \\n[eI10Ba}ed \\n& \\nWAAUOD \\nO} \\naNbIUYIE} \\n,N-JO-9U0, \\n— \\nSa|qeueA \\njed108a}ed \\nOU! \\nSajqeveA \\naayeywUeNb \\nYaAUOD \\n0} \\nanbiuYIE} \\n,UO}EZI}91SIC, \\n— \\n(panujjuo)) \\n:ayeudoidde \\nasaym \\n‘sanbiuyde} \\nuoWeuOysues \\nSulu \\neyep \\nAjddy \\n+ \\ne}ep \\nay} \\naiedald \\n“7 \\nLeen \\neee \\nee \\nreeeeeaaaaaaaaaaaaaaaaacaaacaaaaaaaaaaaaaaaaaaaaaaaaaaaaaamaaaaaaasasaaaaamaaaaaaaaamaaasaaaammmmmmmmmaaa! \\nSYSD}GNS/SYSDL \\nsanAnoy \\nda}s \\nda}s \\njuauudojanaq \\nHenne \\neae \\naaacamaaaaaaaaasaasaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaasaaamaaamamaaaaammammmmmammmaaaa \\nSulul \\need \\n:€L \\ndays \\nyUatdojaneq \\n— \\nXiU}eW \\nyse}qNs/yseL \\n446 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 480}, page_content='447 Meta Data Repository Development Development Step 14 \\nMa \\na \\nsale \\ntiie \\nee \\nee \\nesl \\nae \\na \\neee \\ndaa \\nne \\nae \\nee \\na \\nEE \\nssad0id \\n79 \\n9y} \\nBUUNP \\nUNL \\n[JIM \\n}eU} \\nSWeIZOId \\neYep \\nPOL \\nBU} \\n1S9} \\nNUN \\n- \\nsweis0jd \\npeo] \\neyep \\nea \\n— \\nSWeISOId \\nUOI}EWWOJSULJ} \\nEYeP \\neI \\n— \\nsweisold \\nade}J9}UI \\nJOO] \\n— \\n:(SajnDOW \\npnpoid \\nAuopysodai \\neyep \\neyaw \\nJO) \\nsweiso1d \\nUOeIZIW \\nYEP \\nEOL \\nJU} \\n}S9} \\nHUN \\n« \\nSUOIP<alel \\nJO} \\nSUOSBAJ \\nPUL \\nS}UNOD \\nUO!Dalal \\nEEG \\n— \\nSdUJoW \\n(AyIqelja4) \\nSujsueayd-eyeg \\n— \\n(s}UNOD \\nJUNOWe \\n‘S}UNOD \\nUleEWOP \\n‘s}UNOD \\np4Oda4) \\nS}e}O} \\nUO!}EIINUOI9Y \\n— \\nSdI}SI}e}S \\nPEO] \\n— \\n:ainjded \\n0} \\nssad0id \\n719 \\n8y} \\nSuLNp \\nUNL \\n[IM \\nyeu} \\nSWeIZOId \\nYep \\nP}aLU \\ndy} \\naPOD \\n» \\nAyn \\npeo] \\nSW \\n34} \\n40 \\n~Npoid \\nAuoysoda \\ne}ep \\nJAW \\nJU} \\nJO \\nAyyioe} \\nWOduw! \\nay} \\nasn \\nJO \\nsweIsO1d \\npeo] \\ne}ep \\ne}aW \\nJU} \\nBPOD \\n- \\naT \\nSWEISOIA \\nUOI}EWUOJSULJ} \\nEJLP \\nLJOW \\n9U} \\nBPOD \\n«+ \\nuonelSiw \\ne}ep \\n(100} \\n4SWD \\n‘003 \\n11] \\n‘ajdwexa \\nJ0)) \\nB}JIW \\nJU} \\n3S} \\n‘S]OO} \\nSNOLEA \\nJY} \\nJO \\nAqyIde} \\nYOdxa \\n9} \\nasn \\nJO \\nSWeIBOId \\nJde}J9}UI \\n|[O0} \\nBU} \\nBPOD \\n- \\nyun \\npue \\npying \\n°z \\naseqejzep \\nAioysodal \\nejep \\neJawW \\nau} \\nAjjeidadsa \\n‘sjuauOdWOD \\n~npoid \\nAlopsodai \\ne}ep \\nea \\n|e \\nISA] \\n« \\npnpoid \\nAsoysodai \\neyep \\n2}J9W \\nIY} \\nUO \\nAOU \\nNe \\nGNYD \\nAn \\njas \\n‘npoid \\nAsoysodas \\neyep \\neyawW \\ne Sulsuad|| \\nJ] \\n- \\nSoJN}INI}s \\naseqej}ep \\njuawdojanoqg \\naseqeyep \\nAloysodas \\neyep \\neJaW \\nay} \\nUO \\nAyOUINe \\nGND \\nweld \\n0} \\n1DG \\nayy \\nUNY* \\n—{yoyisodau \\neyep \\nKiousoday \\nsainjomiys \\naseqeyep \\nAuoysodai \\neyep \\neyaw \\njedisAyd \\nay} \\n3}2919 \\n0} \\n1Gq \\nay} \\nUNY \\n- \\ne}aW \\nuy} \\npjing \\n‘1 \\ne}eq \\neRW \\n‘VL \\nener \\nn nner \\nncnncnnnnnncnnnncceennnnnnnnnnececncccnncncecnccceeecceeeeeeeeeeeeeeeeeeeeeeeeeeeeneeneeeeeeeeeeeeee \\nSSS \\nSYSD}QNS/SYSDL \\nSAAR \\nIY \\ndais \\ndajs \\nJuauidojanag \\nLeen \\nnen \\nre \\nnnnnrnnnncnnnncceecnceenncnnccceeenennecncccceececnnnencccccccceceecceeeeeeeeeeeeeeeeee \\nnnn \\nSSS \\nyuauidojanag \\nA1oysoday \\ne}eq \\nea \\n:71 \\ndais \\nuaudojanaq \\n~=— \\nxL}e \\nyseIqns/yseL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 481}, page_content='St \\nan \\nac \\na \\nae \\nee \\nNl \\nA \\na \\na \\nee \\ntn \\naE \\noul} \\nWPS \\n3} \\n}e \\nPaynpuod \\nag \\nAewW \\n3ul}sa} \\n9DuUe}dadde \\npuke \\nYD) \\nieee \\nssauisng \\nau} \\npue \\nYadxa \\nJayewW \\nPealqns \\nay} \\nYM \\nBul}sa} \\nBDUe}d|dIe \\nJNPUOD \\nYeys \\nsuoHesado \\nYUM \\nBUI}S9} \\nYO \\nPNPUOD \\npapedxa \\nse \\nWiopad \\nAau} \\njQUuN \\npus \\n0} \\nSuluUIsaq \\nWO \\nSUUeIsOId \\nAlO}sOdas \\nJEP \\nL}JAW \\nJU} \\n}S9}OY \\n« \\nsweisoid \\nAiopsodai \\ne}ep \\nJAW \\nBU} \\nASIAVY \\n« \\nSINSaJ \\n}S9} \\npapadxa \\nYM \\n$}NSaJ \\n}sa} \\nJen}oe \\naiedwoy \\n- \\nSanss! \\n}Sa} \\nAue \\nJUdLUNDOP \\npuke \\nS}NSaJ \\nsa} \\n[eN}De \\nBU} \\nBOT \\n- \\nssad0Jd \\n7.14 \\n9u} \\nSuuNp \\nuns \\nyey} \\nSWeIsOId \\ne}ep \\ne}aW \\n— \\nsajnpow \\nynpoid \\nJo \\nuoHed|dde \\nAsoysodai \\ne}yep \\ne}JBW \\n— \\nssad0jd \\nuoessiw \\ne}ep \\nea \\n— \\n:Auoysodas \\ne}ep \\nLJ \\nJU} \\n}S9} \\nUOISSAsSa1 \\nJO \\nUOILIBI}U \\n+ \\nssad0id \\n119 \\nau} \\nSuLNp \\nuNJ \\n}eY} \\nSWeIBOId \\ne}yep \\nPJ \\n— \\nsajnpow \\nynpojid \\nJo \\nUOHedI|dde \\nAsopsodas \\neyep \\neB \\n— \\nssadojd \\nUOI}eISILW \\ne}ep \\neI \\n— \\nTask/Subtask Matrix \\n‘Suljso} \\nAioysodai \\neyep \\n&}DW \\nJO} \\nEye \\n}S9} \\nV}eIID \\n+ \\nsuonDun} \\nssad0jd \\n74 \\nau} \\nSuuNp \\nuns \\nyey} \\nSWeIBOId \\ne}ep \\nPJ \\n— \\npnpoid \\nsajnpow \\nynpoid \\nJo \\nswessol1d \\nuoNedjdde \\nAsopsodai \\neyep \\nea \\n— \\nJO \\nsweisoid \\nssad0jd \\nuoles3IW \\ne}ep \\ne}a|\\\\I \\n— \\nAyoysodas \\neyep \\nJO} \\nSASED \\n}S3} \\nUUM \\nUe] \\n}S9} \\nC \\n9}LdID \\n« \\nP}JBW \\n3U} \\n}SAL \\n‘v \\nsweisojd \\nuolpDUN} \\ndjay \\nsulj|uUC \\n— \\ns}duos \\nAuand \\n— \\nswieisOid \\nYoday \\n— \\nSWeISOId \\nadeLJa}U! \\nSSADDY \\n— :(Sajnpow \\npnpoid \\nAoyisodas \\ne}ep \\ne}aW \\nJO) \\nsWeIZOId \\nUOHeDdI|dde \\neyep \\nJAW \\nJU} \\n}S9} \\nHUN \\n- \\nswessojd \\nuoDun \\ndjay \\nauljuo \\nAsojsodas \\ne}yep \\nC}AW \\nBU} \\nBPOD \\n« \\nsjduos \\nAuanb \\neyep \\neal \\ndU} \\nBpOd \\n- \\nuonesidde \\neyep \\nswessojd \\nYoda \\ne}ep \\nL}AW \\n9} \\nBPOD \\n« \\nPL \\nJU} \\n159} \\n(pua \\n}UO’ \\nGaM \\nJO \\nIND) \\nSwWieISOJd \\nBde}J9}UI \\nSS8DIe \\nBU} \\nBPOD \\n- \\nyun \\npue \\npjing \\n‘¢ \\nSYSDIGNS/SYSDL saIvIA oy da}s dajs Juawidojanag \\n448 \\nyuawidojanag \\nAsoplsoday \\need \\nea \\n:vL \\nda}s}uawidojaAag \\n— \\nX}eIA \\nySe}qGQNS/yse_L \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 482}, page_content=\"449 \\nSSOUBAIPAHa Sulules} AuOpsodas eyep eJOW aINsSea| « \\nsuolssas \\nSulules} \\nAlo}ysodal \\neyep \\nC}OW \\nPNPUOD \\n« suolssas Sulules} Asopsodas eyep e}BW B]NpaUpS « s}nopuey yUaul}ad Jay}O pue SUOI}NJOS asID1axq — SdSIDI9X9 YUM SYOOGyJOM jUapnN}s — Sd}]OU JOPNAJSU! PUL Sapl|s UOIW}UISAIdg — ‘sjeuiayew Suluses} Aioysodas eyep LJaW a}eaJD « \\npaules} \\n3q \\n0} \\najdoad \\nssauisng \\nAjijUapy \\n« \\npaules} \\naq \\n0} \\njJauUUOSJad \\nUOSIel] \\nSSOUISNG \\nJ9U}O \\nJO \\n,SJasn \\nJamod, \\nAjUSp] \\n« \\nSuiuien \\nAuoysodas Asoysodas e}ep \\ne}yepP \\nEJIL \\nJU} \\nJO \\nASN \\nPUP \\n}Ud}UOD \\n9} \\nUO \\nPaules} \\naq \\nO} \\nJe}s \\nyYSap \\ndjay \\nAyUap] \\n« \\nPJBW \\nSPIAOId \\n“9 \\nsainpaso01d SuUOPUOW asesn AJopsodas eyep eJaW dojanaq « \\naseqeyep \\nAuoysoda \\ne}yep \\nLBW \\n9U} \\nJOJ \\nSAINpadoJd \\nSulUN} \\npue \\nSULOPWUOW \\nBdUeWOJJad \\ndojanaq \\n« Asoysodas yep LAW 3Y} 9SN O} MOY UO SUO!}NJsUI \\nUUM \\najdoad \\nssauisng \\nay} \\npue \\nYes \\nYSap \\ndjay \\n9} \\nJO} \\nSPINS \\nBduUaJaJal \\n& \\nDIUM \\n« \\nMeta Data Repository Development ¢ = \\nSalI} \\nPU \\nSd}ep \\nPAUIWWa}epaid \\nye \\nsodas \\nAuopsodai \\neyep \\neyo \\nSuluUNL \\nuonnpoid \\n2 \\nJO} \\nSUON}INYSU! \\nYUM \\nYe}S \\nSUOH}EJ9dO \\n3U} \\n10} \\nSaINpad0Id \\nBuNesado \\naM \\n« \\n: A ° oH . ' , 10} Asoyisodas \\n= \\naseqeyep \\nAloysodai \\nejyep \\ne}aW \\nUOIPNpOJd \\ndy} \\nJO} \\nJDC \\nPue \\n1dq \\n9}eaID \\n« \\neyep \\neIOUI \\n= Aioysodas eyep €}9W UOIDNPOJd dy} 10} WUOJeId JAAS JU} }S9} PUL |[e}SU] « 3} aedald “Ss \\na. \\n2 \\nSYSDIGNS/SY¥SDL \\nSalAN \\nIY \\ndajs \\ndajs \\nJuauidojanaq \\n> 7) Q \\nyuawidojanag \\nAioysoday \\need \\nBIW \\n:y1 \\ndays \\n}uaudojanaq \\n— \\nxXL}eI \\nyseIGNS/yseL \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 483}, page_content='Task/Subtask Matrix 450 \\ns}UdUOdWIOD \\nUO!}edIIdde \\n|g \\n[Je \\n10} \\nSjana} \\nAyuNdas \\nUONNpoOsd \\nyUdWa|dwy \\n« uoljyed1|dde |g ay} asn 0} MOY JO} SUOI}DNI}SUI \\nUM \\na]doad \\nssauisng \\ndu} \\npuke \\nye}s \\nySap \\ndjay \\nay} \\nJO} \\nSapINS \\nBdUdJAJOJ \\nDUM \\nSOW} \\npue \\nsajyep \\npauluuajapaid \\nje \\nswessojd \\nyoda \\nuoiedjdde \\npue \\nsweisold \\n119 \\nSUIUUNI \\nJO} \\nSUO!NAYSU! \\nYUM \\nJes \\nSUOIEJ9dO \\nJO} \\nSaINpadO0I1d \\nBuIeJodO \\n3M \\n« \\nsaueiql| \\nWesisoid \\nUODNpold \\nWody \\nswesJsOJd \\n3}Nddxa \\n0} \\najdoad \\nssaulsng \\npue \\n‘ye}s \\nSUO}}eJado \\n‘sJadojaAap \\n0} \\nAyouU \\nNe \\ns}eUdoidde \\njuel5 \\n- \\naseqeyep \\nAioysodai \\neyep \\neyaw \\nUO!NpOJd \\nay} \\nUO \\nAyOU \\nNe \\ns}eLUdodde \\njUeI5 \\n« \\nsaseqejep \\njose} \\n|g \\nUONDNpoOJd \\n|y} \\nUO \\nAyOUINe \\na}eLdoJdde \\njue! \\n« asegejep Alopysodas eyep e}aW UO!PNpOJd ay} a}ea/D « \\n(saseqej}ep \\nSulUILW \\ne}ep \\nSuIpN|dUl) \\nSaseqeyep \\njos1e} \\n|g \\nUO!NPOJd \\n9U} \\na}eaI5 \\n« \\nAyeiqi \\nweisoid \\nAsopsodas \\neyep \\neyaww \\nUuO!DNpod \\nau} \\ndn \\njas \\n« \\nJUaUIUOAIAUa \\nAueiqi \\nwessoid \\nuonedjdde \\nuonpnpoijd \\nau} \\ndn \\njas \\n« \\nuonpnpoid \\nAueiqi| \\nwessoid \\n719 \\nuo \\ndnpojd \\nau} \\ndn \\njas \\n« \\nau} \\ndn \\njas \\n‘7 \\npedul \\nJeuoeziUesJO \\nJO} \\nsieddid \\n« \\n}NO \\npaljOJ \\naq \\n0} \\nSUO!}DUNJ \\nBY} \\naINDAUDS \\n« \\nSdIPAIe \\nUO!}E}USWA|dwW! \\nUl \\na}ediIIed \\n0} \\nsadinosas \\nAeSSdd9U \\n3} \\nB|NDAUDS \\n(AyJenyuared \\npue \\nAjjenul) \\nuolyed1|dde \\n|g \\nay} \\nBuIsN \\naq \\n[JIM \\nOYUM \\najdoad \\nssauisng \\nJO \\nJAQGUINU \\n3} \\nSUILUA}9q \\n« \\nd}eP \\nUOH}E}UIWA|CUWI \\nJU} \\n3aS \\n« \\n(a|doad \\nssauisng \\n[je \\n0} \\nauO \\nuol}e}USW9|duwI \\n}e \\nUO}eDI|dde \\n|g \\na1l}Ua \\nJO \\nJNO]JOI \\nenpess) \\nAsajzes3s \\nUO}eE}USWa]dwWI \\nUe \\nPalas \\n« \\n9U} \\nUP|d \\n“| \\nUOe}UdWadu] \\n“SL \\nSYSDIGNS/SYSDL \\nSaIAn \\nIY \\ndays \\ndajs \\nJuawudojanag \\nuoneyuawalduy \\n:¢L \\ndas \\n}uawidojanag \\n— \\nxXiU}eW \\nyseIqns/yseL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 484}, page_content='451 \\nssad0Jd \\nUOIEISILW \\nJEP \\nLJAW \\nJY} \\nUNY \\n« \\nsaseqejep \\nssad01d \\npeo] \\n|ed0}SIY \\n94} \\nUNY \\n« \\nuonpnpoid \\nssad0id \\npeo \\njelU! \\nay} \\nUNY \\n- \\n3} \\npeOT \\n‘S \\nuoneddde \\nAuoyisodai \\neyep \\ney \\n— \\nssad0jd \\nuOl}eISIW \\ne}yep \\nej} \\n— ‘sweisO1d \\nAuoyisodas \\neyep \\neyaW \\npajnpayrs \\nApejnsas \\nay} \\nJajnpayds \\ngof \\nay} \\nuO \\ndn \\njas \\n« sweisoid \\nyoda \\nuonedijdde \\npajnpayds \\nApejnsas \\nay} \\nJajnpayds \\nqof \\nau} \\nuO \\ndn \\njas \\n- \\nssad0id \\na|npauds \\nLL] \\n2u} \\nSuuNp \\nuns \\njeu} \\nSWesJZOJd \\ne}YeEp \\neJaW \\nJU} \\nJajNDeUS \\nGof \\nau} \\n0} \\nppY \\n« \\nuononpod \\nJajnpayas \\ngof \\nau} \\nUO \\nssad0Jd \\n719 \\n3} \\ndn \\njas \\n- \\nau} \\ndn \\njas \\n‘p \\n(sweisoid \\nuoNDUN} \\ndjay \\nauljuo \\nAloysodas \\ne}ep \\ne}aW \\nSUIPN|DU!) \\nsajnpOW \\nynpodd \\n4o \\nswesso1d \\nUOHeddde \\neyep \\nea \\n— \\nswess0jd \\nUO!}eJSIW \\ne}ep \\nCJ \\n— ‘Aleiql| weisoid \\nAiousodai \\ne}yep \\ne}aW \\nUOHNpOId \\nau} \\nO}U! \\nSWeIsOId \\nAlojsodai \\neyep \\n}BW \\nSAO! \\n+ \\nuolpunN} \\ndjay \\nsuljuo \\n— \\nssad0jd \\nadejJ9}U! \\nPud-}UOI4 \\n— sauando — suoday — \\n‘Aueigl| \\nwesisoid \\nuoied|dde \\nuoydnpoid \\nay} \\nojU! \\nSwessoid \\nUO}edI|dde \\naAOW \\n« peo| Je}UIWIIDU| — \\npeo| JeDU0}sIH — s}UdUOdWOD peo] [elu] — uonedi|dde \\n‘Aleiqi| \\nweisoid \\n714 \\nUONpoid \\n3u} \\nOU! \\nSWeIsOId \\nTL \\nSAO \\n« \\n1g \\nau} \\nye \\nyeysu] \\n“¢€ \\nion Implementat \\nSYSDIGNS/SYSDL \\nSarAnpy \\ndazs \\nda}s \\nyuaudojanaq \\nDevelopment Step 15 \\nuoneyuaweduy \\n:¢L \\ndays \\nyuawidojanaq \\n— \\nxiU}eW \\nySeIGnSs/yseL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 485}, page_content='Task/Subtask Matrix 452 \\nce \\na \\nhe \\na \\nRS \\na \\nel \\na \\nae \\nee \\nee \\nee \\nee \\nee \\n(QAl| \\n08) \\nSulssad0ud \\nUONNpold \\nye}s \\n« \\n(ypIMpueg \\nBUIpN}duUl) \\ns}UaUDdWOD \\nYIOMIAN \\n— \\n3seJO}S \\nySIG \\n— SIOSSOIOId — \\n‘WO; \\n,e|d \\n|g \\nBU} \\n10} \\nsuejd \\nAjyIDeded \\nMalAas \\nJO \\ndojanaq \\n« \\nsyooaup \\nods \\nAyyend \\n— \\nSDUJOW \\ne}eP \\neI \\n— \\n‘Saseqejep \\nJasJe} \\n|G \\nJU} \\nJO} \\nSalpAOe \\nSUUOPUOW \\nAyenb \\neyep \\najnpauds \\n« \\nasesn \\n— \\nUIMOID \\n— \\nQDURWWOLdd \\n— \\nsaseqejyep \\nAuoysodad \\neyep \\ne}oW \\n94} \\nPUL \\nSaseqejep \\nJasJe} \\n[G \\nJU} \\nJOJ \\nSAIPANDe \\nSULOPUOW \\naseqeyep \\najnpaups \\n- \\nSUOI}EZIULBJOAI \\naSeqe}eg \\n— \\n8U1}S98} \\nAJBAODAI \\nJa}SeSIG \\n— \\nsdnypeq \\nasege}eq \\n— \\nsaseqejyep \\nAuoysodai \\neyep \\neyawW \\ndU} pue Saseqejep JasJe} |G JU} JO} SAIPAOe BdUeUa}UIEWW aseqe}ep ajnpaups - yoddns Sulo$uo \\nyoddns Aduassawe |/2d-U0 JO} ajnpays e UsI|qe}sq « JO} aiedaidg “9 SE EEE EE ee \\nSYSD}GNS/SYSDL SAAN IY days dajs }uauidojanaqg \\nEne \\nnc \\ncnc \\ncnn \\nrenner \\nnnnnnnncnnnnnnnnnncnccccnneecececcecceceeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee \\neres \\nuonejuawasduy \\n:¢{ \\ndays \\n}uawidojanaq \\n— \\nxuU}eW \\nyseIgns/yseL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 486}, page_content='453 ion Release Evaluat Development Step 16 \\nM2IAQJ \\nBU} \\nSULINP \\nPassndsip \\n3q \\nO} \\nUOI}E}USLUNIOP \\n3NO \\npuss \\n« \\nepuase \\nBSUI}IaW \\nJEU} \\n9U} \\nPUSS \\nPUL \\nSSIADY \\n« \\nSUNIIW \\nJU} \\nSULINP \\nSa}OU \\naye} \\n0} \\naquds \\nAped-psiu} \\ne \\nJO} \\nABUL \\n- \\nAyed \\npiu} \\ne Ag \\nuoneyioey \\nasueuy \\n« \\nUOI}EIO] \\nS}HS-JHO \\nUe \\n} \\nSUI}IALW \\nBU} \\nB|NDAUDS \\n« \\nSaapua}e \\n0} \\nEpuase \\nAseulwijaid \\nay} \\n}NO \\npuas \\n« \\nSaapuaye \\nWO} \\nSUOIISaNb \\npuke \\nSd!dO} \\nJEUONIPPe \\n}DIIIOS \\n» \\npajaMsue \\npuke \\npassndsip \\naq \\n0} \\nsuO!}sanb \\njs!iq \\n— \\nUdIeaSa1 \\nJO} \\nSd1do} \\nUBISsSe \\npuke \\njsI] \\n— \\nUOISSNISIP \\n10} \\nS10} \\nS17 \\n— \\nSUIIIW \\nMAalAal \\nS99PUSHE \\nPS}PAU! \\n}SI] \\n— \\nuone}UsWea|du! \\naoejd \\npue \\n‘awi} \\n‘a}yep \\njs] \\n— \\n-jsod \\nau} \\n‘epuase \\nMalAal \\nUO!}E}UBWA|duI-}sod \\nAJEUILUIJa1d \\nBY} \\n9}eIID \\n« \\nIZIULBIO \\n‘7 \\n1dadUOD \\nBSedjJIJ \\nBU} \\nJO \\nSSOUSAIPDIYO \\nJU} \\nMIIADY \\n« \\nASayzes}s \\n(yNO|JOJ) \\nUO]FEJUSW9|CW] \\nBY} \\nMAIAdY \\n- \\nSUIUIC \\nJO \\nSSOUIAIPIYO \\nJU} \\nMAIADY \\n« \\nuoljedidde \\n|g \\ndu} \\nJO \\nDUeUOJJad \\naU} \\nSSassY \\n« \\npefoid \\n|g \\nau} \\nUO \\nssassoid \\npasapuly \\nyeY} \\n(|eED1UYI9}UOU \\npuke \\nJed|UYI9}) \\nSadaId \\naunyoN}sesul \\nSuIssiwW \\nAJUap] \\n+ \\n(jed}UYd9a}UOU \\nPUe \\nJed1UYI9}) \\nIINJINASejU! \\nSUNSIXS \\nIY} \\nMAIADY \\n« \\nJUIWUIIe|d \\nJEUOIEZIULBIO \\nJU} \\nJO \\nSSOUBAIPDIYO \\nBU} \\nMAIAY \\n« \\nDANJDNIYS \\nWLS} \\nJU} \\nJO \\nSSOUIAI}DIYO \\nJU} \\nMAIADY \\n« \\nuyseoidde \\nUdWdOJaAap \\nJU} \\nJO \\nSSAUBAIPDAYa \\nIU} \\nMIIADY \\n« \\n(adods \\nwo \\npaddop) \\nsyuswasinba \\npayjyINJuN \\nMalAVy \\n« \\nsasuey) \\nadods \\npuke \\naiNpadodd \\nJOJ}UOD-2BULYD \\nJU} \\nMalAdy \\n« \\n(sanss!| \\npaAjOSaJUN \\nPUL \\nPaAjOSaJ) \\nBO] \\nSANSSI \\nJU} \\nMAIADY \\n« \\nMOAlAd1 \\nSOW} \\nUOIA]AWOD \\nSe} \\n[ene \\nPUL \\nPS}EWI}SS \\nJU} \\nMAIAdY \\n« \\nuoneyuawa|dui \\najnpayps \\njeuy \\npue \\nuejd \\n~afosd \\n[eUlSUO \\n34} \\nMalAdy \\n+ \\n~ \\n4sod \\naut \\nuonenjeaq \\nSaINYWPUddxa \\nJOSPNg \\nMAIAdy \\n« \\nJO} \\naieddld \\n‘1 \\naseajay \\n‘OL \\nSYSD}QNS/SYSDL \\nsamAnoy \\ndays \\nda}s \\njuawuidojanaq \\nuonenjenq \\naseajay \\n:91 \\ndajs \\nyuawidojanaq \\nXH} \\n¥Se}QNS/y4seL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 487}, page_content='Task/Subtask Matrix 454 \\nee \\na \\n8 \\na \\nee \\nspiepue}s \\n— Souljapinyd — \\nsainpadojd \\npuke \\nsassad0/d \\n— \\nAZojopoyuj}aw \\nJUBWdOJaAap \\nay} \\nJO \\nasp \\n— \\nyseoidde \\njuawdojanag \\n— \\n:0} \\nSJUDWAAOIAUW! \\nBINJONYSeAU! \\n[eI!]UYI9}UOU \\nJUIWa|dUW] \\n« \\nS}NSaJ \\nWa} \\nUOIPe \\nJU} \\nUsI|qnd \\n« S}JNSOJ Wd}! UO!}De JY} JUBWINDOG « \\nWea} \\nPaloid \\n|g \\nay} \\napis}yno \\najdoad \\n0} \\npauBisse \\n213M \\n}LU} \\nBSOU} \\nAjjeldadsa \\n‘SwWa}!| \\nUONIE \\nUO \\nPAWWOJJad \\nYOM \\ndU} \\nJOWUOW \\n« SWe}] UO!}IE PaUsIsse UO YOM - \\nSO}NUIW \\nSUIJISW \\n3U} \\nUSI|GNd \\n« \\nmrerren \\nSOINUILY \\nBUSS \\nBY} \\nd}M \\n« \\nuo}}e}UaWa|dwWI \\naseajal \\n|g \\n(2/N}Ny \\ne \\n10) \\n1X9U \\nBU} \\nJO} \\nSJUaWALINbas \\nM3U \\nYUM \\npa|pung \\n-}sod \\nay} \\nuO \\naq \\npinoys \\nydIUM \\n‘(adods \\nwos \\npaddoup) \\nsjuawasnbas \\npayjyinjun \\nyuswWINDOG \\n« \\ndn \\nmojjo4 \\n‘py \\nWea}! \\nUO!De \\nYDde~a \\nJO} \\n9}ep \\nasuOdSaJ \\nJO \\nUO!Ja|dWOD \\ne \\nUsI|qeisq \\n« \\nSW} \\nUO \\nUSISSY \\n« \\nSWa} \\nUO \\nJUsWNDOG \\n-« \\nSUOIINJOSAI \\n‘SUOHSABSNS \\n‘SUOISSNISIP \\nJUaLUNIOG \\n« \\nSUIJIIW \\nMAIAaJ \\nepuase 34} UO Wa}l Udea ssndsiq « \\nuole}yUaWajduI \\nUOISSAS \\nPaj}e}]IOe} \\nBU} \\nJO} \\nSajny \\nay} \\nule;dxy \\n- \\nsod \\nauy \\nS8dPUSHE \\n9} \\nBdNPOJ}U] \\n« \\npnpuoy \\n‘¢ \\nSS \\nSSS \\nSYSDIGNS/SYSDL \\nSAHA \\nIY \\ndajs \\ndajs \\n}uauidojanaq \\nEEE \\nCnn \\nnnn \\nnnn \\nnner \\nSSS \\nSSS \\nSSS \\nuonenjenq \\naseajay \\n:91 \\ndajsjuauidojanaqg \\n— \\nXie \\nyseIqns/yseL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 488}, page_content='arene \\nee \\n6 \\nSe \\nee \\nSe \\nee \\nae \\nee \\nEE \\n‘SISA[EUL \\n}1J9UIG-}SOD \\nJU} \\nUI \\nSIU} \\nA9PNPU| \\n‘UO!NIOS \\n|g \\n& \\nUUM \\nPaAjOsal \\naq \\npjnod \\nsWajgoid \\nasay} \\nMOY \\npUe \\nSWajgoid \\nssaulsng \\n}UaLIND \\nay} \\nJO \\nSadXUaNbasuOd \\n|eINUeUIJ \\ndU} \\na}e}S \\nApea|D \\n« \\n‘pauleye \\nUaag \\nSEY \\nJaA2] \\nHOJLWOD \\nBWOS \\nDUO \\nPUe \\najqe}WJOJd \\nJjas}! \\nUBAOId \\nsey \\ndANEIUI \\n94} \\nBDU \\n‘yae] \\nAyjeuoNDuNy \\nasoW \\nppe \\nued \\nNOA \\n‘UBISap \\najqixaly \\n& UM \\n‘Ajsiyes \\n0} \\nUONeDIdde \\n|g \\naU} \\nay!| \\nPijnom \\nnoA \\nyeu} \\n(AyuNyoddo \\nssauisng \\nJO \\nWajqoid \\nssaulsng) \\npaau \\nssauisng \\nduo \\nYM \\nYe}XS \\n‘ajduuis \\n}! \\nday \\n« \\n‘uonedidde \\n|g \\ninoA \\na}eaJ9 \\n0} \\nsuOseal \\nssaulsng \\ndYI9ads \\nAiaA \\nBAeY \\nNOA \\nssajun \\n(ai0W \\nJO \\nUOIIIWW \\nGZ} \\n0} \\ndn \\nasues \\nAuew) \\ns}sod \\n1g \\nAysnf{ \\nJoUURD \\nNOA \\nABALIP \\nSsaulsnq \\nJea]D \\n& \\nBACH \\n+ \\n\"UOIEZIULSIO \\nJU} \\nJNOYUSNOAY} \\nSACU! \\n|G \\nBY} \\nJO \\nANJA \\nJU} \\n|JaS \\n0} \\nBDUIN|JU! \\nJIU} \\nuodn \\n|e) \\npue \\n‘syjauag \\nssauisng \\nAjuap! \\ndjay \\n0} \\nAAaes \\nssaulsng \\nJay} \\nasp \\n‘SeAenlul \\nYOddns-uolsidap \\nIq \\nJO \\nJUOJJd40} \\nJU} \\nUO \\naMJAS \\nUAYO \\nJaUUOSJad \\nBuNayJeW \\n‘saysnpul \\nAUeW \\nU] \\n‘UOIeZIULSIO \\nJU} \\nJO \\nwe \\nSunayJelU \\ndy} \\nWo \\najdoad \\nssauisng \\nYM \\nased \\nssauUIsng \\nay} \\nSUIUap \\nUO \\nSUOJa \\nANOA \\n9}e1}UBDUOD \\n« \\n‘S}UdI|D \\nJeUIa}X9 \\npue \\n‘QUUOSJad \\nSujayJeW \\nPue \\nSajes \\n‘s}sAjeue \\nSSaUIsng \\n‘SiayJOM \\naspa|MOUY \\n‘S9SCULLW \\nJOIUAS \\nJO} \\nJIJJIP \\n|[/M \\nSpaau \\ne}ep \\nJeUJa}xa \\npue \\n‘AyNdas \\n‘AdeindIe \\n‘SSAUI|AW} \\n‘[JEJaP \\nJO \\nJaAd] \\nAUL \\n‘a|dOad \\nssaulsng \\njUaJas4IP \\nJO \\nSpaauU \\ndy} \\nUZIMIJaq \\na}eHUaIaYIP \\nJay \\n10 \\nWIY \\ndjay \\n‘uoHed|}dde \\n|g \\nau} \\nJO \\nanjeA \\nssaulsng \\nay} \\nauyap \\n0} \\nSAAINDIAXa \\nSSaUISNg \\npue \\nSIaSeULW \\nSSdUISN \\nJO \\nJAQLUNU \\nE \\nUM \\nYOM \\ndAe}UISAJdad \\nSSAUISN \\nJU} \\njo \\n« \\n‘UONEZIULBIO \\nJY} \\nJO \\nsjeos \\nssaulsng \\n318a}e1}S \\nBU} \\nUM \\nUBI|e \\nJOU \\nOp \\nSOANEIIUI \\n|G \\nSAU} \\nJO \\nSAAIPDAlGo \\ndy} \\nEU} \\nSI \\nSOAIVEIUI \\nWOddns-uolsidap \\n|g \\nJO} \\nainje} \\nJO \\nasned \\nUOWWOD \\nJUSLUSSASSY \\nY/ \\n‘SIQAUP \\n[PUId1Xa \\naU} \\nJO \\nPeduw! \\nau} \\npueysiapUN \\n‘sjeOs \\nssaulsng \\nIsaj}eJ}s \\ns UOHeZIUeZIO \\nINOA \\nAjI}UapP| \\n« \\nase) \\nssauisng \\n‘| \\nsod \\ndajs \\njuawudojanaq \\nXLIVR \\nSOUTTAPIM \\n[eot}IeIg \\nANO-ALNIML \\nwaldWHD \\n455 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 489}, page_content='‘JUadJad \\nOZ \\n}EU} \\nWO} \\nOYM \\najdoad \\nasou} \\nJo \\nspaau \\naU} \\nssaippe \\nAjjeniu] \\n‘ALWI} \\naU} \\nJO \\nJUadJad \\n08 \\nJUaWUOIIAUS \\nYOddns-uols|Dap \\n|g \\nay} \\nSulsn \\naq \\n||IM \\najdoad \\nssauisng \\nau} \\nJo \\n}UadIed \\nOZ \\n:asesN \\n- “OAC MIUL \\n1g \\n2u} \\nJO \\nSulpuejsiapuUN \\nJayeq \\ne \\nUles \\nO} \\nJAPJO \\nUl \\nJUaWSAAU! \\nJeINUeUY \\npue \\n‘BuLjeys \\n‘UOeZIUeZIO \\n‘uoeASaIUI \\n‘AYIX9|AWIOD \\n‘AZOJOUYIA} \\nJO \\nSALOB9}Ld \\nXIS \\nJU} \\nJO} \\nYSU \\nBU} \\nSSasse \\n‘ajqissod \\nse \\nAjJea \\nsy \\n« \\n“INIIE} \\nJO \\nYSU \\nJOUSIY \\n@ \\nploae \\n0} \\nPaloid \\nYoddns-uolspap \\n|g \\nAJaAd \\nUO \\nLUNWIUILWW \\n& \\nO} \\nUO!}EJSa}U! \\npUe \\nAyxXa]dWiod \\ndaay \\n« \\n‘aiNjle} \\nJO \\nBdUeYD \\npoos \\nAlan \\ne \\nsey \\nHt \\n‘ASOJOUYII} \\nUl \\nPUad} \\n}S9}e] \\nBY} \\nAq \\nAJUO \\nUBAUP \\nSI \\naAHeU! \\nYOddns-uoIsIDap \\n|g \\nay} \\nJ] \\n— \\n\"ssaoons \\nJO \\nadUeYD \\npoos \\nAJaA \\ne \\nsey \\n} \\n‘Wajqgoid \\nssauisng \\ne \\nAq \\nUaAUP \\nS! \\naAeNIU! \\nYOddns-uolsidap \\n|g \\nJU} \\nJ] \\n— \\n‘J! \\n10 \\nPaaddNs \\n0} \\nsAdULYD \\n« \\nPractical Guidelines Matrix \\nquiny_ \\nfo \\nsajny \\npub \\nsdip \\n‘aaenlul \\nYOddns-uoisidap \\n|g \\n& \\n10} \\nUOHeIYHSNf \\nssauisng \\nUO \\nJ] \\nUM \\nYJOM \\n0} \\nSuIj|IM \\nayinb \\nase \\nsiaseuewW \\nssauisng \\n‘ade|djaysewW \\naAadwod \\nAjsulseasdu! \\nS!y} \\nUl \\nJes \\nULD \\nAdu} \\naSeiUeAPe \\naANadwod \\nAue \\nWo \\nWOsd \\n0} \\nayI| \\npjnom \\nsiaseueW \\nssaulsng \\nyeu} \\ndZI|eay \\n‘“QUOJE \\nYIOM \\nJBAIN \\n« \\n‘aseajad \\nuOT}edI|dde \\n|g \\n}S41J \\nSU} \\nJO \\nSOD \\n211}US \\nBU} \\nJAAOD \\nO} \\nBNUDAD \\nYSNOUS \\n9}eJ9UaB \\nP|NOD \\nJoYy}OUR \\naIIYM \\n4UNOWe \\najnUIW \\ne \\na}eJaUas \\npjnod \\nUaAdxXa \\nSUI|JaS \\nUO \\n‘YJOMSSANS \\naNd \\nSI \\nSul|jas-SSOs \\nWO1 \\npayesaUas \\naq \\nPjNnod \\nyeu} \\nJUNOWe \\nay} \\n‘BUI||AS-SSOJD \\nJO} \\n[e}}UB}0d \\naU} \\nSI \\nHJaUag \\nssauIsng \\ne \\nJI \\n‘ajdwexa \\n104 \\n13jJ0 \\n0} \\npasoddns \\nsi \\nuoMeWOJUI \\n1 \\nSY} \\nJEU} \\nJUSLU}SSAU! \\nUO \\nUIN}aJ \\naNjeA-Je|JOpP \\nIyIads \\ne \\nBulsiwoijd \\nOW! \\npasaAnaueW \\n398 \\n1,U0q \\n- \\n“SSaUIsng \\nJO \\nSoul] \\nBY} \\nSSODe \\npasn \\nSI \\n}EY} \\nUONCUUOJU! \\nBULAAI|ap \\nUl \\nSal] \\nAjjensn \\n|g \\n104 \\njenUa}oOd \\nSSBUISNG \\n9M} \\nOUL \\n‘AAU! \\n|g \\n94} \\npuns \\nAJa}o]dwWOd \\n0} \\nYUN \\nssaulsng \\najsuls \\nAue \\nUO \\npuadap \\n3,u0qG \\n« \\n$7,u0qd \\n456 \\ndajs \\njuauidojanaq \\nJUBLUssassy \\nase \\nssaulsng \\n:1 \\nda}s}uawidojanaqg \\n— \\nXL}eII \\nSaUTapIn5 \\njed1De1d \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 490}, page_content='457 ion Infrastructure Evaluati Enterprise Development Step 2 \\n‘asn \\n0} \\nAsea \\nag \\n3snwW \\nI \\npue \\n‘AyIUNWWOD \\nssauisng \\nau} \\njo \\nsjuaWalINbad \\njedVAjeue \\nay} \\nSayd}ewW \\nyeu} \\nAyyeuoduNy \\naAey \\nJSNW \\n}! \\nSOWA} \\npue \\nysul4 \\nejndod \\nst} \\n#1! \\nasnedaq \\nysnf \\nJOO} \\ndV10 \\nUe \\nPalas \\n},U0 \\n« \\n‘AVUNUWILUOD \\nSSauUISNg \\n3} \\nJO \\nSpaduU \\nBunjiodas \\njerAjeue \\nau} \\nAysizes \\n[IM \\nUH \\n,dW10, \\nPalege] \\nS| \\nnpoid \\naiemyos \\ne \\nasnedaq \\n}eU} \\nSLINSSE \\nJBAON \\n+ \\n‘yi \\nasn \\nyou \\nAew \\npue \\nWOW! \\nAng \\nyou \\nAew \\nAau} \\nasimiaujo \\n‘ajdoad \\nssauisng \\nay} \\nAq \\nuoedidiwed \\nynOUYM \\nJOO} \\n& \\nPalas \\n},U0Q \\n« \\n“QWUI} \\nJOAO \\nSAAJOAS \\njUaWUOIAUa \\nYOddns-uolsidap \\n|g \\nY \\n‘UON|Os \\nAayusn} \\nYoddns-uolspap \\n1g \\ne \\nAng \\n0} \\npadxe \\n},U0q \\n- \\n‘S9A[ASWAY} \\nUIAOJd \\nBALY \\nPUe \\nPaJaAljap \\nale \\nSainjea} \\nGAIA \\nSJOPUAA \\nau} \\nssajuN \\n(gd71A) \\naseqeyep \\nadie] \\nAJaA \\ne \\nyUaWa|duu! \\n0} \\ndun \\n},u0Q \\n-« \\n$1,U0q \\n‘ASZO|OUYIA} \\nUUM \\nJUNI \\ndaay \\n« \\n‘JQS \\n[00} \\na}eLUUdoidde \\n3U} \\nBSOOUD \\nUPD \\nNOA \\n}eY} \\nOS \\nWOJJad \\n0} \\npaau \\najdoad \\nssauisng \\nay} \\nsasAjeue \\njo \\nsadA} \\nay} \\nPUe}SJOpUN \\n« \\n‘POD \\nWO}sNd \\nUMO \\nJNOA \\nBUI}M \\nJO \\nPeaySU! \\na]qISSOd \\nJaABUBYM \\nS[OO} \\nasf \\n« \\n‘sadunosal \\nVOW \\nZuLInbas \\n10 \\nSUIUIEJ} \\nWEIS \\nVOW \\nSUIpaaU \\nJaya \\nS!| \\nBUesaIa \\nsiy} \\n10} \\nAed \\n[IM \\nnoA \\nadud \\nayy \\n‘aduesaja \\njed1UYIa} \\nAressad9uUUN \\nJaJJO \\n}eY} \\nSNPOJd \\n40} \\nJNO \\nYd}eEM \\n- \\ndiN}INAysedu] \\nuonenjeaq \\n‘DalaPISUOD \\n3q \\n0} \\nS1OPe} \\nJUPYOdUII \\nJeEdIULUDIL \\nJSOW \\nJU} \\nJO \\naUO \\nSI \\nAyiqejeds \\n‘Ayood \\najeds \\nyey} \\ns}UBUOdWIOD \\nAue \\nplOAe \\n‘AyIge}eds \\n0} \\nUOHUaHe \\nAed \\n« \\n‘Y \\nUOIpVS \\nuolenjeaq \\naInpNseUu| \\nasudsa}uq *Z sod dajs Juawuidojanag \\nUOTENIEAZ \\n91NINA}SeAJU] \\nasiidia}uq \\n:7 \\ndajs \\nJUaWIdojaA9q \\n= — \\nXL}JELA \\nSOUIIPINY \\n[edTPe1d \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 491}, page_content='Practical Guidelines Matrix 458 \\na \\na \\nae \\nie \\n‘AJBAIPAYO \\nPEO}JOM \\n||/e49AO \\nBY} \\nBdUe|eq \\npue \\nadeUeW \\nOsje \\nyng \\nBulssad0/d \\nNOL \\nXa|dwWod \\njUAaIDIJa \\napIAOId \\nAJUO \\nJOU \\nSWC \\nau} \\n}eU} \\nSasInbad \\nyUaUUOLIAUA \\nUP \\nUNS \\n‘salanb \\nsisAjeue \\nantesedwod \\nxX9|dwod \\nd10W \\nO} \\nS[EAAII}91 \\nPaXapul \\najdu|s \\nWO4 \\nasue \\nJey} \\ns}sanbaJ \\nssa2de \\neyep \\nSuIWUOJIad \\nsiaSeuew \\nssauisng \\npue \\n‘s}sAjeue \\nssaulsng \\n‘siay0m \\naspajmouy \\nJO \\nspaspuny \\nYOddns \\n0} \\nuoned!dde \\n|g \\ne \\n40} \\nUOWWOD \\nSI} \\n‘pueWap \\nPeO}yxJOM \\nUI \\nXIWW \\na]qeyIpaidun \\nue \\nsi \\n}UaWUOIIAUa \\nYWOddns-uOIsIDap \\n|g \\nJUL \\n:PEO}YIOM \\nSWC \\nsuo}jesodo \\npapuayeun \\n— \\nswuoje}d \\nsnosuesoJa}ay \\nUO \\nUOHeDdI|day \\n— \\nS9WAYIS \\nXI9PU! \\npadueApe \\nJo \\nApiqesleAy \\n— \\nUO!}E1S9}U! \\nJOUI9}U] \\n— \\nAyiqejeds \\naseqeyeg \\n— \\n(SiaZIWI}do) \\nsusisap \\naseqeyep \\njeuo!|suatWIp \\nSul|pueY \\nUl \\nadUaSI}|a}U] \\n— \\nspeo| \\ne}ep \\npue \\nsalionb \\nSuljpuey \\nul \\nwWsljayjesed \\nJo \\naasSaq \\n— \\n‘aie \\nJUBWUOIIAUS \\nWoddns \\n-UOISID9P \\n1g \\nBUY} \\n10} \\nSAAC \\nPa}DaIas \\nay} \\nJO \\nSUOHDUNJ \\nJUeLOdUUI \\npue \\nAlessadauU \\naU \\n:suUODUNY \\nSWAG \\nsaseqejyep \\njadJe} \\n|g \\naU} \\nSUIPaa} \\nSWa}sAs \\n[euOHeJado \\nJo \\nJaqUINN \\n— \\nsaseqej}ep \\njadJe} \\n|g \\nay} \\nSulssadde \\najdoad \\njo \\nsaquinn \\n— \\nS]OO} \\nJO \\nJAGUINN \\n— \\nsalianb \\npue \\nsyodai \\nJo \\nJaqunNN \\n— \\nsuJaHed \\nssande \\nejeq \\n— \\nsaluanbay \\npeo] \\n— \\nSUWNIOA \\ne}eEQ \\n— \\n‘Ul \\nS8suUeUD \\npides \\nay} \\nJOWUOW \\n‘asOjaJaUL \\n“Ayigejeds \\nS| \\n}JUBWUOIIAUS \\nOddns-uols|Dap \\n|g \\nay} \\nWOddns \\n0} \\npauinbas \\nsasnyea} \\nULE \\ndU} \\nJO \\nBUC \\n:aIeMpIEH \\n« \\na \\nquiny, \\nfo \\nsajny \\npup \\nsdiyp \\n—— \\nSSS \\nSSS \\nuoHenjeAq \\nain}onjjse4jU] \\nasiidiayuq \\n:7 \\ndays \\nyuauidojanaq \\n=— \\nXL}eW \\nSauTapiny \\njedNdeIAd \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 492}, page_content='459 ion Enterprise Infrastructure Evaluat Development Step 2 \\nen \\nEEE \\nEEE \\n‘uoneziuesio \\nInoA \\nye \\naunyonsysedu! \\njed1UYDa}UOU \\n|NJasn \\npuke \\nJed;9e1d \\ne \\ndojaAap \\n0} \\nued \\nnoA \\nse \\napis \\nssaulsng \\nau} \\nUO \\npue \\nJ| \\nUl \\najdoad \\nAuew \\nse \\nwood \\njndu! \\nJe \\n}aa4M \\n94} \\nJUBAUIAJ \\nO} \\nJOU \\nAil \\n‘uoiyeziuesso \\nau} \\nul \\nysIxa \\nApeauje \\n}eU} \\nUO \\nOS \\npue \\n‘sainpadoJd \\n‘sauljapins \\n‘spaepue}s \\n9Y} \\nBsNed \\n‘giqissod \\nse \\nUDNUW \\nSV \\n« \\n‘spafosd \\n|g \\naunqny \\nUl}! \\nasIAas \\nOF \\nUR|d \\npUe \\n‘AyJEUOHDUNJ \\nS} \\nJO \\nJUdIIEd \\nOB \\nysea] \\nye \\nJUaWA|dU] \\n‘Pafoid \\n|g \\nAsaAa \\nYM \\nJUBWadINbad \\nJ4N}NJ}Se4JU! \\n|2D|UY9}UOU \\n9UO \\n}seo] \\nJe \\nYPN|IU| \\n« \\n‘suoneiado \\nUdAa \\npue \\n‘BuUIUIeJ} \\n‘Spsepue}s \\n4ipne \\n‘Ayundas \\n‘aduesinsse \\nAyyenb \\n‘ainpayyre \\ndI/sa}ze4}s \\n‘UOHeASIUILUpe \\ne}ep \\n:sdnois \\nSUIMO]|O} \\n9} \\nJO \\nJJ2}S \\nJU} \\nO} \\nHIE} \\n0} \\nSI \\nSIU} \\nSSasse \\n0} \\nAEM \\njsa}se} \\nBULL \\n“BUISSILU \\nSI \\n}EYM \\nPUP \\n‘JOU \\nS| \\n}EYM \\n‘[Nyosn \\nS| \\n}EYUM \\n—uojjeziuesio \\nau} \\nul \\nsix \\nApeasje \\nsainpadoid \\npue \\n‘sauljapins \\n‘spiepue}s \\nJo \\nsad} \\n}eUM \\nSUILUA}9Q \\n+ \\n‘Auousodas \\ne}yep \\neyawW \\ne \\nayejndod \\n0} \\npasn \\naq \\n43}2] \\nuD \\n}eU} \\nPue \\najdoad \\nssausng \\nau} \\nAq \\npassed \\n3q \\nUBD \\n}LU} \\nJEU} \\nBLUOS \\nU! \\nSo[nd \\nUOHeWOJsUes} \\naU} \\npue \\nSulddew \\neyep \\nJ9B1e}-0}-8D1NOS \\nJY} \\nJUBLUNIOP \\n‘LWNWIUILU \\n& \\nHWY \\n‘Poysl|qeyso \\nS| \\nuolnjos \\nAloysoday \\njuaUeUad \\nJOU \\ne \\n[UN \\nLULA}U! \\nUY} \\nU! \\nJOO} \\nFSW) \\n}eU} \\nasn \\n‘}00} \\nJsWD \\npayedijsiudos \\nAyuey \\n@ aAeY \\nNOA \\nynq \\n‘auO \\naey \\njou \\nOp \\nNOA \\nJ \\n‘aUO \\naAeY \\nNOA \\nji \\nAsousodas \\neyep \\ne}aW \\nPe \\naSf \\n+ \\nEEE \\nquiny, \\nfo \\nsajny \\npup \\nsdiy \\n‘uonezipsepueys \\neyep \\npue \\nAyjenb \\neyep \\nssaippe \\n0} \\nSs} \\naAWeIUI \\nWOddns-uols|dap \\n1g \\n& 40} \\nSUOSBad \\nUleLU \\nBU} \\nJO \\nBUO \\n‘ALU! \\nUNW \\nOO} \\n$9He} \\n10 \\n}{NIYJIP \\nOO} \\nSI \\n} YUIY} \\nNOA \\nasnedaq \\nUO}}eZIPJepue}s \\neyep \\ndiys \\n},u0q \\n« \\n‘SONIA \\nBINNASeUIUOU \\nUO \\nBULYJOM \\nJO} \\nUe|d \\npafosd \\nay} \\nUO \\nSedsNOSad \\nPUR \\nSLU} \\nB}edOjI/e \\nO} \\n9310} \\n},U0G \\n« \\n‘ssa001d \\nJUBWIUYAI \\nSALIH! \\nUL \\nS| \\nSIUL \\n“A19Y} \\nWO \\nOF \\npue \\n‘aINPayYIIe \\ne}yep \\nSSoulsNg \\nUOWLUOD \\n94} \\nJePOW \\nUsu} \\n‘SPAEPUL}S \\nUM \\nLE}S \\n‘BDUO \\nJe \\nAINNSeAU! \\n[E!UYXB}UOU \\nJU} \\nJO \\ns}UBUOdWOD \\n|e \\npling \\n0} \\n}dwa}e \\n},U0q \\n« \\nnaan \\neee \\neee \\n$1,U0q \\na \\nS \\n‘aoeds \\nyjo-uSIs \\npue \\n‘siaquunu \\nased \\n‘AJO}sIy \\nUOISIAS, \\n‘“Faquunu \\nUOISIA \\njSa}eL] \\n‘a}ep \\nayepdn \\njsaje] \\n‘a}ep \\nUOHPAID \\n“WBUMO \\n“JOUINe \\n‘gsodund \\n‘uonduasap \\n‘aij \\ne sAeY \\nysnuW \\nJUBLUNDOP \\nUDea \\nyeu} \\nAjidads \\n‘aj|dwexe \\n104 \\n‘s}UsWINIOP \\npoafoid \\njew0} \\nINOA \\n10} \\nSpuepUe}S \\nBPIAOId \\n« \\n‘pafoid \\njg \\nAsana \\njo \\nVed \\nJessa}! \\nUe \\nSI \\nUe \\nJUBWUOJIAUS \\nyoddns-uoisidep \\n|g \\nay} \\nYSNosY} \\nUONESIACU \\nSaze} \\nIDE} \\n}{ \\n“UOIEJUBLUNIOP \\nULY} \\nBJOW \\nYINUW \\nS| \\ne}ep \\nejo|l \\n“P}ep \\nEJOW \\nO} \\nUOHUDHE \\nAed \\n« \\nO1NPNASECAJU] \\nuolenjeaq \\n‘Uol}e1ZaiUl \\n|EUOIEZIULSIO-SSOID \\n10} \\nANS \\nay} \\naplAoid \\nJED|UYIOJUON \\ns}JUdUOdWIOD \\nASA \\nSJUBUOACWIOD \\nJANPIN}SeIJU! \\n[EIJUYII}JUOU \\nAIPII}JJoul \\nJO \\nSulssiw \\nay} \\nAjnuap] \\n« \\n‘g \\nUOIDAS \\neee \\neee \\nSe \\nsod \\ndajs \\nJuawuidojanaq \\ndean \\neee \\neee \\nrere \\nrr \\n——L———K \\nuonenjenq \\nainyonysejyuy \\nasiidiayuq \\n:7 \\ndays \\nyUaudojanaqg \\n= — \\nXH}eIA \\nSauUJapiND \\n[eI1eAd \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 493}, page_content='Practical Guidelines Matrix 460 \\n‘(QWUMOP \\nJa}NdWOd \\nYyYM \\nBuljeap \\npue \\n‘ssuNsawW \\nJUBLWedap \\nSUIPUA}He \\n‘SLUd}SAS \\nJ94}JO \\nSUL}OOYSa|qnoJ} \\n‘aj|dwexa \\n404) \\nUe|d \\nyDafoid \\nINOA \\nUO \\nsySe} \\nSe \\npalsi| \\nJOU \\nSIIPAIPE \\n|EUO!}EZIULBIO \\n10 \\npa}ejas-afo1d \\nUOLULUOD \\nJaU}O \\nUO \\nJUadS \\naq \\nO} \\nBWI} \\n9}eI0|/e \\n0} \\nJ9310} \\n},U0G \\n« \\n‘pafoud \\npoddns-uolsidap \\n|g \\nINOA \\n0} \\nanbiun \\naq \\nAew \\nyeu} \\nsyse} \\n|euOHppe \\nAue \\nppe \\npue \\npaau \\nnoA \\nS9UO \\n34} \\nAJUO \\nPalas \\n‘dowpvoy \\naduabiI/a}U] \\nSsauISNg \\nUl \\nSAIADE \\n|e \\nJO \\nSySe} \\n|]e \\nWUOJad \\n0} \\nUe;d \\n},U0Q \\n« \\n‘9]01 \\n8UO \\naJeYs \\nULD \\naJdoad \\najdnynwW \\nyeu} \\npuke \\n‘UOSJad \\nBUO \\n0} \\npaUsisse \\nag \\nUeD \\nSajOl \\najdiyjnwW \\nyeu} \\nJaquIaWaY \\n‘aidoad \\n3014} \\n10 \\nOM} \\n0} \\nUMOP \\nWe9} \\n3109 \\ndays \\nyoea \\ndaay \\n‘(UaAaS \\nUU} \\nAJOL \\nJaAaU) \\najdoad \\nAAI} \\nJO \\nINO} \\nynoge \\n0} \\nUMOP \\nWea} \\n3109 \\nPafoid \\nayy \\ndaay \\n‘pafosd \\nay} \\nUMOP \\nMOIS \\n[IM \\nSJaqUIaLW \\nLea} \\nay} \\nSuowe \\nuonje \\n-UIPJOOD \\nPUL \\nUO}}EIIUNWIWUOD \\n‘pa}ed!|dwWOd \\npue \\nBig \\nale \\nspafosd \\njg \\nUSNOUY \\n‘Wes} \\nad1e] \\ne ajquuasse \\n},U0Q \\n- \\n‘ueld \\npoafoid \\npayieyap \\ne \\nUl \\nSa}eWUI}Sa \\nINOA \\nyUaWUNDOG \\n‘aye} \\n||IM \\nAdy} \\nSUO} \\nMOY \\npuke \\nPauUOjiad \\naq \\n0} \\naAey \\nsyse} \\n}eYM \\nAjaAInju! \\nSUIMOUY \\nyNOge \\nsUONdWNsse \\nAue \\nayYeW \\nJAIN \\n« \\n\"HOY \\nJy} \\nd}eWI}saJapuN \\nIlIM \\nNOA \\npue \\n‘syse} \\nSSIW \\n|JIM \\nNOA \\nasnedaq \\n,s}ued \\nay} \\nJO \\nyeas \\nau} \\nAq, \\nUO!}edI|dde \\n|g \\naU} \\npling \\nJaAAN \\n« \\n$1,u0qd \\n‘a}ep \\nUOIJa]dWOd \\n»pefoid \\n3U} \\n10} \\nSa}EWI}S9 \\nANOA \\nUl \\nBdDUaPUOD \\nBAY \\nUeD \\nNOA \\neu} \\nOS \\nAlea \\ne}ep \\nadINOs \\nJo \\nAyjenb \\nauj \\nssassy \\n« \\n‘A(Su|ps0Ide \\nWay} \\naseuew \\npue \\n‘sys \\njeyUa}od \\nse \\nsuonduunsse \\nANOA \\nJe \\nJapISUOD \\n« \\n‘PEPIOAK \\n3q \\nJOUUPD \\nSYS \\nay} \\nased \\nUl \\nUe|d \\nADUBBUI}UOD \\n© \\nApNjDUI \\n‘OS|Y¥ \\n‘WaU} \\na}e3NIW \\n0} \\nuejd \\n& \\npue \\nsuojepudaWWOdaJ \\napIAOJd \\nPue \\nSy¥SL \\nBY} \\nYSIAM \\nO} \\nans \\nag \\n‘sisAjeue \\nYSU \\npaiejap \\n& \\nWUOLIad \\n« \\n‘aseajal \\naiNynj \\n& \\nO} \\nPauiajap \\naq \\n0} \\naAeY \\nABW \\nsajqeJaAljap \\nawoOs \\npuke \\n‘asueUD \\nadods \\ne \\nul \\nyJNsai \\nAew \\nSIUL \\n‘pafoid \\nay} \\nSuLNp \\npanjosa, \\njas \\nJOU \\nAeW \\nSanss] \\nawWOs \\nyey} \\na1eMe \\nag \\n“3O] \\nsanss! \\nUe \\ndaay \\n0} \\nUe]d \\n« \\n‘S}UIEIJSUOD \\n[|e \\n9}eI}OS9UI1 \\nNOA \\nssajuN \\najqeop \\naq \\nJasuUO| \\nOU \\nIIIM \\nHI \\n‘asUeUD \\nadods \\nay} \\na10jaq \\najqeop \\nsem \\nuejd \\n~afoid \\nAnOA \\n4 \\n‘Ayenb \\npue \\n‘sadinosai \\n‘Ja8pnq \\n‘au \\nJO \\ns}UuesSUOD \\n9U} \\nSU!}ENOBIUAJ \\nJNOYWM \\n3dods \\n9Y} \\nASULYD \\nJAAN \\n‘SAunpadodd \\n[O4}U0D-88uUeYD \\nJUdSUL}s \\nAPH \\n« \\n‘]O4JUOD \\nBSUeYD \\nJO} \\naUlJaseq \\nJNOA \\nse \\n}] \\nasn \\npuke \\nJayeUD \\nPafoid \\npajieiap \\ne \\najea/5 \\n« \\n‘Sssauisng \\n34} \\npuke \\n[|] \\nUB@aMjeq \\n9WOJPUAS \\n,WAaY} \\nSNSI9A \\nSN, \\ndU} \\nSUNEUILUI[a \\nPIEMO} \\nAem \\n8ud| \\n& \\nO8 \\nOsje \\n[JIM \\nSIUL \\n“WeAa} \\n3109 \\nPafoid \\nay} \\nJo \\nWed \\naq \\n[JIM \\naAHeUaSaidas \\nssauIsng \\nau} \\nasnedaq \\n4N3DO \\n|||M \\n43JSUJ} \\naSpa|mouyY \\n‘Os|V \\n‘}Ods \\nay} \\nUO \\npaAjosad \\naq \\nULD \\nsanss| \\nasnedaq \\nJa}se} \\nYON \\nOo \\n[11M \\n410M \\nJUBUUdOJanaq \\n‘}efoid \\nANOA \\nOW! \\npaxLyewW \\naAeUasasdas \\nssauisng \\nawi}-[|N} \\ne SUIAeY \\nUO \\njsSISU| \\n« \\n\"YOO \\nSIY} \\nYM \\npepn|dul \\nGD \\n34} \\nUO \\nainy}oNJ}s \\nUMOPyealg \\nY1OM \\naU} \\nAjjpow \\npue \\nAdod \\n‘paloig \\nYOSOIDIW \\naney \\nno \\n} \\n‘ued \\npafosd \\npue \\nainyonuys \\nUMOpyealg \\nYJOM \\nINOA \\na}ea19 \\n0} \\ndowppvoy \\naduabijjaqul \\nssauIsNg \\nasN \\n+ soq \\nSulUUe]d \\nPaloig \\n“€ \\ndajs \\nJuauidojanaq \\nsuluueld \\nPafoid \\n:¢ \\nda}s \\n}uawdojanaq \\n— \\nXL}eW \\nSaUljapiny \\njerNDeI1d \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 494}, page_content='—e—e—e——eeeeoooooooooo————————— \\n\"Wau} \\nYUM \\nssulpuy \\nJNOA \\nssndsIp \\npuke \\neyep \\n|g \\nay} \\nSuisn \\n9q \\n|IIM \\nOYM \\najdoad \\nssaulsng \\njueyOdu] \\n[e1aAVs \\nUM \\nYOM \\njuajqoid \\nsnoias \\ne \\naAey \\nNOA \\n‘jUa}s|SUOdU! \\nS| \\nBYP \\nay} \\npuke \\nsade]d \\na10WW \\nJO \\nXIs \\nUl \\nPI1O}s \\nS| \\nP1ODIJ \\nJABLUOJSND \\nSWS \\nJY} \\nJ] \\n— \\n‘Wa|qoJid \\npazis-winipaw \\n® \\naAey \\nNOA \\n‘jUa}s|SUOD \\nSI \\nJEP \\nay} \\npue \\nsadeId \\naA} \\n0} \\n3d1U} \\nU! \\nPal0}s \\nS| \\nPlODAI \\nJAWO}SND \\nawes \\nJy} \\nJ] — \\n‘a|qold \\nJOuILW \\n& \\naAeY \\nnoA \\n‘jUa}sISUOD \\nS| \\ne}ep \\nay} \\npue \\nsadejd \\nOm} \\nULY} \\na10W \\nOU \\nUI \\nPIJO}s \\nS] \\nP1ODIJ \\nJOWO}SND \\nBWesS \\ndU} \\nJ] \\n— \\n31X90 \\nByep \\n94} \\nJO \\nsuoHeeA \\nAUP \\nMOY \\npue \\npaio}s \\nsi \\ne}ep \\nay} \\nsadejd \\nAue \\nMoy \\nUI \\nIno \\npuly \\n:Ayyjenb \\nejeqg \\n« \\nSoll} \\nJE] \\nPO \\nU! \\nPasO}s \\nSI \\ne}ep \\nadsnOs \\nANOA \\n$1 \\nANOY \\nAq \\n1 \\nAjdyjnw \\n‘saseqeyep \\nJPEUOHE]o4 \\nUl! \\nPa10}s \\nS| \\ne}ep \\nad1nOs \\nANOA \\nJ! \\naa1y} \\nAq \\n}! \\nAjdyinw \\npue \\nasinbas \\n|jIM \\nNOA \\nyuIUy \\nNOA \\nOWI} \\nJU} \\nSFELUIISA \\nINO} \\n10 \\nBO4Y} \\nJO \\n10392} \\ne Aq \\npass|w \\nUaYyo \\naie \\nBulsuea|) \\ne}ep \\n10} \\npauInbas \\nawn \\nJo \\nS}EWI}SY \\n« \\n‘SdoqUaLU \\nWed} \\nPa{oud \\n|g \\nANOA \\nJo \\nJas \\n[JIS \\nBU} \\npuesJapUN \\nNOA \\nains \\n3g \\n*}] \\nJa}SEW \\n0} \\nSYJUOLU \\nXIS \\nPUB \\nJEUIWWAS \\ne \\nUI \\n|II4S \\nJIseq \\n& a1INbIe \\n0} \\nY89M \\nUO \\nSaye} \\n} \\n:SIIIAS \\n‘ysiy \\nApjenb \\nay} \\npue \\njjewus \\nadods \\nay} \\nSuidaay \\n0} \\naiqevaise \\ns| \\nOyM \\npue \\nspafoid \\n|g \\nJo \\n}dadU0) \\naseajal \\n94} \\nspuej}siapUuN \\nOYM \\nJOsUOds \\nssauisng \\nBu0d}s \\nAla \\ne SUJAeY \\nSI \\nS10}De} \\nssad2Ns \\nJED \\nBU} \\nJO \\nBUC \\n‘SOHENSED \\nBY} \\nJO \\nQUO \\nBWIA \\n},U0 \\n‘sadunosad \\nayenbapeu! \\nJo \\nasnedaq \\npue \\nSujuUR|d \\npafloid \\nyuaysixa \\n-UOU \\nJO \\nayenbapeul \\nJo \\nasnedaq \\npayloge \\nase \\nspafoid \\n1g \\njo \\naSejuariad \\nysiy \\nAaa \\ny \\n:saunjiey \\npafoig \\né}| \\nSUIOP \\naq \\n|IIM \\nOUM \\n— \\né2UOP \\naq \\n} |JIM \\nUdy \\n— \\n€}SOD \\n} [JIM \\nYONW \\nMOH \\n— \\néPaJ3Al|ap \\naq \\n|IIM \\nYEYM \\n— \\n:pefoid \\nAlana \\nynoge \\npayse \\nsAemje \\nase \\nyey} \\nsuonsanb \\nINO} \\n3Y} \\nJamsue \\n0} \\npasedaid \\nag \\n‘sdajs \\npapayas \\nay} \\n10) \\npauuojiad \\naq \\n0} \\nsaianoe \\n94} \\nJO \\nJUadJad \\nOG \\na4inba \\nspafoid \\nsow \\n‘pPafoid \\nsnOK \\nUo \\nWioJJad \\n0} \\npaeu \\nnoA \\nasou} \\nAjuo \\n~eNXxa \\npue \\n‘ \\n‘SYSE}GNS \\nPUL \\nS¥SE} \\nBY} \\nSE \\n|]aM \\nSe \\nSaIANDe \\nay} \\nMalAad \\n‘Ajjeul4 \\n‘aloud \\nsno \\nJO} \\na}eUdoidde \\nase \\nsauo \\nYDIYM \\nsUILa}ap \\npue \\nSdajs \\nay} \\nMaIAad \\n‘UDA \\nJEIIWIS \\n& \\nUl \\n‘UdUL \\n“USISaP \\nYM \\nulgaq \\nuaAe \\nAew \\nsaseajal \\nJUSUSUBYUS \\nYOYs \\naWOs \\npue \\n‘BujUuUR|d \\nYYM \\nUlsaq \\n|IIM \\nS1ay}O \\n‘UONeIyNSNf \\nUUM \\nUlsaq \\n[IM \\nspafoid \\naWos \\n‘ajdwiexa \\n404 \\n‘ulsaq \\n0} \\nspaau \\nyafoid \\nNOK \\naejs \\nUDIYM \\n3 \\nSUIWA}ap \\nPUL \\nSaBe}s \\n3U} \\nMAIADY \\n« \\n_——— \\nes \\nquiny, \\nfo \\nsajny \\npup \\nsdip \\n_—_ \\n“WeaU} \\nUl \\nB2UaPUOD \\nBAeY \\n0} \\nYSnoua \\nAjuO \\n‘sa}eWI}sa \\nANOA \\nSujUN} \\nUO \\nal} \\nYON \\n00} \\npuads \\n},U0q \\n« \\n‘UO \\nOs \\npue \\n‘Aynp \\nAinf \\n‘anea] \\nyDI5 \\n‘SUO}EIeA \\n104 \\nSLI} \\n3}2d0]|2 \\n0} \\n39310} \\n},U0q \\n« \\nCC \\nSujuueld \\nPafO1d \\n:¢ \\ndays \\nyuauidojanaq \\n— \\nxLjeEW \\nSOUIJAPIND \\n[eINDe1g \\n461 ing Project Plann Development Step 3 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 495}, page_content='I \\n0 \\n‘ajdoad \\nssauisng \\nay} \\n0} \\npue \\n10suods \\nssaulsng \\na4} \\n0} \\naiqe}danoe \\naq \\n}0U \\nJIM \\nLYM \\npue \\naiqe}darde \\naq \\n[IM \\nJEYM \\nJO \\nSHUI] \\n493NO \\nOU} \\nyuawndop \\nUD? \\nNOA \\n‘aABMOH \\n“YW \\n3q \\nued \\nAau} \\nJi \\nMOU \\n0} \\nAlea \\nOO} \\nSI \\n}} \\nasNedeq \\nS]UIWUBI1B \\n[BAA-I1/MAS \\nO} \\n}LUWOD \\nO} \\nAI} \\nBY} \\nJOU \\nSI \\nSIUL \\n‘payenogau \\naq \\n0} \\npaau \\nsjuswasinbay \\n‘sjuataunbai \\n|euly \\nay} \\nse \\nsHOdas \\nYDOW \\nJO \\nye} \\n& PUL \\nS}UBWa]o \\nBYPP \\nJO \\n1SI] \\nUSIM \\n& 3dadIe \\nJBAQN \\n+ \\n‘(syualuaja \\ne}ep) \\nsaynquye \\nJULDIJIUSIS \\n94} \\nppe \\nO} \\nPUP \\n[PAP \\njenjdaauod \\nay} \\npuohaq \\n}1 \\n942} \\n0} \\nUSNOU— \\nAjuO \\n‘Japolw \\nyep \\njed130] \\nau} \\nSuIUIa1 \\nUO \\ndays \\nsiy} \\nUl \\nBLU} \\nYONW \\nOO} \\npuads \\n},U0qd \\n‘siskjeuy \\neyed \\n‘¢ \\ndays \\nul \\npauuopied \\naq \\n||! \\nsiskjeue \\ne}ep \\nadiNOs \\nsnoJOSU \\npue \\n‘days \\nsiy} \\nul \\npawojied \\nag \\nysnuw \\nsisAjeue \\neyep \\nadinos \\nAreuwuijeld \\n“e}eP \\n991NOS \\nAIP \\nJaAOISIP \\n0} \\nBUSA} \\nJO \\nUBISap \\n[HUN \\neM \\n1uop \\n‘AjasiaAUOD \\n‘AYXa]dWOD \\nBuUlsUea]D \\nAU} \\nJO \\nZulpue}siapuN \\nJa}jaq \\n& \\nJed \\n0} \\nYsNoUS \\nAjuo \\nswajqoid \\nAyyenb \\neyep \\npapeadsns \\na}esi}soAul \\n‘siskjeue \\ne}ep \\naduNOS \\nUO \\ndajs \\nsiy} \\nU! \\nSU} \\nYONW \\nOO} \\npuads \\n},U0d \\n‘sysAyeue \\nSWay}sAs \\nJ] \\nWOsJ \\nJOU \\najdoad \\nssauisng \\nWOd} \\nSWOD \\n}sNW \\nsjuawadnbad \\nPalOld \\n‘Qatyejuasaidal \\nssoulsng \\n& \\n}NOYWM \\nYOM \\n},U0C $3,U0q \\nPractical Guidelines Matrix \\n‘ \\neee \\neee \\neee \\naan \\n‘sajpe}sqo \\nay} \\nayidsap \\nssadIns \\n10} \\nseduey \\nINOA \\nsaseasUl \\nSUOISID~aP \\n[je \\nUl \\nPAAJOAU! \\ndAl}e}UaSaidaJ \\nSSAUISNG \\n9} \\nSuidaay \\nuosuods \\nssaulsng \\naU} \\npue \\naaljeyuasaidas \\nssaulsng \\naU} \\nYM \\npajel}03aual \\nJOU \\nS$! \\nadOds \\nay} \\nJ \\npafoid \\ne \\njlesap \\nUD \\nSyDO|GQpeO! \\npapadxaun \\n‘pefoid \\nay} \\nJNOUSNOIU} \\nSB|GeJaAIap \\nJEUL} \\nOU} \\nayeno8aual \\npue \\na}e}}03au \\n0} \\npaiedaid \\nag \\n+ \\n‘saseqeyep \\n3a8Je} \\n| \\naU} \\nJO \\nUSISap \\na4} \\nUO \\nSuueag \\naAkY \\n||IM \\nUOHEULOJUI \\nSILL \\n“SISeG \\nJejngai \\ne \\nuo \\nyse \\nAjjensn \\nKay} \\nsuonsanb \\njo \\nWiayed \\ne \\naAey \\najdoad \\nssauisng \\n}sOwW \\n‘peuljap \\n30K \\nOU \\nase \\nSalianb \\naso} \\n}eY} \\nsaljdul \\n(DOU \\npe, \\nYsNoUYy \\n‘a}4M \\n0} \\nJUEM \\nKew \\najdoad \\nssauisng \\nay} \\nsauanb \\n0y \\npe \\nJO \\nsadA} \\nay} \\nBUILA}ap \\n0} \\nALL \\n+ \\n‘uoneaijdde \\nyoddns-uolsidap \\n1g \\n& \\nYM \\ne}ep \\nMou \\n3}8319 \\nJOUULD \\nNOA \\n‘Wa}sAs \\njeuolyeiado \\nue \\nUl] \\npalo}s \\npue \\npasayjyes \\nUsed \\nJaAe \\nsey \\ne}yep \\nad1nos \\npasinbas \\n34} \\nJOYJ@YM \\nSUILUI}OC \\n+ \\n‘S| \\nUOJ \\nBY} \\nJe \\nBIIUM \\ns| \\nJeY} \\naSNeIIq \\nWNWIUILW \\ne \\nO} \\nadons \\neyep \\ndaay \\n0} \\nJaquaWaY \\n*e}eP \\nBACY-O}-2d|U \\n94} \\n9PN|U! \\n},UOP \\npue \\n‘eyep \\njueyodui! \\npue \\nAoyepuelw \\nay} \\nUO \\nayesUaDUOD \\n‘A108a}e9 \\nYdee \\nAq \\nJAW \\naq \\n|||M \\nJL} \\nSPIdU \\nssauisng \\npexa \\nau} \\nAjl}Uap] \\n“@AeY-O}-99/U \\npue \\n4ueyoduil \\n‘AioyepuewW! \\nO}U!] \\ns}UaWasINbad \\nBJP \\nSZ/VOld \\n« \\n‘gdors \\npafoid \\nay} \\nWO1 \\npaddoup \\naq \\npynoys \\nuoluyeq \\nsjuatalinbad \\nBACY-0}-99IN \\n“SMOJ|e \\nAW]} \\nSe \\nSUO!PUN} \\nyuevoduwil \\nppe \\npue \\nsuojouny \\nAuoyepuew \\n94} \\nsjualuasINbey \\nUO \\n3}21}]UDDUOD \\n“BACY-O}-9d!U \\npue \\nSuevodui \\n‘AioyepuewW \\nO}U! \\nsjuaWadInbas \\nJEUOHIUN} \\nUY} \\n9ZI}UOUd \\n« \\npalold \\n“7 \\nsod \\ndays \\nuauidojanag \\n462 \\nuoniuyag \\ns}uawasinbay \\nPal0ld \\n‘tv \\ndays \\nuawidojanag \\n~— \\n= XH}eIA \\nSaulJepiND \\n[e1e1d \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 496}, page_content='463 \\nEe \\n“SUEIDIUYDO} \\nAU} \\nJOU \\n‘UOIS|Iap \\nJEU \\n94} \\nIYeW \\ndAl}e}UaSasdad \\nSSAUISNG \\n9} \\n13] \\nJBAIMOH \\n‘adods \\nWalid \\n|g \\nBY} \\nUl \\nPapn|ou! \\naq \\nO} \\nBAY \\nJOU \\nSBOP \\nAjqeqoid \\n}sow \\n} \\nyeU} \\nSUBS \\nSIUL \\n‘a}doad \\nssauisng \\nay} \\nAq \\npasn \\nJaAau \\n10 \\nWOP|as \\nS|] \\nB}eP \\n9d1NOS \\nYSIYM \\nAynuap! \\ndjay \\n0} \\nye}s \\n11 \\n94} \\n4SV \\n» \\n‘QUI \\nBY} \\nJO \\nJUaDIAd \\nQB \\npasn \\nALRjNBai \\nsi \\neyep \\n1g \\nBU} \\nJO \\nyuadied \\nOZ \\nAjuo \\n‘sased \\n}sOW \\nul \\neu} \\npull \\nU! \\ndaay \\n‘Jenba \\npa}zeaid \\nSI \\neyep \\n[|e \\nJON \\n‘@UeUSJUeLW \\nPue \\n‘Zulsuea|> \\n‘UOIDeA}Xa \\neyep \\n10} \\njuads \\nAQUOW \\nPU \\nJI} \\nBJOW \\nPUP \\nSjapolw \\ne}ep \\nXajdwo? \\na1ow \\n0} \\nspea| \\n,Aep \\nawos \\n}! \\npaau \\n|| Aau} \\nased \\nul \\nysn{, \\neyep \\nJeuoHesodo \\nYINW \\nOO} \\nJaye \\nSulog \\n‘saseqejep \\n}93Je} \\n|g \\nGY} \\nJO} \\nE}ep \\nBd1NOS \\nO} \\nspJeSal \\nUl \\n» \\n‘saundsip \\nsaajosad \\nUaAa \\nAjjeuoIsedd0 \\npue \\n‘ssulpue}siapunNsiW \\ndn \\nsueay \\n‘suajqoud \\nAyyenb \\npue \\nJeuo}UYap \\nSI9AODUN \\n‘adeJINS \\n9U} \\nO} \\nsjuUaWasiInbes \\nMau \\nS8ULqG \\nUaYO \\nSUOISSAS \\nBSA} \\nSULNP \\npa}eadd \\nAiauks \\naul \\n‘ajqissod \\nse \\nsmalAsayul \\ndnous \\nAuewi \\nse \\nONPuod \\nO} \\nAl \\n« \\n‘op \\n0} \\nay! \\nAuew \\nse \\n‘atul} \\nSIy} \\n}e \\nUOHNIOS \\nBU} \\nSUIUSISAP \\nO}U! \\nduunf \\nsueidiuyd2} \\n94} \\nJo] \\n},U0d \\n“UO! \\nNOs \\ne \\nZulusisap \\nue} \\nAWAIE \\nJUDOYIP \\n& \\nSI \\nsjuaWasINbas \\nSUIUIC \\n‘aniyeyuasaidas \\nssauisng \\nay} \\npue \\n1osuods \\nssauisng \\nau} \\nyyM \\nAlessadaU \\nUdYM \\nWau} \\nayeno8aual \\npuke \\ns}ulejsuo? \\nay} \\naduejeq \\nsAem|y \\n‘Ayyenb \\npue \\n‘saaunosad \\n‘Jaspnq \\n‘SUI \\nJO \\nSJUJEA}SUOD \\nSU} \\nU!YYM \\n3|GeOP \\nIIHS \\nSIH \\nJ! \\n99S \\n0} \\nadods \\nBy} \\nMalAa \\nSARMIV \\n« \\nee \\nquiny, \\nfo \\nsajny \\npup \\nsd \\nEE \\nuonUyaq \\nsyuaWasNbay \\nWaloid \\n:p \\ndays \\nyUaUdojaneq \\n— \\nXH}PIA| \\nSeUI|eP{ND \\n[eIe4d \\nProject Requirements Definition Development Step 4 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 497}, page_content='Practical Guidelines Matrix 464 \\n—_————————————— \\neJep \\nJO \\nsuoeyasdiajul \\npue \\n‘sajm \\nssauisng \\n‘sulewop \\neyep \\n‘suoMIUap \\nB}ep \\nPI|EA \\nUO \\nSNSUaSUOD \\ne \\n}e \\nSALW \\n0} \\najdoad \\nssauisng \\nay} \\nSuowe \\nsajyeq \\nAuew \\nayy \\nIAJOSI1 \\nO} \\nDHE} \\n[IM \\n}! \\nAW} \\nBY} \\nB}EWI}SaJapUN \\n},U0G \\n« \\n‘SUJUOWW \\nUUM \\npa}dnu0d \\nJad \\nued \\ne}ep \\nMau \\n‘UOH}EZIULZIO \\nUe \\nye \\npadiOjUa \\nJOU \\nale \\nsassazoid \\nAyjenb \\n4] \\n‘Adeund2e \\nay} \\nJaySIY \\nay} \\n‘eyep \\nay} \\nJUaLIND \\naJOW \\n9U} \\n}eU} \\nALUNSSe \\n},U0G \\n- \\n‘suadxa \\nJayewW \\npalqns \\npue \\n‘s}sAjeue \\nssauisng \\n‘sio}es}siulupe \\neyep \\nse \\nyons \\n‘sisAjeue \\nssauisng \\npajlejap \\nAofua \\noum \\naidoad \\npuly \\n(‘Surwuwessoid \\nAofua \\nyou \\nop \\nAjjesauas \\ns}sAjeue \\nssauisng \\nse \\nysnf \\n‘siskjeue \\nAofua \\nyou \\nop \\nAjjes9uas \\nsueld|UYraI) \\n“e}ep \\ne}aW \\nssauIsngq \\n9U} \\n932919 \\n0} \\najdoad \\nswa}sAs \\n10 \\nsiauWesSOid \\nyse \\n},U0Q \\n« \\n‘UO \\nOS \\npuUe \\n‘sain \\nssauisng \\n‘suleWOp \\n‘SUOIUNap \\ne}yep \\nINOK \\n$O \\nssaUuDaLIOD \\naU} \\nd}epljeA \\nO} \\nWay} \\n}JUEM \\nAjuo \\nnoA \\nyeu} \\najdoad \\nssauisng \\n1aujo \\n9SOU} \\nPUlWAaY \\n“adOds \\nINOA \\nUl \\ns}UaWAasINbas \\neYep \\nMau} \\nSuIpN|DUI \\n}SISaJ \\n‘s}UaUpedap \\nJay}O \\nWO \\najdoad \\nssauisng \\nuM \\neyep \\new \\nSSOUISNG \\nJU} \\nSUIMAIAAI \\nUIUM \\n« \\n9g \\n0} \\nSey \\n}! \\nUPB] \\nMOY \\npur \\n‘}! \\npaau \\nAsy} \\nUaYyM \\n‘4! \\npaau \\nAdy} \\nMOY \\n‘paau \\nAay} \\nUO!ELUOJU! \\n}eEUM \\n:sjUaWadINbad \\ne}ep \\nay} \\nSALUIP \\n}snW \\najdoad \\nssauisng \\n‘UO}LIOS! \\nU! \\n|BPOW \\nL}ep \\njed130] \\n& \\ndojanap \\nJaAAN \\n« \\n—_—_—_—————— \\n$1,U0q \\nee \\n‘Aysigeljad \\neyep \\nJo \\nsuoHeyadxa \\nssauisng \\nau} \\nJaa \\nO} \\npasuee]> \\naq \\n0} \\nBABY \\nS}USLWa]9 \\nE}EP \\n|LIFUD \\nasa \\n“anjeA \\nssaulsng \\njead \\naAey \\n}eY} \\ns}UaWala \\nyep \\n|edIUD \\n34} \\nAjuapy] \\n« \\n‘91q|seoj \\nJ! \\n“eyep \\nad1nOs \\nJeuoljeJado \\nsay} \\ndn \\nuea]d \\n0} \\nWau} \\nASV \\n“e}ep \\nJay} \\nJo \\nAyjenb \\nay} \\n404 \\nAyjigeyunodde \\npue \\nAyIqisuodsai \\ndadde \\n0} \\nsIaUMO \\ne}eP \\ndU} \\nASIN \\n- \\n“HOSOI \\njse] \\n© \\nSB \\npleOg \\nUOHeIGUe \\n1g \\n& JO \\nJUBWAAJOAU! \\naU} \\n}Sa8Bns \\npinous \\nsainpadoid \\nasa] \\n‘adesn \\nejyep \\npue \\n‘sajni \\nssauisng \\n‘sulewop \\neyep \\n‘SUO}UYAp \\ne}ep \\nSulpsesai \\nsjuawyedap \\nJUdJAHIP \\nWO \\najdoad \\nssaulsng \\nSuowe \\nsaduasayyIp \\naAJOSa1 \\n0} \\naiNpadoid \\nUO!}NJOSaJ \\nayndsip \\ne \\nYsijqeisy \\n« \\n‘asesn \\ne}ep \\npue \\n‘sajni \\nssaulsng \\n‘sulewop \\neyep \\n‘SUOI}Uap \\neyep \\nUO \\n22U9NIUOD \\n1194} \\nUlE}GO \\nO} \\n(2}ep \\n}LY} \\nAsn \\nOYM \\ns}uaed~ap \\nJaUjO \\nUI! \\ns}sAjeUe \\nssauIsng \\npue \\nsiaSeUeL \\nSSBUISNQ) \\nSJPLUNSUOD \\nUO!EULOJU! \\nBY} \\nYIM \\nPUL \\nSIBUMO \\ne}eP \\ndU} \\nUIIM \\ne}ep \\nPIO \\nSSausng \\n[Je \\nMAlAay \\n« \\n“UOHEUNOJU! \\nJEUIS}U! \\nBY} \\nYM \\nUOHEUOJU! \\n[EUI9}X9 \\nBY} \\n9ZISAYIUAS \\n0} \\ndq \\n[JIM \\nSISeg \\nay} \\n}eUM \\nSUILWI9}9q \\n‘UBWUOIAUS \\nYOddns-uolsidap \\n|g \\nay} \\nUI \\npasn \\naq \\n|IIM \\nyeu} \\neyep \\n;eUIa}xa \\nJO \\nSPUIy \\n9} \\nPue}sJapUN \\n- \\n‘SJUBUOdWOD \\n|ed/}LID \\nale \\nSUOIUYap \\nNpoid \\nPUP \\nJAWO}SNI \\nUOWWOD \\n‘UO}}Z/ULSIO \\n34} \\nUl \\nSaul] \\nNpoOid \\nje \\nssoud \\nyeu} \\nsajyjoid \\nJaWO\\\\sNd \\nApnjs \\n0} \\nS| \\nd1ISap \\n34} \\nJ}! \\n‘a]dwexa \\n4104 \\n‘}UaWedap \\nauUO \\nJO \\naAIeyUasaidal \\nSS8UISNG \\nBUO \\nJO \\nMAIA \\npa}ejOs! \\nue \\nJOU \\nSI \\npue \\ne}ep \\nJo \\nBUlpueysiapUN \\n|eUOeZIULSIO-sSO1D \\nBU} \\nS}DaIJOJ \\nJ9POW \\nezep \\njed130] \\ndU} \\n}eU} \\nJuNsuq \\n- \\nsishjeuy \\nBeg \\n‘Ss \\n— Ot \\nsod \\ndajs \\njuawudojanaq \\nee \\nee \\nsiskjeuy \\ne}eq \\n:¢ \\ndays \\nyuawdojanag \\n= — \\nXe] \\nSAUIJAPIND \\n[edWDeAg \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 498}, page_content='465 \\nBo \\ndha \\ni \\na \\niis \\nals \\noe \\nSo \\nelt \\naol \\na \\nae \\nEden \\nhea \\nele \\nei \\na \\n‘eyep \\nau} \\njo \\nAlojsiy \\nay} \\npue \\n‘sdiysuonejas \\nau} \\n‘Adeindde \\nay} \\nJO \\naspajmouy \\nYdap-ul \\naAeYy \\nUa}yO \\nAaul \\n‘pasn \\npue \\n‘passadoid \\n‘pasojs \\nsi \\ne}ep \\nBy} \\nBJBYM \\nPUL \\nMOY \\nSMOUY \\nHes \\n1] \\nFUL \\n“OP \\nSUMO \\ne}eP \\ndU} \\nJO \\nBANeUaSaidal \\nSsauUIsSNg \\nay} \\nUL} \\nAja}EW}U! \\nBOW \\ne}ep \\nay} \\nJO \\nSPodse \\nJed1UYIO} \\nBy} \\nMOUY \\nUSYO \\nsio}yeNSIUIWIpe \\naseqejep \\npue \\n‘siadojanap \\n‘s}sAjeue \\nSWa}sAs \\n‘papaau \\nUdYM \\nJe}s \\n1] \\nFY} \\nWO \\nAjay \\nHINOS \\n- \\n‘HW \\nO}EUILUIJa \\nJOUURD \\nAdu} \\n‘VWOYS \\nJU} \\nYUM \\ndjay \\nued \\nsoo} \\nYSnoyYy \\n‘Oye \\njenuew \\naatsuazul \\nue \\nAjewud \\nsi \\nsisAjeue \\ne}yep \\nBdiNOS \\n-« \\n‘INOJ \\nJO \\n10};9e} \\ne \\nAq \\npasinbas \\naw} \\nay} \\naJEWSaJaPUN \\nUBYO \\nYOHa \\nau} \\nYPM \\nJelIWeyUN \\nsie \\nOYUM \\npue \\nalojag \\nSulsueaj> \\ne}ep \\nYSnoJU} \\nUaeg \\nJOU \\naAeY \\nOYM \\n(SiaseuUeW \\nJ] \\nAUeW \\npuke) \\nSiadeULW \\nSSaUISNg \\n« \\n‘ainyny \\nay} \\nUl \\nSWUa}SAs \\nJEUOI}EJAdO \\nJ!9U} \\nJO} \\nEYEp \\ne}aW \\nssauisng \\nBuI}Da]]O2 \\npue \\nsjapow \\ne}ep \\n[e130] \\nBUI}EI1D \\nJBPISUOD \\nO} \\n(SJaseUeWW \\nSSauIsSNg \\n-J0-dUI|) \\nSWa}SAs \\n|eUOeJadO \\ndy} \\nJO \\nSIBUMO \\nBY} \\nABN \\nPjnoys \\nJOsUOds \\nssauUIsng \\npuke \\naAe}Uasesdas \\nssauisng \\ndul \\n‘}sixa \\nAjaies \\nAay} \\n‘asojasau} \\n‘pue \\nswaysAs \\njeuoHesiado \\n10} \\npayeasd \\nAjases \\nase \\neyep \\nPJD \\nPUL \\nSJapOW \\nasauy} \\n‘Aja}eUNLOJUA \\n‘swa}sAs \\nadINOS \\nJeUOI}eJadO \\naU} \\nJO} \\nJsIxo \\nApeauje \\ne}ep \\ne}JOW \\nssaulsng \\npuke \\nsjapow \\ne}ep \\njed1SO| \\nJi \\npadnpas \\nAj}ea13 \\naq \\nued \\nspafoid \\n|g \\nUO \\nYWOYa \\nsisAjeue \\ne}ep \\nUL \\n« \\n‘SQUO \\nJEDI} \\nJSOW \\nJU} \\nUO \\n9}2J}UBDUOD \\nPUR \\n‘S}UBWA]a \\nEJP \\n9Y} \\n9ZUOU \\n‘WuaWaja \\neyep \\nyDdea \\nazZAjeue \\n0} \\nSWI} \\nUZNOUA \\nJADU \\nSI \\nBay} \\nDUIS \\n‘pazAjeue \\nyep \\nJdINOS \\nay} \\nBAeY \\n‘PajaPpOW \\nBulag \\nS| \\nP}EP \\nJU} \\naIUM \\n« \\n‘SQN \\nSSOUISNG \\nJU} \\nSAWD/OIA \\nB}YEP \\nIDINOS \\nBY} \\nBJBYM \\nJBAODSIP \\n0} \\nsisAjeue \\neyep \\nadJNOs \\ndn-Wo}0qG \\npue \\nsajni \\nssauisng \\nau} \\nauyap \\n0} \\nSuljapowW \\ne}ep \\n|e130] \\nUMOp-do} \\nasn \\n‘sajni \\nssauIsNg \\n0} \\nSpiesai \\nUl \\n« \\n‘salnuedasdsip \\ne}ep \\nBAJOSA1 \\nPuke \\nPUL \\nO} \\n[@POW \\nyep \\n[ed130] \\nasUdia}US \\nBU} \\nYM \\nJaPOW \\nejep \\nje13o} \\nDyI9ads-pafoid \\nInoA \\nassiaw \\npue \\naiedwod \\nUday} \\npjnoys \\nUO!}eJ}siuIWpe \\ne}yeq \\n‘|apowW \\ne}yep \\nJed180] \\nJY} \\n9}e919 \\n0} \\nPafod \\n4NOA \\nUO \\nJO}ZeAS|UJWpe \\neyep \\ne \\nAAJOAU| \\n“‘SUIJaPOW \\nej}ep \\n|ed!3O] \\npue \\nsain \\nUONeZI|EWUOU \\nase \\nsiskjeue \\ne}ep \\nadinOs \\npue \\nUOHeIZaIU! \\nE}eP \\nYOU \\n10} \\nSanbiUYIE} \\naANDa}Ja \\nJSOW \\nSUL \\n« \\nIs Data Analys \\nquiny, \\nfo \\nsajny \\npup \\nsdiy \\n‘AUAIDE \\nSulsuea|d-eyep \\nINCA \\nase \\n‘anjea \\nssaulsng \\njeas \\nSUIPIAOId \\nyNoyWM \\nSUILUJBYMJIAO \\nBWIOIAG \\nUD \\nYSe} \\nSUISUL|]D \\nBY} \\nasNedaq \\ne}ep \\nJo \\nadaid \\nAJaAB \\nBSULA|D \\nO} \\n}JdWaye \\n},U0Q \\n- \\n‘SUOISIDAP \\nJa}}aqg \\nPYeW \\nSAAI}NIaxa \\nssaulsng \\ndjay \\nyou \\n|IM \\nUOHedI|\\\\dde \\n|g \\ne \\nYsnosYy} \\ne}yep \\nAYP \\n0} \\nssadde \\nSuing \\nAjdwis \\n‘eyep \\nuea]d \\npue \\najqeljas \\n0} \\nssadde \\nBujUles \\nSI \\naAeINU! \\nYOddns-uolsidap \\n|g \\ne \\n10} \\nSUOSeAL \\nUIEW \\nJU} \\nJO \\nBUC \\n‘SI \\nSe \\nE}LP \\nJdINOS \\n3y} \\n|/e \\nPAOW \\n0} \\nUe|d \\n},UOP \\n‘sp1OM \\nJaU}0 \\nUJ \\njYUNJ|d \\npuke \\nyNS \\nJBABN \\n-« \\nDevelopment Step 5 \\nsishjeuy \\ne}eq \\n:¢ \\ndajs \\n}UaWdojanag \\n— \\nXLWj}eIA \\nSaUTJapINy \\n[edd \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 499}, page_content='Practical Guidelines Matrix 466 \\nrs \\n‘“auoje \\nSulsuea|) \\ne}ep \\nYSnosy} \\npadaiyse \\naq \\nyouUeD \\npue \\nYDeoJdde \\ndNsI]OY \\ne \\nsi \\neep \\nJo \\nAyyenb \\nS \\nUO]}EZIUCZIO \\na4} \\nSUIAOIdU] \\n“SUJUIe4} \\nPue \\n‘SyDaUD \\nYpa \\n‘sajnd \\nAjua \\neyep \\napn|U! \\npjnous \\nJUaWIaDIOJUA \\nAyeNH \\n“swia}sAs \\nJeuo}esado \\nay} \\nul \\nsassadoid \\nAyjenb \\njo \\nJuUaWadJOJUa \\nBY} \\nSe \\nPOO \\nse \\naq \\nAjuO \\n[IM \\nAyenb \\neyep \\nadinos \\n« \\nsa|ni \\nssouisng \\n— \\nsuJeLUOp \\ne}eg \\n— \\nAyjeulpaes \\n— \\nsdiysuolejay \\n— \\nSUOIHHUJOq \\n— \\nsaweu \\nejeg \\n— \\n‘ounjded \\n‘WwinuwiuIW \\n2 \\nyy \\n‘dajs \\nsiy} \\nSuLinp \\neyep \\nea \\nSsauIsng \\nay} \\nSuLN}ded \\nJO} \\nLUSsIUeYDaLU \\ne \\naAeY \\nNOA \\n}EU} \\nONS \\nag \\n« \\n—____ \\nSS \\nSSS \\nsishjeuy \\neyeq \\n:¢ \\ndays \\nyuawdojanaq \\n=— \\nXxL}eW \\nSauljapiny \\njesnDe1q \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 500}, page_content='467 ing on Prototyp icat Appl Development Step 6 \\n‘uejd \\npafoid \\nJU} \\nASIA \\nPUP \\n‘SAAIDA[GO \\nMAU \\nJos \\n‘SZuidA}0}01d \\nSNul}UOD \\nO} \\nJUPM \\nnoK \\n}] \\n‘paydeas \\nUseq \\ndACY \\nadfyo}01d \\nau} \\nJO \\nSAAIPalgo \\n|eUISO \\n34} \\nUBYM \\nadhjo}o1d \\nau} \\nJO \\npua \\nay} \\n0} \\nAyyeuoUN} \\nMou \\nSuippe \\ndaay \\n},U0q \\n+ \\n‘uoneridde \\n|g \\njeuy \\nau} \\nJo \\nadaid \\njews \\ne \\nAjuo \\nJaaljap \\npinoys \\nadAjojo1d \\nyee \\n‘uonesi|dde \\nIq \\nay} \\nJo \\nUOIPOd \\nsiskjeue \\nPuke \\nSsedde \\nBY} \\n10} \\nPOYJOW \\nyuawidojanap \\ne \\nse \\nadAjo}01d \\njeuol}e1ado \\nay} \\nZulsn \\nUayM \\nUdAq \\n‘adAjo}OId \\nay} \\nJO \\nadoos \\nay} \\nul \\nsjuaWasINbad \\n}eafoid \\nay} \\n|]/e \\napn|rul \\n},UO \\n‘uoeyndas \\nuno \\naSewep \\nued \\nsas|wWold \\npal|JinJuN \\nJAl[ep \\nJOUUe> \\nnoA \\n}eyM \\nasiwodd \\n},U0d \\n+ \\n$},u0d \\n“SUIN}1 \\nSUIYSIUILWIP \\nJO \\nJUIOd \\nay} \\nYIedJ \\nnof \\nuaym \\nSuidAyo}01d \\ndojs \\n+ \\n‘adAyojoid \\nau} \\nSuNp \\nusisap \\naseqeyzep \\naU} \\n}SaL \\n‘PassadIe \\nejep \\njo \\nAjaUeA \\nau} \\npuke \\n‘papseduU \\nuoHesai8se \\nJO \\nJaAV] \\nBU} \\n‘SUO!SUBLUIP \\nSuiodas \\nay} \\njnoge \\nWes] \\n‘uoneridde \\n1g \\nAuyiom-uolonpoid \\n‘g]e9S-|[N} \\n& JOU \\n‘YING \\nSuUlaq \\nSI \\nadfqojoid \\ne \\nAjuo \\nyey} \\nazijea1 \\najdoad \\nssauisng \\nay} \\nye} \\n4NS \\nOxPI \\n‘jadojaAep \\npee] \\n1.14 \\neu} \\npue \\nJo}edsiulUpe \\naseqejyep \\naU} \\nAyjeidedsa \\n‘siaquualu \\nWed} \\n3409 \\npefloid \\nay} \\nuM \\nAjjep \\nayed!UNWIWOD \\n‘sagueys \\nadAjo}01d \\nBy} \\nJO \\nAdOds \\nBY} \\nABADUSYM \\nS}UIeA}SUOD \\npafoid \\nay} \\nayeHosauas \\npue \\nMalAZy \\n‘uonpuny \\nuoHeriidde \\nsyIdeds \\ne \\n10 \\nBale \\npalqns \\ndyads \\ne \\n0} \\nadAjo}O1d \\nYes \\nWWI] \\n‘uoresay! \\nadAjoyoO1d \\nYea \\n410} \\nPAMO}|O} \\nPUR \\nJAS \\nO12 \\nSHUI] \\nOUT \\nye} \\nduns \\nOye \\n‘sInoK \\nJOU \\n‘S}UNOD \\n}eU} \\nBN|!e} \\nPUP \\nSSADINS \\nJO \\nUOIUYSP \\n4/AY} \\nS|} \\n“JEquUiaWoy \\n‘UONDNAYSUOD \\nadeyJaqUl \\nJasn \\nJed14ydeis \\npue \\n}UBWssesse \\nspaeu \\nSuunp \\nAjjelsedsea \\n‘Bujuulsaq \\nay} \\nWoy \\nadAjo}01d \\n9y} \\nUl \\nayedioied \\n0} \\najdoad \\nssauisng \\n}eD \\njeuoljesado \\n— \\nowed \\n— \\nusISop-JEnsiA \\n— \\njdadU0D-}0O-JOO]d \\n— \\ndn-y»DOW \\n— \\n||9}-PUe-MOUS \\n— \\nSuidA}0}0ld \\n-3}231) \\n0} \\nadAjo}oO1d \\nuoHe>1|dde \\nJo \\nad} \\n3y} \\nUO \\nap|ded \\nuonerddy \\n°9 \\nsod \\nda}s \\nJuauidojanaq \\nSuidA}o}01g \\nuoneriiddy \\n:9 \\ndays \\n}uawidojaneg \\n= — \\n= Xi}eIA \\nSauTjapinyd \\nJed1e1d \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 501}, page_content='Practical Guidelines Matrix 468 \\nrere ee \\nee \\nee \\n‘adAjo}O1d \\ndy} \\nUI \\n} \\n}S9} \\n0} \\nJ1NS \\nag \\n‘spUNOs \\n}! \\nSe \\n[PIAL] \\nSe \\nag \\nJOU \\nAew \\neyep \\npajiejap \\n3ulpiAoid \\n‘Suisn \\naie \\nno \\nsj00} \\nau} \\npue \\nUSIsap \\nJNOA \\nUo \\nSulpuadaqg \\n\"eyep \\npayjlejyap \\n10} \\nSuse \\ndn \\npua \\nAau} \\n13}e] \\n10 \\n12UOOS \\nyng \\n‘eyep \\nAuewiuNs \\nAjUO \\npadu \\nAau} \\n4UuIY} \\nUaYO \\nSJaseueW \\nssauisng \\n« \\n‘19}SEJ \\nBUOP \\nSBUIY} \\nJ93 \\nO} \\nWED} \\nay} \\najqeua \\n||IM \\npuke \\nSiaquaW \\nWea} \\nSuowe \\nUOHe>1UNWILWOD \\npasinbad \\nadnpai \\nJIM \\naZis \\nWea} \\nay} \\nBUULYS \\n“a10W \\nUdaAa \\nUMoOp \\nsbulYy) \\nMo|s \\npue \\nUOIVe>|UNWWOD \\n}#2}s \\nJO} \\nposInbas \\naw} \\nay} \\naseas \\ndu! \\n[JIM \\nWea} \\nay} \\n,SUeO|g, \\njaZIS \\nWea} \\naU} \\nYULYs \\n‘peaysu] \\n‘Passi \\nJ1e \\nSOUI|PRAP \\nJ] \\n9ZIS \\nWe} \\nBY} \\n0} \\nppe \\n},U0q \\n‘adA}O}0Jd \\n|y} \\npling \\n0} \\nWea} \\nyeafoid \\naBie] \\ne \\nSuisn \\nploAy \\n» \\n‘QUBIa \\nUY} \\ndJOW \\nOU \\nyng \\n9UO \\nUY} \\n340) \\nadAjo}Od \\n9} \\nUI \\nayed!DIWed \\najdoad \\nssaulsng \\njo \\nJaquinu \\nayeidoidde \\nue \\neu} \\nainsuq \\n« \\n\"S9AIINIAXa \\nSSaUISNG \\nJOIUSS \\nPUk \\n‘SIaSeURL \\n|| \\n‘sla3CULLU \\nSSAUISNG-JO-dUl] \\nJO \\nPasUdwWOd \\nUO!JeOd \\ne \\nUJe}UIEW \\npUe \\npying \\n0} \\nAYANDe \\nadAyoj0O1d \\n3U} \\nasf \\n« \\nHH \\npling \\n0} \\nsujuueld \\nase \\nNOA \\nAem \\nay} \\nasn \\n0} \\nAsea \\nag \\n|I!M \\nuOHedI|dde \\nay} \\nJauJaYM \\naas \\nUD \\nNOA \\n}eY} \\nOS \\na]qIssod \\nse \\nadAjo}01d \\nay} \\nYM \\nadUaLadxa \\nUO-spueY \\nYNW \\nSe \\naney \\najdoad \\nssaulsng \\nay} \\n32] \\n‘asn \\nJO \\ndSCd \\n}S9} \\nOL \\n« \\nsees \\nees \\nquiny, \\nfo \\nsajny \\npup \\nsdip \\nes \\nsss \\nspunea \\nses \\n‘JUBWUOIIAUD \\nSUI}S9}-SSA1}S \\n& JOU \\nSI \\nSIU \\n‘a2UDULIOfIad \\nKSO|OUYDa} \\n}Sa} \\n0} \\nadAjO}O1d \\naU} \\nasn \\n1,U0q \\n« \\n‘SasURYD \\nPa}sassns \\nUsWa|dw! \\n0} \\npasinbas \\naw \\nay} \\na}ewNsasapunN \\n},U0QG \\n« \\nYING \\nSulaq \\ns} \\nadAyo}01d \\nay} \\nWOYM \\n10} \\ndnoss \\n3409 \\nay} \\nWO} \\nAau} \\npue \\nya8png \\nJJ94} \\nJO \\nJNO \\nBUIWOD \\nSs} \\nSulpuNy \\nay} \\naduIs \\nadAjO}O1d \\nBy} \\n40} \\n,yD9UD \\nay} \\nUSIS, \\nOUM \\najdoad \\nssoaulsng \\ndu} \\napnysul \\n‘Ajueyoduu! \\nJsOW \\n‘JOU \\nS| \\n}eYM \\npUe \\nBUIMIOM \\nSI \\nyeYM \\nBuIdA}O}O1d \\nSuLNp \\nino \\npuy \\noO} \\njUeEM \\nNOA \\n“SUD{JOM \\nJOU \\nS| \\nSUIYJOLUOS \\nUUM \\nAj|peas \\na1OW \\nNOA \\n1]9} \\n|]! \\nABU} \\naSNedaq \\n|[|aM \\nSe \\nSIaAalJaquOU \\naWOS \\nBAPY \\nO} \\nPI9U \\nNOA \\n‘sa}JOAey \\nINOA \\nae \\nOYM \\nJO \\nJBdIOA \\nae \\nOYM \\najdoad \\nssaulsng \\nay} \\nUM \\nAJUO \\nYOM \\n},U0q \\n« \\n‘PAAJOAU! \\najdoad \\nssaulsng \\nay} \\naAey \\n0} \\naiNs \\nag \\n‘UBISaP \\nadeJJa}U! \\nPU-JUOJ! \\nBY} \\na1OUB! \\n},UOG \\n« \\n“WINLIUILU \\n& \\nO} \\n}day \\naq \\npjnoys \\ns}uaWaJINbad \\nUOe1Sa}U! \\nEEG \\n“aye} \\nJIM \\nadAjO}O1d \\nauy \\nJasUO] \\n94y} \\npue \\n‘AYXa|dWOD \\naU} \\nJeYsIY \\na4} \\n‘UO}esBa}U! \\nBIOW \\nBY! \\n‘s}UaWALINbay \\nUONeIZaIUI \\neyYep \\nAUeW \\nOO} \\nSSOIPpe \\n},U0Gq \\n« \\n‘uO}}IUNJ \\nTLJ \\nUe \\nBUl}sa} \\nBe \\nNOA \\nssajun \\ne}yep \\nay} \\nSulsuea|) \\nawl} \\nAue \\npuads \\n},uop \\npue \\n‘eyep \\nAyjenb-100d \\nyy \\nadAjojo1d \\nayy \\nd}EUILUL}JUOD \\n1, UDG \\n‘adAjojold \\nseyndiped \\nyeu} \\nUl \\nP9}S9} \\n9q \\nO} \\nPI9U \\nFLY} \\nSUO!}EUIGWUOD \\najqissod \\nay} \\n||e \\n}UaSasdaJ \\nAjLessadau \\nyou \\nAew \\najdwes \\nAvesique \\nUB \\nPUR \\n‘SNOUIWNIOA \\nAjjensn \\nsI \\neyep \\nadsNOs \\n“e}ep \\nadINOs \\nJo \\najdiues \\nArejIque \\nUe \\nASN \\n0} \\nJOU \\n3Saq \\nSI} \\nSSS! \\nSuldA}o}01d \\nuonerddy \\n:9 \\ndays \\n}uauidojanaqg \\n— \\nxiujeEW \\nSQUIJIPIND \\n[edI~e1d \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 502}, page_content='469 ing Prototyp ication Appl Development Step 6 \\neS \\nA \\nI \\nAEE \\nAE \\nA \\nEE \\n‘sjsAjeue \\nSSAUISNG \\nSNSIBA \\nSJIASCULW \\nBAI}NIOXd \\nJO \\nSpadU \\njUdJa}JIP \\n9Y} \\npUL}SJapUN \\n‘Jenba \\npayeasd \\naie \\najdoad \\nssauisnq \\n||e \\nJON \\n:spaau \\npuke \\nasesn \\nUI \\nadUDAaHIG \\n— \\n‘BUISNJUOD \\nOO} \\nJO \\nPa}LII|dLUOD \\nOO} \\nSI \\n}} \\nasNedaq \\n}! \\nSUIPIOAe \\nURL} \\nJaY}E1 \\nYJUOW \\nFSA} \\nau} \\n10} \\nAep \\ne adu0 \\njseaj \\n}e \\nUODUN} \\ndjay \\nay} \\nBulsn \\naq \\npynoys \\najdoad \\nssauisng \\nauL \\n:UO!}UN} \\ndjay \\nayL \\n— \\n‘Yt \\nSUIPIOAe \\nOU \\nPUe \\nUOT}edI|dde \\nIq \\nMau \\naU} \\nSuIsn \\n0} \\npreMO} \\nSUIYOO] \\naq \\nPinoys \\najdoad \\nssauisng \\nayL \\n:uONIeJsHes \\ndAIDa{[qns \\n— \\n‘Jayse} \\nJUadJad \\nGZ \\njsea] \\n}e \\nSSE} \\nSISAJEUE \\nJAY} \\nYSIUY \\nO} \\najqe \\naq \\n0} \\naAeY \\ns}sAjeue \\nssaulsng \\npuke \\nsiayJOM \\na8pajmouy \\n‘uoH}ed1|dde \\njg \\nmau \\nay} \\nBulsn \\nAg \\n:JUaWYsI|dwodde \\nyse} \\nJO \\npaads \\n— \\n‘uoneddde \\nmau \\ne \\n3ulused| \\nJO} \\napse \\nyas \\nAjjensn \\nued \\nuosiad \\nssauisng \\ne \\n}eU} \\nWINWIXeW \\nau} \\nSs! \\nSAep \\nOM} \\nJO \\nBUC \\n‘aAIND \\nBUJWeaT \\n— ‘SUIMO]JO} \\n3U} \\naPN}Iu! \\nSJUaWAINSeaW \\nSWS \\n¢asn \\n0} \\nAsea \\npasJapisuod \\nWa}sAs \\ne \\nS| \\nUBYM \\n‘ASN \\nJO \\nasea \\nBUIjaq \\n‘adAyo}01d \\njeuonesado \\nay} \\nJO \\nUOI}e19} \\n[EUL \\nBY} \\n0} \\npaljdde \\naq \\npinod \\n‘jJuawdojanag \\nuoHedI|ddy \\n‘Z1 \\ndays \\nyo \\nsaIANDe \\nSUL \\n‘SUOHeJ9}! \\nPaj]os}UOD \\nAWYSI \\n[eJaAes \\nJaye \\nuonerijdde \\nsiskjeue \\npue \\nssadde \\n[UlJ \\n3Y} \\nOJ! \\nBAJOAD \\nAjyeinyeu \\npjnod \\nadAjo}01Jd \\nJo \\nadA} \\nSiu} \\njeu} \\n‘USNOUA \\na|qIXalj \\na1 \\nS]OO} \\nsIsAjeue \\npue \\nssadde \\npue \\n‘Ysnous \\njsngoOJ \\nase \\nsadAjo}ONd \\njeuolesiadO \\n‘uonerijdde \\n|g \\nau} \\nJo \\nuoIod \\nsisAjeue \\npuke \\nssadde \\nau} \\n40} \\nadAjo}ONd \\nJeuOHeJado \\nUe \\nBUIP|INg \\nJapISUOD \\n« \\nSuidA}0}01g \\nuoHedI|ddy \\n:9 \\nda}s}UuaWdojaAsg \\n— \\nXL}eA/ \\nSOUT[apINyD \\n[edNWDe1d \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 503}, page_content='Practical Guidelines Matrix \\n470 \\n‘yok \\nAloysoday \\neieg \\nPW \\n94} \\nUl \\nSdajs \\nJuatUdojanap \\nOU} \\nJO} \\nSa}ELUI}SS \\nSLU} \\nINOA \\najdiy \\n‘e}Ep \\nBa \\nBulssauppe \\naie \\nNOK \\nSUH} \\nSJ \\nOU} \\nSI \\nSIY} \\npul \\nUOINIOS \\neye \\ne}aLU \\nOU \\nSeY \\nUO!}EZIULBIO \\nINOK \\nJ] \\n« \\nquiny, \\nfo \\nsajny \\npup \\nsdiy \\n‘uoledidde \\n|g \\nAuana \\nJo \\nIIGeJIAIJap \\nJessa} \\nUe \\nJuOJa1aU} \\nS! \\nH \\n}UsWUOIIAUS \\nYOddns-uolsidap \\n1g \\n24} \\nUl \\n[O0} \\nUOHeSIAeu \\ne \\nse \\npasn \\nsi \\npue \\nBYP \\nSSaUIsNq \\nJO} \\n}X9}U0D \\nay} \\nsapIAoid \\nP}eP \\nPIN \\n‘UOHE}UBWINDOp \\nJsnf \\naq \\n0} \\nEep \\nea \\nJOPISUOD \\n},U0qG \\n« \\n$100} \\n194}0 \\npue \\n‘Syd \\n‘dV10 \\n“119 \\nOU} \\nO} \\nDEpo}UI \\n|O0} \\n94} \\npue \\n‘sueld|UYda} \\npuke \\najdoad \\nSSOUISN \\nJO} \\nBde{J9}U] \\nSSadde \\nBY} \\nJapIsuoDd \\n0} \\nS2DPL9}UI \\nJO \\nsadA} \\nOm} \\naue \\nala. \\n‘Auoysodai \\neyep \\neyaw \\n94} \\nJO} \\nS}uUaWadINbad \\nadeLa}U! \\nay} \\nazAjeue \\n0} \\n930} \\n},U0G \\n» \\nqUSWUOAIAUS \\nYOddns-uolsidap \\n1g \\nay} \\nJo \\ns}UaUodWOD \\n4JOU}O \\nBY} \\ndl] \\nISNf \\nSWI} \\nBAO \\nAAJOAA \\n[IM \\nMioysodai \\neyep \\neyaw \\nSUL \\nJOYHS \\na1n}dId \\nSiq \\nay} \\n39310} \\n},UOp \\n3Ng \\n‘9dU0 \\n3e \\nSulyAlana \\nOp \\n0} \\nAuy \\n},U0G \\n« \\n$},u0q \\n“P}EP \\nBJU \\n[Bd|UY9} \\npuke \\ne}ep \\neJaW \\nssauIsng \\n0} \\nuo}}Uua}e \\nJenba \\nAeg \\n« \\n‘UBISap \\npa}UaO-Palqo \\nue \\nUO \\npaseg \\nauo \\nPiling \\n0} \\n40 \\nAuoysodai \\neyep \\neyaw \\ne \\n9SU9)I] \\nO} \\nBP!Iap \\n4J9}e] \\nNOK \\nJ \\nUaAd \\n‘anbiuyra} \\nSuljapow \\ndiysuonejas \\n-AyyUa \\nay} \\nBuIsn \\njapow \\neyaW \\nJed130] \\n& \\nySnoiy} \\ns}usWaJINba \\neyep \\neJaW \\nay} \\n9}epl/eA \\npue \\nainjdey \\n. \\n‘Auoysodad \\neyep \\neyow \\n9SUd13}Ua \\nJUO \\nO}U! \\nS]OO} \\nSNOHEA \\nWO \\ne}ep \\neJaW \\nBUN}SIXa \\nJe \\n9}EPI|OSUOD \\n0} \\nUR] \\n» \\n\"spJepuejs \\nasou} \\nysijgnd \\npue \\nspJepue}s \\ne}ep \\njeUuOH}ezIUeSIO-sso)D \\n9SIABJ \\n10 \\ndojanap \\n0} \\nSJO}E1}S|UILUPE \\nJEP \\nJY} \\nYUM \\nYON \\n« \\nSOHIWLWOD \\nBAI}e}UaSaIdal \\ne \\nAg \\nJO \\nAyrenpiaipul \\nsiaSeuew \\nssaulsng \\nAq \\npauunsse \\naq \\nued \\ndiysiaumo \\ne3eq \\n‘AyWoune \\naney \\nAau} \\nUDIYM \\nJ3AO \\nP}EP \\nSSOUISNG \\nBY} \\nJO} \\nB}ep \\n&JILU \\n9Y} \\n[O1]U0D \\n0} \\nsIaUMO \\nPEP \\n9SOY} \\nMojje \\npue \\ndiysiaumo \\neyep \\nUsl|ge}sq \\n- \\n\"eJEp \\nssaulsng \\nsisAjeuy \\nSB \\nUOHUSHe \\nJO \\nJUNOWe \\naWes \\nau} \\nUaAIS \\n9q \\n0} \\nsp9au \\npue \\nyaloid \\n|g \\nAlana \\nJo \\ned \\nyueyodul \\nue \\nsi} \\neiep \\nAioysoday \\nPJ9I \\n‘ssad01d \\nuoMUYap \\ns}uatuauinbas \\nByep \\nPOW \\nJU} \\nU! \\n9}edIDI1ed \\naANeUasaidas \\nSSOUISN \\n3} \\nSAH \\n« \\ne}eq \\neI \\n7 \\nsoqd \\ndajs \\nJuauidoyjan \\n2d \\nsiskjeuy \\nAioysoday \\ne}eq \\nPII \\n:Z \\ndajsjuauidojanag \\n— \\nXH} \\nSAUIJapIND \\n[erDe1g \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 504}, page_content='471 Is Meta Data Repository Analysi Development Step 7 \\n‘SMOJJE \\nJWI} \\nSE \\n[APOW \\nLOW \\n[ed130] \\nINOA \\n0} \\nS}JUBUOdWIOD \\n|eUOHIPpe \\nppy \\nSa|ni UONEUWOJSULLL — \\nUO!UYaq \\n— \\nu}sua] \\npue \\nad} \\ne}eg \\n— ulewog — (usia10} pue Asewtd) shay — uLUNI|OD — \\nage \\n— \\n(Ayjeuondo \\npue \\nAyyjeulpsed) \\nsajni \\ndiysuonejay \\n— ainquyny — \\nAyquq \\n- ‘S}UQUOdWOD e}ep \\nPOW \\n[EDD \\nJSOW \\nJU} \\nJO} \\nWeISeIP \\ndiysuoe|jas-Aj}}US \\nBY} \\nMEJIP \\n‘J|AaPOLW \\nJAW \\n[ed13O] \\ndy} \\nBueIID \\nUDUM \\n‘QUI} \\nJO \\nNO \\nUNL \\nNOA \\n41 \\nsauO \\nJeUOI}dO \\nay} \\nBUOd}sod \\npue \\n‘ued \\nNOA \\nse \\ns}uUsUOdWOD \\nJUeVOdWI \\nAuew \\nse \\nainided \\n0} \\nAu} \\nosjy \\n‘paso}s \\npue \\npoinjded \\naq \\npynous \\ns}uauOdWOD \\ne}ep \\ne}awW \\nAJOJepuUeW \\nIV \\njeuondo \\n— \\nyUueVOdw] \\n— Asoyepuey — ‘SOUOB9}ED 9IJY} OU! SJUBUOdWOD e}eP L}JA@W BU} 9ZI}UOUd \\nsisAjeuy A1oyisoday e}eq e}aW :Z da}s JUaWIdOjaANVq — XL}eIA/ SAUIJapINyD jedNIe1d \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 505}, page_content='A \\na \\nET \\nOS, \\nA \\nA \\nRE \\nNIE \\na \\nTE \\na \\n‘(le}UaWAIDUI \\nJO \\n‘JeNJed \\n‘{jnJ) \\nsdnydeq \\nyuanbad \\nSule} \\nUO \\nUe} \\n‘IJ \\n}e \\nBUOP \\naq \\nPjNOd \\nH \\nJ \\n‘ay \\nSuo} \\nAJaA \\n& \\naye} \\nP|NOM \\nY \\n‘auNjiey \\naseqeyep \\ndIYdoseyed \\n& \\nJaye \\nYI}IDS \\nWO \\nSaseqe}ep \\nja31e} \\n|g \\nINOA \\npeojas \\n0} \\najqe \\nSulag \\nUO \\nUNO? \\n},U0G \\n« \\n‘SpudJ} \\nUBISAP \\n10 \\nAZO|OUYII} \\n}S9}e] \\nJY} \\nJOU \\n‘UOISIDap \\nUBISap \\naseqeyep \\naU} \\n9ALIP \\nSpuaWasINbas \\naU} \\n9] \\nO} \\nBINS \\nag \\n‘ayeUdoudde \\nsi \\nUSIsap \\ndiysuonejas-AyyQUa \\nUL \\nIJIYM \\nSUOISEIIO \\nJe \\nBJIUL \\nJEUOISUIWIPHNW \\naq \\n}sNnwW \\nSaseqe}ep \\njosJe} \\n|g \\n[Je \\nJey} \\naWINSse \\n},U0q \\n- \\n‘Ayyenb \\npue \\n‘Ayyigqeyiene \\n‘ssauljauut} \\nJO} \\nSJUaWAJINbaJ \\nJUdJaJIP \\naAey \\nAvy} \\npue \\n‘UOHeZUeWLUNS \\npur \\nj[Ie}ap \\nJO \\nS[aAa] \\n]UdJAIP \\npadu \\nAay} \\n‘syuawasinbad \\nssadde \\nJUaJayjIp \\naaey \\najdoad \\nssauisng \\njUasaJI \\n‘I|e \\nSJ \\n9ZIs \\nBUO \\nye} \\nalUNSSe \\n},U0Q \\n- \\n‘(usIsap \\naseqe}ep) \\njapow \\neyep \\njed1sAud \\n© \\nO}U! \\nPaZI/DULOUAP \\naq \\n|II}S \\n}SNW \\nJaPOW \\neyep \\njed180] \\ndy} \\n‘UBsSOYD \\nS| \\nEWUaYDS \\nUBISap \\ndiysuoNejas-AyUa \\nue \\n}] \\nUdAJ \\n“sISAJEUL \\nSSAUISNG \\na}eUIIDe} \\nO} \\nSI \\n(|g \\n10 \\n|eUO!}e4ado) \\nUaWUOIIAUA \\nAue \\nU! \\nJ|apOW \\neyep \\nJed13O} \\nPaZIJEWUOU \\ne& \\n10} \\nasodind \\nau \\njjapow \\neyep \\njed130] \\npazijewuOU \\nAjjn} \\ne \\nUSWA]! \\n0} \\nydWa}e \\nJBAAN \\n« \\nPractical Guidelines Matrix \\n$1,u0q \\n‘sanje \\nUl \\nUOHNQUIsIP \\nYsIy \\ne aAeY \\nyeu} \\npuke \\nA}}UaNbay \\nUO \\npaydJeas \\nase \\n}eY} \\nSULUNJOD \\nBSOU} \\nXapUT \\n« \\n‘pull \\nUl \\nSdUeWUOJJed \\nYM \\nSUIXapu! \\npuke \\n“UaWade|d \\neyep \\n‘BuUOH \\nWed \\n‘sajqe} \\nSuLa}sn}d \\njnoge \\nsuOIsIDap \\naye \\n« \\n‘sUBISAP \\naseqeyep \\nJasJe} \\n|g \\nJY} \\nAUas \\nAjjfenuNUOD \\n0} \\nadxq \\n» \\n‘siseq \\nJejndai \\ne \\nUO \\nSHOdal \\npuke \\nsalianb \\nJo \\nadUeWOJJad \\nJU} \\nJOWUOW \\n0} \\nUE] \\n« \\n‘papaau \\nsewayUrs \\nJe}s \\nJO \\nJOQUINU \\nJU} \\nSZILWJUIW \\nO} \\nJapsO \\nUl \\ns}sAjeUe \\nssauIsng \\n8uoWe \\nsuJa}yed \\nSuodas \\nseyIWISs \\nAjUAap] \\n« \\n‘papaau \\nsi \\nA}UNdas \\n}eUM \\npuke \\n‘papaeau \\nase \\nSUO!|SUaWIP \\n}eUM \\n‘jajjered \\nul \\nUNI \\naq \\nued \\nsalianb \\npue \\nsyiodas \\nAuew \\nMoy \\naa \\n‘saliAoe \\nBuUIdA}O}01d \\nay} \\nWO. \\nPaUea| \\nSUOSSA] \\nJU} \\nMAIAdY \\n« \\n\"SUOISUBLUIP \\nBYL[JMOUS \\nPdZI|ELOU \\nJU} \\nPUL \\nSUOISUaLWIP \\nPAWWOJUOD \\nay} \\nSuIUsIsap \\n10} \\njUIOd \\nSulpie}s \\n& \\nSe \\ne}ep \\nEJAW \\nSsauIsng \\nay} \\npue \\njapow \\ne}ep \\n|ed130] \\nay} \\nUO \\nSaI}Ua \\nau} \\nasf \\n« \\n‘suiayed \\nssaade \\npuke \\ns}uawauinbas \\naSOU} \\nUO \\npaseq \\nPWAY)s \\nUsISap \\naseqeyep \\najelidoidde \\nay} \\nasooyD \\n‘e}ep \\nay} \\nssadde \\nJIM \\nAdu) \\nSAM \\ndU} \\nusisoq \\npue \\nwvoyiad \\n0} \\npaau \\nAay} \\nsasAjeue \\nJo \\nsad} \\nay} \\npueysiapun \\n0} \\najdoad \\nssauisng \\najdiyjnwu \\nUM \\nYOM \\n« \\naseqejeq \\n‘8 \\nEEE \\nnnn \\nnnn, \\nSSS \\nSSS \\nsod \\ndajs \\njuauidojanaq \\nNeen \\nn \\nnnn \\nnnn \\nnnn \\nnnn \\nnnn \\nnnn \\nnnn \\nnnn \\nSE \\nSSS \\nSSS \\nusIsoq \\naseqejeq \\n:g \\ndais \\n}uauidojanaqg \\n= — \\nxL}eIAJ \\nSaUTJapIND \\n|edNdeI1d \\n472 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 506}, page_content='473 ign Database Des Development Step 8 \\n‘So|ge} \\nUOISUDUWIP \\ndU} \\nUI \\nSaN|eA \\neyep \\nJO \\nUONNqUIsIpP \\npuke \\n‘azis \\n‘asesn \\n‘dnayew \\nay} \\nUO \\nspuadap \\nUOIsIDap \\nJUL \\n‘(JQABOS}EUM \\nBULAPJO \\nJO \\nXapu! \\njed1sAYd \\nOu) \\ndeay \\ne \\nse \\najqe} \\nay} \\naAed] \\n— \\n‘JUBIS \\nUl \\nSUIUJAIBAS \\nXapU] \\n— \\n‘yo \\nAed \\nAew \\nsaureoidde \\nawasj}xa \\nOM} \\nJO \\nJaY}A \\n‘S3]qe} \\nUOISUALUIP \\n34} \\nSUIX9pU! \\nUBUM \\n‘“QALIP \\nYSIP \\nBY} \\nUO \\nS3]qe} \\nPoa}ejas \\n3}ed0]-0D \\nAjjed1sAUd \\n‘sUeWWOJed \\naAosjduul \\nAjjedizewuesp \\nUed \\nanbiuydI} \\nsiy} \\nSuisn \\n‘SuoHedjdde \\n|g \\nUl \\nWOU \\nay} \\nSI \\neep \\nJo \\nssadIe \\njeluanbas \\naouls \\n‘evep \\nJo \\nS}JunOWe \\naie] \\nJO \\nssadde \\nJelUaNbas \\n10} \\nanbjuYde} \\n[nNJasn \\nAJaA \\ne \\nSI \\nSULa}sN|D ‘aseqe}ep \\n(a81e| \\n10) \\nWin|paw \\nsteak \\nyxau \\ns| \\naseqgeyep \\n|jews \\ns Aepo} \\n‘AjUO-Mols \\nS| \\naSeqeyep \\njad1e} \\n|g \\n& \\nBDUIS \\nsaVqeia} \\nAUeW \\n0} \\ngD \\n008 \\nJO \\na8ueJ \\ndU} \\nUl \\nBe \\nSGCTA \\n— \\n99 \\n008 \\n0} \\nOOE \\nJO \\nasuUL! \\nJU} \\nUl \\nJIE \\nSaseqeyep \\nodie] \\n— \\n9D \\nOOE \\nO} \\nOOL \\nJO \\nasuUeJ \\nJU} \\nUl \\nBie \\nsaseqej}ep \\nLUNIPe \\n— \\n9D \\nOOL \\n0} \\nOL \\nJO \\naSsuUeJ \\ndU} \\nUl \\nJUe \\nSaseqeyep \\njews \\n— \\n‘AlOSIILD \\nFATA \\nJu} \\nOU! \\n|e} \\nA[qe}ADU! \\nJSOW]e \\n[JIM \\nSaseqeyep \\njosie} \\n|g \\nAue \\n‘Sulxepul \\nAaeay \\npue \\n‘AUSa,Uu! \\n|elUasJa}a1 \\nPad10JUd-LULIZOId \\nUO \\nJDUEIIaI \\n‘UONeZI|EWUOUaDP \\n:a}isoddo \\nau} \\nysnf \\naie \\nsaseqeyep \\njesse} \\n|g \\nUl \\nSaunjea} \\nAay \\n“Sulxapul \\nJo \\nasn \\nsnojipnl \\npue \\n‘Ayal \\nJeNUdajos \\nSWIG \\nJO \\nUOHeZIIIN \\n‘UO}eZI}eWOU \\naie \\nSaseqeyep \\njeuoHesJado \\npausisap-|jam \\nul \\nSainjeas \\nAdy \\n‘saseqejep \\njosie} \\n|g \\npue \\nsaseqejep \\njeuoeiedo \\nUsamjag \\nSadUaJaJIP \\n94} \\nPue}sJapUN \\n‘Sanbiuyda} UBISap JEUOISUBWWIPH}|NW Ul se \\nJOM \\nSe \\nSJdZIWIdO \\ndy4IDads-SWG \\nBU} \\nUl \\npeules} \\naq \\nPjnoUs \\nJO \\nale \\nSJO}eJ}SIUILUPe \\naseqej}ep \\njeu} \\nUOSeal \\nUIELU \\nJU} \\nJO} \\nUSISAap \\naseqe}ep \\nsapnjdu! \\nsiO}eJ}S|JUILUpe \\naseqejep \\nJo \\nUONdUIsap \\ngof \\nau \\n‘siaWIWeIsOId \\nay} \\nAq \\nWay} \\n0} \\npapuey \\n1dq \\nuns \\npue \\ndn \\nadj \\nAjdwis \\noym \\n,syJaj> \\nAyjua \\neyep, \\nse \\nsioyeJ}SIUILUpe \\naseqelep \\nasn \\njou \\nOg \\n‘saseqe}ep \\nUsISap \\npjnoys—siaWWeIBOId \\nJOU—SJO}EJ}SIUILUPe \\naSeqe}eq \\n« gquiny_ fo sajny pub sdiy ‘Ja}e] aseqeyep ANOA usisapai 0} SUIAeEY \\n0} \\npea] \\nAjisea \\npynod \\nydIyM \\n‘UOHEZ|ULSIO \\nUdAIS \\n© 10} \\nBPE \\nSAS|LUODIGWIOD \\nPa|jaJ \\nS[|apOW \\n9soy} \\nUdYO \\n‘UONeZIULZIO \\nJUdJAJJIP \\n& 10} \\npadojanap \\n(uUsIsap \\naseqe}ep) \\njapow \\neyep \\njedisAud \\ne \\nasn \\nAjpuljg \\n},U0q \\n« \\nuSIsaq \\naseqe}eq \\n:gdajs}uaWwidojanag \\n— \\nXL}eIA \\nSAUTapINy \\n[ede \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 507}, page_content='Practical Guidelines Matrix 474 \\n“SUBUUOJJad \\nSaAoiduI \\nUOHE}UaWIseI \\nSUIAOWDY \\n‘Pa}aJaP \\n10 \\nPaPasul \\nJe \\nSp1OIaJ \\nJU} \\nJO \\nJUaDIEd \\ng \\nUaYM \\n— \\néPdZlUes1OAJ \\naq \\nSaSeqe}ep \\nau} \\npjnous \\nUdUM \\n‘aseqej}ep \\nXapu! \\nay} \\nSUIUIe}UIeW \\npuke \\nSadipu! \\nJo \\nSulddoip \\npue \\nSulppe \\njeuonippe \\nau} \\njO \\nasnedag \\nJaYyYN} \\nUdAd \\npapeisap \\nS| \\nDUeWOJad \\n‘xapU! \\nJU} \\nSUIPJING \\nJO \\nyNsai \\ne \\nse \\nUBYM \\n‘BSIOM \\nJO \\n— \\n‘9AOICU| \\nJOU \\nSBOP \\nIII}S \\nBUeWOPad \\nUBUM \\n— \\n‘Ajeuanbas \\npaydieas \\nsl \\naseqe}ep \\nxapul \\nau} \\nUdUM \\n— \\n, JJEW, \\nANJLA \\nJU} \\nJO} \\nSAL}US \\nJUIDINd \\nOG \\npuke \\n,ajewWaj, \\naN|eA \\nay} \\n40} \\nXapuUl \\nau} \\nUl \\nS8L}Ua \\nJUIIJAd \\nOG \\n}NOge \\naq \\n|IIM \\naJaY} \\nBPOD \\nJapUaH \\nULUNJOD \\nay} \\nUO \\n}INg \\nSI \\nXapUl \\nUe \\nJ \\n‘ajdwexa \\nJo4 \\nyo \\nAed \\njou \\nsaop \\nxapul \\nue \\nBuIpjing \\n‘juadJed \\nS| \\nUB} \\nBOW \\naie \\nXApUI \\ndU} \\nU! \\nSalj]Ua \\nAaNjeA \\nUBUM \\n— \\néyIng \\naq \\njou \\nXxapul \\nUe \\npynous \\nUaYM \\nCaen \\nnn \\nnnn \\nncnennnncnccncnnnnnnnnnnncnncnncn \\nSSS \\nSSS \\nSS \\nusIsaq \\naseqe}eq \\n:g \\ndajs}uawidojanaq \\n= — \\n= XxL}eIAJ \\nSaUJapIND \\n[edNde1d \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 508}, page_content='475 Ign Extract/Transform/Load Desi ° \\n° Development Step 9 \\n“SWeIZOJd \\nJeUO!}EJBdO \\n3} \\nUI \\nPUL \\ne}eP \\n3DINOS \\ndU} \\nU! \\nPong \\noe \\n}eY} \\nSajM \\nSsauIsNng \\nay} \\npuejsiopun \\n|| \\npue \\najdoad \\nssauisng \\nay} \\nAjUO \\n‘sajNJ \\nUOISJAAUOD \\nPJEPUL}S \\nSUIMO]|O} \\nAg \\nsaseqeyep \\njos1e} \\n1g \\nay} \\na}e;ndod \\n0} \\nMoy \\nAj}DeXd \\nMOUY \\n0} \\n}! \\nUO \\nAjaJ \\n},UOP \\n‘S! \\n[OO} \\nTJ \\nBY} \\nPABXUeAPe \\nMOY \\nJd}eW \\nON \\n- \\n‘MO|} \\nSSOD0Jd \\n714 \\n9U} \\nJO \\nPUS \\n9} \\nPJEMO} \\npd}LJOdJODUI \\n3g \\nO} \\nPIdU \\nSAUL \\n‘SEW \\neJep \\nJU} \\nJO} \\nSUOIFEZULULUNS \\nPuke \\nSUON}ESIISse \\nYOOLIAO \\n},U0Q \\n«+ \\n‘Wau} \\na}yesedoid \\n0} \\n}OU \\nUdUM \\npue \\nSasegejep \\njadJe} \\n|g \\nBU} \\nO}U! \\nSUOIJaJaP \\nP1ODa1 \\nJeUOHeJado \\nayesedoid \\n0} \\nUayM \\nAyDads \\nYdIUM \\n‘SSad01d \\nLJ \\nUj \\nJO} \\nSajni \\nssauisng \\ndojaAaq \\n‘aseqe}ep \\n3d1NOs \\nJO \\ndjlj \\n9dINOS \\n& \\nWO \\nPaj}ajap \\nSEM \\nP1OIaI \\njeuoieiado \\nue \\n}ey} \\nSULAAODSIP \\nJaye \\nSaseqe}ep \\nJassie} \\n|G \\nBU} \\nWO’ \\nSMOJ \\ndjoJap \\nAjjedeWO \\nNe \\n},U0 \\n« \\n‘sajmi \\nAyu8aj}ul \\ne}ep \\nSsaulsng \\npuke \\nsajni \\nUIELWOP \\ne}ep \\nssauIsng \\nJ0j \\n180] \\nUOHEWOJSUeI} \\nSAPNIUI \\nOs]e \\n} \\n‘SaINJONUYs \\neyep \\nJaSJe} \\nINOA \\nO} \\nSaiN~NYjs \\ne}ep \\nadinos \\nINOA \\nJo \\nY}Sua] \\npue \\nadj \\neyep \\nJU} \\nSUIIAUOD \\nUU} \\nBOW \\nYONW \\nSI \\nLJ \\n‘SAM \\nUOISI9AUOD \\nJeEd1UYI9} \\nBU} \\n0} \\nSS9dO1d \\nLJ \\nOY} \\nPW] \\nJOABN \\n« ‘MO|} SSAD01d TL OU} \\nauljweass \\ndjay \\nued \\n}eY} \\napes} \\nBU} \\nJO \\nSYD} \\nNOGe \\nMOUY \\nUSO \\nsJO}eJ}s|UILUpe \\nvseqgejeq \\nJO}eJSIUILUpe \\naseqejep \\nay} \\nJo \\nuoedioied \\npue \\nadue}sIsse \\n34} \\n}NOUWM \\nMO} \\nSSad0I1d \\n719 \\nBY} \\ndojanap \\n3,U0q $z,u0q \\n‘eyep \\nsayejndiuew \\n10 \\nSOAOW \\nyeu} \\nWesiZoid \\nAlana \\nJO} \\nUSISAp \\nssad0I1d \\n7LJ \\nBU} \\nUl \\nS]e}O} \\nUOH}E!]INUOdIJ \\npue \\nsow \\nAyyenb \\neyep \\napnjdu| \\n- ‘MUN |ed130] UO \\nSe \\npaseURLU \\naq \\nPINOUS \\nLae \\nSUISE}S \\n119 \\nBU} \\n‘SS9JBULIADN \\n*]00} \\nLJ \\nOU} \\nJO \\nSW} \\nSulsuad|] \\npue \\n‘saniyiqeded \\n‘SUOIDUNJ \\nJU} \\nSe \\n[|aM \\nSe \\n‘Saseqe}ep \\nad1NOS \\npue \\nSal} \\nIDINOS \\nJO \\nSUOI}EIO] \\nPuke \\nsad} \\nJUdJaJJIP \\n0} \\nanp \\nase \\nSUIZI|e1JUDDIP \\n10} \\nSUOSEAI \\nPI|eA \\nAJUO \\ndU} \\n‘(SUUOJ}e]d \\nJUDJAJJIP \\nUO \\nSUO!DUNJ \\n7LJ \\nWaJaJJIp \\nSuluuns) \\npazijeijuadap \\naq \\nued \\nPale \\nBuUIse}s \\ne \\nayIUM \\n‘SWa}sAs \\nadidano}s \\nsadnpoid \\nyeu} \\nasnedaq \\nssad0Jd \\n74 \\nUMO \\nSi \\nBAeY \\nO} \\nPEW \\ne}yep \\nYea \\nMoje \\nJOU \\nOG \\n‘ease \\nBulse}s \\nPue \\nssad0Jd \\n79 \\nQUO \\na1eUS \\n- \\n‘AleSSODOUUN \\nPUL \\nBUILUNSUOD \\nSUI} \\nOO} \\nS| \\naSeqej}ep \\njosse} \\n|g \\nJOYJOUe \\nPeo] \\npue \\n‘WUOJsUeI} \\ne1)X9 \\n0} \\nUIeSe \\n11 \\npeal \\npue \\nPuNOJe \\nUJN} \\n0} \\nAJUO \\naseqe}ep \\njesse} \\n|g \\nBUO \\nSulpeo7 \\n‘ssad0Jd \\nLA \\nawes \\ndU} \\nWO \\nJWI} \\nUS \\ndy} \\n}e \\nPOLad \\npeo] \\naWes \\naU} \\nJO} \\nSaseqeyep \\nJaBJE} \\n1g \\n[|e \\n10} \\nSajly \\nPEO] \\nJY} \\n9}LdID \\n- ‘SIOPUSA \\nay} \\nWO’ \\nadAy \\nBuayxJEW \\nJOU \\n‘[OO} \\n7LJ \\nUe \\nJO \\nUO!PaIJas \\n9U} \\nBALIP \\nS}UDWAJINbas \\nUONEWUOJsUes} \\nANOA \\n397 \\n« \\nuSisaq \\n‘UNL [IM SSa00Jd 7.14 9Y} JASUO] 9} PU ‘Papod aq 0} PeOT/WWOjJsSUeIL \\nPdaU \\n|JIM \\nSUOMEWUOJSULI} \\nSJOW \\n34} \\n‘adods \\nay} \\nUI \\naBpNjdu! \\nNOA \\nsjUdWaJa \\nEP \\nDAOW \\nJY} \\nJEU} \\nJOQUIDLUDY \\n/PeNXI \\n“6 \\nsod \\ndajs \\nJuawdojanaqg \\nuSISag \\npeo \\n/WHOjsues] \\n/}9e1}Xq \\n76 \\ndajs \\nJUaWIdOJaAag \\n— \\nXL}eI\\\\] \\nSAUTApIND \\njedWpeId \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 509}, page_content='Practical Guidelines Matrix 476 \\nSSS \\nSSS \\nss \\n‘paja|dwod \\nsey \\npeo] \\nay} \\nJaye \\nWay} \\n3}e31991 \\npue \\n‘a[9AD \\npeo] \\n7.14 \\nay} \\nSuunp \\nsadipul \\nje \\ndoug \\n« _sulpuad \\nyD9YD, \\nUl! \\n$9/Ge} \\nJO} \\nYOOT \\n‘SUO}LJOIA \\nAYSIU! \\n[e}USs2Ja1 \\nPUL \\n0} \\nSWC \\naU} \\nMO|je \\n0} \\npaia|dwiod \\nsey \\npeo] \\nay} \\nJaye \\nUO \\n¥Deq \\n}! \\nUN} \\npue \\n‘ajDAD \\npeo] \\n7LJ \\n9Y} \\nBSuLNpP \\nAyUSajul \\n[eUJAJo1 \\nHO \\nWNL \\n« \\n‘aseajas \\nUONedI|dde \\n|g \\nay} \\njo \\nAlantjap \\ndn \\npaads \\npue \\npoafoid \\n24} \\nJO \\nadOds \\naU} \\nBdNPad \\n|[IM \\nJEUL \\n‘BSeajad \\n}XaU \\nay} \\n[JUN \\nSsad04d \\npeo] \\n|ed0}sIy \\naU} \\nSuIp|Ing \\nauodysod \\n0} \\nAuy \\n‘uoyedidde \\n|g \\nay} \\nJo \\nUOHe}UaWa|du! \\njeu! \\nay} \\nYM \\npauinbas \\nyou \\nsi \\nA1ojsIY \\nysed \\nSuipeoy \\nJ] \\n« \\n‘saseqejep \\nad1NOS \\nPUE \\nSajlJ \\nDINOS \\nBY} \\nJO \\nBWOS \\nJo \\nANO\\\\sIY \\n24} \\nMOU \\nOYM \\npue \\nsJeak \\nAuew \\n10} \\npunose \\nUsag \\naAeYy \\nOUM \\nSiaWWes1BO1d \\n10} \\nYOO] \\n‘a[doad \\nssauisnqg \\n2Y} \\nO} \\nJJASANOA \\nHUI] \\nJOU \\nOG \\n“e}ep \\nadiNOs \\nay} \\nJo \\nA10}SIY \\nPUL \\nUIBZLO \\nay} \\npueyssapuN \\nOYM \\najdoad \\nSulpuy, \\nS| \\nSUOHeIYIDads \\nSulsuea|d \\nPU \\nUONEWUOJSUL} \\n90 \\nBY} \\nSUJUIWA}ap \\nU! \\naSua|[eyd \\nIsaSBig \\naul \\n« ‘son \\nAyi3aju! \\nyep \\nSsauisng \\npue \\nsajni \\nUleWOP \\ne}ep \\nssaulsng \\nadJOjuUa \\nOS]e \\nPjnoUs \\nsUONeWOJsUeI] \\n“sadINOS \\nJUDJIJJIP \\nWO14 \\nL}EP \\nILLS \\nUY} \\nJO \\nSUOISSAIAXA \\nJUDJIJJIP \\nB[IDUOIA \\nPINOYS \\nSUOI}EWIOJSUEJ} \\n‘LUNWIUIW \\ne IY \\n« \\n‘MUO \\npuadap \\nAewW \\naAeiU! \\n|g \\nINOA \\nJo \\nssaddns \\nSUL \\n‘Sassad0id \\n1LJ \\nay} \\nSulUsIsap \\n410} \\nBWI} \\nYSNOUa \\na}edO]/e \\n0} \\nJINs \\nag \\n‘UOHedI|dde \\nyoddns-uolsiDap \\nId \\nAue \\njo \\nssad0id \\npayed||dw0d \\n}SOW \\nay} \\nSI \\n}] \\n(WUOJSULI}) \\n, 1, \\n9} \\nUl \\nS| \\nYOM \\n7LJ \\nJO \\nJUadIAd \\nEg \\nINoOgy \\n+ \\neee \\nSSS \\nSSS \\nquiny, \\nfo \\nsajny \\npup \\nsdip \\nEEN \\nSSS \\nSSS \\nUsISaq \\nPeOT/UOJsUueL \\n/}9e1}Xq \\n:6 \\nda}s \\nUaUdojanaqg \\n= — \\nxL}eJ \\nSaUTapiINy \\njesNDeAd \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 510}, page_content='477 Meta Data Repository Design ° \\n° Development Step 10 \\n‘uolnjos \\nAuoysodas \\neyep \\neyowW \\ne Bululeysns \\nJO} \\nJUeYOUUI \\nSI \\nAy]Iqe}s \\nJOPUaA \\n‘s}NpOJd \\n41a} \\nO} \\nUOIIPPe \\nU! \\nSIOPUSA \\nJY} \\nBJENJEAD \\nO} \\n39310} \\n},U0Q \\n« \\n‘sjuawauinbal \\nejep \\neyaw \\nAiojppupw \\nANOKA \\nAysiyes \\nJOU \\nOp \\n}eU} \\ns}Npold \\nAloysodai \\ne}ep \\ne}atW \\nAUe \\nJaPISUOD \\nUDA2 \\n},UO0Q \\n« \\n\"SdI}SI}E}S \\nPO] \\nPue \\n‘sje}O} \\nUO!LIINUOIII \\n‘s10}e} \\nAyigeljas \\neyep \\nse \\nUdNs \\n‘sda \\nSuLN}ded \\n10} \\nS}JUBUOGWIOD \\ne}YEP \\nL}ALU \\nAPNIIUI! \\nO} \\n39310} \\n},U0Q \\n«+ \\n‘ssad0jd \\naAISUaIUI-JOGe] \\n& \\nSI \\nAjjenuew \\ne}ep \\nea \\nJO \\nsadA} \\nOM} \\nasoU} \\n(BuUN}eJa1) \\nSUNUTIT \\n‘eyep \\nEOL \\nJEDIUUD} \\nJU} \\nUM \\n}ep \\nP}JOW \\nSsauIsng \\ndy} \\nSU!AU!| \\nJO \\nSSad01d \\nUOHEIBI}U! \\nDY} \\n9JEWONL \\nO} \\n|Ie} \\n},UOG \\n« \\n‘QDUO \\n}e \\nSdIN}ed} \\nJU} \\nJO \\n[Je \\nJUSLUa|dWI! \\nJOU \\nAew \\nno \\ny8nou} \\nuaa \\n‘SuIlUONDUN \\nAI[N} \\n3g \\n0} \\n}] \\nUSISAp \\n‘UOINJOS \\nPaZIWO}sNd \\ne \\nSUIp|INg \\nUBUM \\n‘sal}j}Ue \\nPep \\nPJOW \\nUOWLUOD \\nSOW \\nay} \\nA[UO \\nSul|japowW \\nAq \\nusIsap \\nAJOySOdaJ \\neyep \\nEYAL \\nJY} \\nINDOUS \\n},U0q \\n« \\n$z,u0q \\n‘QJOUM \\n& \\nSe \\nJUBWUOIIAUS \\nYWOddns-uolsleap \\n|g \\nay} \\nYsnosy} \\nosje \\ning \\nAuoyisodas \\neyep \\ne}aW \\nay} \\nUSNO1Y} \\nAJUO \\nJOU \\na}eBIAeU \\nWAU} \\ndjay \\nO} \\n}! \\nasn \\n[JIM \\nOYM \\n‘ajdoad \\nSSdUISNG \\nO} \\najgGenjeaul \\nS| \\nainjzea} \\nSIUL \\n“e}EP \\nEJOW \\nJO} \\nUO!DUNY \\ndjay \\nBUI|UO \\ndAI}ISUAS-}X9}UOD \\n& \\nSPIAOJd \\n« \\n(s}joo} \\nsisAjeue \\npuke \\nssadde \\nJaY}O \\n‘sia}UM \\nOda \\n‘dW10 \\n“114 \\n‘JSWD) \\nS|00} \\nJayO \\npue \\nAJO}sodas \\ne}ep \\ne}BW \\nJY} \\nUVBMjoq \\nAde}Ja}U! \\najqesnad \\ne \\nUSISAq \\n« \\n‘spnpold \\nau} \\nynoqge \\nayl| \\n1. Uop \\nAau} \\n}eEYM \\nPue \\nOP \\n}OUUED \\ns}NpOJd \\nJOPUSA \\ndy} \\n}EYM \\nS}UAI|D \\nSIOPUDA \\ndU} \\nySY \\n‘PNpoid \\nAuoysoda \\neyep \\neyaw \\ne \\n(SulAnq) \\nSulsuad!] \\nUaYM \\nsiOpUaA \\nAq \\npaplAOsd \\nsadUaJAJoJ \\nJUAI]D \\nYM \\ndn \\nMojo \\n« \\n‘JUBI} \\nSI \\nA|NDaUDS \\nay} \\nUaYyM \\nAjjeIadsa \\n‘a1eMYOs \\nWO}sNd \\npling \\n0} \\nueY} \\nNpodd \\ne \\n|Je}SU! \\nO} \\nJa}Se} \\npuke \\nJaIsea \\naq \\nAewW \\n} \\n‘eyep \\nEJ \\nJeEDIUYII} \\nYM \\ne}ep \\neJOW \\nssouisng \\na}ye13a}u! \\n0} \\nAyyiqeded \\nay} \\navey \\nYydIymM \\n‘s~npoid \\nAyoysodad \\neyep \\nEJ \\nJJ9YS-9U}-JO \\na}enjeAq \\n« \\nuSisoq \\n‘uolsuedxa 3}e_powWwodde UeD USISap Aioysoday \\nInoK \\nains \\nag \\n‘paloid \\n|g \\nAlaAa \\nYUM \\nUBISap \\nAuopsOdad \\ne}yep \\neJaW \\nay} \\n(AUessadaU \\nJI) \\npuedxa \\npue \\nMAIAdY \\n« \\ne1eq \\nPIN \\n“OL \\nsod \\ndajs \\nJuawuidojanag \\nusisag \\nAioyisoday \\ne}eq \\nEW \\n:OL \\ndais \\n}UaWIdoOjaAVq \\n— \\nXL} \\nSAUIapPIND \\njed1eI1d \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 511}, page_content='Practical Guidelines Matrix 478 \\nsss \\n‘Auoysodas \\nB}eP \\nE}OW \\nJU} \\nO} \\nBdeJJa}U! \\n$SaIde \\nasn-O}-Asea \\nUe \\nBUIUSISap \\nUO \\nalU}} \\npuads \\n‘aJOJaJUL \\n“} \\naSN \\n0} \\nMOY \\npue \\n‘(wWa}sAs \\n334NOs) \\nWO \\nBW \\nPEP \\nBU} \\nAJBYM \\n‘JUB}UOD \\ne}ep \\nau} \\nJo \\nAyjenb \\nau} \\n‘eyep \\nay} \\njo \\nSulueaw \\n94} \\npuejsiapun \\najdoad \\nssauisng \\nsdjay \\ne}ep \\neya|\\\\| \\n‘SULIDIUYI9} \\n9U} \\nWO \\n}UaDJad \\nOL \\nInoge \\nAjuO \\npue \\najdoad \\nssauisng \\nay} \\nWoy \\naq \\n|1M \\nAsoysodai \\neyep \\ne}atU \\n34} \\n0} \\nSsadde \\nPailp \\nJo \\njUadJIad \\nQE \\nINOGYy \\n« \\n‘pudsyaJdWOd \\n0} \\nJalsea \\npue \\nyUaWaldu \\n0} \\nJalsea \\naie \\nAy! \\n‘UsISap \\npa}UaliO-a/go \\nUe \\nUY} \\nJayyes \\nUBIsap \\ndiysuo!ejas-Ayua \\nUe \\nUUM \\ne}S \\n« \\n‘UIE}UJEW \\nPUR \\nPIING \\nO} \\nNIIP \\nBAW \\n3Je \\nSUO!INIOS \\ne}eEp \\neJaW \\npajqeua-TIX \\npue \\nsavoysodai \\neyep \\ne}aW \\npaynquysip \\nasnedaq \\naseqeyep \\nAuoysodai \\ne}ep \\ne}JaW \\n[e1}UaD \\n© \\nYM \\nHe}S \\n« \\n‘us|sap \\nAioysodas \\neyep \\neal \\nO} \\najqerI|dde \\nosje \\naie \\nUSIsap \\naseqeyep \\n0} \\najgedidde \\naie \\nyey} \\nquuny} \\njo \\nsajni \\npue \\nsdiy \\nAuew \\n‘aseqeyep \\ne \\ns| \\nAsoysodas \\neyep \\neat \\nau} \\nQDUIS \\n« \\nSS \\nquiny, \\nfo \\nsajny \\npup \\nsdiy \\n— \\nSSS \\nusisaq \\nAioysoday \\ne}eq \\nPIII \\n:01 \\ndays \\nyuawidojanaq \\n~— \\nxieW \\nSIUIJAPIND \\n[ede1d \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 512}, page_content='479 \\n‘swajgold \\nAyjenb \\neyep \\nSuijenjodiad \\nploAe \\n0} \\nUOH}EZIULBIO \\ndJI}Ud \\nJY} \\nSSID \\npajuawajduil \\naq \\npinoyus \\nspiepue}js \\nAyjenb \\neyep \\njesduas \\nSWOS \\n\"}UBWUOIAUa \\nYOddns-uOIsIap \\n1g \\nJU} \\nJO} \\nE}EP \\nPeg \\nJa} \\naBSUL|]D \\n0} \\nS9XL} \\n}! \\nHOYa \\npuke \\n}SOD \\ndU} \\nJO \\nIeMe \\nSAANIAXa \\nSsauIsng \\nay} \\npue \\nSa}sAs \\njeuonesado \\nau} \\nJO \\nSIQUMO \\ndU} \\nAaYeW \\n0} \\nJOSUOdS \\nssauUIsNg \\nINOA \\nysY \\n‘passaippe \\naq \\nPinoys \\nswiajqoid \\nAyyjenb \\neyep \\nasay} \\nadnpoid \\njeu} \\nsuqey \\npeg \\npue \\nsaddeJ/d \\npjo \\n‘pueY \\nJ9Y}O \\nJY} \\nUOC \\n“AAI}IAJJa-}SOD \\nJOU \\nSI \\nWa}sAs \\nJeuolesado \\nue \\nSulAjIpow \\n‘sase>d \\nAuew \\nU| \\njA]]NJssaddns \\nUN \\n0} \\neyep \\nApp \\n4194} \\nPadxe \\nAjjenye \\nyyeys \\nswajsAs \\njeuoljesado \\naul \\n‘swayshs \\njeuoljeiado \\nay} \\nU! \\ne}EP \\nBdINOS \\ndy} \\nBSULa|D \\n0} \\nPadx— \\n},U0Q \\n« \\n‘ajdoad \\nssauisng \\nau} \\n0} \\nasn \\nOu \\nJo \\nS| \\nUOH}ed1|dde \\n|g \\nay} \\n‘e}yep \\na0 \\nYWM \\nApadoid \\npapeo|] \\n}OU \\naie \\nsaseq \\n-e}ep \\nJ9BJe} \\n|g \\nDY} \\nJ] \\n‘ASeajas \\n}X9U \\nay} \\nUI \\nSWajqoid \\nXl \\nUeD \\nNOA \\nyUIY} \\nNOA \\nasnedaq \\nBUI}S9} \\ndIyS \\nJOAON \\n« \\n‘JJ \\nJOM \\nSUN \\n}! \\n[JUN \\nLWead}s \\nGof \\na4}Ua \\nBU} \\n}S8}91 \\nPUL \\n}S9} \\nNg \\n‘daJ} \\nJoa \\naie \\nAdu} \\n[UN \\nSajNnpOwW \\n|enNpIAIpU! \\n}Sa} \\nysNf \\n},UOP \\n‘SP1OM \\nJaY}O \\nU] \\n‘Pua \\nO} \\nBulUUIsaq \\nWO4 \\npa~edxa \\nse \\nund \\nssad0J/d \\n714 \\nOU} \\nUl \\nSWeIZOJ \\n|e \\n[JUN \\npayaj|dwWod \\nSUI}S9} \\nUOISSA139J \\nJO \\nUO!|}EIB9}U! \\nJAPISUOD \\n}, UO \\n\"ssad0Jd \\n74 \\nYU} \\nSuljsa} \\nUI \\nPaAJOAU! \\nOsje \\naie \\nAa} \\nauns \\nag \\n‘uO!}ed1|dde \\n|g \\nay} \\nJO \\nUOIIOd \\nsisAjeue \\npue \\nssaa2e \\nay} \\nAjuo \\nSul}sa} \\n0} \\nHadxa \\nJayVeW \\npalqns \\nay} \\npue \\ndAl}e}UaSIJdaJ \\nSSOUISNG \\nJU} \\nHUI] \\n},UOQ \\n- \\n‘sJadOjaAaP \\nJ9Y}O \\nJO \\nBPOD \\nau} \\n}S9} \\nULD \\nAdY} \\nAABMOY \\n‘BPOD \\nUMO \\nJIaU} \\n}S9} \\nJOU \\nPjNoYs \\nSJadojanaq \\n« \\n$},U0q \\n‘jou}U0D \\nAyjenb \\n410} \\nsanbiuyra} \\nSulwuWWessO1d \\nqX \\nJO \\nSMAIAdJ \\nJaad \\nasf \\n- \\n“eye \\n[edi \\nYUM \\nSd} \\n(SS9J}S) \\nSDUPLUOJJOd \\njenyoe \\nue \\nSulUUN \\ndJOJag \\nSJaqUINU \\nBdUeWWOJJad \\npa}eWI}Sa \\nPalosd \\n0} \\nJOO} \\nUO!L|NUIS \\nSa} \\nSSAJ}S \\nB \\nBS \\n« \\n‘S}[NSOJ \\n}S9} \\npayadxa \\npuke \\nsased \\n}S9} \\nJY} \\nSUM \\nUl] \\ndAe}UVSaIdad \\nSSAUISNG \\nJU} \\nAJOAU| \\n« \\n‘S[NSOJ \\n1S9} \\npayadxa \\npue \\n‘sased \\n}sa} \\n‘Sued \\nJS} \\nJELLO} \\nYUM \\nBUI}S3} \\nSNOJOSL \\nWHO}Jad \\n« \\n‘UO \\nOS \\nPUP \\n‘SUOLIOIA \\nSajNI \\nSSaUISNg \\nJO \\nJaqUINU \\n‘SUOHEOIA \\nUJELUOP \\nJO \\nJaquunu \\n‘sanjeA \\nBuUISSIW \\nJo \\nJaquunuU \\nse \\nYoNs \\n‘pazUO08a}ed \\n9q \\nPinoys \\nSiO \\n‘paydadse \\nsem \\njnq \\nsajNJ \\nUps \\nay} \\npayies \\nJey} \\nEJP \\nIDINOS \\nJO} \\nse \\n[JOM \\nSe \\n‘papafas \\nsem \\npue \\nSajnJ \\npa \\nau} \\npayies \\nJY} \\nEJEP \\n9diNOs \\nJO} \\nSUUNOIIE \\nJOUa \\nPajlejap \\n& \\nIINPOJd \\nExtract/Transform/Load Development \\nbe \\n‘aj[aAd \\npeoy \\nAuaAa \\n10} \\nAuoyisodas \\ne}yep \\n&}aW \\nBU} \\nUl \\nPIJO}S \\n9q \\npynoys \\n= \\ns]2}0} \\nISIUL \\n*S}UNOD \\nJUNOWE \\npue \\n‘s}UNOD \\nUIELWOP \\n‘S}UNOD \\nP1ODII \\nJOJ \\nS]L}O} \\nUOHLIIDUOIAI \\nBDNPOld \\n« \\ng \"SJUBIU JEJIAVS JBAO SSAD0Id 79 ANOA UNI jUalUdojarneq \\n= \\n0} \\npaledaid \\naq \\n‘(Wysiu \\nJad \\nsinoy \\nmaj \\ne \\nAjUO \\nUayo) \\nWoOUs \\nAJaA \\nSI \\nSUOI}EZIULBIO \\n931e] \\nJSOW \\nJe \\nMOPUIM \\npeo \\ny/WWOjsueLL \\n= \\nSulSeys \\n7.LJ \\nau} \\naduls \\n“@wWIUNI \\nUO \\nUMOP \\n3nd \\nO} \\najqissod \\nse \\njayjesed \\nul \\nswuesso1d \\n714 \\nAuew \\nse \\nuny \\n« \\n/PeXA \\n‘LL \\na. \\n2 \\nsod \\ndajs \\n}uauidojanaq \\na Q \\njUaWdojanag \\npeo \\nT/ULOJsueIL/}Ie1}XZ \\n211 \\ndays \\n}uawdojansq \\n— \\nXU} \\nSaUTapINny \\n[ede \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 513}, page_content='Practical Guidelines Matrix 480 \\nssn \\n‘uo}}e}UdWa|duwII \\nSuLnp \\nsasege}zep \\n39812} \\n|g \\n34} \\nBuIpeo| \\nUaYM \\npue \\n‘jUaWdoOjanap \\n719 \\n‘WUaWdojanap \\nuoljed1|dde \\n‘SuldAyoyoud \\nSuunp \\nAjaAdea/ \\npasaaodsip \\naie \\nAauL \\n‘siskjeue \\nAuoyisodai \\neyep \\nejow \\npue \\n‘sisAjeue \\neyep \\n‘Suvaujes \\nsjuawasinbas \\nSuunp \\nAjaaqoeasd \\npasanonsip \\nAjjensn \\nase \\nsajni \\neyep \\nadunos \\n“OWI} \\njO \\npeaye \\npawuoyiad \\ns| \\nsisAjeue \\ne}ep \\naduNOs \\naAIsUa}xXa \\nJ] \\nSWa|qosd \\nJama} \\nOF! \\nUNL \\n[JIM \\nssad0J/d \\nLJ \\naU \\n« \\n‘pazijiqN \\naq \\nUD \\n[O0} \\nLA \\n94} \\n0Jaq \\npauuoyiad \\naq \\njsnw \\npuke \\nYOYa \\njenuew \\ne \\n|INNS \\nS| \\nSWYWOS|e \\nSulsueas-eyep \\nSunuM \\nyeu} \\n9}0U \\n“BAVMOH \\n‘AljenueW \\nsUOP \\nUBYM \\nSANOY \\nUeY} \\nJay}e4 \\n‘SA}NUIW \\nUI \\nSUOE|SUL. \\naPOD \\nPUe \\nSUOISIaAUOD \\nyysua| \\npue \\nadA} \\neyep \\nWOPad \\nUeD \\nS[00} \\n1LJ \\n‘suleLUOp \\ne}ep \\nazAjeUe \\n0} \\nSaye} \\n1 \\nALI} \\nay} \\nUa}OUS \\nAjUeIYIUSIS \\nUBD \\nS|OO} \\nBul|jo1d-eyeq \\nEUOFEWUOJSULJ} \\nBYE \\n104 \\nS[OO} \\naLeEMYOS \\npa}ewo \\nne \\nasn \\nAUM \\n« \\n‘SSuUJUBAW \\nJUdJaYIP \\nUBZOp \\ne Jey \\nadcey \\nAjd1Jdu! \\nUeD \\nJO \\nsatu \\nUaZOP \\nPB \\nJJeY \\nPauyapal \\naq \\nAj}!d1]dxe \\nUBD \\n}UBW]a \\nYP \\nBUO \\nJJaYyM \\n‘Sajij \\nJe \\nPjO \\nUI! \\nAjjeIdadsa \\n‘syuawaya \\nB}LP \\nJO \\nBSMIBAO \\nPUP \\nSalDUA}SISUODU! \\nyep \\nase \\ne}ep \\nadInOs \\nAyIp \\nJo \\nsWO}dWAS \\nUOWWWOD \\nJSOW \\ndU \\n« \\n‘Sa|Nd \\nUOISIBAUOD \\n2}ep \\n/Pd|UYI9} \\nUO \\nyUAds \\nS| \\nYOY \\na4} \\nJO \\nJUaDIAd \\nQZ \\nInoge \\nAjuO \\npue \\n‘sajns \\nAyZazuI \\neyYep \\nssauIsng \\npue \\nSa[Md \\nUJEWOP \\ne}ep \\nssaulsng \\nSuld10juUa \\nUO \\njUAdS \\nSI \\nYOY \\nUOHEWUOJSUe.} \\ne}eP \\nay} \\nJO \\nJUadIad \\nCg \\nINogyY \\n« \\n‘spaou \\nUONEWUOJU! \\nBY} \\nJO \\nJUdIIAd \\nOB \\nanjos \\nAew \\nejep \\nasiidiajUa \\n3Y} \\nJO \\nJUadIad \\nQZ \\nSulsuea|> \\naduIs \\nsayyeq \\nJnoA \\nasooy) \\nuay} \\npue \\n‘azioud \\n‘ezAjeuy \\n‘ssad0id \\nanjsuadxa \\npuke \\naAlsuazUl-dUUI}} \\n& \\nS| \\ne}ep \\nBuUIsUuea]D \\n« \\n\"e}Lp \\npOOs \\nOjUu! \\ne}ep \\npeg \\nIN} \\nAjjed/SewW \\nJouUeD \\nAau} \\n‘swWia}sAs \\n|eUOHe1ado \\n3U} \\nUl \\nswa|qgold \\nAyjenb \\neyep \\n40 \\n}Ua}Xa \\nay} \\nSulssasse \\nYIM \\ndjay \\nued \\nsjoo} \\nYSnouyy \\n‘Sulsuea|> \\ne}eP \\nSAISUSUI \\n-10ge| \\nSUIPNIDU! \\n‘SHOYa \\nPud-ydeq \\n0} \\nAW} \\nPafoud \\n|g \\naU} \\nJO \\nJUadIAad \\nQE \\n0} \\nQSO[D \\nJJOAIP \\nSUOI}EZIULBIO \\n- \\nEE \\nEn \\nSSS \\nSSS \\nSSS \\nquiny, \\nfo \\nsajny \\npup \\nsdit \\n—— \\nSSS \\nSSS \\njUaWIdoOjanaq \\npeo \\nT/WHOJsueIL \\n/~eNX \\n:L \\n1 dajsyuauidojanaqg \\n— \\nXLJeW \\nSaujapiny \\njes \\nWde1dg \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 514}, page_content='481 Development ication Appl Development Step 12 \\n‘uononpoid \\nul \\naqua} \\npue \\njUawdojaAap \\nSuuNp \\nSulpuej}s}no \\ns}| \\nsuUeWWOpad \\n‘yNSoJ \\nesy \\n,jJaseaw, \\nAlaA \\nase \\nSaUIyDeW \\nUOHNpoOJd \\nay} \\nIng \\n‘sadinosad \\nUl \\n,YOU, \\nAJaA \\nS| \\nWUOyje|d \\nJUDWUdOJaAap \\nau} \\n‘Suoneziuesio \\nAuew \\nuy] \\n‘swuosjeyd \\nyuawidojanap \\npue \\nuo|pNpold \\nyUaJayIp \\nAjajajdwio0d \\nSUIAeY \\nPIOAY \\n« \\n‘uolpnpodd \\nou! \\nUOedI|dde \\n|g \\nau} \\nSUIAOWW \\nal0jaq \\nUsIsap \\nANOA \\nysn[pe \\n0} \\nJapio \\nUl \\nAiea \\nsuOHeYLWI] \\nBSOU} \\nPuy \\n}snwW \\nNOA \\npue \\n‘sUONe}WI] \\n1!9U} \\ndAPY \\nS|OO} \\nd¥10 \\n‘UOHedI|dde \\n|g \\nay} \\nJO \\ns}UaUOdWIOD \\nsishjeUe \\nPUL \\nSSAdIP \\nJU} \\n}S9} \\nSSA1}S \\nO} \\n}9310J \\n},U0Q \\n« \\n‘ued \\nno \\nasnedagq \\njsnf \\n(DeJ) \\nOle1 \\npue \\nUOEYNdWOD \\najqissod \\nAjaAa \\nJJ1O}s \\n0} \\nULI \\n1,U0Q \\n- \\n‘Sauianb \\npue \\nsoda \\nuns \\n0} \\naye} \\n[IM \\n} \\nJaSUO] \\nBU} \\npuke \\n‘UNL \\n[JIM \\nSSad0Jd \\n7LJ \\nBY} \\nJABUO] \\nBY} \\n‘sPe} \\nBY} \\n9}e]NDJeIII1d \\n0} \\n9ye} \\n|IIM \\n}] \\nJASUO] \\ndU} \\n‘SDe} \\nJU} \\nJeE|NUeIS \\nBIOW \\ndU} \\n‘Aseqeyep \\nau} \\nJasBIq \\nay} \\n‘aAeY \\nNOA \\nsuOISUSLUIP \\nBJOLWW \\nJU} \\n}EY} \\nPUIW \\nUl \\ndaay \\n‘Auanb \\njeuoisuawipnjnw \\najqealaduod \\nAlana \\nAysiyes \\n0} \\nUOISUALUIP \\na}qissod \\nAJaA9 \\nYUM \\nUe}s \\n1,U0Q \\n» \\ns7,u0qd \\n‘(dV10) \\nsisfjeue \\n_AUM, \\nau} \\n0} \\n(Suodas \\npue \\nAuanb) \\nsisAjeue \\n,JeYM, \\ndU} \\nWOJJ \\nSe \\nUNS \\n‘sasAjeue \\nJO \\nSadA} \\n}UDAJJIP \\nJO} \\nS|00} \\nUJ9MjJoq \\nUMS \\n0} \\nBAeY \\nJOU \\nPinoys \\nUOSJad \\nssauisng \\nY \\nJOO} \\nUO \\nYUM \\npo}UdWe|dwI \\n39g \\nued \\npue \\nDANEJI \\nPUL \\n‘BAIPEJOJU! \\n‘Pa}yejauayu! \\naie \\nsisAjeue \\npue \\n“Bulodas \\n‘BulAiandy \\n‘sisAjeue \\nJEUO|SUdWWIPI}|NW \\nJO} \\nsaniqeded \\nsiskjeue \\npue \\n‘Suiodas \\n‘BuiAanb \\nsaulquiod \\nyey} \\nayins \\nyNpodd \\ne \\nSulpDajas \\nJapISUOD \\n« \\n100} \\nAlanb \\nJ9U}OUL \\nJO \\n‘}O0} \\ndY1O0 \\nUe \\n‘Ja}UM \\nOda \\ne \\nSIH \\nJaYJOYM \\n100} \\nsISAJeue \\nPUL \\nSSaDIE \\nLDA \\nJO \\nSASS9UHLIM \\nPUL \\nSY}SUII}S \\nJY} \\nJ}LIIUNWWLUOD \\nPUL \\nJUILUJI}IQ \\n«+ \\n‘Saunjeo} \\nppe \\npue \\ndiN}EW \\nSOO} \\nse \\nyUeVOdUI! \\nssa] \\nBWIOD9q \\nBAeY \\n(uonezipsepue}s \\n[dV \\n‘Ayjiqejeds \\npue \\nsualueg \\nazis \\n‘saydeoidde \\nSulxapu! \\n‘ajdwexa \\n10J) \\nsassauyeam \\npue \\nsyu}suals \\ndV10 \\na}eauljap \\nAjea}d \\n0} \\npasn \\nyey} \\nSainyeay \\nBUL \\n“JaYIO \\nYea \\nBOAdea| \\nsoinjeay \\npue \\nSjOO} \\nMAU \\nPue \\n‘Aj}UL}SUOD \\nBUIAJOAS \\naJe \\nS]OO} \\nPUL \\nSPJEPUE}S \\n“S}OO} \\n|g \\n}SA}E] \\nJY} \\nJO \\nSeaIge \\ndaay \\n- \\n‘pajO}S \\n3q \\npjnoys \\neyep \\nau} \\nYDIIUM \\nUl \\nPLUBUIS \\nJU} \\nSUSP \\nSOO} \\nBU} \\nJO \\nS}UBWA4INbad \\ndU} \\nJa] \\n‘Puy \\n‘peAO|dap \\naq \\n0} \\nSjOO} \\nJO \\nBd10YD \\ndy} \\njUdWdojsAeq \\nJAUP \\nSpaau \\nSisAjeue \\n1d} \\n397 \\n“WUOJJad \\n||IM \\nAau} \\nSasAjeue \\nJo \\nsad} \\n}eEYM \\nUap \\najdoad \\nssaulsng \\ndu} \\njo \\n« \\nuonerddy \\n‘71 \\nsod dajs juauidojanaq \\nyusudojanag \\nuoHed|ddy \\n:71 \\nda}s \\nJUaWdojaAsq \\n— \\nXL}eIA \\nSAUTJapINyD \\nJeIDe1d \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 515}, page_content='Practical Guidelines Matrix 482 \\n\"Yt \\nayejndiuew \\npue \\nPJEP \\nABU} \\n10} \\nYOO] \\nWAU} \\nJO] \\n0} \\nWUOJ}eId \\n[NJamod \\ne \\npaau \\nAay} \\nOs \\n‘pjos \\nayl4}s \\nAdy} \\na1ojaq \\nsaul \\nAuew \\nSIp \\nAayjJ—SiauIW \\npjos \\nay] \\nase \\nsauanb \\nxajdwod \\nBuljndexe \\ns}sAjeue \\nssauisng \\npue \\nSiayJOM \\naSpa|Mouy \\n« “SQUuI}NOJ \\nasay} \\nAysizes \\n0} \\nsajqe} \\nplingaid \\n‘asueWWOJJad \\nJa}aq \\n393 \\n0} \\nJaPsO \\nUT \\n‘sIseq \\n4ejNZai \\ne \\nUO \\nSdolDd \\nsau} \\nysaMiey \\nAay}—SsdUUe} \\ndy] \\na1e \\nSaanb \\najdwis \\nBuyjndaxa \\ns}sAjeue \\nssauisng \\npue \\nsiayJOM \\naSpajmouy \\n*xa]dwiod \\nase \\nsyodal \\nau} \\nJo \\nJUadJed \\nOg \\nInogy \\n— \\n‘ajduuis \\nase \\nsodas \\nay} \\nJo \\nyUadJad \\nOZ \\njnogy \\n— \\n‘sauianb \\n10} \\neu} \\nJO \\nayisoddo \\nay} \\nAljeiauas \\nSI \\nSasegejzep \\nja81e} \\n|g \\nay} \\nJsUlese \\nUNI \\nSOdaL \\nJo \\nAyxa]dWOd \\nay} \\njo \\nUMOpyealGg \\naUL \\n*x9]dwod \\nase \\nsauanb \\nau} \\nJo \\nJUuadJed \\nQZ \\nnogGy \\n— \\n‘ajduiis \\naie \\nsalianb \\nay} \\nJo \\nyUadJad \\nOg \\njnogy \\n— \\n“SMO]|O} \\nSe \\nUMOP \\nSyealq \\nAjJeJ9Uas \\nSasege}ep \\n39312} \\n|g \\nAY} \\nsSUJese \\nUNI \\nSaLanb \\nJo \\nAyixajdwod \\naus \\n‘sauanb \\nxa]dwod \\n410} \\nuaAa \\n‘adUeWUOJJad \\najqouospas \\nyadxe \\nAauL \\n“Suixapul \\nJUIIIIJJOU! \\nJO \\nBSNEI9q \\nJO \\nS3]/qe} \\nBY} \\nJO \\nSAZIS \\nJY} \\nJO \\nasNedaq \\naU} \\nasuOodsa \\nU! \\nAejap \\nau} \\njnoge \\nSulmouy \\nUl \\npa}saJ9}U! \\nJOU \\nJe \\najdoad \\nssaulsng \\n‘spuodas \\ng \\nUe} \\nssa] \\nU! \\nUNI \\n0} \\najqe \\naq \\npjnous \\nAuanb \\najduuis \\nV \\n‘sishjeue \\nSUIDIP-PUe-ZUIDI|S \\n10} \\n$}De} \\npayejndjeda1d \\nasn \\npue \\naiojs \\n‘aouUeWOJad \\naziWNdo \\n0} \\nJapsoO \\nU| \\n‘pasn \\nSUOISUALUIP \\nJO \\nJOqUINU \\nLUNWIXEW \\n3} \\naq \\nPinoys \\nUdAasS \\n— \\n‘AJBAIAYS \\nVSN \\n0} \\npue \\npUdsyaJCWOD \\n0} \\nYNDIJJIP \\nJS \\nSUOISUdIP \\nXIS \\npuke \\ndAI4— \\n‘(UOISUBWIP \\nSWI} \\nBU} \\nAjjensn \\nsi \\nUOIsuaWIP \\nYYNOJ \\nay}) \\nUO|sUdaYyasdWOD \\n40} \\nad149eI/d \\npue \\nSuJUIes} \\nasINbad \\nSUOISUdLUIP \\n1NO4 \\n— \\n‘padseis \\nAjisea \\naie \\nSUOISUALUIP \\n3aJU} \\nJO \\nOMI \\n— \\n“BUIDIP \\nUe \\nBUIDI|s \\n10} \\nasn \\nAJUOWWOD \\najdoad \\nssaulsng \\nay} \\nsuoIsuaWIp \\nAuew \\nMoy \\nyno \\nPUI \\ne \\nNeen \\nSS \\nSSS) \\nquiny, \\nfo \\nsajny \\npup \\nsdip \\nEEE \\nnn \\nnnn \\nnnn \\nnn \\nnn \\nnnn \\nnner \\nSSS \\nSSS \\njuauidojanaq \\nuoneriddy \\n:71 \\ndais \\njuawidojanaq \\n— \\nxije,W \\nsauljapin5 \\njed1e1g \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 516}, page_content='483 \\n“SNOWJOUS \\n3g \\nPINOM \\nswWa}sAs \\n[eUOI}eJadO \\n3U} \\nUO \\nedu! \\nadUeUUOJJed \\naU, \\n‘sasegeyep \\njeuOHesodo \\npure \\nsayy \\neuOesado \\njsulese \\nAyposIp \\nBulut \\nyep \\nUNI \\n},UOG \\n« \\n‘ZuIUILU \\ne}ep \\n10} \\ndiNOs \\najqeyns \\ne \\naq \\n|jIM \\naseqeyep \\njosie} \\n|g \\nAlaAa \\nJe} \\naLUNSSe \\n},UOp \\n‘OS|y \\n“SUIUILU \\neyep \\nJUIWa|dwI \\n0} \\nJapsO \\nUl \\nJUaWUOJIAUa \\nYOddns-uoIsIap \\njg \\n& \\naAey \\nysNW \\nNOA \\n}eU} \\nolUNSSe \\n},UOG \\n«+ \\n‘sase}ueApe \\njead \\nAue \\nJa}J{0 \\nJOU \\nSaOp \\nBUIUILU \\nyep \\n}eU} \\nAeS \\nOYM \\nSJOPUDA \\nBJEMYOS \\ndAdI|9q \\n},UO0 \\n« \\n‘QuISUA \\nJedIAjeUue \\ndU} \\naq \\n0} \\nySAJeUe \\nSsaUISNg \\nau} \\nauInbas \\nyey} \\ns}oo} \\nAuanb \\nysnf \\naie \\nsjOo} \\n1194} \\nUUM \\n‘spnpodd \\nslau} \\nUl \\nSalyigedes \\nSululwW \\neyep \\naAey \\nO} \\nWIL]D \\nOYUM \\nSIOPUDA \\naeEMYOS \\nAq \\nPa|OO} \\n}o8 \\n},U0d \\n+ \\n‘SUIUILU \\nBYep \\naZIII}N \\nOsje \\nULD \\nSadINOSaJ \\nURLUNY \\npue \\n‘BuUl||Ig \\n‘UOH}sINbde \\n‘SULINPEJNUeW \\n‘YSU \\nHpasd \\n‘}JaUaq \\nUD \\n}eY} \\nS}JUaLUJed~ap \\nAjUO \\nBy} \\nOU \\nade \\nSuNayJeW \\npue \\nsajes \\n‘SuIUILU \\neyep \\nJO} \\nSUOed1|dde \\njeUa}0d \\njeUOppe \\nPUY \\n0} \\ns}UaWUPEdap \\nJ8Y}O \\nYUM \\nYOM \\n0} \\n}93J10} \\n1,UOG \\n« \\nsz,uoq \\n‘suoieyadxa \\ninoA \\nuo \\nspuadap \\nuolDeRYsI}es \\nINOA \\nyey} \\nUMOUY \\nA[UOWUWOD \\nSI \\n}] \\n‘}UaWUIOddesIp \\nul \\nynsai \\nAew \\nYsiy \\n00} \\nsuonepadxa \\nSuljas \\n‘suoHepadxa \\ndI}sI}e91 \\nUM \\nSOY \\nSuUIUILU \\ne}epP \\nJY} \\nVe}S \\n- ‘s}[NSoJ SUIUIW eyep JosdJoyUI \\n0} \\npunoJsypeg \\nJedijsi}e}s \\ne \\nSouINba \\n} \\n‘YNDWIP \\nSI \\nSuJUIW \\ne}eq \\n“s}NSei \\nSujUIW \\neyep \\ndy} \\nJosdJayUl \\ndjay \\n0} \\npue \\nJUaWUOAUa \\nSuUlUIW \\ne}ep \\nINOA \\ndn \\njas \\ndjay \\n0} \\nSulu \\ne}ep \\nUl \\nBuUIZI}eIDads \\ns}UeL}NSUOD \\ndJIH \\n- \\n‘spnpold \\n419} \\nUl \\npasn \\nsi \\nJaAV}EUM \\nPJEMO} \\nPaseiq \\naq \\n|JIM \\nJSOW \\n‘SpOUJoW \\nPUL \\nSaNbiUYII} \\nSUIUIW \\ne}ep \\nJO \\nasUeL \\n|[NJ \\nC JBJJO \\nSIOPUBA \\nMa} \\nBDUIS \\n‘9DUdBII|O}U! \\njelouiwe \\npue \\n‘sdijsi}e}s \\npadueApe \\n‘sd1IVeEWUaUJeW \\npalj|dde \\njavg]-ysiy \\nsAojdwia \\npue \\nsaydeoidde \\nSNOLILA \\nSA¥e} \\nJS} \\nASOJOUYII} \\nSUL \\n“S}UL}NSUOD \\nBULIY \\n10 \\nS~NpoOJd \\nBuldaI]as \\nB1OJaq \\nSpOYy}OW \\npue \\nsanbiuyde} \\nAlaAODsIp \\naspajmouy \\npue \\nBUIUIW \\neyep \\nBulydIeISa/ \\nWOJa \\npue \\nBWI} \\naWOs \\npuads \\n- \\n‘Yoys \\nSulullW \\neyep \\nau} \\nUOIdWeYD \\nAew \\npue \\nBUIUILU \\ne}ep \\nJO \\naNjeA \\nssaulsng \\nau} \\npue}ssapuN \\n0} \\nSdnods \\nAjo» \\nJSOW \\nJU} \\naie \\nsdnois \\nasayL \\nABojOUYIE} \\nBuus \\ne}ep \\nUl \\nSULIG \\n0} \\nSdnNOJS \\nSuNoyJEW \\nJO \\nSajes \\nYUM \\nYOM \\n« \\n‘SaepUNO \\nJEUO!}UN} \\nSSOIDE \\nPa}yepl|OSUOD \\npUe \\nPasuea])d \\nUdeq \\nSEY \\ne}ep \\nBJ9YM \\nadejd \\nAjuo \\nay} \\napiaoid \\nAjjensn \\nsaseqeyzep \\njasJe} \\n|g \\n‘Saseqejyep \\npue \\nsajlj \\n|eUOH}eJ9do \\nWO \\ne}ep \\nasn \\nining Data Mi Development Step 13 \\nued \\nSuluiW \\ne}yep \\nUSNOUYY \\n‘}UaWUOIIAUS \\nYOddns-uOIs|dap \\n|g \\nJY} \\nOJU! \\nSUIUILW \\neyep \\n39}eJOdJOIUI! \\n0} \\nUR]d \\n+ \\nSUIUI \\nb}eq \\n“EL \\nsod \\ndajs \\njuauidojanaqg \\nSUIUI \\ne}eq \\n:€L \\ndas \\n}UaWdOjanag \\n— \\nXL}eIA \\nSaUIjapINyD \\n[edDe1d \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 517}, page_content='Practical Guidelines Matrix 484 \\n‘SHOYs \\nSUIUIWW \\ne}ep \\nay} \\njnoUyWM \\nAjjeinyeu \\npaindd0 \\naAey \\npjnom \\nsaSueud \\nasau} \\nUBUM \\npue \\nSHOJa \\nSUJUILU \\nB}eP \\nJY} \\n0} \\nSASULYD \\nBsay} \\naynqUye \\n0} \\nUUM \\nMOUY \\n0} \\nSuISua||eUp \\nSI \\n1 \\nUAaAIMOH \\n‘SHOJo \\nSUIUIW \\ne}ep \\nJO \\nyJNSaJ \\n& \\nSe \\npauinbde \\naq \\npinous \\nsJaWOIsND \\nMAN \\n— \\n‘SHOHa \\nSUIUIW \\ne}ep \\nJo \\nyNSaJ \\ne \\nSe \\npadnpai \\naq \\npjnous \\ns}sod \\nSunayeW \\n— \\n‘BUIUILW \\nBJP \\nYSNOJY} \\npadi}OU \\nUdag \\n}0U \\npey \\nUayed \\nUO!IIJap \\nPB JI \\nY9] \\nACY \\nP|NOM \\nSJBWO}sNd \\naSaUL \\n‘PaulejaJ \\n9g \\nP|NOYS \\nSJ@WO}SND \\nJO \\nasejUadJad \\naZse] \\ny \\n— \\n‘SHOYs \\nSUIUIWW \\ne}ep \\nJo \\nyINSaJ \\ne \\nse \\npadUeYyUd \\nJO \\npalqeua \\naq \\npjnous \\nSuljjas-ssolD \\n— \\n“AWAD \\nay} \\nApysnl-}sod \\n0} \\nJaps \\nUl \\npezijeed \\naq \\npinoys \\nsaiuNyoddo \\nSujayeW \\nSUIMOj|OJ \\ndU} \\nJO \\nB10 \\nJO \\nBUO \\n‘BuIUIW \\nyep \\nSuIsn \\nUayM \\n‘eyep \\njo \\nsajdwes \\na81e] \\nAlaa \\nBulsn \\nAq \\nAjjed1pouad \\npausijqeyse \\nale \\nsdysye}s \\nAuysnpu \\n‘siseq \\nsejndaJ \\ne \\nUO \\nsdIIsHe}s \\nANJsNpUl \\nYM \\nS}Nse4 \\nSuluIW \\neyep \\nANOA \\nauedwo7 \\n‘sanjen \\nAjay] \\nSOW, \\nYM \\nSaNjeA \\nSUISSIL \\nBY} \\ndde/daJ \\n10 \\nsa|qeUeA \\ndy} \\na}CUILUI]a \\nJayya \\n‘sanjeA \\nSuissiw \\naAey \\njeu} \\nSojgelieA \\npuy \\nNoA \\n4] \\n‘aAHepUeNb \\nJO \\naneyjenb \\n‘SnonuNuUod \\nJO \\n3}a1DSIP \\naq \\nPjNod \\nsajqeueA \\n‘Sajqelen \\nay} \\nSulAysse|> \\nAq \\neyep \\nay} \\nasedaid \\n0} \\naAey \\nnOA \\njapow \\neyep \\njed13Ajeue \\nue \\nSulpjing \\naiojag \\n‘synsai \\nSulullW \\neyep \\nANOK \\nYO \\nMOJU} \\nPjnod \\neyep \\nSiy} \\nBUISH \\n‘Sioa \\npUe \\n‘SaIDUAa}sISUODUI \\n‘sayedi|dnp \\n40 \\n|[N} \\nUayo \\nS| \\neyep \\njeuoHesiadoO \\n‘BuluW \\ne}ep \\nJO} \\neyep \\njeUONeJado \\nSuisn \\nJo \\naiemag \\n« \\nquiny, \\nfo \\nsajny \\npup \\nsdip \\nSUIUIN \\ne}eq \\n:€1 \\ndays \\nyuaWdojanaq \\n— \\nXLRI \\nsauljapiny \\njerNDe1d \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 518}, page_content='485 Meta Data Repository Development Development Step 14 \\npa}eUlsO \\nsI \\neyep \\nJDL \\nJJBYM \\nSjOO} \\nay} \\npue \\nAuopsodad \\ne}ep \\neJaW \\nJY} \\nUB9Mjoqg \\nPep \\nPOW \\nSULEYS \\nJOJ \\nBde}a}U! \\n|OOL \\n— \\nSUEIDIUUD9} \\nPuke \\najdoad \\nssaulsng \\n410} \\nadepa}U! \\nSSaddV \\n— \\n-sadepiaqul \\nAuousodai \\neyep \\neyawW \\nJo \\nsadA} \\nom} \\ndojanap \\n0} \\npaiedaid \\nag \\n- \\n(SUO}DUN} \\nMAU \\nJU} \\nJOJ \\nS]2}O} \\nUO!PEIINUOII \\nPue \\nSUOH}EINI|ed \\n‘gj}dwiexa \\n10}) \\nA10}!sodai \\neyep \\ne}aW \\nJU} \\nO} \\nPappe \\nSs! \\ne}ep \\ne}BW \\nMoU \\n‘suonedijdde \\njg \\nay} \\n0} \\npappe \\ns} \\nAWeuoNdUN} \\nMau \\nJaAaUaYM \\n‘(e}eP \\nSSAUISNG \\nMau \\nay} \\nJO \\nSUJeEWOP \\npuUe \\n‘SUO}UYep \\n‘SowWeuU \\n‘gjduuexa \\n40}) \\nAioysodas \\neyep \\ne}JaW \\nBY} \\nO} \\npappe \\nS| \\ne}ep \\nEyal \\nMau \\n‘saseqej}ep \\n9312} \\n|G \\nJY} \\nO} \\npappe \\nsi \\neyep \\nSSOUISNG \\nMAU \\nJAAVUBYM \\n‘SISEG \\nSUIOSUO \\nUL \\nUO \\nBAIOAS \\nO} \\nSANUIJUOD \\nPUP \\ndAI}EIHU! \\nyoddns-uolsidap \\n1g \\nIS1lJ \\nQU} \\nUM \\nSE}s \\n}] \\n‘UONNJOAA \\nUe \\nS| \\n}}—JUAAA \\nUe \\nJOU \\nS! \\nUOANJOS \\nA1o}!sodai \\neyep \\neyoW \\ne Suldojanaq \\n« \\nquiny, \\nfo \\nsajny \\npup \\nsdi \\n‘PI[eA \\nJASUO] \\nOU \\nSI \\n}EU} \\nUO!EWIOJU! \\npa}epINO \\nWO} \\nUOHEWHOJU! \\nJUBUND \\najqgenjea \\nay} \\na}eiedas \\n0} \\naq \\n||IM \\nasua||ey \\ndy] \\n“UOHe}USUNIOP \\nUl \\nSUIUMOIP \\nSALUIJALUOS \\nJue \\nSUOHJEZIULBIC \\n“eyepP \\nLJOLU \\nJO \\nSADINOS \\nBUIJSIXE \\nYOOLAO \\n},U0C \\n- \\n‘siseq \\nSUIOSUO \\nUe \\nUO \\nAuOysSOdad \\nP}ep \\nPJALU \\nJU} \\nUIEJUIEW \\n0} \\nUOSJad \\npa}edIPap \\nUO \\n}sea] \\n}e \\nPIdU \\nNOA \\n‘pa}Uaua|dul \\nSs! \\nAsoyisodas \\neyep \\nPJD \\nBY} \\nJaye \\naAeay \\n[IM \\nOUM \\najdoad \\nauwy-yed \\nYM \\nAoysodai \\neyep \\neJOW \\ne \\ndojanap \\n0} \\n}dw}e \\n},U0G \\n« \\n‘SalHAIe \\nJEIAL} \\nJOU \\nale \\nsjeyiod \\npue \\nsAemayes \\nBulpjing \\n‘yreoidde \\npaynqljsip \\n40 \\npezijejjUadap \\n& \\nBsOOyD \\nnoA \\ny1 \\nAieiadsa \\n‘Auoysodai \\neyep \\neyo \\n& \\nUleyUJeLW \\npue \\nPing \\nO} \\npasinbas \\nWoe \\nay} \\na}eW}sSas9pUN \\n},UOC \\n+ \\n$1,U0q \\n‘yw \\nBuisn \\ndoys \\nAew \\najdoad \\nssauisng \\nay} \\npue \\n‘ajqeuoysanb \\nAioysodai \\neyep \\neyaW \\nay} \\naYeW \\n|II/M \\nHI \\n‘e}ep \\nEJaW \\nau} \\nJo \\nADeundde \\npue \\nssaua}a|dWOd \\nay} \\nUO \\nSuIAja1 \\nB12 \\nOUM \\najdoad \\nssauisng \\n34} \\nPaye \\n||IM \\n} \\n‘3124s \\nsawi0daq \\nAuoysodai \\ne}ep \\ne}AWW \\nAY} \\nJO \\nJU9}UOD \\nay} \\nJ] \\n‘AsO}sOdas \\neyep \\neJOW \\n94} \\nU!E}UJELW \\nAJaADY \\n‘suiesZoid \\nUa}UM-WO}sNd \\nYSNosU} \\nJO \\nAjjenuew \\npawojied \\naq \\n0} \\nsey \\nUOHezIUOIUDUAS \\naU} \\nJey} \\nSUBALU \\nDIM \\n‘AAISSed \\n|[}S \\nae \\nSALOYSOdad \\neyep \\ne}OW \\n‘Ajayeunyojun \\n“SINC \\naU} \\nUI \\npure \\nsjOO} \\nJay}O \\nU! \\npauleyUOD \\ne}ep \\neyaW \\n9Y} \\nYM \\nYDUAs \\nUl \\nAuoysodas \\neyep \\ne}aW \\n3y} \\ndaa» \\n« \\njuaudojanaq \\n‘OAIUN}U! \\npue \\nAsea \\naq \\npjnous \\nAuoysoday \\nKioysodas \\neyep \\neJaW \\nay} \\nBUISH \\n‘sal|iqeded \\nAuanb \\neyep \\ne}aLU \\nBAIISUIS-}X9}UOD \\nPUL \\nBALE}! \\nPIAOId \\n+ \\nejeq \\nPW \\n‘VL \\nsod \\ndajs \\njuauidojanaq \\njuawidojanag \\nA1oysoday \\ne1eq \\nBJA \\n:71 \\ndais \\n}UatdojaAaq \\n— \\nX}eIA| \\nSAUIJaPIND \\nJed1Ie1d \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 519}, page_content='Practical Guidelines Matrix \\nnesses \\n“Sul}Ssa} \\nUO \\nSAep \\ndaisy} \\n}sea] \\nye \\npuads \\nAjqeqoid \\n|jI!M \\nNOK \\n‘BZuipod \\nyo \\nAep \\nAsaAa \\nJO} \\nYEU} \\nJaqUIaWay \\n« \\n\"Saseqejyep \\njesse} \\n|g \\ndu} \\nJO \\nUSISap \\nay} \\npue \\nssad0id \\n79 \\nBU} \\nDaye \\nOsje \\nAewW \\ne}yep \\nadiNOs \\n0} \\nSaSUeYD \\n‘AjazDIpaWiU! \\neyep \\nadiNOs \\n494} \\n0} \\nS28ueYD \\nAue \\n3}ed1UNWWOD \\n0} \\najdoad \\nswajsAs \\njeuoesado \\nau} \\n393 \\n0} \\nSI \\nBua|eUd \\n1a83iq \\nBUL \\n‘spafoid \\n|g \\n[Je \\nUO \\nSJapjoyaye}s \\nJe \\nWl \\nUOTEIOGe]|OD \\na4inbad \\n|[IM \\n}] \\n‘“aSUaljeyd \\ne \\nsi \\nsWeISOId \\npue \\n‘saseqe}ep \\n‘s}00} \\nJ94}0 \\nY}M \\npaziuosYDUAs \\npue \\na}ep \\n0} \\ndn \\nAuoysoda \\ne}ep \\ne}aW \\naU} \\nSuidaay \\n- \\n‘Aj}UaBIIIP \\npue \\nAj}D90D \\nauOp \\nJI \\n‘sasegeyep \\n}9312} \\n1g \\nJO \\n9ZIs \\n[e}0} \\n94} \\nJO \\nJUaDJad \\nG \\nYea \\nPjnod \\nAiOYsOdas \\ne}ep \\nea \\nP \\nJO \\nAZIS \\npayeUUsa \\ndU] \\n« \\n‘SWLISOId \\nDE}J9}U! \\n[O0} \\nJUDAIJIP \\n[EIBAVS \\n9}1M \\nO} \\nBAeY \\nAew \\nNOA \\n‘s}O0} \\nau} \\nSUOWE \\nSI \\naa} \\nA}JEUOWLWOD \\n9}}}] \\nMOY \\nJO \\nYONW \\nMOY \\nUO \\nZulpUuadag \\n‘dV10 \\n“114 \\nASW) \\n‘ajduuexa \\nJO} \\n‘eJeP \\nBBW \\neI}XO \\n[IM \\nNOA \\nYDIYM \\nWO \\nS[OO} \\nay} \\nJO \\nSaunyeay \\nYOdxa/jiOdw! \\nay} \\npueysiapUN \\n0} \\nans \\nag \\n« \\nEEE \\nnn \\nnnn \\nnn \\nnnn \\nnnn \\nSSS \\nSSS \\nyuawidojaneg \\nA1oysoday \\ne}eq \\nea \\n:71 \\ndais \\n}uauidojanag \\n= — \\nxi} \\nsauT|apin5 \\nJed \\neld \\n486 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 520}, page_content='487 ion Implementat Development Step 15 \\n‘QIELUIISS \\nBAIEAIISUOD \\nC \\nSI \\nSIU} \\nBATIJ9G \\nBWOS \\n‘sIedA \\nOMY \\nAJBAB \\n9ZIS \\nUl \\nBJGNOP \\nI|IIM \\nJUBWUOIIAUS \\nyoddns-uoisidap \\n|g \\nJNOA \\nyey} \\naWNsse \\nUeD \\nNOA \\n‘sUO}eZIUCSIO \\nJ9Y}O \\nJO \\nBdDUaLIadxa \\ndy} \\nUO \\npaseg \\nSNOSUR]|9DSIW \\nJUdDIEd \\nOL \\n— \\nsajesalsse \\n‘SOUeWLUNS \\nJUadIEd \\nOF \\n— \\nS9DIPUI \\nJUDDJOd \\nOE \\n— \\neyep \\nssauisng \\njUaddJed \\nO€ \\n— \\n“SMOJ|O} \\nSE \\npaynquysip \\nUayo \\nsi \\nadeds \\nJO \\nuOed0]|e \\nJUL \\n“(jy \\naJ}dnupenb \\n‘payeasd \\naie \\nsad1puI \\nJO \\n}O] \\ne \\nJI) \\n9ZIS \\nJNSIJeaJ \\ne \\n393 \\n0} \\n| a]diy \\nUY} \\n‘e}ep \\nssaulsng \\nNOK \\nJO \\nSWINJOA \\ndU} \\nd}EWI}SA \\nO} \\nS| \\nSASeqe}ep \\nBUIZIS \\n10} \\nWIXeW \\nSULIOUISUa \\nPJEPUE}s \\nUL \\n« \\nquiny, \\nfo \\nsajny \\npup \\nsdiy \\n‘UO \\nOS \\npuke \\n‘sadUaNbasuOd \\njeSo] \\n‘SOUL \\nJO} \\nB]qGel] \\naq \\nOsje \\nAew \\nNOA \\n‘ased \\n}SJOM \\nJU} \\nU] \\n“UO!EWOJUI! \\npafeyjdsip \\nasnqe \\nJO \\nasnsiW \\n0} \\nAUDBWOS \\nMOE \\nJO \\n‘e}P \\nJAaWO}SND \\n3as \\n0} \\najdoad \\npezuoyyNneun \\nMoje \\n‘eyep \\nJEUONZIULZIO \\nSAIPSUAS \\nMAIA \\nO} \\nS1O}Y}J9dWIOD \\nMO||e \\nPINod \\nsainseaw \\nAyndas \\nJadoJduwy] \\n‘saunseaw \\nAyindas \\npajsa} \\nAadoid \\njnoyym \\nsaseqeyep \\nJa3JL} \\n|g \\nBY} \\nO} \\nSS9dde \\nJOUJa}U] \\nUSdoO \\nJajJO \\n},U0Q \\n« \\n‘SULIOJUIW \\nPIdU \\n||IM \\n3]doad \\nssaulsng \\nau} \\npue \\n‘xajdwod \\nAJaA \\nSI \\n}UaWUOJAUa \\nYWOddns-uolsiap \\n1g \\nV \\n‘YeIs \\nWOddns \\nuo \\nduuys \\n},U0q \\n+ \\n‘(saunpado0id \\nUO-8o| \\nay} \\naBUeYD \\nJO \\nssadoid \\naU} \\nUl \\nJala \\nSulUles} \\nBp|AOJd \\n‘g]dexa \\nJ0J) \\npapaau \\naiayM \\nSjuatujsn{[pe \\nayew \\npue \\n‘od \\nnoA \\nse \\nused] \\n‘yseoudde \\nuoHe}UaWa|duI \\nJEJUDLUAIDU! \\nUL \\nSF] \\n“ADUO \\n}e \\n[|e \\nUOHJEZIUCSIO \\nJ11JUd \\nBY} \\nO} \\nUO!}EDI|dde \\n|g \\ne \\n}nO \\n|]O1 \\nO} \\nAj} \\n},U0G \\n« \\n$1,u0q \\n‘9SN \\nJOY} \\nJO} \\nPapusju! \\nSI \\n}eY} \\nEYEP \\nJU} \\nSSadde \\nUPD \\nSUOSJad \\npazOYNe \\nAjUO \\nyey} \\nsNsS \\naye \\npue \\n‘xU}eW \\nsiskjeue \\ndes \\nAyndas \\ne \\naiedaid \\n0} \\nJadIYyO \\nAyLNdas \\nSs UOI}eZIUeSIO \\nINOA \\nUUM \\nYJOM \\n« \\n‘Ayea \\nSWajgoid \\nad1nNOSal \\nASOUBeIP \\npuke \\nPayap \\n0} \\nSaIIyN \\naye \\npue \\nSuLOPWUOW \\na}eLUdoidde \\nasp \\n- \\n‘SUOI}EZIULSIOOI \\npue \\nsdnyoeg \\nasege}ep \\nse \\nupns \\n‘ajnpayds \\ngof \\nau} \\nUl \\nSaANDe \\nsdUeUA}UIeEW \\naseqe}ep \\nJejNsai \\napnjdu| \\n« \\n‘JUDWUOJIAUS \\nUO!NpPOId \\ndu} \\nOU! \\nSWIeISOId \\nJe \\nSUIAOW \\npue \\nsaleiqi \\nWwessoid \\nUOINpold \\nay} \\nBuNjea/d \\nUl \\nJe}s \\nSUOT}EJ9dO \\n9Y} \\nYUM \\nAjasop> \\nYOM \\n«© \\nUOH}EJUSWa|dwW] \\n“SL \\nsod dajs }uauidojanaq \\nuoHeyUuaWwadu] \\n:¢{ \\ndays \\nyuawidojanaq \\n— \\nXL} \\nSAUIJapIND \\n[ed1WDeId \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 521}, page_content='Practical Guidelines Matrix 488 \\nSSS \\n\"SyD9Ua]}}0g \\npsyadxeun \\nPIOAe \\n0} \\nAjaso}> \\nuO}ezI}IN \\njaBUUOSJad \\nPuke \\n‘UOHEZIIN \\nYOMyaU \\n‘UOHEZIIIN \\nJaIndwWod \\nJOWUOW \\n« \\n‘suoiued \\njo \\nsdnypeq \\need \\n10 \\n‘sdnydeq \\naweyulew \\npaads-ysiy \\n‘sdnydeq \\n(,a8ueyd \\n}OU,) \\n[E}UIWIIDU! \\nJAPISUOD \\n‘ajqissod \\naq \\nyou \\nAew \\nadu0 \\n}e \\n{Je \\nsajqe} \\naulua \\ndn \\nSurjreq \\n‘sqqA \\nJO \\naZIS \\naSUaLUWI \\nay} \\nJO \\nasnedag \\n+ \\n‘Woud \\ne \\nayeW \\nO} \\nUOHeZIUeSIO \\nay} \\nSuldjay \\ns| \\nUONed1|dde \\n1g \\nau} \\n$1 \\nadeds \\nysIp \\nBuAlasuOd \\ndo}s \\n‘aJOJasIUL \\n“SACTA \\nanqeu \\nslay} \\nAq \\nase \\nsaseqeyep \\njaSe} \\n|g \\nAue \\n« \\n—_————— \\nSSS \\nuoneUaWia|dul] \\n:¢1 \\ndays \\n}uaudojanaq \\n=— \\n= xiU}eW \\nSauljapiny \\njeINdeAd \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 522}, page_content='489 Release Evaluati Development Step 16 \\n‘SuljaawW \\nJu} \\nSuUNp \\nsaj}OU \\naye} \\nAquos \\nAyed-pily} \\ne \\nBAeY \\npuke \\n‘BUIIIW \\nJU} \\nyNpuod \\n10} \\neW \\nDe} \\nAyed-psiy} \\npauses} \\n& BAL} \\n‘S2}OU \\nBye} \\nJO \\nUOISSAS \\n9Y} \\nPea] \\n0} \\npey \\nAdu} \\n}! \\nPays|ulwWIp \\naq \\npInom \\nuonediiyed \\nJo \\nJada] \\nJAUL \\n‘MalAad \\nUOHe}UaWa|dwI-}sod \\nay} \\nSULNP \\nSio}NgUyUOoD \\npue \\nsiaAejd \\nJOfELUW \\nJie \\nSIAGWIAW \\nWd} \\nBOD \\n“AUIS \\nAU} \\nJO \\n10} \\nIDE} \\nBU} \\n9g \\n0} \\nWed} \\n310d \\nJY} \\nWs} \\naUOAUR \\nasn \\n},U0Q \\n+ \\n\"SONSSI \\nJU} \\nJOSJO} \\n|JIM \\nPUL \\nPa}SaJo}UISIP \\nJUUOIIG \\n[IM \\najdoad \\nasnedaq \\nUONe}UaWa|dwWI! \\nJaye \\nSYJUOW \\n391} \\n0} \\nOM} \\nPUOA| \\nSUIJadW \\nBU} \\nBUOd}sod \\n},U0Q \\n- \\n‘uolssas \\n,SUI}UIOd-Ja3Uly, \\n© OJU! \\n9}JEJOLA}JOP \\nSUNIIW \\nIU} \\nJa] \\n},UOG \\n« \\n‘SUIJIILU \\nJU} \\nWOjJaq \\nWay} \\npees \\nued \\nSd9PUDHE \\nJU} \\nJEU} \\nOS \\nJWI} \\nJO \\nPRaYe \\nyNO \\nS}UBLUNDOP \\nasSOU} \\nPuas \\n‘BUI}IdLW \\nBY} \\nSULINP \\nPadUdJajaJ \\naq \\n|||M \\nSJUDWNIOP \\nDWOS \\nJI \\nAAIMOH \\n“AANINpOidun \\nSs} \\nyey} \\nVsNeIaq \\nUOHE}UBWINIOP \\nSNOUIWNIOA \\nMalAdd \\n},U0 \\n« \\n‘yuem \\nAay} \\nwield \\nAdu} \\nUdIUM \\n‘ssad0Jd \\nJUaWdOjaAep \\naU} \\nJO \\npaads \\npue \\nAyyenb \\nay} \\naAosJdu! \\n0} \\nJUBWAseUeW \\nLOI \\nJUBWHIWLWOD \\nJO \\nye] \\n& \\nSa}ed1PU! \\nSIUL \\n,,MaIAdJ \\nUO}L}UdWa|duuI-}sod \\nAep-auo \\ne 10} \\natu} \\nSey \\nAPOGOU, \\n}eY} \\nBSNDXo \\nJU} \\n}dadde \\nJBAON \\n«+ \\n‘ydaduod \\naseajas \\nay} \\nJO \\nWIds \\nau} \\nUl \\nOU \\nSs! \\nAyyenb \\n100d \\npue \\n‘Qunjonsys \\nOU \\n‘YSnou} \\najyy] \\nUYWM \\nUOHe}UaWa|duU! \\n0} \\nPafoid \\nayajdwosul \\nue \\nAuny \\nAjdwis \\nOL \\n‘sauljapins \\naseajai \\nUOHedI|dde \\n1g \\nay} \\nMOJO} \\n},UOP \\nNOA \\n}! \\n}dadUOD \\naseajad \\nay} \\nBuIsN \\naie \\nNOA \\npuajaid \\n},U0Q \\n« \\ns_,u0qd \\n‘SJUIWAAOIGUUI \\nSSad01d \\nssauIsng \\najqissod \\npue \\ns}uaWanosduy] \\nJUaWIdOJaAap \\naunyny \\nJO} \\nsWa}] \\nUOIDIe \\npausisse \\nYM \\npue \\najOU \\naAISOd \\ne \\nUO \\npu \\n« \\nYO} \\nSW} \\nppe \\n0} \\nSAapuaye \\nd}JAU! \\npue \\nAiea \\nepuase \\nAyeuluuijaid \\ne \\nIno \\npuss \\n+ \\n‘pazerdoj/e \\nSWI} \\n9} \\nUl \\nAjayenbape \\npaserod \\nag \\nJoUUeD \\nsd1do} \\naU} \\nJi \\nSUSaW \\nPUODaS \\ne \\najNnpayrS \\n“SuNsawW \\nay} \\nSuNp \\nepuase \\nay} \\nUO \\npasndo} \\nAe}js \\n« ‘pafoid |g \\nJU} \\nWO \\nPAUJLa| \\nSUOSSA] \\nBU} \\nU] \\n}SAJB}U! \\nPI}SaA \\ne \\naAeY \\nAdy} \\n}] \\nSIAAJASGO \\nSe \\nSJapjoysye}s \\n|eUOHIPpe \\nayAul \\nAewW \\nNo, \\n‘(Wea} \\npapuayxXa \\nau} \\nSe \\n[JAM \\nSE \\nWd} \\n3109 \\n9Y} \\nWIJ) \\nSiaqWalW \\nWea} \\nPalOld \\n|]e \\nS}AU| \\n« \\nuonenjeaq \\n‘SUONANUDIU! \\nSJLUILUIJS \\nO} \\nSHSYO \\nBUNIdW \\nMalAad \\nUOHE}USWa|dWI-Jsod \\n3y} \\nJNPUOD \\naseajay \\n“OL \\nsoq dajs Juauidojanaqg \\nuoHenjeaq \\naseajay \\n:91 \\ndays \\n}uaWdojaAsqg \\n— \\nX}e \\nSaUTapINy \\njede1d \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 523}, page_content='Practical Guidelines Matrix \\nener \\nnnn \\nnnn \\nnnn \\nnnn \\nnn \\nnnn \\nnnn \\nnnnnnnnnnncnnnnnnccncenencnncccccneeeeeceeeeceeeeeeeeeeeeceeceeeeeeeeneeeeeeee \\nSSS \\nSSS \\nSSS \\n‘SJaSCULLU \\nSSaUISNg \\npue \\nsWiea} \\nPafoid \\nJaYy}O \\nUM \\nPaseys \\naq \\nOsje \\npjnod \\nsuossa} \\nasayl \\n‘ydeoidde \\njuawdojaap \\n|g \\na4} \\nBAOJdUI \\n0} \\npue \\n,pauea| \\nSUOSSA], \\nJUBLUNDOP \\n0} \\nSI \\nSMAIAII \\nBSAU} \\nJO} \\nasodind \\naus \\npeafoid \\n|g \\nydea \\nJaye \\npauuoyiad \\naq \\nsKemje \\npjnous \\nsmalAas \\nUOIe}UBWa|CUI-}SsOq \\n« \\n‘SSad01d \\nJUSWUCOJaAAP \\nJAI}C19}! \\nBY} \\n0} \\npasn \\njas \\najdoad \\nssauisng \\nau} \\nse \\nasJawa \\n||IM \\nS}uaWasINbaL \\nMAU \\n‘[NJsSadINS \\nS| \\naseajad \\n}SJy \\nBU} \\n$] \\n“eVEP \\nAIP \\nYUM \\npue \\nspajap \\nAUeW \\nYUM \\nJUSNe, \\nSI \\nyey} \\nUOMed|dde \\npayajdwod \\n‘Ayjenb-mo] \\ne \\nJaAljap \\n0} \\nUeY} \\nSW} \\nJBAO \\nSaseajas \\nUOHeDI|dde \\nSuluoNDuNy \\nAjjensed \\n‘Ayyenb-Yysiy \\nJ2Alap \\nO} \\nJa}39qg \\nYONUW \\nSI \\ni \\n‘}dadu0d \\naseajas \\nay} \\nSuIsn \\nsuO}edI|dde \\n|g \\nANOA \\nyUaWa|duy \\n« \\n—————EEE—————— \\nee \\neee \\neee \\nquiny_ \\nfo \\nsajny \\npup \\nsdip \\nenn \\nnnn \\nnnn \\nnnn \\nnner \\nnner \\nnnnnnnnnnnnnnnnnnnnnnnncnnnncnnne \\nrenee \\nSSS \\nSSS \\nSS \\nuoHenjenq \\naseajay \\n:91 \\ndays \\njuatudojanaq \\n— \\nxXxL}eW \\nSaUTjapINy \\njedIDeI1d \\n490 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 524}, page_content='saoipeid \\nAijua \\neyep \\n100d \\nAyuap| \\n0Z \\nsainparojd \\njeuoijesado \\n}UaLIND \\nssassy \\n6L \\nsadipeid \\nuoedijdnp \\neyep \\nMalAey \\ngL \\nsaolpeid \\nuonejndiuew \\neyep \\nMalAay \\nZL \\nsanlpeid \\nUOIpeI}X9 \\nE}eEP \\nMAlAdY \\nOL \\nsanipeid \\nAyjua \\ne}ep \\nMalAdYy \\nSL \\nJUSLSAOUW \\nE}ep \\n}UALIND \\nJU} \\nSSassy \\nvl \\nS}UBWA]a \\nE}EP \\n3diNOS \\nJO \\n(UJEWOP) \\n}Ud}UOD \\nMAIADY \\n€L \\nsaseqe}ep \\nPUL \\nSdINPMNI}S \\naj \\nMAIABY \\nZi \\nswia}sAs \\njeuoneiado \\njo \\nAyyjenb \\neyep \\nau} \\nssassy \\nLL \\nS \\nsainpad0Jjd \\npue \\nsadinos \\n|euo}jejado \\nay} \\nSsassy \\nOL \\nsisAjeue \\ndeS \\nWOped \\n6 \\nSSC \\nBUIISIXS \\nJU} \\nJO \\nSSUIWODVOUS \\n3} \\nSUIW8}0q \\n8 \\nSSC \\nSUI}SIX \\nJU} \\nJO \\naseSN \\nJUDIND \\nSSassy \\nvi \\nce \\nSUO]}NIOS \\n(SSq) \\nWia}sAs \\nWoddns-uoOlspap \\n}UdIND \\n3} \\nssassy \\n9 \\nPpaau \\nSSaUlsng \\ndu} \\nJO \\nSAdUaNbasuUODd \\n|eIMULUIJ \\nJUDIND \\nSUIWWI}Oq \\nG \\npaau \\nssaulsng \\n3u} \\nAjijuap| \\nv \\nP99U \\nSSaUISNG \\n3} \\nBUILLLIG}9q \\n€ JUBLUSSassy ase> ssauisng :1 dais Zz aWeN Pafoig NOA. \\nssossadapatd \\naWDN \\nYSDL~~=s« \\nZI \\nVLVG XSWL \\n‘WOU-G)D \\nPeSO]IUS \\nJU} \\nJO \\nS}UD}JUOD \\nIU} \\nS}PIoI|Jol \\nxipuadde \\nSIU} \\nUl \\nDINPNAS \\nUMOPYeIG \\nYIOM \\nIYUL \\nd1INJINIJSG \\nUMOPYLIIG \\nYOM, \\nXIQGNdddV \\n491 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 525}, page_content='SL \\nSY \\nI \\nSL \\na \\nSE \\nSS \\nI \\nIIE \\nI \\nCA \\nI \\nICE \\nIEEE \\nEE \\nIE \\nLEP \\nEEE \\na \\nSysU \\nAyxa}dwod \\n3y} \\n3s! \\n6v \\na \\nsysi \\nASojouYra} \\nay} \\n}S!7 \\n8b E XLIJELW JUDUUSSASSE HSL e a}ea1D Lv \\nLZ \\nJUDLUSSaSse \\nYSU \\nCe WUOLad \\nOv \\ntv ‘ly (IOY) JUBWSSAU! UO UIN}a1 Papefoid ay} a}ejnojeD Gv \\nUOHEZIULBIO \\nBU} \\nO} \\nS}JQUaq \\nW9}-3UO] \\nAjJUap| \\nvv \\nUONEZIULBIO \\nJU} \\nO} \\nS}J9UAq \\nWd}-YOYS \\nAjUap| \\n€v \\n(21q13ue}U! puke aiqisue}) syyauag SUIWLIa}3q (ay \\nS}SOD \\nJUILWI9}9G \\nLv \\nTz \\nsISAJCUP \\n}1J9UIG-}SO) \\nBE WUOLad \\nOv \\nJapOwW \\neyep \\njed130] \\n(jen}daduod) \\njaAaj-YsIY \\ne \\na}eaID \\n6E \\nspafoid \\n|g \\nsnolaaid \\nWoy \\nsyuaWasNbas \\npayyinjun \\nazqyuoud \\npue \\nayepljosuoD \\nBE \\nUONNIOS \\n|g \\npasodoid \\ndy} \\nJO} \\nBANPaWYoe \\njaAgj-YUSIY \\ne \\na}ea/D \\nja \\nuled \\nssauisng \\nay} \\nUassay \\n|[IM \\nUOeIdde \\n|g \\nay} \\nMOY \\nJUILWa}9q \\nOE \\nsisAjeue \\nde3 \\nssq \\nMalAoy \\nGe \\nSUOI}NJOS \\nSSq \\n}USUND \\nMalAdy \\nve \\niz \\nuOoNIOs \\n|g \\n& asodoig \\nKS \\nsjeOS \\nssaulsng \\n3189}€13S \\n9Y} \\n0} \\nSAAIa{qo \\nUOHeDdI|dde \\n|g \\nd4IDads-~af{o1d \\naU} \\nYdIEW \\nZe \\nsjeod \\nssauisng \\n318a}€1}S \\n34} \\n0} \\nSAAI}afqo \\nYoddns-uolsidap \\n|g \\n|JeJ9AO \\nBU} \\nUDd}eW \\nLE \\nSaAlyal[go \\nUoHed|dde \\n|g \\ndyI9ads-}Dafoid \\nayy \\naUIaq \\nO€ \\nSdAl}al[go \\nYWoddns-uols!dap \\n|g \\n|JeJ9AO \\nJU} \\nBUIaG \\n6Z \\nUONEZIUCBIO \\nBU} \\nJO \\nSjeOS \\nssauIsng \\nIISa}e1}s \\nay} \\nAjUAap| \\n87 \\nvz \\n‘OL \\n‘9 \\nsanydafqo \\nuonedidde \\n|g \\nay} \\nauIWa}3aq \\nLC \\nSOSEJULAPE \\nJAaYJELW \\nPAules \\nS1O}J9dWOd \\nJaUJBUM \\nSUILWA}9q \\n97 \\nSoin} \\nPUL \\nSaSSadINS \\nSJO}JadWOD \\nJy} \\nSUILLA}aq \\nGe \\n€ \\nsaAnemul \\nWoddns-uolspap \\n|g \\n$10}1}3d \\nWO) \\nay} \\nssassy \\nvz \\nBulules} \\nJO \\nye] \\nAyRUAp] \\nEZ \\n9pod \\nWeisold \\naAIpajap \\nAyuUap] \\nae \\nSYIOU) \\nHpa \\nJO \\nye] \\nAjUap] \\nLZ \\ng \\nssossadapasd \\naWDN \\nYSOL~ \\n= \\nI \\nanne \\nnner \\nnnnnnnnnnnnnnnnnnnnnnnnnereennncnnneeneeecceeceneeeeeeceeeeeenneeeeeneceneceereeceeeeceeeeeeeeeeeeseeeeeeeeeeeeeeeesr \\nce \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 526}, page_content='SSS \\nfaa] \\n= \\n(S}00} \\n‘SIG \\n‘aJempsey) \\nayenjera \\n0} \\npaau \\nNOA \\nsayo8a}ed \\njnpoid \\nay} \\nAyuap] \\n8/ \\nv9 \\nsyonpoid \\nMau \\nPajas \\npue \\na}enjeaq \\nLL \\nsisAjeue \\ndes \\nWiOjad \\nQ/ \\nAsoysodai \\neyep \\neyaW \\nBY} \\nMAIADY \\nGl \\n(239 \\n‘dV10 \\n‘114 \\n‘ASVD) \\nS]00} \\nMalAay \\npl \\nSINC \\n9U} \\nMalAoy \\nEL \\nUypImMpueg \\nPUe \\ns}UBZUOdWOD \\nYIOMJOU \\nMaIAayY \\nCL \\nSODPP9}U! \\nLWO}SND \\nMAIADY \\nLZ \\nshemayes \\nSW \\nAjjedadsa \\n‘asema|ppilu \\nMalAay \\nOZ \\nswa}sks \\nBulelado \\nMalAay \\n69 \\nDIEMPIEY \\nMAlAdy \\n89 \\nv9 \\nULIOj}e|d \\nSuUNSIXd \\nJY} \\nssassy \\nL9 \\nUOHeNeAZ \\na41NyINA}sesju] \\n[ENUYIAL \\n:y \\nUOIDIS \\n99 \\nuonenjeaq \\nainyonAysesuy \\nasiidiayuq \\n:7 \\ndays \\nfefe) \\nyRe \\nJosuods \\nssauisng \\nWoy \\n|eaoidde \\nyafoid \\nuleigo \\n9 \\n(s}UaWAaAOIdUUI! \\nssad0Jd \\nssauisng \\njeuO!}e1ado \\napnpul) \\nSUOHePUdaLUODA! \\nSIM \\n€9 \\nS}INSaJ \\nJUBLUSSaSse \\nYSU \\napnjdu| \\n79 \\nIO \\npepedxe \\npue \\nuoyedyisnf \\nsod \\nay} \\na}e}S \\nLQ \\nUO!}NJOS \\n|g \\npasodoid \\n3y} \\naquodseq \\n09 \\nsaljunyoddo \\nso] \\naquoasaq \\n6S \\npaau \\nssaulsng \\ndy} \\naquoseq \\n8S \\nOv \\n‘Ov \\n‘EE \\nHoda \\nJUaUssasse \\ndy} \\n3}UM \\n7S \\nv \\nvs \\nUO!}NJOs \\n|g \\ne SuUaWa|dw! \\nJOU \\nJo \\n(SUOHedYJWeJ) \\nSys \\nBUY \\nSUILLLIA}OQ \\n9S \\n= \\nvs \\nYSIy \\nJO \\n‘WUNIpal \\n‘Mo| \\n‘sys \\nay} \\nyUeY \\nGS \\n~ \\nLv \\nSSL \\n3U} \\nO} \\nS}YSIaM \\nUSISSY \\nvS \\n2 \\nSYS \\nJUSWYSIAU! \\n[EINUCUL, \\ndU} \\nISI] \\n€G \\n2 \\nSYS \\nWed} \\nPefoid \\nau} \\nIsS!I7 \\nrs \\nzy \\nSYS \\nUONEZIUCBIO \\n3U} \\nISIT \\nLS \\no \\nSSH \\nUO!}C1S9}U! \\nBY} \\nISI \\nOS \\n=| \\n—_—IY \\ns \\nS1OSSAIAPIId \\nQUIDN \\n¥SOL-~—s \\nQI \\nDDL \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 527}, page_content='APPENDIX 494 \\nI \\nEE \\nST \\nSY \\nSS \\nSE \\nSS \\nRS \\nA \\nBS \\nSE \\nPF \\nTN \\nPE \\nI \\nEET \\n90L \\nspnpoid \\nMau \\n3saL \\nZOL \\nSOL \\nsyonpoid \\nMau \\n|/e}Su| \\n90L \\nspnpoijd \\nMau \\nJapJO \\nSOL \\nv6 \\nWu0s}e]d \\nJUaLIND \\nay} \\npuedxy \\nvOL \\nAJEWILUNS \\nBAI}NIAXa \\nJU} \\nBUM \\n€OL \\nPL9}UD \\nUOIPeIas \\n[eULy \\n9U} \\nULeE|dxy \\nZOL \\nspnpold \\nBulpdeafes \\n10 \\nSuNDajas \\nJO} \\nafeuo!es \\nay} \\nUle|dxJ \\nLOL \\n}SI| \\nHOYS \\nBY} \\nUO \\nS~Npodd \\naU} \\n}sIT \\nOOL \\n$}SOD \\nNpold \\nau} \\n3s!7 \\n66 \\nS810IS \\nJODUSA \\ndU} \\nSIT \\n86 \\nSaJODS \\nPNpoOJd \\ndu} \\n3SI7 \\n16 \\ns}UdWAJIND|s \\nP3}USIOM \\nJU} \\n4SIT \\n96 \\n‘DJo \\n‘QUeMaIPpIW \\n‘sWia}sAs \\nBuljesado \\n‘siaAJas \\njNOge \\nSSUIPUIJ \\n9ZIWA}| \\nG6 \\nLL£°19 \\nHOdaJ \\n}UaWssasse \\n3.1N}INYSeYU! \\n[2ED1UYII} \\n3Y} \\n9M \\nv6 \\n76 \\nsyonpodd \\nay} \\nasuad|| \\n0} \\n|eAoJdde \\n1osuods \\nssauisng \\nule}qO \\n€6 \\n16 \\nAiogaye) \\nnpoid \\nydea \\nul \\nNpoid \\njeuyy \\nay} \\nasooyD \\n76 \\n06 \\nSIOPUBA \\nay} \\nAq \\npa}esjJSUOWAp \\ns}onpold \\nau} \\naAeH \\n16 \\n68 \\nAio8aye) \\nyea \\nUI! \\nSIOPUAA \\nPU \\ns}NpoOdd \\nJo \\njsI] \\nWoUs \\ne \\na}ealD \\n06 \\n88 \\n‘€8 \\nS91OIS \\nJOPUSA \\nPU \\nSA109S \\nPNpOJd \\nay} \\nayenjeAgq \\n68 \\n78 \\nJOPUA \\nUDCA \\nJO} \\nBOIS \\n[L}O} \\nJU} \\nSUILUIA}OQG \\n88 \\n98 \\n(OL \\n0} \\n0 \\nJO \\na]eDs) \\ns}UdWaINbas \\npa}Yyslam \\nau} \\nysulese \\nJOPUSA \\nUDdea \\nYUeY \\n/8 \\n(OL \\n0} \\n| JO \\nayeds) \\nJUaWaUINbal \\nJOPUaA \\nUDdeAa \\nUZIaM \\n98 \\nSIOPUDA \\nJU} \\nJO} \\nS}JUdWAJINbDaJ \\nANOKA \\n9ZIWa}| \\nfore) \\nsjnpoild \\n|e \\nJO \\nSIOpUaA \\nIIe \\nISI] \\nv8 \\nZ8 \\n~Npold \\nydea \\nJO} \\n3JOIS \\n[e}0} \\nBY} \\nDUIWAIaQq \\n€8 \\n1g \\n(OL \\n0} \\n0 JO \\na]e9s) \\ns}uaWaJINbas \\npayysiam \\nay} \\n}sulese \\nPnpoid \\nudea \\nyUeY \\n78 \\n(OL \\n0} \\n| JO \\nafeds) \\nJUaWadINbaJ \\nyNpoJd \\nYdea \\nYSIaM \\nLg \\nspnpodd \\n3u} \\n10} \\nsjuaWasINbas \\nunOA \\naziway \\n038 \\nAio8aye) \\nUdea \\n10} \\npalaplsuod \\nSulaq \\nsynpoud \\nqe \\nIsIq \\n6L \\n$JOSSaIaPAld \\nQUWIDN \\nYSDL \\nal \\nenn \\nnn \\nnnn \\nnnn \\nnn \\nnn \\nnner \\nSSS \\nSSS \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 528}, page_content='SSS \\nSSS \\nwn \\n¢ \\nSalyliqisuodsas \\npue \\nsajoi \\nau} \\nAyIpow \\n9EL \\nAsojopoujew \\njuatudojanap \\nay} \\nSuisn \\n10} \\nsauljapinS \\nay} \\nasueyD \\nGEL \\nsainpasoid \\n‘sauljaping \\n‘spsepueys \\nMau \\nSUIAJIPOWW \\n40 \\nBuea \\n10} \\nSd}EWI}sa \\nSUI} \\na}eaID \\nvEL \\nLet \\n31N}INASEAJUI \\n[EDIUYII}UOU \\nJy} \\nBAOIdW] \\n€€L \\nAJEWLUNS \\nSAI}NIAX9 \\n3U} \\nBUM \\nZEL \\npefoid \\n|g \\nay} \\napis}no \\n40} \\ns}uatuauINbas \\naunyonsysesju! \\n[ed1UY9}UOU \\nZNO \\nLEL \\npafoid \\n|g \\nau} \\n40} \\ns}uaWauINbas \\naunjoNAysSeyuU! \\nJedIUYI}UOU \\nIZUOLd \\nO€L \\nSA9SUCLP \\nAINJINIAISEAUI \\n[|UYDI}UOU \\nJO} \\nSUOHEPUBLWLUODAI \\ndL \\n6ZL \\n‘39 \\n‘Sainpadoid \\n‘sauljaping \\n‘spsepue}s \\nayenbapeul \\nynoge \\nsSulpuly \\naziway| \\n8ZL \\nOLL \\nHoda \\nJUSUUSSasse \\n3.1N}INA}SeAJUI \\n[2I1UYI9}UOU \\nJU} \\naM \\nviele \\nsisAjeue \\ndeS \\nWO}ad \\n9ZL \\nSS900Jd \\nUOHEDIUNWILUOD \\nJY} \\nMAIADY \\nGz \\nSsad01d \\nUONOSal \\nayndsip \\nay} \\nMalAaY \\nvZL \\nuondun \\nyOddns \\n|g \\nay} \\nMalAay \\n€ZL \\nSS9D0Jd \\n(7S) \\nJUBLUGIIBE \\n[AAI]-9d|AJS \\nJU} \\nMAIAJY \\nZ7ZL \\nssad0Jd \\nadel} \\nSulsueajd \\nay} \\npue \\nsainseaw \\nAyjenb \\neyep \\nmalAay \\nZI \\nJEPOW \\ne}ep \\nasiidiajua \\nay} \\nOF! \\nSjapolw \\neyep \\n[e130] \\nSulZiaw \\n410} \\nssadoid \\nay} \\nMaIAaY \\nOZL \\nAyjeuonouny \\nAsoysodai \\neyep \\neyo \\nMalAay \\n6LL \\nsassadoid \\nAlanljap \\npue \\nainyded \\neyep \\nejaw \\nMalAay \\nSLL \\nSauljapins \\npue \\nsassadojd \\nAyindas \\nMaIAay \\nyaw \\nSaIHIIGIsuOdsad \\npuke \\nS3jO1 \\nMAIANY \\nOLL \\nSainpadoid \\njuUaWaseUeW \\nSaNnss! \\nMAIAdY \\nSLL \\nv \\nSaiNpad0Jd \\n|01}U0D-38ULUD \\nMalAdy \\nvLL \\n= \\nSaUlJapIns \\nSUNeWISAa \\nMalAdYy \\nELL \\nc \\nAsojopouyaw \\nJUsWdojanap \\ndy} \\nJO \\nasn \\nay} \\nMalAayY \\nZLL \\n‘DJ \\n‘SulJapOw \\n‘suOHeIAaIgge \\n‘BulWeU \\ne}ep \\nJO} \\nsprepue}s \\nMaIAay \\nLLL \\n3 \\nZS \\nS}UBUOdWOD \\na1n}INjse4jUI \\n[e1UYII}UOU \\nSUNSIXa \\nJO \\nSs2UaANDaJJa \\naU} \\nssassy \\nOLL \\nUOHeNeAZ \\n34N}INA}se4ju] \\n[eEI1UYII}UON \\n:g \\nUONDAS \\n60L \\nv \\n90L \\nsynpoid \\nmau \\nUO \\nJe}s \\n[edUYIE} \\nUIEIL \\n8O0L \\n<1] \\n[een y= \\n$ \\nS1OSSAIAPAId \\nOUIDN \\n4SDL \\nal \\nSS \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 529}, page_content='SLE \\nEEEE \\nEEE! \\nx \\n5 \\nySiy \\n‘Winipaw \\n‘Moy \\n:3UIZITELa}EW \\nSSL \\nBY} \\nJO \\nPOOYI|ay!] \\nBU} \\nSU|W9}9q \\nSOL \\n2 \\nXLJELW \\nJUBLUSSASSE \\nYSH \\n[EUISO \\nBU} \\n9SIAQ1 \\nPUL \\nMAIAdY \\nvOL \\na \\nOL \\nJUDLUSSISSE \\nYSII \\nDU} \\nVSIAVY \\n€9| \\nLOL \\nSd}EWUI}SA \\n}SOD \\n[EUISLO \\nJU} \\nASIAOY \\nZ9OL \\nSululed \\n‘BUDeI}UOD \\n“BUN|NSUOD \\nJO} \\nPIDU \\nBY} \\nMAIADY \\nLOL \\n(Ayjenb \\n‘sadinosaJ \\n‘aspnq \\n‘adods \\n‘aul}) \\ns}uses}SUOD \\npafoid \\nay} \\nMalAOY \\nO9L \\nsjuaWasInbas \\npafoid \\nay} \\nMalAeY \\n6SL \\nYoda \\nJUaLUSSaSSe \\nJINJNI}SEIJU! \\n[EDIUYIS}UOU \\nJY} \\nMAIAZY \\n8SL \\nYoda \\nJUaUssasse \\naINJINASeAU! \\nJEDIUYIO} \\nBY} \\nM2IABY \\nyeh \\norl \\nSd}JEUUT}SA \\n}SOD \\nJY} \\nBSIADI \\nAO \\nBUILUIG}9G \\nOSL \\nVSL \\n‘ESL \\nMOs \\nZulsueasd \\nau} \\naziuoud \\npue \\nJosuods \\nssauisng \\nay} \\nYM \\nSa}eUWI}se \\nSulsueald-e}ep \\nMIIAdY \\nSSL \\nZSI. \\neyep \\nadinos \\njuepOdUI! \\nJO \\nSulsuea]d \\n10} \\npapaauU \\nSUI} \\nBY} \\nd}EWI}SA \\nvSL \\nZSL \\nPJP \\nVDANOS \\n|edI}D \\nJO \\nSulsuea|]D \\nJO} \\nPapaauU \\nBWI} \\nBY} \\n9}EWI}SJ \\neG). \\nJULDIJUBISU! \\n‘JUeLOAU \\n‘JEDHUD \\nae \\nSJUBLWA/a \\nE}EP \\nYIIYM \\nUIW9}9q \\nZGI \\nsain \\nAya}! \\neyep \\nSSOUISNG \\nMalAeY \\nLSL \\nSajni \\nUJEWOp \\ne}ep \\nssauisng \\nMalAey \\nOSL \\nSd]MJ \\nUOISJAAUOD \\ne}ep \\nJeEdIUYIO} \\nMalAdyY \\n6tL \\nSUO}}LIOIA \\nE}EP \\n3d1NOS \\nssassy \\nSrl \\n(jeusa}xa \\npuke \\n|eWJa}U!) \\naseqeyep \\nadINOs \\npue \\naly \\nadINOs \\nJeUa}Od \\nYea \\nJO \\n}U9}UOD \\nBY} \\nMA!AZY \\nLvl \\n6€EL \\nsaseqe}ep \\nPUP \\nSajlJ \\n3D1NOS \\nJY} \\nJO \\nUO!}PUOD \\n9Y} \\nBUILUI9}9q \\norl \\nvel \\nsjuawasINbas \\nay} \\n10} \\n|eAosdde \\nsosuods \\nule}gO \\nStL \\nZl \\n‘Lvl \\n‘OvL \\najdoad \\nssauisng \\nJau}0 \\nYM \\ns}UaWesINbas \\nay} \\nayepljen \\nrel \\nOvL \\nJ9POW \\nyep \\n[ed1SO] \\n[aAa]-YSly \\nau} \\n9}e919 \\nJO \\npuedxy \\n€vl \\n(je}UYyd9}UOU \\nPUe \\nJed1UYIA}) \\nS}UaWAaJINbad \\nainyonyseyul \\nBUYoeq \\nraial \\n(uoDUNy \\ndjay \\nauljuo \\n‘savanb \\n‘syodad) \\nsyuawasInbas \\njeuo| \\nUNS \\naUulJaq \\nLvl \\nsjuawasINbas \\neyep \\nSued \\nOrl \\nLZ \\n‘v6 \\nsjuawalinbas \\npafoid \\nay} \\nBUILI3}9q \\n6EL \\nSujuueld \\nPaloid:€ \\ndais \\n= \\nBEL \\npapaeu \\nse \\nsassad0jd \\nMau \\n3}e9ID \\nPSI. \\ni \\n9 \\nssossavapald \\nQUIDN \\n¥SDL~—s \\nZI \\n+ \\na, \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 530}, page_content='eee \\nBN \\n= \\nasiviedxa \\nJayew \\npalqns \\nssaippy \\nv6L \\nJSA9] \\n|]D{S \\nSsouppy \\n€6L \\nL6L \\nS9D1NOSA1 \\nPIUSIsse \\n10} \\nSd}EWII}SS \\naseq \\nay} \\nasIAdY \\nZ6L \\nSal2Uapuadap \\nyse} \\nAynUap| \\nL6L \\nSYSE} \\n|] \\n10} \\nSa}EUI}SA \\naseq \\nSUILUA}aq \\nO6L \\nain}ynyjs \\nUMOpyealg \\nYOM \\nke \\na}ea1D \\n68L \\nELL \\nueld \\npafoid \\njanaj-ysiy \\ne ayeasD \\n88 \\nSJOPPJ \\nSS9DINS \\n[eII}D \\nISIT \\nZ8L \\ns}ule1}SUOD \\npuke \\n‘sUOH}duUNsse \\n‘SySL \\n3ST \\n981 \\nSaluliqisuodsay \\npue \\n‘sajod \\n‘ain}on4ys \\nWea} \\nauaq \\nS8L \\n(W1s \\nAreululjaid) \\najdoad \\nssauisng \\nau} \\nWoy \\nsuolj}e}adxa \\n3S1] \\nv8L \\nadods \\n3y} \\nUl \\n}OU \\nSW}! \\nISI] \\n€8L \\n(suondun \\npue \\ne}ep) \\nadods \\nJanaj-ySIy \\nay} \\naquosaq \\nZ8L \\nS}UBWAAOJdUI| \\nssad0id \\nssauisng \\npue \\nainyonAyseyul \\naquosaq \\nL8L \\nSHJOU9Q \\nPU \\nS}SOD \\n9}e}S \\nO8L \\npofoid \\n|g \\nau} \\n10} \\nUOSeal \\npue \\nasodind \\n9} \\n9}e1S$ \\n6ZL \\n€/L \\nJayey) \\npafoid \\nay} \\naiedaig \\n8ZL \\nQZL \\n4Osuods \\nssaulsng \\nay} \\nWO \\ns10}De} \\nSSaddNs \\n[eID \\nay} \\nUO \\nuo}}49d00) \\npue \\njUawWaa/3e \\nUle}GO \\nZLL \\nG/L \\nJosuods \\nssaulsng \\nay} \\nUM \\n$403k} \\nSsadoNs \\n}eINUD \\nMalAay \\nO/L \\nvZL \\n$10}DE} \\nSSIIINS \\nJEDI \\nSUILAI9q \\nG/L \\npeloid \\n|g \\nau} \\n40} \\nEa}LID \\nssadodns \\nauy \\nauyag \\nvZL \\n€9l \\n‘OSL \\n$10}9B} \\n$Sa2INs \\nJed \\nAynuap] \\nE/L \\nv \\nYSU \\n0} \\na}ejaJ \\nAdu} \\nse \\ns}ulesjsuod \\npafoid \\naU} \\nMaIAaY \\nCA \\n= \\nuejd \\nAdXUaBuUI}UOD \\ndu} \\nUO \\nSys \\nSe \\nsuonduunsse \\napnu| \\nLZL \\n= \\nsuonduunsse \\nnok \\nAynuap] \\nOZL \\nvs \\nuejd \\nAsua8unuod \\ne auyaq \\n69L \\n2 \\nuejd \\nuonesiiW \\nys \\ne aUYaq \\n891 \\nz \\n$1933} \\nDUIIIq \\nZ9OL \\no \\nYsly \\n‘WNIpaw \\n‘mo] \\n:¥sU \\nAlana \\nJo \\npedul \\nay} \\ndulUa}aq \\n99L \\nS \\noe \\neesesSsSsS— \\n$ \\nS10SSAIAPAId \\nQUIDN \\n¥SDLE—s \\nI \\n-_ \\nCO \\nOO \\neS \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 531}, page_content='APPENDIX 498 \\nSSS \\nSSS \\nSSS \\nSSS \\nSSS \\nsauljapind \\nSUIEWI}SS \\nJO} \\nSJUIWINbaJ \\ndy} \\nBUG \\n€7Z \\nAZojOpoyJaW \\nJUBWdOJaAap \\nJY} \\nJO} \\nS}UaWasINbas \\nay} \\naUaG \\nCoc \\nSainpadojd \\npue \\nspiepue}s \\n(8ulzIWOUd) \\nBdUeUIaAOS \\nJO} \\nS}JUaWAaJINbas \\nay} \\naUaq \\nie \\n00z \\nSJUBLWIIULYUS \\nBANINA}SeAJU! \\n[ED1UYII}UOU \\n10} \\nS}UBWAAIND|J \\nay} \\nAUIJaG \\nO7Z \\nAioysodas \\neyep \\ne}aW \\nBUI}SIXS \\nUL \\nBDULYUA \\nO} \\nMOY \\nJUILUJaI0q \\n61Z \\nAsoysodai \\neyep \\neyaW \\ne \\npling \\nJO \\nasuadI| \\nO} \\nJOUJBYM \\nJUILAIaq \\nBIZ \\nJ00} \\nSuIUIW \\neyep \\nMAU \\ne JO} \\nS}UdWAaJINbas \\nay} \\naUIaq \\nL1Z \\n(S19}UM \\nYOdad \\n‘d¥10) \\n$|00} \\n3uljJOda1 \\npue \\nssadde \\ne}ep \\n10} \\nsjuaWauInbas \\nau} \\naUIaq \\n91z \\n(1.L9 \\n‘ASVD) \\nS]O0} \\nJUBWdoOjanap \\nJO} \\ns}UdWINbas \\nay} \\naUNaq \\nGIZ \\nsjuaWeasINbas \\nANDAs \\nJY} \\nDUILUII}aq \\nviz \\n}! \\nO} \\nSapessdn \\n10 \\nYAOMJOU \\nBU} \\nJO} \\nS}UBWAJINbas \\nau} \\naULaq \\nELZ \\nSW \\nS8Ul}sixa \\na4} \\n0} \\nsapes3dn \\n10 \\nSING \\nMau \\ne \\nJO} \\nS}JUaWAJINbas \\nay} \\naULaG \\nZLZ \\ndJEMa|PpIW \\n|EUOHIpPpe \\nJO} \\nSJUBWAIINbas \\ndy} \\nBUaq \\nNira \\naJempiey \\nJeUOIppe \\nJO} \\nS}JUaWadINbas \\nay} \\nauag \\nOLZ \\n00Z \\nS}UBWBIULYUS \\n91N}INA}SeAJUI \\n[eEIIUYII} \\n10J \\n$}UaWaIINbaJ \\nay} \\naUIZag \\n6072 \\nUOIHUag \\ns}JUaWaIINbay \\nWaloid \\n:py \\ndais \\n802 \\nZ0Z \\nSLULd} \\nSUIZIUCSIO-JJ9S \\nJO \\n}dadUOD \\naU} \\nSsndsIG \\nL0Z \\nZ0Z \\nueld \\npafloid \\nau} \\nUsNosU} \\nyIEM \\n902 \\n707 \\nJayey> \\npefoid \\nau} \\nssnosiq \\nSOz \\nZ0Z \\nSAI \\nIGISUOdSaI \\nJI9Y} \\nMAIABI \\nPUe \\nSJaqUIaW \\nLed} \\npapualxa \\nAjuUap] \\nvOz \\nZO0Z \\nSISGWIIWW \\nLUL9} \\n30D \\n0} \\nSalp|iqisuodsa \\npuke \\nsajol \\nUSIssy \\n€0Z \\nLOZ \\nBUNIIW \\nJOY! \\n& ||eD \\nZOZ \\nSUNB9W \\nJJOYI!4 \\nBY} \\nJO} \\nEpuase \\nue \\naiedaid \\nLOZ \\n88L \\n‘BZL \\npafoid \\nay} \\nyo \\nyoy \\n002 \\nZ6L \\nHEY) \\nHUD \\nPe \\no}edI) \\n66L \\nL6L \\nHEY) \\nad \\nJO \\n(Idd) \\npoyjaw \\nUyed \\nJedd \\ne a}ea!D \\n861 \\nZ6L \\n(SU!J2A9] \\n9d1NOSa) \\nSaIUapUadap \\nadinosai \\nAJUAp] \\n/6L \\nSOIPAIDE \\nPd}e[aJ-yJOM-UOU \\nSsaippYy \\nO6L \\nSAIPANDe \\nSAHeNS|UIWpPe \\n[eUONIPpe \\nssaippy \\nS6L \\nSIOSSAIAPIAId \\nQUIDN \\nSDL \\nal \\nSSS \\nSSS \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 532}, page_content='499 Work Breakdown Structure \\nSst \\n002 \\n00c¢ \\nSjuaWadInbad \\neyep \\n|edT0}sIU \\nay} \\nBUaG \\nsjUaWadInbad \\nSulsuea|d-e}ep \\ndy} \\nIUILWIa}9q \\nEJEP \\nJU} \\n1Oj \\nSajnd \\nSSaulsng \\nSNOIAGO \\npuke \\nJUeDIJIUZIS \\nay} \\naUaQ \\n(sanjea \\najqemoyjje) \\nsulewop \\ne}ep \\nay} \\naujaq \\nJUBDIJJUSISUI \\n‘JUELOALUI \\n‘[ed1}D \\nSe \\nsyUaWaj—a \\neyep \\nAjIsse;D \\nS}JUIWaJa \\ne}eP \\nJdiNOs \\n[je \\naujaq \\nB}Jep \\n3D1NOs \\n10) \\ns}UdWasINbaJ \\nay} \\naUaq \\nSQdeLJ9}U! \\nSSadde \\nBUJaq \\n(21GISsod \\n}1) \\nsauanb \\ndoy \\npe \\njo \\nsajdwes \\n3a5 \\nSOUELIGI| \\n4} \\nJO \\nSpleMays \\nAjUap| \\nsaueiqi| \\nAianb \\nauyaq \\nSUOISUBWUIP \\nBUI}IOdas \\ndULJaG \\ns9[nJ \\nUO}}EZUeWULUNS \\npue \\nUOHeSasse \\nauljaq \\nSHOdaJ \\n34} \\n10} \\nSaji \\nssauisng \\naujaq \\nSavianb \\najdwes \\na}ea49 \\n40 \\nPaljoD \\nsynoAe| \\nYodas \\najdwes \\na}ea19 \\n40 \\nPaljoD \\ns}uaWadnbal \\nSuiodas \\nay} \\nauyaq \\nSS9901d \\nUO!}EI|UNWWOD \\ndU} \\nJO} \\nS}UaWasINbas \\nau} \\naUNaq \\nssa201d \\nUO!NJOSaJ \\nayndsip \\nau} \\n10} \\nsyUaWasINbas \\nayy \\naUyaq \\nuonduny \\nYOddns \\n|g \\nau} \\n40} \\nsyuawWasnbas \\nay} \\nauaq \\nSSa201d \\nW1S \\naU} \\n10} \\ns}uaWasnbas \\nay} \\naULIaG \\nSainpadoid \\nBuys} \\nau} \\n40} \\nsyuawWasINbas \\nay} \\naUaq \\nssa01d \\nSulsuea|> \\ne}ep \\ndu} \\nJO} \\nS}UaWasINbas \\nau} \\naUNaq \\nSUI|aPOW \\nB}ep \\n[e180] \\n10} \\nsyuaWasINbas \\nay} \\nauyaq \\nssa20id \\nAianyjap \\npue \\nainjded \\neyep \\nejat \\nau} \\n10} \\nsyuatuauinbas \\n3} \\nBUIJaq \\nssa01d \\nAyindas \\nay} \\n10} \\ns}uatasInbas \\nau} \\naUaq \\nsai|igisuodsai \\npuke \\nsajoJ \\n10} \\ns}uatauinbas \\nay} \\nauyaq \\nssa201d \\nJuawWaseUeW \\nSanssi \\nay} \\n10} \\ns}UaWaJINbad \\nau} \\nouyaq \\nssad01d \\nJuawaseueW \\nadods \\nay} \\n10} \\ns}uaWiasINbal \\nau} \\nsUulag \\n_™.SS \\nee \\nSAOSSAIBPAId \\nQUIDN \\nSDL \\n_ \\nes \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 533}, page_content='APPENDIX 500 \\nSV1S \\nAreulwjaid \\nau} \\n3S!T \\n6L7Z \\nsjuaWalInbas \\nAyundas \\nay} \\naquosaq \\n8/7 \\ns}UaWadINbas \\nSUISUea|D-e}ep \\nJY} \\naquosaq \\nIe \\nAsojysiy \\nSulpnpdul \\n‘eyep \\n9dinos \\nJO} \\ns}uaWaJINnbas \\nay} \\naquaseq \\n9/Z \\nsjuawadInbes \\nAianb \\npauued \\npue \\nd0Yy \\npe \\nay} \\naquoseq \\nGUE \\nsjuUaWadINbes \\nSUIpOdas \\nay} \\naquosaq \\nvlZ \\nSJUSWAINDAI \\nBINJINYSEIJU! \\n[EDJUYII}UOU \\nJU} \\nVaqUIsag \\n€/Z \\nS}UBWAIINDA \\nJINJINYSEAUI \\n[EDIUYIO} \\nBU} \\naquosaq \\nZLZ \\nS9Z \\n‘097 \\nJUSLUNIOp \\ns}UaWasINbas \\nUOHedI|dde \\nay} \\n3M \\nLZZ \\nyoddns \\nsujosuo \\n10} \\nsuoijeyadxa \\nay} \\nasiAas \\n10 \\nAjuapy] \\nOZ \\nSSOUI|Uea]D \\nEJP \\nJO} \\nSUOI}E}DAdXa \\nBU} \\nASIAAI \\nJO \\nAjijuap| \\n6972 \\nJWI} \\nasUOdSaJ \\nJO} \\nSUOI}E}DAdX9 \\n3U} \\nASIAII \\nJO \\nAyUap] \\n897 \\nAyundas \\n10} \\nSuo}}e~adx~a \\nay} \\nasiAal \\nJO \\nAjUap| \\n197 \\nAqjiqesieae \\n10} \\nSUO}}e}adxa \\nBU} \\nASIAJI \\nJO \\nAjUap] \\n992 \\n€SZ \\nS}UIWI9I8e \\nJaAa]-adIAJas \\nAseulujasid \\nauyaq \\nS9zZ \\nCOT \\nS}UDWIJ9 \\nEJP \\nJEI}UD \\nYM \\nJapOW \\neyep \\n[ed13O] \\nay} \\naINqUNY \\nVIC \\n797 \\nAyyUa \\nYdea \\nO} \\nSJayyijUap! \\nanbiun \\nppy \\n€97 \\nL9Z \\nSdiysuoiejas \\nAuew-o}-Auew \\nay} \\nSUlAjOSal \\nAg \\nJapOW \\ne}ep \\njed1So] \\nay} \\naUYaY \\nZ9OZ \\nSdiysuonejas \\npue \\nSaijjUa \\npasanoosip \\nAjmau \\nppy \\nL9Z \\n€SZ \\nJapouw \\neyep \\njed150] \\nay} \\npuedxy \\n092 \\nSO] \\nSaNssi \\nUe \\nd}eaID \\n6SZ \\nJUSLUNIOP \\n[O1}UOD-aSueYD \\ne \\na}ea1D \\n8Sz \\n9SZC \\nAiessadau \\nJI \\n‘adods \\nay} \\najeno8auay \\nGG \\nS}UJE1JSUOD \\nBSOU} \\nJAPUN \\nDiISI}eaJ \\nS| \\n9dods \\nBy} \\nJAYJOYM \\nBUILWAI9q \\n9SZ \\n(Ayjenb \\n‘sadinosai \\n‘Jaspnq \\n‘adods \\n‘awI}) \\ns}Uses}SUOD \\nPDafoid \\naU} \\nMalAaY \\nGSZ \\nJayseyp \\nafoid \\n9} \\nUl \\nadods \\nJaAa]-YSIY \\nay} \\n0} \\ns}UaWasINbad \\n~afoid \\npayleyap \\nay} \\naiedwioD \\nvSz \\n97 \\n‘9EZ \\n‘OZZ \\n‘602 \\nadods \\npafoid \\nay} \\nMalAay \\nGz \\n$4OSSa2apasd \\naUWDN \\n3¥SDL-~—s \\nI \\nEen \\nnner \\nnn nner \\nnnnnnnennnee \\nneers \\neneeeeeeeee \\nSSS \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 534}, page_content='501 Work Breakdown Structure \\n—_—_—_——————————— \\nSWed} \\nPafoid \\npapaye \\n19U}0 \\nAION \\nJ9POW \\ne}ep \\nJed180] \\nasidiajUa \\nay} \\nJO \\nJaPOW \\neyep \\n[ed130] \\nDyIDads-ya{oud \\naU} \\nJBUYE \\nisn{[py \\nSOAINIOX9 \\nSSaUIsNg \\n484}O \\nPUL \\nSIBUMO \\nP}eP \\nYUM \\nSalduUedaJDSIpP \\nau} \\nssndsiq \\n06Z \\nsapuedadsip \\neyep \\nanjosay \\nSJPPOW \\nB}ep \\n[e130] \\nay} \\nUdaMjaq \\nSaldUa}sISUODU! \\nPUR \\nSaldUedaIDSIP \\neyep \\nAyUApy \\nJOPOW \\ne}ep \\n[e180] \\nastdiajzua \\nau} \\nOW! \\nJapOw \\neyep \\nJed1Z0] \\nJyIdads-aloid \\nau} \\nasap \\n06Z \\n‘v8Z \\nJapOwW \\ne}zep \\njed1go] \\nasiidiayua \\nay} \\npuedxq \\nWajqoid \\nay} \\nJo \\nAyes \\nau} \\naUIWA}aq \\nWa]qold \\nay} \\nJo \\nAyaAas \\nau} \\nJUILA}9q \\nshay \\nAiewud \\na}ed1|dnp \\n10) \\nyoo \\nsKay \\nAled \\nSuUIssIWu \\n10} \\nYOO \\nS9|NJ \\nSSOUISNG \\nJU} \\nS}LIOIA \\n}EY} \\nSAN[LA \\n10} \\nYOOT \\nSaN|eA \\nBUIPDIPLJ}UOD \\nJO} \\nYOOT \\nSanjea \\nd1dAud \\n10} \\nYOOT \\nSANJA \\nBUISSILW \\nJO} \\nYOO] \\nSANIEA \\n}NEJIP \\n10} \\nYOO \\nsajni \\nAy13a}ul \\ne}ep \\nssauisng \\npue \\nsajni \\nuleWop \\ne}ep \\nssauisng \\nAjddy \\nL8Z \\n‘LZZ \\nAyjenb \\neyep \\nad4nos \\nay} \\nazAjeuy \\nS}UZUOdWOD \\ne}ep \\ne}JaLU \\nSSauISNg \\ndJDads-e}ep \\nay} \\na}L91D \\nS}USW]d \\nE}EP \\nBdiNOS \\npaljiuap! \\n|} \\nJO \\n}Ua}UOD \\nau} \\nazAJeuy \\nSOSeqe}LP \\nBDINOS \\nPUE \\nSajlj \\nBDINOS \\nPaljIjUap} \\nJe \\nJO \\nNOAe] \\nau \\nazAjeUuy \\nSOINGUHE \\nM3U \\n3} \\n240}s \\nO} \\nPapsau \\n494M \\nSdiysuol}ejai \\nPUL \\nSai}i}Ua \\nMau \\n3}ea! \\nS}UBW9]9 \\nB}LP \\nBdUNOs \\npadinbai \\n|Je \\napnjdu! \\n0} \\n|apow \\neyep \\njed1/Zo] \\nau} \\nainquye \\nAjjn4 \\n| evabal \\nWare \\nJapouw \\ne}ep \\njerIZo] \\nay} \\naUIZaY \\nJaPOW \\ne}ep \\njed130| \\n94} \\nOFUI! \\nSOdINOS \\nBE} \\n[EUJ9}Xa \\nJU} \\nWO \\nSd|YSUO!eJaJ \\npUe \\nSaij}Ua \\nMAU \\ndU} \\naSJa/\\\\V \\n221NOs \\ne}ep \\nJeUJa}xe \\nYea \\nWO \\nSdiysuOHejas \\npue \\nsaiua \\nAjUAap] \\nLZZ \\n$931NOS \\ne}ep \\n[eUI3}Xa \\ndy} \\nazAJeuy \\nsisAjeuy \\nb}eq \\n:¢ \\ndais \\n™ \\na, \\nS1OSSAIaPAId \\nJUIDN \\nSDL \\n- \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 535}, page_content='APPENDIX 502 \\nSS \\nRB \\nEE \\nLE \\nI \\nPR \\nSS \\nETE \\nLD \\nFL \\nSESE \\nRI \\nAE \\nCE \\nI \\nICL \\nAE \\nOSL \\nAE EE \\nIE \\nTLE \\n2 APE \\nEOS \\nLOE \\nOLE \\nGATE \\nE \\nITA \\nLEE \\nSuIdA}O}OJd \\nJO} \\nSUINJO1 \\nSUIYSIUILUIP \\nJO \\nJUIOd \\nay} \\nBULA} \\nLEE \\nUO!}e19}1 \\nBdAYO}OJd \\nYDS \\nJO} \\n}J9UIG \\nPUL \\n}SOD \\n3U} \\n9}eWIS \\nLEE \\nuol}e49}1 \\nBdAYO}OJd \\nYDS \\nJO} \\nSWI] \\nDWI} \\nBY} \\nDUILUIA}OQ \\nsjuedioivied adAjo}01d Jo JAGUINU 3U} SUIW9}9q SUO!}C19}! BdA}O}JOJd JO JAGWINU JU} BUILWI9}9q \\n3dA}0}0Jd \\nay} \\nJO} \\nSO] \\nSanssi \\nUe \\na}ed1D \\n3dAj}O}O1d \\n3} \\nJO} \\nJUBWINDOP \\nJO04J}U0D-8BUeUD \\ne \\n9}edID \\nsaseqejep \\na01NOs \\npuke \\nsajlj \\n3d1NOS \\nWO} \\nEyep \\najdwes \\nJO \\nJasqns \\ne \\npajas \\n(adej49}U! \\n‘7.19 \\n‘Sauanb \\n‘syiodaJ) \\nsuoHDuNy \\nJo \\nJasqns \\ne \\npajas \\n(30 \\n‘OWap \\n‘|Ja}-pue-MoOYs) \\npjIng \\n0} \\nadAjo}OJd \\nJo \\nadA} \\nYdIYM \\napldeq \\nadA}0}01d \\nay} \\njo \\nasn \\nAvewud \\nay} \\npue \\naaipelgo \\nay} \\nauluajaq \\nLZZ \\nadA}0}01d \\nay} \\nJo \\nadods \\nay} \\nAUILWI3}0q \\nYadxea \\n‘paduenpe \\n‘BUUUISaq \\n:aspa|MOUy \\nUO!}ed!|dde \\n3}e>1pU] \\nYadxea \\n‘paduenpe \\n‘BUIUUISaq \\n:|9Ad] \\n||I4S \\nJ9}NdWOd \\n3}ed1pU| \\nsaliAoe \\nsuldA}o}01d \\nay} \\nul \\nSuNnedDHAed \\nuosjad \\nssauisng \\nYea \\n10} \\nXLJEUW \\nJas \\n|[D{S \\n& 3}ea1D \\nJOJEASIUILUPe \\naseqej}ep \\nJy} \\nO} \\nSBUIPUIJ \\nANOA \\n|e \\na}ed!UNWIWOD \\ns}UdWalINbas \\nadejJ9}U! \\nBU} \\naZAJeEUY \\ns}UaWalInbas \\nJOY \\npe \\nay} \\nazAjeuy \\nsjuaWadinbes \\nAianb \\nau} \\nazAjeuy \\nsjuawasINbas \\nYOdas \\nau} \\nazAjeuy \\ndA}e}UISa1dai \\nSsauISNg \\n3uy} \\npue \\nPadxe \\nJayeW \\nPafqns \\nay} \\nYM \\nJUaLUNDOpP \\ns}uaWasINba|s \\nUOIeD]dde \\nay} \\nMalAay \\nLZZ \\ns}UdWaJINbaJ \\nssadde \\n3U} \\nazAjeuy \\nSuidAjo}01g \\nuo}ed1\\\\ddy \\n:9 \\ndais \\ns}UdWaja \\ne}ep \\nJUELOAdUI \\npa}daIas \\nJO} \\nsUOHeIYIDads \\nSulsueajd-e}ep \\n91M \\nS}UIWaja \\nE}ep \\n[EDAD \\n[je \\n10} \\nsuOedyIDads \\nSulsuead-e}ep \\naU \\nJULIIIUBISU! \\n‘JUCLOCLUI \\n‘EdD \\n:S}UBLUA]a \\nEYLP \\nJO \\nUOILIIJISSE|D \\nBU} \\nMAIADY \\nvOE \\nsuonedyidads \\nSulsuea]d-e}ep \\nay} \\n3M \\nSUOINJOSAJ \\nJO} \\nBWI} \\nBJNPIYIS \\npue \\ne}ep \\ne}aUW \\nSe \\nSaIDUedaIDSIP \\nay} \\nJUBLUNDOG \\n6LE BLE LIE \\nOle SLE DLE \\nEle CLE LLE OLE \\n60€ \\n80€ \\nee \\nSS \\na \\nLS \\nES \\nSS \\nA \\nEE \\nS1OSSadapasd \\nQUDN \\nSDL \\nal \\ni SE \\nEE \\nEE \\nEEE \\nTLE \\nDELON \\nEE \\nFEELERS \\nI \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 536}, page_content='503 Work Breakdown Structure \\nSs \\nLVE 8SE \\nLVE \\nOEE \\n‘VZE \\n‘VLE SVE LZ¢ \\nS1OsSsadapald \\nSUOda \\nJO \\nJaSqns \\npayajas \\n& \\nJIM \\neyep \\najdwes \\nyum \\naseqejep \\nadAjojoJ1d \\nau} \\npeo \\ne}ep \\n}S9} \\najdwes \\no}easD \\naseqeyep \\nadAjoj01d \\njed1sAud \\nau} \\najealD \\nadA}0}0.1d \\n3y} \\npying \\naseqeyep \\nadhjo}01d \\nay} \\noF! \\neyep \\nSa} \\nMAU \\nJO \\nB}ep \\nadINOs \\najdwes \\ndew \\nadAjo}o1d \\nay} \\n10} \\npasn \\naq \\n0} \\ne}ep \\nay} \\nAynuap] \\naseqeyep \\nadfjoj01d \\nay} \\n104 \\n(UsIsap \\naseqe}ep) \\njapow \\neyep \\njedisAud \\ne \\na}ealD \\nSOdPJJ9}U! \\nBU} \\nUSISAG \\nSalienb \\nay} \\nusIsaq \\nSHOdal \\nay} \\nUSISAag \\nsalianb \\npue \\nsyioda. \\nay} \\nusIsaq \\n3dA}0}01d \\nay} \\nJO \\nssadons \\nay} \\nainseaw \\n||IM \\nNOK \\nMoy \\nauyag \\n(SUO}E19} \\n‘OLUN} \\n‘adods) \\naie \\nsajns \\nay} \\n}eEYM \\naUYaq \\n(21doad \\nssaursnq \\npue \\n{)) \\nayedisted \\njm \\nOM \\nJsI] \\npapayas \\nnoA \\nadAjo}0/d \\njo \\nadj \\nyeyM \\na}e15 \\n2dA}0}0/d \\nay} \\nJo \\nasodind \\nau} \\na}e15 \\nJayey) \\nadAjo}01d \\nay} \\naiedaid \\nSUOISSIS \\nBUIUIEJ} \\nJINDIUDS \\nS]OO} \\nMAU \\nAU} \\nJO} \\nSpaau \\nBUIUIEJ} \\nDUILLIA}Oq \\n$]00} \\nMAU \\nJO \\nBUIISIXA \\nBJOW \\nJO \\nBUO \\nalas \\nSSINEC \\nPe}se} \\npue \\npajje}su! \\n9} \\nJO \\nBUO \\nPajas \\npedojanap \\nag \\n|JIm \\nadAyo}01d \\nay} \\nUdIyM \\nUO \\nWIOJe\\\\d \\n9} \\nPalas \\nadAjo}o1d \\nay} \\n10} \\nsuondo \\nswaq \\nSunsixa \\nMalnay \\n$]00} \\nUOHNUISIP \\nYOda1 \\nMau \\nJO \\nSUNSIXS \\nMalAayY \\n$]OO} \\nJed1Ydess \\nMau \\nJO \\nSUI}SIXA \\nMAIAJY \\n$]00} \\nsulAsanb \\npue \\nBulyodas \\nmau \\njo \\nAyiqeyreae \\nauy \\nMAalAdy \\nWW9U} \\nS8SN \\nOYM \\nNO \\npul} \\nPU \\nS]OO} \\naSNOY-U! \\nSUN}SIXS \\nMAIAaY \\n2dA}0}0.1d \\naU} \\n104 \\nS]}00} \\n}Da]aS \\naUIDN \\nSDL \\n—_e_——— \\neerro”_O_—o \\naa \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 537}, page_content='APPENDIX 504 \\nsa|qeJaAljap \\nAsopsodas \\ne}yep \\nLBW \\nay} \\nJO \\n3doOds \\ndU} \\nBUIWA}9q \\nO6E \\nYOdas JUBWSSASSE JINPNJSEAUI [2ED|UUDI}UOU 3U} MAIAVY 68E \\nZBE \\nAioysodas \\neyep \\ne}BW \\n& \\nPIINg \\n10 \\naSUAaDI| \\n0} \\nUOISIDAP \\nJU} \\nDY \\n88E \\nAioysodas \\neyep \\ne}awW \\n© \\nBUIPIING \\nSNSIBA \\nBUISUADI| \\nJO} \\nSISAJeUL \\n}JaUdG-}SOD \\nE \\nWOLJAad \\nZ8E \\nYOdas \\nJUBWSSASSE \\nJINIDMYSeIJU! \\nJEdIUYI} \\nBY} \\nMIIADY \\nO8E \\nLZZ \\nsyuaWwatinbas \\nA10jisodas \\neyep \\neJaW \\nay} \\nazAjeuy \\nG8E \\nsishjeuy \\nA1oyisoday \\ne}eq \\nea \\n:Z \\ndais \\nv8E \\nELE \\naiqeaidde \\n41 \\n‘uonesay \\nadAjo}od \\n}x9U \\nBU} \\nWOLAd \\n€BE \\nO8E \\nuoledi|dde \\n|g \\nay} \\na}0WO1d \\n0} \\nsuOH}eijsUOWAP \\nadAjo}O/d \\nasp \\nZBE \\nWed} 3109 days \\nO8E \\nLI \\n8y} \\nYUM \\nJejNdWWed \\nUl \\npue \\nWea} \\n3109 \\nPafoid \\nasljUa \\nBY} \\nYM \\nPausea] \\nSUOSSa] \\nMalAdY \\nLSE \\n6ZE \\nsasueyp \\nparoidde \\napnjdul \\n0} \\nJUaWINIOP \\ns}UsWaJINbas \\nUOI}eDI|dde \\nay} \\nasiAay \\nO8E \\naAyeyUuasosidas \\nBZE \\nssaulsng \\n34} \\npue \\nJOSuOds \\nssauisng \\nay} \\nYUM \\nSasueyD \\npa}sanbal \\nJo \\nedwi \\nMaiAay \\n6ZE \\nZLE \\n—_ \\n(Sadunosad \\n‘sod \\n‘Ayjenb \\n‘awi}) \\ns}ulesjSUOD \\nJ9Y}O \\nUO \\nSasUeYD \\nPaysanbai \\nJo \\npeduil \\nau} \\nazAjeuy \\nB/E \\nJUBWINDIOP \\n|[01}UOD-BSUELD \\n3U} \\nUl \\nSASUeUD \\nPo}senbai \\nJUaWINIOG \\nDis \\ndA}eUISaIdod \\nssaulsng \\ndy} \\npue \\nYadxe \\nJayewW \\npafqns \\nay} \\nYUM \\ns}UaWauINbas \\npaloid \\nay} \\nMalAaY \\nOLE \\naAjejUasaidas \\nssaulsng \\nay} \\npue \\nJOSUOdS \\nssaulsng \\nay} \\nUM \\nSanss! \\npue \\nSWa|goid \\nMaIAdY \\nc/E \\na|doad \\nssauisng \\n3u} \\nyyM \\nSauanb \\npue \\nsyodas \\nMalAay \\nple \\nO9€ \\n‘ESE \\n2df}0}01d \\nay} \\na}e4}suOWag \\nELE \\nLOE \\nuoHed!|dde \\n|g \\nay} \\nJO} \\nSa}eLUISa \\n}SOD \\nPU \\nALU} \\nBY} \\nayepIeA \\nGe \\nLOE \\neyep \\nadinos \\nAyip \\num \\nsanss! \\nAue \\njuawind0q \\nLZE \\nLOE \\nSUOIJDUNJ \\nJ9UJO \\nJO \\nS9IEJJ9}U! \\nBY} \\nYM \\nSanss! \\nAue \\nJUaWINDOG \\nOLE \\nLOE \\nsalanb \\n10 \\nsyiodas \\nau} \\nUM \\nSanss! \\nAue \\nJUauNnd0q \\n69€ \\nLOE \\nJOO} \\n84} \\nYUM \\nSWa|qoid \\nAue \\njUatuNd0g \\n89E \\nQ99€ \\n‘SOE \\n‘HOE \\nSUOI}IUNJ \\nJ9Y}O \\nJO \\n‘SadejJ49}U! \\n‘SAaaNb \\n‘syioda \\nysay_ \\nLOE \\nSUOIPUNJ \\nJ9YIO \\nJO \\nS9dEJJa}U! \\nJO \\nJaSqns \\npayajas \\ne \\naM \\n99¢€ \\nsalianb \\njo \\nJasqns \\npayajas \\ne \\naM \\nSOE \\na \\na \\nee \\nSIOSSAIAPAId \\nQUIDN \\nSDL \\nal \\nee \\neee \\nEISELE \\nIE \\nET \\nEI \\nIEEE \\nAEE \\nIE \\nSEES \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 538}, page_content='505 Work Breakdown Structure \\n—— \\nSSS \\nSdl}}US \\nJEP \\nLjOW \\n[Je \\nUBaMjaq \\nSdiysuoHejas \\nJy} \\nBUIjaq \\nSLv \\nSol}}U9 \\ne}ep \\nCJOW \\n|/e \\nIUIjoq \\nLIV \\nSol}}U9 \\nE}LP \\nPJOW \\nJY} \\nQWeN \\nOl \\n807 \\nSof}}Ud \\nB}ep \\nej \\n[je \\nsqudseaq \\nSLD \\nP}ep \\nC}IUWI-L}ILW \\nJY} \\na}eaID \\ntly \\nweiseip \\ndiysuoiejai-Ayjua \\nue \\nMeg \\nEly \\nS9l}]}U9 \\nEJP \\nLOW \\nJEDIUYII} \\nPue \\nSsausng \\nJO} \\nSajnquye \\na}easD \\nZLv \\nS9I}}US \\nEJLP \\nEJB \\nJY} \\nUBIMjaq \\nSdiysuO}ejas \\nJU} \\nJUIWAIEq \\nLv \\nSal}I}US \\nEJP \\nJW \\n[EDIUYII} \\na}eaID \\nOlv \\nSalj}JUa \\ne}ep \\nE}AW \\nSsaulsng \\na}ea/D \\n6017 \\nZOv \\n‘€6E \\n‘SBE \\nJ@pOwW \\nea \\n[ed1TO] \\nBY} \\na}ea1D \\n800 \\nMioysodai \\neyep \\ne}awW \\nay} \\nWO \\npadnpoid \\naq \\npinoys \\nsyodas \\nyeym \\naulwwayaq \\nLOv \\nUO]UN} \\ndjay \\naAIISUas-}X9}UO) \\ne \\nJO \\nAjjiqisea} \\nau} \\nazAjeuy \\n901 \\n(IW.LH \\n‘4Gd) \\nelpat \\nadejJa}u! \\nssadde \\nay} \\nAyuapy \\nSOV \\nsjuatwasinbas \\nAyndas \\ne}yep \\ne}BW \\nJU} \\nMaIAdY \\nvOv \\nsjuawiasinbas \\nSujpodad \\npue \\nssadde \\nAuoysodas \\neyep \\neyawW \\nJeUISLO \\nayy \\nMalAay \\n€Ov \\nWire \\nsyuauadinbas \\nSupsodai \\npue \\nssad.e \\nAuoysodai \\neyep \\ne}awW \\nay} \\nazAjeuy \\nZOv \\npnpoid \\nMoysodai \\neyep \\neyaw \\nau} \\nU! \\najgeylene \\nase \\nsainyeay \\nodxa \\npue \\nWodui \\nyeum \\nQUIWWI9}9q \\nLOv \\n$]OO} \\nasa} \\nUI \\najqejleAe \\nase \\nSainjyeay \\nYOdxa \\npue \\nYWOdwI \\n}eym \\nauIWa}aq \\nOOr \\nJ00} \\nSululwW \\neyep \\nay} \\nazAjeuy \\n66E \\n$}00} \\nAuanb \\npue \\nsia}uM \\nYoda \\nazAjeuy \\n86E \\n$100} \\ndV10 \\n‘114 \\n‘4SVD \\nazAjeuy \\nL6E \\nSaHeUO!DIP \\nSWIG \\nazAjeuy \\n96¢ \\nsyaayspeaids \\npue \\nsajlj \\nBulssad0id \\npom \\nazhjeuy \\nG6E \\nS901NOs \\ne}ep \\ne}aWI \\nBY} \\nazZATeuy \\nv6E \\niZ2 \\nA1oysoda, \\neyep \\nea \\nBY} \\n10} \\ns}UaWasINbad \\n3dPH9}U! \\n9y} \\nazAjeuy \\n€6E \\nL6E \\nsasueyp \\nAue \\n}aljaJ \\n0} \\nJUaWINIOP \\nS}UatWauINbal \\nUOHeDI}dde \\nou} \\na}epdn \\n76E \\nOGE \\nSa|qeJanljap \\nAsoyisodas \\neyep \\ne}3W \\nay} \\nAZO \\nL6E \\nS10SSAIAPAId \\ndUIDN \\nYSDL-~—s \\nQI \\n—_—_ \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 539}, page_content='APPENDIX 506 \\n(Sia}UM YOdad ‘dV10 “1.L3) SUOHEPLWUI| OO} BUILA}9q 90 SUOH}EYWUI] WUO}e]d JUIWA}Iq Stvv spouiad Suljodas [euoseas pue Yead du} dUIWA}0qG vr suolijndexa Auanb pue yodai Jo Aduanbay dy} SUILWa}aq Err \\na]doad \\nssauisng \\njo \\nUOI}edO] \\nBY} \\nJUILA}aq \\nZvv \\nsasesn \\naseqej}ep \\nJUAUNIUOD \\nJO \\nJaqUINU \\npapelojd \\naU} \\ndUIWA}eq \\nIvy \\nSIOPEL} UYMOIS PUL SALWNIOA e}ep papalosjd aUuIWW3}9q Ovr s}UdWaIINbas Ayndas eYeEp MAIAdy 6EV s}UaWaJINbas SulAJanb D0Yy pe UMOUY MalAdy Sev S}UdWJINbas SuIAJanb payie}ap MalAoYy LEv s}UdWadINbas SUIOdas pajieyap MIIAIY Of \\ns}UaWatInbad \\nsiskjeue \\npue \\nssadde \\npajiejap \\nMIINIY \\nSEV \\nsynsad \\nSUIdA}O}OJd \\nay} \\nMaIAaY \\nvev \\nSUOHEDIDads \\nSUISUBaD-2}eP \\nJY} \\nMAIADY \\n€€p \\nELE \\n‘60E \\ns}UdWa4INba. \\nssadde \\nEJP \\nJY} \\nMIIAZY \\nZEV \\nusisaq \\naseqe}eq \\n:g \\ndais \\nLev \\n€@v \\nsdiysuoljejas \\npue \\n‘saynquye \\n‘saiyuUe \\neyep \\ne}AW \\nJO} \\nSajMI \\nSSauIsNg \\nay} \\nauUJaq \\nO€r \\nsayNquyYe \\nejep \\neo \\nJO} \\ndiysIaUMO \\ndUIJaG \\n67 \\nsaynquye \\neyep \\neyaw \\n10} \\nAyndas \\nay} \\nsuyaq \\n87 \\nsaynquye \\ne}yep \\ne}oW \\nJO} \\nUIEWOP \\ndU} \\nJUIJaG \\nltv \\nsainqupe \\nejyep \\njaw \\nJO} \\nYYSuUa] \\npue \\nadA} \\nauyaq \\n97 \\nsoynquye \\nejyep \\nejolu \\n|]e \\nJUljoq \\nSCV \\nSsopNquHYe \\nejep \\nCjoOW \\nJY} \\nIWeN \\nvCV \\nGly \\nsaynqiiye \\neyep \\neyaw \\n|e \\naqLIsaq \\n€@v \\nSdl}}US \\nEJP \\nJAW \\nJO} \\nDWINJOA \\ndua \\n7? \\ne}yep \\nC}OW \\nJO} \\nSSOUIJAaLU} \\nBULLAG \\nL7v \\nSaljua \\neyep \\neyawW \\n10} \\nUOI}EdO] \\n[ed1ISAYd \\naU} \\naULIaG \\nO07 \\nSal}I}JUd \\nE}EP \\ne}BW \\nJO} \\nAyUNDAS \\ndU} \\nBUIG \\n6Lv \\neee \\nEEE \\nee \\neee \\nS10SSA2aPAId \\naWIDN \\nXSDL~~—s \\nZI \\nSS TE \\nI \\nIE \\nA \\nEEE \\nEEE \\nEEE \\nIR \\nAE \\nEET \\nI \\nEGS \\nEE \\nREE \\nSIE \\nI \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 540}, page_content='SSS \\nSs \\nN \\nin \\nsdnois \\naseso}s \\nauijaq \\nvLv \\n(1aq) \\nesensue] \\nuouyap \\neyep \\nay} \\na}ea15 \\nely \\nZ9v \\nsasegeyep \\njade} \\n1g \\nay} \\npling \\nZLv \\nSWAG \\n24} \\nAq \\npadiojua \\nag \\n|JIM \\nAWBajU! \\n[eHUDIAJaI \\nJAYJIYM \\ndUIL|IAQ \\nLLv \\nAsayeus \\nSurxapul \\nayeudoidde \\njsow \\nay} \\naulwiajag \\nOLY \\n9ZISYIO]G \\nJU} \\nJAS \\nO} \\nASL] \\nMOY \\nBUILWIa}9q \\n690 \\naue|2ap \\n0} \\nadeds \\nJajjnq \\nYONW \\nMoy \\ndUIWJa}39q \\n89r \\n8SOOUD \\n0} \\nadeds \\n391} \\nYONW \\nMOY \\ndUILWa}9aq \\n19 \\nSYSIP \\najdhyjnw \\nssoude \\nsajqe} \\nay} \\nUOT \\nWed \\n0} \\nMOY \\nauUIWa}aq \\n9917 \\nSYSIP \\n9dLyS \\n0} \\nMOY \\nSUIWA}9q \\nSOv \\nSjasejep \\njo \\nJUaWAade|d \\ndU} \\nBUIWA}aq \\nvor \\nS3]Ge} \\nJY} \\nJa}SNID \\n0} \\nMOY \\ndUIWWAa}Iq \\n€9r \\nLSv \\nsain}onjs \\naseqe}ep \\njerisAyd \\nay} \\nUsIseq \\nZOv \\n6Sv \\nJOPOW \\neyep \\nJe/8o] \\n3y} \\n0} \\nSjapoww \\neyep \\njed1sAyd \\nay} \\ndew \\nLov \\n6S \\nSJapowW \\ne}ep \\njed1sAyd \\nay} \\n10} \\nEyep \\neyaWW \\n[ed1UYI9} \\nay} \\na}e3/5 \\n09r \\n(swieiseIp \\nUSISap \\naseqeyep) \\nsjapow \\neyep \\njedIsAUd \\nay} \\na}easD \\n6S \\n(diysuonejas-Ayua \\nJO \\nJ2UO!|SUSWIPI}NW) \\nSeWUaYIS \\nUBIsap \\naseqeyep \\nayeudoidde \\nau} \\naulWajaq \\n8S \\nLev \\n‘SEV \\nsaseqe}ep \\njasJe} \\n|g \\nau} \\nusIsoq \\nLSV \\npapeau \\nag \\n|IlM \\n(sdiysuojejas \\nAyQuUa) \\nsdiysuonejas \\nssauisng \\nAuew \\nMoy \\nauIWWa}aq \\n9S \\n(0y \\npe \\n10 \\nUMOP-||LP) \\npassadde \\naq \\n|IIM \\ne}ep \\npayleyap \\nay} \\nMOY \\naUII|}EG \\nGSv \\npapaau \\n(Ajejnuedsg) \\njle}ap \\nJo \\nJaAa] \\naU} \\naUIWaIAG \\nvSv \\nv \\nJ0}e1}S|UJLUpe \\nB}eP \\nIY} \\nYUM \\nJePOW \\neyep \\n[ed13O] \\n9YU} \\nMAIADY \\nESV \\n= \\nSUOISUaLUIP \\nSuljJOdaJ \\npasn \\nAjuanbay \\nysow \\nay} \\naUIWaIaq \\n7S \\nS \\nsoda \\nSuljsixa \\n8uowe \\nswayed \\nSunsodas \\nuowWWOD \\nMOAIAdY \\nLSv \\n“ \\nadAjojoid \\nay} \\nyo \\nsuoouny \\ndn-jo1 \\npue \\nUMOp-||LIp \\nay} \\nMaIAaY \\nOS \\n2 \\nadAjojod \\nay} \\nAq \\npasn \\nsuolsuawip \\nau} \\nMalAay \\n60 \\n= \\nadAjoyod \\nay} \\nAq \\npasn \\n(s}e}) \\nsaunseaw \\nMaIAay \\nStL \\n5 \\nELE \\n‘BOE \\ns}uawasinbas \\nUoHeZeWUNs \\npue \\nUOHeSa13Se \\nay} \\nSUILIa}9q \\nLov \\nx \\n—_—_eeoee”::_— \\naa \\n$ \\nS10SS3I2PI1d \\nQUIDN \\nYSOL~—s \\nQI \\n_—_ \\nSs \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 541}, page_content='APPENDIX 508 \\nI \\nSEE \\nSESS \\nOS \\nSES \\nSES \\nSS \\nSR \\nSR \\nSS \\nEE \\nEGE \\nAEF \\nSWEISOIA \\nUl \\nSJE \\nTOS \\n[Je \\nFUI[Wed1}S \\nPUe \\nMAaIAaJ \\n0} \\nULI \\n€0S \\nL6v \\nsusisap \\nAianb \\nay} \\naun} \\npue \\n10}1UOW \\n0} \\naiedaid \\nZOS \\nAiessadau \\nJI \\n‘SadIpul \\n[EUOHIPpe \\nppe \\nO} \\nUejd \\nLOS \\nSELUALDS \\nUBISAP \\naSeqe}ep \\nJU} \\nSUIJoJ \\nO} \\nULI \\n00S \\nuoHepeisap \\nsdUeUOJJed \\nasouselp \\n0} \\nAyIyN \\nSULOPUOW-sdUeWWOLed \\ne& \\nasn \\n0} \\nULId \\n660 \\nauw}uNJ \\nye \\nSauanb \\npue \\n‘syiodas \\n‘speo| \\n1LJ \\nJO \\nBUeUOPad \\nJU} \\nJOWUOW \\nO} \\nULI \\n86r \\nL6v \\nsudISap \\naseqe}ep \\nay} \\nBUN} \\npuke \\nJOWUOW \\n0} \\naedald \\n16 \\nSAIPAN \\nSULOWUOW \\nIdUeUOJJad \\n10} \\nainpadojd \\npuke \\nJo \\nAduanbad \\nay} \\nauyaq \\n96 \\nSage} \\npoUawsed \\n10} \\nSaInpad0Jd \\nUO}eZIUeSIOSI \\nBUIAG \\nG6V \\nsainped01d \\nAla@AOD9J \\nJ3}SeSIP \\nBUIOG \\nv6 \\n(sdnydeq \\n|e}UawWeJDU! \\npue \\n|jNJ) \\nsdnydeq \\naseqeyep \\nauijaq \\n£6 \\nSdIAIIe \\nBULUAJUIEW \\naseqe}ep \\nauyjaq \\n760 \\n€8v \\nsainpadojd \\nadueUa}UIeEW \\naseqe}ep \\ndojanaqg \\nL6v \\n887 \\nSQD/PUl \\nBY} \\nping \\nO67 \\n€8v \\nSainjoniy}s \\naseqeyep \\njedisAyd \\nay} \\n0} \\nAyoujne \\nJUeIs \\n0} \\n1DG \\nau} \\nUNY \\n687 \\nELV \\nsainjomijs \\naseqejyep \\njedisAyd \\nay} \\n3}e919 \\n0} \\n1Gd \\nuy} \\nUNY \\n88 \\nSCI \\ndnous \\na}endoidde \\nay} \\n0} \\nsweisoid \\npue \\n‘sjsAjeue \\nssauisng \\n‘siadojanap \\nUSIssy \\n180 \\nSCI \\ndnous \\n0} \\nAyoujne \\n(ajajap \\n‘a}epdn \\n‘peas \\n‘ayea19) \\nNUD \\nyWe!D \\nO8v \\nsq| \\ndnous \\ndn \\njas \\nS8v \\nFTAVLSAS \\nAyUNdas \\nau} \\nJO} \\nSuaJaWeJed \\nauyaq \\nv8v \\nELp \\n(19) \\nasensue] \\njo4}U0) \\neyep \\nay} \\na}ea1 \\n€8v \\nO8r \\nSadIPU! \\nBUIJaq \\nZ8P \\nO8r \\nsKay \\nUSI9J0} \\nBUaG \\nL8v \\nskoy \\nAiewud \\nauyaq \\nO8r \\nSUWWNIOD \\ndUIJaq \\n6Lv \\nsajqe} \\nauljaq \\nSL \\nsaoedsajqe} \\nsuyjoq \\nLLYv \\nsuoiped \\nauyjaq \\nOlt \\nsaseqe}ep \\nauljaq \\nSLY \\nS1OSSA2aPIJd \\nQUIDN \\nYSDL_~—s \\nI \\nNEE \\nnnn \\nenn \\nnnn \\nnn \\nnn \\nnnn \\nnn \\nnnn \\nnnn \\nnnn \\nSSS \\nSSS \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 542}, page_content='509 Work Breakdown Structure \\n—_e—e_e_e_eeeee—————————— \\nS9]qe} \\npuke \\nsajlj \\nYOM \\nJUSUeLad \\npue \\nAre1odu9} \\n[Je \\nAjyuap] \\nZES \\nssad0id \\n73 \\nau} \\nul \\ndays \\nasa \\npue \\nYOS \\nay} \\naUILIa}aq \\nLES \\nB}EP \\n9} \\nPeo] \\npuke \\n‘asuea|> \\n‘WOJSUEJ} \\n0} \\nBDUANbaS \\nJUAIDIJo \\nJSOW \\nJY} \\nSUILA}9Q \\nO€S \\nB}EP \\n9dINOS \\nEL1}X9 \\nO} \\nBDUANbAS \\nJUIIDIJJa \\nJSOW \\nSU} \\nDUILUA}AQ \\n67S \\nvZS \\n‘LOS \\nMO|J \\n$$a201d \\n7,19 \\n3U} \\nUSISAq \\n87S \\n97S \\nUIHUM \\naq \\nJsNW \\napod \\nWo}snd \\nAuejUaWajddns \\n}euM \\nduUILa}aq \\nizs \\nETS \\n3180] \\nUOHeWUOJsUeJ} \\npauinbas \\nay} \\nUUOJJad \\nUBD \\nSUONDUNJ \\n{00} \\n74 \\naU} \\nJOYJOYM \\nBUIWWI}3aq \\n97S \\nOLS \\njuaWNdOp \\nSulddew \\n3331e}-0}-9uNOs \\nay} \\nUI \\nSUOHeIYDads \\nUOHeWOJSUe \\nBU} \\nMaIAay \\nG7G \\nL677 \\nSUO!UNJ \\n[00} \\n7174 \\n9} \\n}sSaL \\nVCS \\n(s}UNOD \\nJUNOWe \\n‘s}uNOD \\nUJELUOP \\n‘s}UNOD \\nP4OAJ) \\n$}2}0} \\nUOHEI[IDUOIAI \\n104 \\nI1BO] \\napN|ou| \\ne7e \\nS}UNOD \\nUO!Pe{eJ \\np1OIaJ \\nPUL \\nSaBeSSaW \\nJOA \\nJO} \\n1ZO] \\napN}ou] \\nreas \\n(SW \\n2u} \\nAg \\npauojiad \\nyou \\n$1) \\nAyUSayU! \\nJenUaJajos \\nSuPPaUD \\n104 \\n3130] \\napnpu| \\nLZ7S \\nULUNJOD \\nYea \\nJO} \\nSUOH}EIIJIDads \\nBulsuea|d-e}ep \\napnjdu] \\nO7ZS \\nSWY}OS|e \\nUOHeZUeLULUNS \\npuke \\nUO}eSaIS8e \\napnjduy \\n6LS \\n(Papaau \\n}1) \\nSULUNJOD \\najdyjnW \\nssoiDe \\nyUaLUA]a \\nE}eP \\nBUD \\nWO \\n}Ud}UOD \\neyep \\nyWIdS \\n81S \\n(Papseu \\nJ!) \\nSaduNOs \\najdhjnwW \\nWOY \\n}Ud}U0D \\ne}ep \\naUIqUIOD \\nZS \\nGIS \\n‘PLS \\nSULUNIOD \\nay} \\nSuNeINdod \\n10} \\nsuoHeIyDads \\nUOMeULIOJsUeI} \\nJILIN \\nOLS \\n}UIWa|a \\ne}ep \\nadinos \\nAlana \\nJO} \\ny}Sua] \\npue \\nad} \\neyep \\nIs! \\nSLS \\nULUNIOD \\nJade} \\nAJaAa \\n10} \\nYYSua] \\npue \\nad} \\neyep \\nisi] \\nrls \\nULUNIOD \\n38812} \\nAlaAa \\n10} \\nS}JUaWAaja \\neyep \\n3d1NOs \\nJURAAI—aL \\n[]e \\nIST] \\nSIG \\n9/qe} \\n39812} \\nAlana \\n40} \\nSaseqeyep \\nadinos \\npue \\nsajly \\nadunos \\najqeaijdde \\nWe \\n3S!17 \\nas \\nSUWUNOD \\nJas1e} \\nPUL \\nSa]qe} \\nJaBIL} \\n[Je \\n10} \\nXUJeLU \\ne \\na}eaID \\nLIS \\nS}UBWa]a \\nB}LP \\n9d1NOs \\n10} \\nsuOHedYIDads \\nBulsuea|d-e}ep \\n9u} \\nMalAadY \\nOLS \\nSOSEQE}LP \\nBANOS \\n34} \\nJO} \\nSyDO]q \\nUONdLDsap \\ne}ep \\nay} \\nMAaIAaY \\n60S \\nSOI} \\nIDINOS \\nBY} \\nJO} \\nSyNOAe] \\nP1OI91 \\nBY} \\nMAIADY \\n80S \\nL6v \\nyuawNdOp \\nSulddew \\n333.1e}-0}-3D1nOs \\nay} \\na}ealD \\nZOS \\nUSISaq \\nPOT \\n/WOJsUeLL \\n/19e.1}Xq \\n:6 \\ndais \\n90S \\nuolndaxa \\nAuanb \\njayjesed \\nazijiyn \\n0} \\nUeld \\nGOS \\nAiessadau \\njI \\n‘S]00} \\nd¥10 \\n10} \\nsauanb \\nySnoiu}-ssed \\n3M \\n0} \\nUL} \\nvos \\nS10SSAIBPAId \\nQUWIDN \\nYSDL~—s \\nGI \\na \\nes \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 543}, page_content='APPENDIX 510 \\nSSS \\nSS \\nSE \\nSS \\nSS \\nSR \\nSSS \\nSSS \\nSSR \\nSSS \\nSS \\nEE \\nEET \\nTD \\naseqejep \\nAsopsodal \\nejep \\ne}aW \\n9} \\nJO} \\n1Gq \\nay} \\na}ea/D \\nLOS \\nJ9POW \\nE}JAW \\n[ed!/SO] \\nBY} \\nO} \\nJapOW \\nEyal \\njedIsAUd \\nau} \\ndew \\n09S \\n(pa}UdHO0-}afqo \\n10 \\ndiysuosejas-AyjUa) \\nWeISeIP \\njapOW \\nejJawW \\njed1shud \\nay} \\nMeIG \\n6SS \\n(pa}UIHO-Dalqo \\n10 \\ndiysuoejas-Aj}Ua) \\naseqe}yep \\nAso}sodas \\neyep \\ne}JaW \\nay} \\nUBISEq \\n8SS \\nAsoysodas \\ne}ep \\n&}BW \\nJY} \\nJO} \\nJAPOW \\nCJS \\n[eIISO] \\nBY} \\nMalADY \\nZSS \\nvLV \\nasegejep \\nAsojisodai \\nejyep \\nea \\nAY} \\nUSISIG \\nOGG \\nusisaqg A1oysoday eed BIN :0L dais = SG \\nLSS \\nsainpad0jd \\nSUIUOISJaA-WeIZOId \\nYsi|qe}sy \\nSS \\nLSS \\nsauesql| \\nWesisold \\na}ealD \\n€GG \\nLSS \\nS3]qe} \\npue \\nsal} \\nYIOM \\nJUBUeUEd \\npue \\nAe1OdWAa} \\nJ0j \\nadeds \\na}ed0]|¥ \\nCSS \\nJMS \\n119 \\n2u} \\ndn \\nyas \\nLSS \\nSS9D01d \\nLJ \\n9Y} \\nBINqUISID \\n0} \\nMOY \\nPUe \\nJAYJOYM \\nJUIWIIEq \\noss \\n87S \\nease \\nSUIZe}s \\n714 \\nay} \\ndn \\nyas \\n60S \\nLvS \\nsuo}}eo \\ndads \\nSulluWeIsOld \\nOJU! \\nSUOHeIYIAds \\nUO}EWUOJSUeI \\nJY} \\na}e;SUeLL \\n8rS \\nswe1s0Jd \\n119 \\n9} \\naZUe;NpO|!y \\nLvs \\nSWEIZOId \\nPeO| \\n[eE}UIWIIDU! \\nBU} \\nUSISAg \\nOVS \\nSWEISOJd \\nPeO| \\n|EDUO}sS!IY \\ndU} \\nUSISAG \\nSvs \\nSWEISOI \\nPeO| \\nJel}U! \\n3y} \\nUSISAg \\nvrs \\nsWeIdO1d \\n71J \\nJO \\nS}as \\n3a14} \\nUSISaq \\n€vS \\n87S \\nswieis0ld \\n7,17 \\nay} \\nUsIsaq \\nZvS \\nSolin \\npeo] \\npue \\nsoaji} \\npeo] \\nay} \\nMOUS \\nLvs \\nSUOdal \\nJOUa \\npuke \\nSaif \\nUOI}DAfas \\nJO \\n9Yy} \\nMOUS \\nOvs \\nSWEIBOJd \\nUO!}EWIOJSULJ} \\nBU} \\nMOUS \\n6ES \\nSassad0ld \\na8jalu \\npue \\nOS \\nay} \\nMOUS \\nQEG \\nS9jqe} \\npue \\nsajl} \\nYOM \\nJUaUeUIad \\npue \\nAJeJOdWwa9} \\n3}ed1pU] \\nLES \\nSOSeqe}ep \\nBDINOS \\nPUe \\nSaji} \\n9DINOS \\nLUO \\nS}DLI}X9 \\nJU} \\nMOUS \\n9ES \\nVES \\n‘EES \\nWeISeIP \\nMOL \\nSSad01d \\nay} \\nMeig \\nGEG \\njajfeaed \\nul \\npapeoj \\naq \\nued \\nsajqe} \\nyeUM \\ndUIWIA}13aq \\nves \\njajesed \\nul \\nuns \\nued \\nssad0id \\n714 \\n3U} \\nJO \\ns}UaUOdWOD \\nyeYM \\naUIWAa}ag \\nSG \\n$10SSa2aPaId \\nQWDN \\nYSDL~ \\n=I \\nNene \\nnnn \\nnnn \\nnnn \\nnner \\nnnnnnnncnnnnccnnencceeeeeeecceeeeeeeeeeeeeeeeeeereeeee \\nener \\nSSS \\nSSS \\nSSS \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 544}, page_content='511 Work Breakdown Structure \\n—_ee_—_ee———— \\nUO!}UN} \\ndjay \\nduUI|UO \\nSANISUaS-}X9}UOD \\nJU} \\nUSISAaq \\n68S \\nSS9901d \\nBDeJJ9}U! \\nSSaDIe \\nJU} \\nUZISAag \\n88S \\nsyinsaJ \\nAuanb \\ndoy \\npe \\neyep \\nejaw \\nSulAejdsip \\n10} \\nelpaw \\nau} \\nusIsaq \\nZ8S \\nsweisoid \\nyoda \\nAuoysodai \\neyep \\nejaw \\nay} \\nuSIsaq \\n98S \\n9S \\nuonesiidde \\neyep \\nea \\nay} \\nUSISaq \\nSs \\n08S \\nsuo}yedyi9ads \\nSujwiwessoid \\npeo; \\nAuoysodai \\neyep \\neyawW \\naM \\nv3s \\n6ZS \\nsuoHedyioeds \\nSulwwessoid \\nUOHeUUOJSUE \\nIU \\n€8s \\n8ZS \\nSUOHEIIDads \\nSUIWILUEIBOJd \\nBde}19}U! \\nJOO} \\ndL \\n78S \\nssad0id \\nUONeASIWU \\neyep \\nEa \\nBY} \\n10) \\nSUOHeIYDads \\nSurwmuesSoid \\nayy \\n31UM \\n18S \\nMioysodai \\neyep \\nea \\nBY} \\n10} \\nSueZOId \\npeo] \\nay} \\nUSISAag \\nO8S \\nB}EP \\nEJOW \\nPI}IL1}X9 \\nBY} \\nJO} \\nSUOEWOJSULI} \\nBU} \\nUZISAaq \\n6ZS \\nSS9DO1d \\nBdLJ19}U! \\n|OO} \\nJU} \\nUZISAag \\n8S \\nB}EP \\nJAW \\nJEI!UYI9} \\nSUIDEI}Xa \\nOJ \\nSadiNOS \\n[Je \\nazAjeUuY \\nTIS \\ne}ep \\neJaW \\nSSaUISN \\nBUI}DEI}Xa \\n10} \\nSAdINOS \\n[Je \\nazAjeuy \\n9/S \\nS9S \\n‘9GS \\nssa201d \\nuOHeISIW \\ne}ep \\nEBL \\n9Yy} \\nUSISag \\nGTS \\ne7G \\n~npoid \\nAsoysodai \\neyep \\ne}aW \\ndy} \\n}Sa} \\nPUe \\n|]e}SU| \\nZS \\nGUS \\nynpoid \\nAioysodai \\neyep \\ne}aw \\nay} \\nasuadq \\nEJS \\nSIIUBIIJOA \\nJUD! \\nSIOPUBA \\nBU} \\nyI9UD \\nZLS \\nsoweap \\njnpoid \\nAioysodas \\ne}yep \\ne}aW \\n10} \\naSUeLIY \\nLZS \\n69S \\n‘89S \\n}SI] \\nHOYs \\n& \\nO} \\nSIOPUSA \\npuke \\ns~npoid \\nAyoysodas \\neyep \\nL}aW \\nJO \\n}SI] \\nJU} \\nMOEN \\nOLS \\nJopuan \\nAioysodad \\neyep \\ne}aW \\nPayenjers \\nDea \\n10} \\np1eddIODs \\ne \\na}e01) \\n69S \\npnpoid \\nAio}sodas \\neyep \\neyawW \\npayenjerd \\nUdea \\nJO} \\np1ed9109s \\ne \\na}ealD \\n89S \\nsjuatwalinbas \\nAuoysodas \\neyep \\naw \\nau} \\n0} \\ns~nNpoid \\nAioysodal \\neyep \\neJaW \\nay} \\naledwo7 \\n29S \\nSIOPUDA \\npuke \\nsPnpold \\nAloysodai \\neyep \\ne}aW \\njo \\n3sI| \\ne \\nalIdwoD \\n99S \\ntlt \\npnpoid \\nA1o}soda, \\neyep \\nea \\n94} \\n}S9} \\npue \\n|]e}SU] \\nGQOS \\nSainpadoid \\njeAlydie \\npue \\nSUJUOISJaA \\nUSISAaq \\n9s \\nseinpad0jd \\nAlaAoda1 \\npue \\ndnydeq \\nuSisaq \\n€9S \\naseqejyep \\nAloysodas \\ne}ep \\neJAW \\n3} \\n10} \\n7D \\ndU} \\naya! \\n79S \\nSIOSSAIAPAId \\nOUIDN \\nYSDL \\nal \\n™ \\nCEE \\nes \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 545}, page_content='APPENDIX 512 \\n}S9} \\nUOH}E|NWIS \\nEC \\nUNI \\nPU \\nS}UBUDGWOD \\n}S$9} \\nBUYSP \\nJOO} \\nUO!}E|NWIS \\n}S9} \\nSSaJ}s \\ne BuISN \\nJI \\nZL9 \\nBUI}S3} \\nIDUEWUOJad \\nJO} \\nEJEP \\nBWINIOA-||N} \\nasN \\n919 \\nsuolesodo \\npayed||dwod \\nWuojJad \\nyeu} \\nsajnpOW \\n{OO} \\n114 \\npue \\nswessoid \\n719 \\nay} \\nySaL \\nG19 \\nSa]qe} \\nALINJOA-YslY \\nJSUIeEse \\nSajnpOW \\n{OO} \\npue \\nsweISOJd \\nTL \\nJO \\nUONDaxa \\nJayjesed \\nay} \\nIsa \\nvl9 \\nS9]qe} \\nSLUNJOA-YSIY \\nO} \\nd}UM \\nJO \\npeal \\n}eU} \\nSajNpOW \\nJOO} \\npue \\nswesZoJd \\nTJ \\nJenpIAIpul \\nsay. \\nE19 \\nvo9 $$9901d 14 9} }S9} IUPULIOLad ZLO \\nOL9 \\npua \\n0} \\nSUJUUISaq \\nWOJ \\nSSad01d \\n79 \\ndUI}Ua \\nJU} \\n4Sa}Oy \\nLLO \\n609 \\n(]00} \\nTLF \\nBY} \\n40} \\nSUOINAJSU! \\nBY} \\n10) \\nSWeIBOId \\nTLJ \\nBU} \\nBSIABY \\nOL9 \\n909 \\n‘S09 \\nS}[NSaJ \\n}S9} \\npa}adxa \\nYUM \\n$}NsaJ \\nsa} \\nJenpe \\naiedwoy \\n609 \\n909 \\n‘SO9 \\nsanss| \\nSa} \\nAue \\nJUBWUINDIOP \\nPUE \\nS}[NSaJ \\n}s9} \\nJeEN}De \\nJU} \\nSOT \\n809 \\n909 \\n‘SO9 \\nSSOD0I1d \\nLJ \\nJd1}UA \\nBU} \\n}S9} \\nUOISSAISAI \\nJO \\nUOIEIS9}U] \\nZ09 \\nSWeISOId \\n714 \\nSU} \\n10} \\nB}eP \\nsd} \\no}eaID \\n909 \\nSSad0Jd \\nTJ \\nBU} \\nJO} \\nSASED \\n359} \\nUUM \\nUe \\n}Sa} \\nBe \\na}RAaID \\nS09 \\n96S \\n$$901d \\n1LJ \\nJY} \\n}S9} \\nUOISsa13—1 \\n10 \\nUOEIS9}U] \\nv09 \\nZ09 \\n‘LOO \\nSaiyan \\npeo] \\npue \\n‘asso \\n‘Os \\nay} \\npue \\nsweISOId \\nLJ \\nJY} \\n9}NDIXa \\n0} \\nS}dUDS \\nBU} \\nSIUM \\n€09 \\n009 \\n‘86S \\n3|NPOW \\nJOO} \\nTLJ \\nYea \\n}S9} \\nPUN \\n‘}OO} \\nTLJ \\nue \\nSuIsn \\nJ \\ncO9 \\n009 \\n‘26S \\nainpow \\nweisoid \\njenpiAlpul \\nydea \\n3Sa} \\nHUN \\nLOo9 \\nSdSI}e}S \\npeo] \\npue \\n‘sjowW \\nAyjenb \\n‘sje}0} \\nUOHeIDNUOIIJ \\nBdINpOId \\n0} \\napOd \\nJUM \\n009 \\nAiousodas \\neyep \\n&}9W \\nJY} \\nJO} \\ne}EP \\nEJOW \\n[eIIUUDE} \\n7.19 \\nUy} \\naunjdepD \\n66S \\nSI|NPOW \\nOO} \\n714 \\nAU} \\nJO} \\nSUONINAYSU! \\n3}M \\n‘}O0} \\n7LJ \\nUe \\nBuIsn \\n4] \\n86S \\nsweis0Jd \\n714 \\n3u} \\napo) \\nZ6S \\n60S \\n‘7VS \\n$$9901d \\n717 \\n3Y} \\n}S9} \\nYUN \\npue \\npling \\n96S \\nJUBUIdOJaAVq \\nPeOT/WUOJsUeAL/PeIYXA \\nLL \\ndais \\nS6S \\n68S \\nsuoHesyioads \\nSuluweisoid \\nuolduny \\ndjay \\nauljuo \\naM \\nv6S \\n89S \\nsuonedyidads \\nSulUWeIsoid \\nadejsa}U! \\nSSadDde \\nJIM \\n€6S \\n18S \\nsuonedyideds \\nyduos \\nAuanb \\naq \\n76S \\n98S \\nsuonedyidads \\nSulwweisoid \\nYodas \\naM \\nL6S \\nuoHesidde \\nejyep \\neyaw \\nay} \\n10) \\nsuonedyiads \\nSuswuUes301d \\nay} \\naM \\n06S \\nSIOSSIIAPIAId \\nQUWIDN \\nSDL \\nal \\nener \\nnennnennnnnnnnnnnncnnnnnnnnnnnnnnccnncnncnececeneeeeeeeeeeeeeeeeeeeeeeen \\nreece \\nSSS \\nSSS \\nSSS \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 546}, page_content='SS \\nSs \\nfaa) \\nIn \\nlv9 \\nsuonedyideds \\nyduos \\nAuanb \\naM \\n979 \\nOv9 \\nsuonedyioeds \\nSujwiwessoid \\nyoda \\naM \\nSv9 \\nsuonesydads \\nSulmueiso01d \\n3M \\nv9 \\nuolDuUNJ \\ndjay \\nauljuo \\nau} \\nUsIsag \\n€v9 \\n(leyod \\nqaM \\n‘1ND) \\nadeJ49}U! \\npuds-}U01y \\nay} \\nUSISAq \\n7v9 \\nsaianb \\njeuly \\nay} \\nUsISAag \\nLv9 \\nsuoda \\n|euly \\n94} \\nUSISaq \\nOv9 \\nL6v \\nswieis0id \\nuone \\nri \\ndde \\nay} \\nusisaq \\n6£9 \\nLE9 \\nsasueyd \\nAue \\nya|jaJ \\n0} \\nJUaWINDOp \\ns}uaWauINbas \\nUOHedI|dde \\nay} \\na}yepdp \\n8c9 \\nsjUdWaJINbad \\n~eafoid \\njeuly \\nay} \\nUO \\naaISy \\nLE9 \\nJUBUINDOP \\ns}UsWaJINbad \\nUOIedI|dde \\nJy} \\nJO \\nUOISJAA \\n}S9}E] \\nBU} \\nMAIABY \\n9€9 \\nSjaayspeaids \\nSul}sIXo \\nMAIADY \\nGE9 \\nsynoAe| \\nYodai \\ndn-y90wW \\npuke \\nBuUN}sIxa \\nMAIAaY \\nvega \\n80] \\nSANSS!I \\nBU} \\nMAlAaY \\n€€9Q \\nJUSLUNIOP \\n[O1}U0D-BBULUD \\nYU} \\nMAIAIY \\nZEQ \\ns}duds \\npue \\nswiessoid \\nSuidAjo}01d \\nay} \\nMalAady \\nLEQ \\n2dA}0}01d \\nau} \\nJO \\ns}nsaJ \\nay} \\nMaIAaY \\nO€9 \\nL6v \\ns}UsWadinbas \\nPafoid \\njeuly \\n9y} \\nSUILLIa}9q \\n679 \\nyuawdojanag \\nUuoHerI|ddy \\n:z1 \\ndais \\n879 \\n€79 \\naAHeUISaIdas \\nssauisng \\nay} \\nWOY \\nssad0id \\n7LJ \\nBY} \\nJO} \\nUOEDWIIaD \\nUIeEIGO \\n179 \\n5]2}O} \\nUOHLIIDUOIAI \\naJepI|eA \\n979 \\nSQUIINOI \\nBUI|PUBY-JOUA \\nayeplep \\nSz9 \\nv \\nSUO!}EWIOJSUBI} \\nBUISUBA]D \\n[]e \\na}JepIeA \\nvz9o \\n= \\npua \\n0} \\nSujuulseq \\nWO. \\nssad0id \\n7LJ \\na4)}Ua \\ndU} \\n}sa} \\naUL}daD.y \\n€79 \\n= \\nZL9 \\n$$9201d \\n73 \\n3Y} \\nS39} \\naduL}dady \\n779 \\npa \\n0z9 \\nuolNpodd \\nOU! \\nssad0J4d \\nLJ \\nBY} \\nBAOW \\n0} \\nye}s \\nsUONeado \\nayy \\nwo} \\nJeAOJdde \\nule}qoO \\nLZ9 \\n2 \\n6L9 \\npua \\n0} \\nSuluUIsaq \\nWO. \\nssad01d \\n719 \\naUA \\nBY} \\n3sa} \\nWO \\n0z9 \\n& \\nJUSWUOIAUS \\nYO \\n3} \\nOJ! \\nSWeISOId \\n719 \\n[Je \\nSAO \\n6L9 \\ng \\nZL9 \\n$$901d \\n1.14 \\n24} \\n3S9} \\n(yO) \\na2ueANsse \\nAyyend \\n819 \\n<1] \\n[ey \\n$ \\nS1OSS3IAPIAId \\nauUIDN \\nY¥SOL~—s \\nQI \\n_SCSeee \\n er \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 547}, page_content='APPENDIX 514 \\nSS \\nLS \\nI \\nEES \\nSE \\nSES \\nSS \\nSRS \\n7 \\nIE \\nTD \\nIII \\nEEE \\n699 \\npud \\n0} \\nSuluulsaq \\nWOd \\nUOIedI|dde \\na41}Ua \\nJU} \\n}S9} \\nBDUe}daDdY \\nGl9 \\n€Z9 \\nuolDnpodd \\nOy! \\nswWeIsOId \\nUO}eDI1|\\\\dde \\naU} \\nFAOW \\n0} \\nJe}s \\nSUOIeJodO \\nJY} \\nOJ \\nJeAOIdde \\nUle1GO \\nvZ9 \\nZ7L9 \\npua \\n0} \\nSujUUIsaq \\nWO \\nUOIedI|dde \\naiUa \\ndy} \\n1s9} \\nWO \\n€/9 \\n699 \\nJUILUUOIJIAUS \\nYO \\n3} \\nOF! \\nS}dUDs \\npue \\n‘sWeIZOJd \\n‘sasegej}ep \\ndAO \\n7L9 \\n899 \\n}S9} \\nUOHE|NUWIS \\nC \\nUNI \\npuke \\nS}USUOCWOD \\n}S9} \\nBUIJAP \\n‘JOO} \\nUOI}E|NWIS \\n}S9} \\nSSaJ}s \\n& BSUISN \\nJ| \\n19 \\n899 SUI}S9} IDUCWUOJad JO} EYEP AWINIOA-||N} asp 0Z9 \\n899 sWeIZOJd SWINJOA-YSIY X3|dWOD }S3} BDURWOPad 699 \\nZ99 \\npUa \\n0} \\nSuJUUIseaq \\nWO \\ns}dUds \\npue \\nswessoi1d \\nUONedI|dde \\nau} \\n1sa10y \\n899 \\n999 s}duds pue swessoid uolyedidde ay} asiaoy 199 \\nS}JNSaJ \\n}S9} \\npapedxa \\nYM \\nS}NSaJ \\nsa} \\nyen}oe \\naiedwioD \\n999 \\nsanss| \\n}Se} \\nAue \\n}USWINDOP \\nPUe \\n$}[NSaJ \\n}s9} \\nJeEN}De \\nJU} \\nSOT \\nS99 \\nsweisojd \\nUOlDUN} \\ndjay \\naul|UO \\n359} \\nUOISSAJBa1 \\nJO \\nUON}e139}U] \\n799 \\nSWEISOI \\nBDELJ9}UI \\nPUD-JUOJJ \\n}S9} \\nUOISSAISAI \\nJO \\nUOIEIS9}U] \\n€99 \\ns}duds \\nAuanb \\n3s} \\nuolssai3aJ \\nJO \\nUONe139}U| \\n799 \\nsweisoid \\nYoda \\n}s9} \\nUOISSaISaJ \\nJO \\nUONeIS9IU| \\n199 \\npua \\n0} \\nSuluUIsaq \\nWO. \\ns}dL9s \\npue \\nsue1ZOud \\n[Je \\n}S9} \\nUOISSa1ZaJ \\n10 \\nUOIe1Z9}U] \\n099 \\n0s9 \\nsweigoid \\nuonedidde \\nay} \\n}sa \\n6S9 \\nLS9 \\n‘959 \\n‘G9 \\n‘S9 \\nainpow \\nweisoid \\njenpiAlpul \\nyde—a \\n3S9} \\nWU \\n859 \\nSWeISOJd \\nUO!UN} \\ndjay \\nauljuo \\nau} \\napoD \\nLS9 \\nSWEISOId \\nBdPjJa}U] \\nPUS-}UOJJ \\n[EULE \\nJY} \\nBPOD \\n959 \\ns}duds \\nAuanb \\njeuly \\nay} \\napoD \\nGs9 \\nsweis01d \\nOda \\n|euly \\nJY} \\nBpoOD \\nvs9 \\ns}duds \\npue \\nsweisoid \\nSuldAyojoid \\nadueyua \\nJO \\n3}LIMay \\n€S9 \\ne}ep \\n1S} \\naj]dwes \\nYUM \\nsaseqe}yep \\nJUsWdoOjanap \\nau} \\npeo \\n759 \\ne}ep \\n}So} \\naj|dwes \\na}ea1D \\nLS9 \\n6€9 \\nswieig01d \\nue \\ndidde \\nay} \\n3s} \\nHUN \\npue \\nping \\n0S9 \\n919 \\n‘S~9 \\n30] \\n}S9} \\nE \\nPUL \\nSASED \\n459} \\nYUM \\nUeR|d \\n}Sa} \\ne \\na}eaID \\n609 \\n€v9 \\nsuoljeayideds \\nBulwuwessoid \\nUoNDUNY \\ndjay \\naul|UO \\naM \\n879 \\n79 \\nsuoljeoyidads \\nBulLUWeIsOld \\nadejJa}U! \\nPUd-]UOJ \\ndL \\n1v9 \\nssossadapald \\naWDN \\nXSOL~—s \\nGI \\nNeen \\nnnn \\nnner \\nnnnnnnnnnnnnnnnnnnncnnnnennnennceceeeeecennneeenenennn \\nnner \\neneneeeeeeeeeeeeeeeeeeeeee \\nsees \\nSSS \\nSSS \\nSSS \\nSSS \\nSSS \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 548}, page_content=\"515 Work Breakdown Structure \\nNNN \\nZOL \\nsanjeA \\neyep \\nJo \\nAyjiqeuoseas \\npue \\nAyjenb \\nay} \\nainseaw \\npue \\nsulewop \\nejyep \\nau} \\nMOIAdY \\nvOZl \\nMioysodad \\neyep \\neal \\nay} \\nWO \\ne}ep \\nEYL \\nPayejai \\nalas \\n€OL \\nJOpOwW \\neyep \\njed}Ajeue \\nYea \\n10} \\neye \\njo \\najdwes \\ne \\npajas \\nZOL \\ne}ep \\npasJalUW \\n9y} \\nJO \\nBINNS \\nau} \\nMaIAdY \\nLOZ \\nB}ep \\nJEUs9}X9 \\nYM \\ne}ep \\n[EUJd}U! \\nBBJaW \\nPue \\nUDd}e/\\\\ \\nOOZ \\nS8dINOS \\nByep \\nJEUJI}UI \\nSNOWLA \\nWO \\ne}ep \\nassay \\n669 \\n689 \\ne}Ep \\n9} \\nBSUBV]D \\nPUB \\n9}epI|OSuO) \\n869 \\nSedINOs \\nyep \\nJeuUJa}x9 \\nWOJ \\ne}ep \\nJUdUIVad \\nauInboy \\n169 \\nS9dINOS \\ne}yep \\n[EUJI}UI \\nSNOWeA \\nWO \\nyep \\nJUdUIPed \\npeRIXyW \\n969 \\n(Id \\nse \\n|JaM \\nse \\njeUO}}eJad0) \\nsadinos \\neyep \\najqejieae \\nAynuap] \\nG69 \\n689 \\nB}ep \\n9} \\naI|[OD \\nv69 \\n169 \\nluajqoid \\nssaulsng \\nau} \\n0} \\nJUeAIa1 \\nSWYWOSe \\nAyeuiwjaid \\nAyuap| \\n€69 \\n169 \\nJ00} \\nSuJUILW \\ne}ep \\nJU} \\n40} \\nSUO}e}Dadx— \\nIISI|e9/ \\n49S \\n769 \\n069 \\nUOINJOS \\nBuju \\ne}yep \\ne \\nJO} \\nJUSWIWIWOD \\nule}qgoO \\n169 \\nWwa]qold \\nssauisng \\nau} \\nsuyaq \\n069 \\nl6v \\nUW3]GO1d \\nssauisng \\nay} \\n3}e}S \\n689 \\nSUIUIIN \\n8} \\n:€1 \\ndais \\n889 \\n989 \\nSSQUIAIPOo \\nSUIUICI} \\nJINSeaj| \\n289 \\nG89 \\nSUOISSAS \\nBSUIUIeJ} \\nNpUoD \\n989 \\nv39 \\nSUOISSIS \\nBUIUIEJ} \\nJINDIUDS \\nS89 \\n€89 \\ns}nopuey \\nJUaUl}yad \\nJaY}O \\nPue \\nSUO!NIOS \\nasidJaxa \\na}e3/D \\nv389 \\nc89 \\nS9SIDJIX9 \\nYIM \\nSYOOGYJOM \\nJUSpN}s \\n3}e01D \\n€89 \\n$9}OU \\n10}NJ}SU! \\nPUe \\nSapI|s \\nUOHe}UaSaId \\na}eaID \\n789 \\nSJELI9}EW \\nSUIUIE]} \\n3}ea1D \\n189 \\npaules} \\naq \\n0} \\najdoad \\nssauisng \\nAynuap| \\n089 \\npoules} \\naq \\n0} \\nJauUOSJad \\nUOSIel] \\nSsauUIsSNg \\nJaU}O \\nJO \\n,Siasn \\nJamod, \\nAjiuap| \\n6L9 \\npoaules} \\naq \\n0} \\nHe}s \\nySap \\ndjay \\nAynuap| \\n8Z9 \\n0S9 \\nSujule} \\nsiskjeue \\npue \\nssad0e \\neyep \\napIAOJd \\nLL9 \\nGZ9 \\naAl}ejUasaidad \\nSsaulsng \\nay} \\nWO \\nUOHedI|dde \\ndu} \\n10} \\nUOEIYIID \\nUle}GO \\n9/9 \\ns4OSSaIaPAId \\nQUWIDN \\nSDL \\nal \\n'_-SSS \\no \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 549}, page_content='APPENDIX 516 \\n61LZ QCL SCZ. 6LZ GGL \\n90Z \\n‘869 \\n‘769 \\nSIZ cOZL COZ \\nsoijsize}s Aujsnpul ay} pue s}nsau sisAjeue 1NOA UdaMjaq SUOIJEULA JU} Aj}Uap| \\nsoiysize}s AujSnpul au} jo awey \\nOUI} \\nPUL \\nSI|GeUPA \\n9U} \\nJSUIeSe \\nBWI \\nSUI} \\nPU \\nSa|qeUeA \\nINOA \\nJo \\nUOIPaIas \\ndU} \\na}epI|eA \\nsoiysieys \\nAujsnpul \\npaysijqnd \\n0} \\ns}jnsaJi \\nSululW \\neyep \\nasedwoy \\nS}[NsaJ 9Yy} JO UOEPIEA [eU1I}X9 ULIO}Jad \\npapyo|dxa \\naq \\nUPD \\nUOHEWOJU! \\nMAU \\nJY} \\nUDIUM \\nUl \\nSAeM \\n9}e|NWUO4 \\nABO|OUYII} \\nUOIJEZIJENSIA \\nBUISN \\nSBUIPUI} \\nMOU \\n3U} \\n}UISId \\na]qeuolpe \\npue \\n‘pen \\n‘BUl}SA19}U! \\nJe \\nJEU} \\nS}]NSAJ \\nJO} \\nYOOT \\nS}[NSoJ \\nSUJUILU \\nEJP \\n9} \\nMalAaYy \\n$}[Nsai \\nSUIUIW \\ne}ep \\nay} \\n}a1dJ9}U] \\nJ2POW \\nJU} \\nUleJ}JaJ \\nPUL \\nUIs} \\nOF \\nsdays \\nJOUd \\nyeaday \\nsasfjeue \\nA}AlpSUas \\njndul \\npue \\nsadu}eW \\nUOISNJUOD \\nBuIsn \\nAdeiNDDe \\nSal. \\nswuy}Osje \\nayeudoidde \\nau} \\nuM \\nsuolesJado \\nSulullW \\neyep \\nalas \\nJapow \\ne}ep \\n(JeEUONeULOJU!) \\n[edAJeUe \\ndU} \\na}ea/D \\nJapow \\neyep \\njedAjeue \\nau} \\npjing \\nanbjuyde} \\n,N-}0-au0, \\nAjddy \\nanbiuype} \\n,Uoezassip, \\nAjddy \\nsanbiuyea} \\nUOeUWWOjsUueI} \\nSUIUIW \\ne}ep \\nAjddy \\nuolpnNpe \\neyep \\nAjddy \\nSddIAJBS \\nPUL \\nSPNpPOJd \\nYM \\nSJaWO}sSNd \\n9}e]9y \\nSIOWO}SND \\nPo}ejaJ \\nO} \\nJAquINU \\nPjoyasnoy \\ne \\nBulusisse \\nAg \\nsiaWO}sNd \\na}epljOsuOD \\neyep \\nyndul \\n|eulsuoO \\nWold \\nsaj|qeueA \\nMau \\ndALIaG \\npasn \\nwuywogyje \\nSulullW \\ne}yep \\nJejnNdIyed \\nJu} \\nUNS \\n0} \\ns}eUOJ \\nELEP \\naAUOD \\nSONIA \\nSBUISSILU \\nUYM \\nSa[qeUeA \\nade]|daJ \\nJO \\na}eUIWWIIA \\n2}ep \\nJU} \\nUl \\nISIOU \\nJa}J \\n0} \\nSJa}aWWeJed \\nUOINGU\\\\SIP \\nJedISHeIs \\nash \\nSa|]qeveA \\naAljey}uenb \\n10} \\nUelpaw \\npue \\n‘apow \\n‘UedW \\n‘LWNWIUILU \\n‘WUNLUIXeLU \\nMalAay \\nS9|GeUeA \\nJedI108a}e) \\nJO \\nUOHNqUIsIP \\nADUaNbasy \\nay} \\nMaIAdY \\ne}ep \\n9y} \\najedaid \\nSI]GeEUPRA \\ndAIWe \\nssoide \\nAyjiqeuoseas \\nUleWOp \\na}eplje/A \\nSSS \\nSS \\nSS \\nSSS \\nSJOSSAIAPAId \\nJUIDN \\nYSDL \\ndl \\neee \\nSS \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 550}, page_content='51 \\nWork Breakdown Structure \\n6PZ \\nSS9901d \\n719 \\nay} \\nsSuunp \\nuns \\nIIIM \\nJU} \\nSwueuSoud \\nB}EP \\nBOW \\nJY} \\nSa} \\nwun \\n8bZ \\nSWeISOId \\npeoy \\nBJP \\nBOW \\nJs} \\nay} \\nwun \\nLvl \\nSsweisoid \\nUOHEULOJSUe} \\ne}Ep \\nPIO \\nJU} \\n353} \\nWU \\nODL \\nSweISOId \\nSIPJLI9}UI! \\n[OO} \\n94} \\n3S9} \\nWU \\n1449 \\nSuunp \\nuns \\nITEM \\n3ey} \\nsuresSoud \\nP}ep \\nB}aW \\nay} \\napo) \\nAMIN \\npeo) \\nswag \\nau \\nJo \\n}npoid \\nMioysoday \\nB}EP \\nBBW \\nUy} \\nJo \\nAye; \\nUYOdul \\nay} \\nasn \\nio \\nSWeI3OId \\npeo; \\n2}eP \\nB}9W \\nay} \\napop \\nOZ \\n$s9901d \\nuoneriuy \\nPJP \\nP}9W \\n3Y} \\nsa} \\nUN \\npue \\nping \\nS8S \\n‘G/¢ \\neseqeiep \\nAiojsoda, \\n21ep \\n&}3W \\nay} \\npling \\nGey \\nH \\nUled}31 \\npue \\njapouw \\nB}ep \\njednAjeue \\ninofk \\nasuey \\n‘asueyp \\nsonsHe}s \\nAsnpur \\nUsUM \\nSJEA19}U! \\nBWI) \\nJejnZay \\n#€ \\nSdSHeIS \\nANsnpul \\nsulese \\njapow \\nB}ep \\njedAJeue \\ninok \\nSupepyen \\ndaay \\n67L \\n‘bZZ \\nSUH \\n49A0 \\nJapow \\neyep \\nJeon \\nAyeue \\n24} \\nJOyUOW \\nSUOHMPLEA \\n34} \\n10} \\nsuoseay \\n24} \\nSUlUajag \\nSIOSSAIaPaId \\nOuIDN \\nYsvy \\n8SZ Lal 9SZ 552 SZ €SZ €SZ LGZ OSZ 6vZ 8bZ Lol 9bL SbZ Dbl €vZ CrZ LpZ OvZ 6€Z 8EZ LeL Jer “per EL di \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 551}, page_content='APPENDIX 518 \\nES \\nSS \\nI \\na \\nPF \\nEEE \\nETSY \\nS8Z \\nS8Z \\nv8Z \\n€8Z \\n8ZZ 8ZZ \\nPLL \\n‘OLL \\n6SZ ‘SZ ae yd CSL LOZ O9Z OvZ \\ndA}E}UISAIda1 \\nSSAUISNG \\nay} \\npue \\nYadxa \\nJa}eW \\nPalqns \\nay} \\nYM \\nBul}sa} \\nadUe}daDde \\nJONpUOD \\ne}s SuOI}eJadO YUM BUl}SA} WO PNpuoy \\npua \\n0} \\nSuluulseq \\nWold \\nsuesso1d \\nAJoysodas \\ne}yep \\ne}OW \\ndU} \\n}Sa}9yY \\nsweis0jd \\nAioysodas \\ne}ep \\nCJAW \\nJU} \\nASIADY \\nS}JNSOJ \\n1S9} \\npoyadxe \\nYUM \\nS}NSaJ \\n}Sa} \\n[enpe \\nasedwoy \\nsanss|] \\n}Sa} \\nAue \\nJUaWINDOP \\npue \\nS}NSaJ \\n}Sa} \\n[ene \\n9} \\nSOT \\nssad0jd \\n714 \\n94} \\nSuuNp \\nund \\njeu} \\nsSWeISOId \\ne}ep \\neJaW \\naU} \\n}Sa} \\nUOISSaISaJ \\nJO \\nUONeIZ9IU] \\nsajnpow \\nynpoid \\n10 \\nuOHed|dde \\nAyopsodai \\ne}yep \\ne}BW \\ndU} \\n}S9} \\nUOISSAISAJ \\nJO \\nUONEIZ9IU| \\nssad0/d \\nUOH}eISIW \\nLJP \\nL}IW \\nJU} \\n}S9} \\nUOISSAIBAI \\nJO \\nUOIEIS9}U] \\nAioysoda. \\neyep \\n&}aW \\nJU} \\n}Sa} \\nUOISSa1d9J \\n10 \\nUOI}LIS9}U] \\nssad01d \\n719 \\n94} \\nSULINp \\nUNL \\n}eY} \\nSWeIZOId \\ne}Ep \\nLJ@W \\ndU} \\nJO} \\nEJP \\n359} \\na}eaID \\nSa]NnpOwW \\nynpold \\n10 \\nuOHed|dde \\nAyoysodas \\ne}yep \\nCSW \\ndU} \\nJO} \\nYEP \\n}S9} \\n9}ea1D \\nssad0Jd \\nuOl}esSIW \\ne}EP \\nCBW \\nJU} \\nJO} \\nEYEp \\n4Sa} \\na}ea1D \\n3ul}sa} \\nAlo}sodad \\nyep \\nLIL \\nJO} \\nL}LP \\n}Sa} \\na}eaID \\nssad0jd \\nLJ \\n94} \\nSULINP \\nUNL \\nyey} \\nSWeISOJd \\neyep \\nL}JAaW \\ndU} \\nJO} \\nSased \\n3S9} \\na}eaID \\nSa|NPOW \\njnpold \\n10 \\nswesso1d \\nuONed|dde \\nAsojsodas \\neyep \\ne}BW \\nJU} \\nJO} \\nSaSed \\n1Sa} \\n9}e31D \\nssad0jd \\nUOH}eISIW \\ne}EP \\nLBW \\nJU} \\nJO} \\nSSD \\njs} \\na}eaID \\nS9SP) \\n}S3} \\nYM \\nUe; \\n}sa} \\ne a}RaID \\nsuoluny \\n~npod \\nJ0 \\nswiess01d \\nAuoyisodas \\neyep \\nLYIWI \\ndy} \\n}saL \\nsuesso1d \\nUOHDUNJ \\ndjay \\nauljuO \\nAlopsodad \\neyep \\ne}aW \\nJU} \\n3S91 \\nWU \\ns}duos \\nAuanb \\neyep \\nejaw \\nau} \\n}sa} \\nNUN \\nsweisoid \\nYodas \\neyep \\ne}9W \\ndU} \\n3S} \\nHUN \\nSWEISOId \\nSDELI}U! \\nSSADIE \\nJU} \\n1S} \\nHUN \\n(sajnpow \\nyonpoid \\nA10}Isoda, \\ne}ep \\neyawW \\n10) \\nswieAsOAd \\nUONed1dde \\neyep \\neyaW \\nay} \\n}S9} \\nWU \\nsweisojd \\nuoNdUN \\ndjay \\nauljuo \\nAloyisodad \\neyep \\nea \\naU} \\napo) \\ns}duos \\nAianb \\neyep \\nejaw \\nau} \\napop \\nSWeISOId \\nOdes \\nE}eEP \\nLBW \\nJY} \\naPOD \\nSWEISOId \\nBdeLa}UI \\nSSadde \\nBU} \\nBpOD \\nuonesijdde \\neyep \\ne}aW \\nay} \\n}S9} \\nHUN \\npue \\npjing \\nL8L \\n982 \\nS8Z v8Z €8Z CBZ L8Z O08Z 6ZZ 8ZL \\nLET: \\n9LL SEE \\neannnnnnnnnnnnnnnnnnnnnennnnnnennceecneceeeeeeeeeeeeeeec \\neee \\nnceneneeeeeeeeceneeesee \\nee \\nSSS \\nSSS \\nSSS \\nSSS \\n$4OSSaIaPAd \\nQUIDN \\nSDL \\nal \\nemma \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 552}, page_content='519 Work Breakdown Structure \\npedui! \\njeuoleziuesio \\n10} \\naiedaid \\n€Lg \\n}NO \\nPojJO1 \\n9G \\nO} \\nSUO!IUNJ \\n9Y} \\nB|NDBYDS \\ncL8 \\nSOMA \\nUOHLE}UIWA|dwI! \\nUl! \\na}edioed \\n0} \\nsadinosai \\nAlessadau \\nay} \\najNnpayIS \\nLLg \\n}NOJJO4J \\nJeIU! \\nBY} \\n40} \\najdoad \\nssaulsng \\njo \\nJaquNU \\nau} \\ndUIWAa}9q \\nOLg \\na}ep \\nUOHe}UIWA|dUWI! \\nau} \\n32S \\n608 \\nA8ayess \\n({nO|JO1) \\nUOI}EyUSWA|du! \\nUe \\nPaIas \\n808 \\n88Z \\n‘6IZ \\n‘659 \\n‘7Z9 \\n‘B19 \\nuone}UaWa|duu \\nay} \\nUe}d \\nL08 \\nuoHeuauajduy \\n:¢i \\ndag \\n=: \\n908 \\nv08 \\nSSOUBAIPaHo \\nSulules} \\nAioysodas \\ne}yep \\nejalW \\nainseapy \\nSO8 \\n€08 \\nsuolssas \\nSulules} \\nAlopsodal \\neyep \\nea \\nNpuOD \\nvO8 \\ncO8 \\nsuolssas \\nsululed \\nAloysodas \\neyep \\neyaW \\najnpaudS \\n£08 \\n108 \\nsynopuey \\nJUaUI}ed \\nJ34}O \\nPUL \\nSUOIINIOS \\nasidiaxa \\na}ea1D \\nZ08 \\n008 \\nS9SIDJ9X9 \\nYUM \\nSYOOGYIOM \\njUapn}s \\nAJO}SOdaJ \\neyep \\neJaW \\na}eaID \\nLog \\nS9}0U \\nJOPNA}SU! \\nPUL \\nSapI|s \\nUO!}E}UaSaId \\nAJOYsOdal \\neyep \\neJaWW \\n9}ea1D \\n008 \\nsjeLiajew \\nSuruses \\nAiopsodas \\neyep \\neyaW \\na}ealD \\n66Z \\npauled} \\noq \\n0} \\najdoad \\nssauisng \\nAjinuap] \\n86Z \\npaules} \\nog \\n0} \\n,Siasn \\nJamod, \\nAjuap] \\nZ6L \\npoulel} \\naq \\n0} \\nye}s \\nysap \\ndjay \\nAynuap] \\n96L \\n69Z \\nsujures \\nAoyisodas \\neyep \\ne}aW \\naPIAOId \\nG6L \\nSeinpadoid \\nSuOPUOW \\nasesn \\nAuoysodal \\neyep \\ne}aW \\ndojanaq \\nv6Z \\naseqej}ep \\nMioysodai \\ne}ep \\ne}W \\nBU} \\n10} \\nSainpado01d \\nSujuN} \\npue \\nSuLOWUOW \\naUeWWOJJed \\ndojanaqg \\n€6Z \\naidoad \\nssauisng \\nau} \\npue \\n}e}s \\nySap \\ndjay \\nau} \\n40} \\napInS \\naduaiajas \\ne \\naM \\nZ6L \\nsyodal \\nMioysodas \\neyep \\neyaw \\nay} \\nBulUUNL \\n10} \\nJye}S \\nSUOHeIadO \\naU} \\n10) \\nsainpadoud \\nSuljesado \\naM \\nL6Z \\naseqejep \\nAloysoda \\neyep \\ne}aW \\nUOHINpOJd \\nay} \\n10} \\n1Dq \\npue \\nqq \\na}ea!D \\nO6Z \\nAuoysodai \\neyep \\neyawW \\nUOHINpOid \\naU} \\n10} \\nWO \\neI]d \\nJanuas \\n9U} \\n}S9} \\nPuke \\n|]e}Su] \\n68 \\n69Z \\nuo} \\nnpod \\n105 \\nAioysodai \\neyep \\neyaw \\nay} \\naiedaig \\n88Z \\n$10SSA22PIJd \\naUIDN \\nYSDL~—s \\nQI \\nSSS \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 553}, page_content='APPENDIX 520 \\nSS \\nSS \\nA \\nI \\nSS \\nSA \\nST \\nSS \\nA \\nSa \\nSLES \\nET \\nssad0jd \\n714 \\n94} \\nSuUNp \\nuns \\n}eU} \\nSWeIsoid \\ne}Yep \\nea \\nJU} \\nJajNpaUs \\nGof \\nay} \\n0} \\nppy \\nlv3 \\nJajnpauds \\ngof \\nay} \\nUO \\nssad0Jd \\n7LJ \\n9u} \\ndn \\njas \\nOrg \\nvLs \\n3[Npays \\nuo} \\nNpod \\nay} \\ndn \\nyas \\n68 \\nSa|NDOW \\nyNpodd \\nJo \\nsuseuso1d \\nUOH}edI|\\\\dde \\ne}ep \\ne}JOLW \\nSAO \\n8E8 \\nSWeISOJd \\nUOICISILU \\nCJEP \\nCJOLW \\nSAO \\nLEQ \\nAsearqy weisoid \\nAuoysoda, \\neyep \\neyaW \\nUOHINpod \\nay} \\nO}UI \\nsUeISO1d \\nA1OYsOdai \\nE}ep \\nP}AW \\nBAO \\n9€8 \\nsweis0Jd \\nUODUN} \\ndjay \\nauljuO \\nBAO \\norate) \\nSWeISOId \\nBDeJJ9}U! \\nPUd-}UOI \\nSAO \\nveg \\ns}duos \\nAianb \\naaow \\n€€8 \\nsweisojd \\nYOdas \\ndAOI \\nZEB \\nAieigi| \\nwessoid \\nuoneddde \\nuonsnpoid \\nay} \\noyu! \\nsue1Z01d \\nuoNe>1|dde \\nano; \\nLEg \\nSWeISOIJd \\nPEO] \\n[CE}UBLWIJDU! \\nBAO \\nO€8 \\nsweis0jd \\npeo \\n[edU0}SIY \\nBAO! \\n678 \\nSWEISOJd \\nPeO] \\n[eIIUI \\nSAO] \\n878 \\nAseagy \\nweigoid \\n714 \\nUOHINpod \\nau} \\nO}UI \\nSWe1Z01d \\n7,14 \\nBAOW \\nLZ8 \\nVlg \\nsyuauodwiod \\nuonedidde \\n[gq \\nay} \\n|1e \\n[1e}su] \\n978 \\ns}UdUOdWOD \\nUOHedI|dde \\nJg \\n[Je \\n10} \\nsjana] \\nAyundas \\nUONNpoud \\nJUaWal|duW] \\nG78 \\na|doad \\nssaulsng \\nay} \\npue \\ne}s \\nysap \\ndjay \\n10} \\nsapind \\naduasajas \\nUONedI\\\\dde \\naM \\nvzg \\nyeys \\nsuonesado \\n10} \\nsainpadoid \\nSunesado \\n119 \\naWM \\n€78 \\nZL8 \\n‘OLE \\n‘SLE \\nsaeiql| \\nWessoid \\nuolonpoid \\n|je \\nuo \\nAyOUINe \\na}yeudoidde \\n1uUeID \\n778 \\n618 \\naseqgeyep \\nAioysodai \\neyep \\neyaw \\nUONposd \\nay} \\nUO \\nAyouNe \\nayeudoidde \\nyueIDH \\n178 \\n819 \\nsasegejep \\njosie} \\n|g \\nUONDNpoid \\nay} \\nUO \\nAyOUNe \\nayeUdoidde \\nyueIDH \\n078 \\naseqgejep \\nAloysodai \\neyep \\ne}aW \\nUO!PNpoOd \\nay} \\na}eaID \\n6L8 \\nsaseqejep \\njesse} \\n|g \\nUONpold \\nau} \\na}ealD \\n818 \\nAseigi| \\nweisoid \\nAuoyisodas \\ne}yep \\ne}aW \\nUOHDNpod \\nay} \\ndn \\njas \\nZL8 \\nAseiqi| \\nweisoid \\nuoyedjdde \\nuoipnpoid \\nau} \\ndn \\njas \\n918 \\nAieiqi| \\nwessoid \\n7,143 \\nuoNdnpoid \\nau} \\ndn \\nyas \\nS18 \\nZ08 \\nJUSWIUOJIAUS \\nUOTNpod \\nau} \\ndn \\nas \\nvlLg \\nSJOSSAIAPAd \\naWDN \\nYSDL~ \\nsi \\nNeen \\nnnn \\nnnn \\nnnn \\nnnn \\nnnnnnnnnnnnnnnnnnnnnnnnnnnnnn \\nnner \\neee \\ncreer \\nSSS \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 554}, page_content='521 Work Breakdown Structure \\nSSS \\nshep \\n0€+S40S8 \\n0S8 978 \\n6€8 \\n‘928 \\nsainyipuadxa \\nJaspng \\nMaIAay \\nMAIAI1 \\nUO}}L}UIWI9|duuI-}sod \\n3y} \\n404 \\naiedaig \\nuonenjenq \\naseajay \\n:91 \\ndais \\n(QAl| \\n08) \\nSuissad0id \\nuONDNpoud \\nyWeIS \\n(uypImMpueg \\nSUIPNdUl) \\ns}UaUDdWOD \\nYOMIaU \\n410} \\nSUL|d \\nAyDeded \\ndojanaq \\ndSEIO}S \\nYSIP \\n10} \\nSued \\nAjIDeded \\ndojanaq \\nS1OSSaD0Jd \\n10} \\nsuejd \\nAyideded \\ndojanaq \\nW0s;}e]d \\n|g \\nJY} \\n405 \\nsuejd \\nAyIDede>d \\nMainas \\n10 \\ndojanaq \\nsydey) \\nyods \\nAyjenb \\najnpauds \\nSIUJOW \\ne}EP \\nLOW \\nBUIMAIAAI \\nJO} \\nSAIPAIDE \\najnpaudsS \\nsaseqgejep \\njade} \\n|g \\ndU} \\n10} \\nsaNiANIe \\nSuULOPUOW \\nAyyenb \\neyep \\najnpayrs \\nSaMAIDe \\nSULOPUOW \\nasesn \\najnpaudS \\nSAHA \\nSULOPUOW \\nYWOIS \\najnpauds \\nSIIPAIIE \\nBULOPUOW \\nSdULWOJJad \\najnpaydS \\nsaseqejep \\nUO} \\nINpOld \\nay} \\n40J \\nSaANIe \\nSULOPUOW \\naseqe}ep \\najnpaurs \\nsuoleziuesioas \\naseqe}ep \\najnpauds \\n8U1}S9} \\nAlBAOIAI \\nJ3}SeSIP \\najNpIUDS \\nsdnypeq \\naseqej}ep \\najnpauds \\nsaseqezep \\nUO \\nNpoid \\nau} \\n10J \\nSaNIAN.e \\nadUeUD}UIEW \\naseqe}ep \\najnpayrsS \\nwYoddns \\nAduasJsawea \\n|]e9-UO \\n10} \\najnpauds \\ne \\nYsi|qe}sy \\nuoddns \\nSulo3uo \\n10} \\naiedaig \\nssad0id \\nuOHeIZIW \\ne}ep \\nPJaW \\nau} \\nUNY \\nSsad01d \\npeo} \\njedV0}sIY \\nau} \\nUNY \\nSsad0jd \\npeo] \\njeu! \\nau} \\nUNY \\nsaseqe}ep \\nUOlnpod \\nay} \\npeoy \\nuo}erdde \\nAioysodas \\neyep \\ne}awW \\nay} \\ndn \\njas \\nssad0id \\nuonessilW \\ne}yep \\neyawW \\nau} \\ndn \\nyas \\nsuieisoid \\nA1o}soda \\neyep \\nea \\npainpays \\nApeynas \\nayy \\nsajnpays \\nqof \\nay} \\nuo \\ndn \\nyas \\nsuuessoid \\nYodas \\nuoHed!|dde \\npainpayrs \\nAyejnZas \\nay} \\nJajnpayps \\ngol \\n94} \\nUO \\ndn \\njas \\nSS \\nSIOSSAIAPAd \\naUIDN \\nSDL \\n——— \\nSS \\nSSS \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 555}, page_content='APPENDIX 522 \\nL68 MalAaJ BU} SULIND Passndsip aq 0} UO!}E}UBLUNDOP }NO PUas 868 €68 epuase BUlJIIW [EULJ BU} PUSS PUL asIAdY 168 SUIJIBW JU} SULIND S9JOU Bye} 0} Aquos Ayed-psiy} e 10} asueUY 968 \\nAyed \\npuiy} \\ne \\nAg \\nuoieqioey \\nasueuy \\nS68 \\nUOHEIO] SHS-JO Ue }e SUI}IB9W JY} a|NPIUDS v68 \\nSaapuaHPe \\n0} \\nEpuase \\nAyeulwijasd \\n3} \\njNO \\npuas \\n€68 \\nSeapua}e \\nWO \\nSUOISaNb \\npue \\nsd!Ido} \\n[eUOIPpe \\n}D!]0S \\n768 \\npalamsue \\nPUe \\npassndsip \\naq \\n0} \\nsuO!}sanb \\njs!7 \\n168 \\nYdseaSas JO} Sd1d0} UBISSe PU }sIT 068 \\nUOISSNISIP \\nJO} \\nS10} \\n3S1T \\n688 \\nSdapUdHL \\nPAHPAU! \\n3S! \\n888 \\naoe|d pue ‘awi} ‘a}ep }s!7 Z88 \\nepuase \\nMaiAal \\nUOI}E}UaWa|duui-jsod \\nAseulwjasd \\nay} \\na}ea1D \\n988 \\nsKep \\n0€+S40S8 \\nSU}IIW \\nMAIAa1 \\nUOI}E}UBWa|duu-}sod \\nay} \\naziuesiOC \\nS88 \\n}d9dUOD \\nBSEIJaJ \\nBY} \\nJO \\nSSAUSAIPAYa \\nJY} \\nMIIADY \\n88 \\nA8a}e4}S \\n({NO|JO4) \\nUOE}USWa|du! \\nBY} \\nMAIADY \\n€88 \\nSUIUIEJ} \\nJO \\nSSQUSAIPDAYO \\nJU} \\nMAIADY \\n788 \\nuonedijdde \\n|g \\nay} \\nJO \\nBdUeWUOJJed \\naU} \\nssassy \\n188 \\n628 \\n(JEd1UYd9}UOU \\nPUe \\n[edUYIE}) \\nSadeId \\naunyNYsedUl \\nSuIssiW \\nAjUap] \\n088 \\n(}eD1UYI9}UOU \\nPuke \\n|ed]UYIA}) \\nB4N}DNIYSesJUI \\nSUI}SIXS \\nBU} \\nMAIADY \\n628 \\nJUIWIIL|d \\n|EUOHEZIUCBIO \\nJY} \\nJO \\nSSOUSAIPAJJa \\nJU} \\nMAIADY \\n8/8 \\nINNS \\nWLI} \\nJU} \\nJO \\nSSAUSAIDAYS \\nJY} \\nMAlAVY \\nZL8 \\nuseoidde \\njuawdojanap \\nay} \\nJO \\nSSSUBAI}IAY9 \\nIY} \\nMAIADY \\n9/8 \\n(adods \\nwo \\npaddoip) \\nsyuawasinbas \\npayjijjnjun \\nMalAay \\nS/8 \\nsasuey> \\nadods \\npue \\nainpadoid \\n[0J}U0D-a8ULUD \\nJU} \\nMAIAdY \\nvZ8 \\n(SanssI \\npaAjOsaiuN \\nPUe \\nPaAjOSad) \\nBO] \\nSANSS! \\nJY} \\nM3IADY \\n€/8 \\nSOW} \\nUOIa|dWOd \\nyse} \\nJen~e \\npuke \\npa}yeUI}sa \\n3U} \\nMAIAIY \\n728 \\naijnpayds \\njeuly \\npue \\nuejd \\npafojd \\njeulsu0 \\n9u} \\nMaIAdY \\nLZ8 \\nSS \\n$4JOSSA2APIId \\nQUIDN \\nYSOL~ \\n= ss \\nZI \\nSS \\na \\nIE \\nIIE \\nIE \\nEEE \\nSEL \\nEEA \\nECE \\nCLI \\nEI \\nEIT \\nI \\nI \\nLIYE \\nOE \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 556}, page_content='523 Work Breakdown Structure \\n€L6 \\nLL6 668 \\nS88 \\n‘698 \\nspiepue}s \\ndAoidwy \\nsauljapins \\nasAojduy| \\nsainpadojd \\npue \\nsassad0i1d \\naAosdu| \\nA80jopoyuj}awW \\nJUaWdOJaAap \\nau} \\nJO \\nasn \\naAOJdWy] \\nydeoidde \\nyuawdojanap \\nay} \\naAoiduwy] \\nS}UIWIIAOICUI \\n3.4N}IN.YsSeIyU! \\n[ed1UYd9}UOU \\nJUBA] \\nS}JNSI1 \\nWd} \\nUODE \\n3U} \\nUSI|GNd \\nS}[NSOJ \\nWA}! \\nUOIDe \\n34} \\nJUaLINDOG \\nSW}! \\nUOC \\nUO \\nPAaWWOpad \\nYOM \\ndu} \\nJOWUOW \\nSWa} \\nUOC \\nPausisse \\nUO \\nYIOM \\nS9}NUILW \\nSUIJBIW \\n9U} \\nUSI|GNd \\nSO}NUILW \\nSUIJBIW \\n3U} \\ndM \\naseajal \\n|g \\n}X9U \\nBY} \\nYM \\npajpung \\naq \\n0} \\nsjuaWauINbas \\npayyjnjun \\nJuUawNdDOG \\nMaIA31 \\nUO}L}UIWIa|duwI-}sod \\nay} \\nuo \\ndn \\nmoyjo4 \\nWa}! \\nUO!}IL \\nYILa \\nJO} \\na}ep \\naSUOdSad \\nJO \\nUOI}a|dWOd \\nysi}qe}sz \\nSW} \\nUO! \\nUSISSY \\nSWe}! \\nUO! \\nJUaWINIOG \\nSUOI}NJOSA \\n‘SUOSABSNS \\n‘SUOISSNISIP \\nJUaWINIOG \\nepuase \\n3} \\nUO \\nWad}! \\nYea \\nssndsiq \\nUOISSAS \\nPa}eUfINe} \\nIY} \\nJO} \\nS|jNI \\nau} \\nUle;dxy \\nSdapua}j}e \\n9} \\nadnNpoU] \\nSUI}9IUW \\nMalAd1 \\nUOe}UaWa|duI-}sod \\nay} \\nWnpuoD \\nSS \\nSIOSSIIAPIAId \\naUIDN \\nYSDL \\ndi \\nSSS \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 557}, page_content=''),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 558}, page_content='Index \\nA \\nAbbreviation, standards for, 72 \\nAcceptance testing \\napplication development, 294, 296 \\nETL development, 272, 277 \\nmeta data repository and, 326-327, 332 \\nAccess interface, meta data repository, 325 \\nAccess requirements \\nanalyzing for prototype, 163 \\ndatabase design for, 204, 206-207 \\nAcronyms, standards for, 72 \\nActivities \\napplication development, 295-297 \\napplication prototyping, 163-164 \\nbusiness case assessment, 45—48 \\ndata analysis, 141-143 \\ndata mining, 313-315 \\ndatabase design, 204-207 \\nenterprise infrastructure evaluation, nontech- \\nnical, 75-76 \\nenterprise infrastructure evaluation, technical, \\n61-62 \\nETL design, 231-232 \\nETL development, 276-277 \\nimplementation, 352-354 \\nmeta data repository analysis, 186-188 \\nmeta data repository design, 254—255 \\nmeta data repository development, 331-332 \\nproject planning, 90-92, 98-100 \\nproject requirements definition, 118-121 \\nrelease evaluation, 369-370 \\nActivity Dependency Matrix, 405-410, xxvii \\nAdditional reading. see Bibliography/additional \\nreading \\nAdministrative support, DBMS features, 60 \\nAgenda, post-implementation review, 367 \\nAggregation \\ndatabase design and, 204, 206 \\ndefining, 286 \\nmanaging growth in data volume with, 350 \\nOLAP tools providing, 285 \\nsource data transformation and, 262 \\nAlerts, 347 \\nAmount counts, ETL reconciliation, 228, 265-266 \\nAnalysis tools. see also data mining \\napplication development considerations, 282 \\nmultidimensional, 287-289 \\nmultivariate, 289 \\nOLAP, 283-287, 291 \\nAnalytical data model, 314-315 \\nAPIs (application programming interfaces), 58, \\n239, 244, 292 \\nApplication design document, 297 \\nApplication developers \\napplication development, 298 \\nbook chapters of interest, xxxi \\nHuman Resource Allocation Matrix, 383-385 \\nimplementation, 355 \\nresponsibilities of, 24 \\nApplication development, 281-300 \\nactivities, 295-297 \\nActivity Dependency Matrix, 408 \\nadditional reading, 299 \\nconsiderations about, 282-283 \\nconstruction stage, 13-14 \\ndeliverables, 297 \\nEntry & Exit Criteria and Deliverables \\nMatrix, 399 \\nenvironments, 292-295 \\nHuman Resource Allocation Matrix, 383 \\n525 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 559}, page_content='526 \\nApplication development continued \\nmultidimensional analysis factors, 287-289 \\nOLAP architecture and, 289-292 \\nOLAP tools and, 283-287 \\noverview of, 281 \\nPractical Guidelines Matrix, 481—482 \\nrisks of not performing, 299 \\nroles, 298-299 \\nTask/Subtask Matrix, 442-444 \\nApplication inventory, 70-71 \\nApplication lead developer \\napplication development, 298 \\napplication prototyping, 165 \\nbook chapters of interest, xxxi \\ndatabase design, 208 \\nHuman Resource Allocation Matrix, 380-385 \\nimplementation, 355 \\nproject planning, 101 \\nproject requirements definition, 121-122 \\nrelease evaluation, 371 \\nresponsibilities of, 22 \\nApplication program library, 297 \\napplication programming interfaces (APIs), 58, \\n239, 244, 292 \\nApplication prototyping, 149-168 \\nactivities, 163-164 \\nActivity Dependency Matrix, 407 \\nadditional reading, 167 \\nbest practices, 153-155 \\nbusiness analysis stage, 12 \\nconsiderations about, 150-151 \\ndeliverables, 165 \\nEntry & Exit Criteria and Deliverables \\nMatrix, 393 \\nenvironment, 293-294 \\nHuman Resource Allocation Matrix, 381 \\noverview of, 149 \\nPractical Guidelines Matrix, 467-469 \\npurposes of, 151-152 \\nrisks of not performing, 166-167 \\nroles, 165-166 \\nsuccessful, 159-163 \\nTask/Subtask Matrix, 427-430 \\ntypes of, 156-159 \\nApplication release concept, 361-363 \\nApplication requirements document \\ncontents of, 113, 114-116 \\nrevising for prototype, 165 \\nwriting, 121 \\nIndex \\nApplication test plans, 297 \\nApplication Track, 17-18 \\nApplications \\nmeta data repository design, 255 \\nmeta data repository development, 331-332 \\nsecurity measures for, 340-341 \\nArbitration boards, 26 \\nArchitecture \\nenterprise, 68-71 \\nOLAP, 289-292 \\nsecurity and, 342 \\nthree-tier computing, 56 \\nAssociations discovery technique, 306, 307-308 \\nAssumptions, project planning and, 87-88 \\nAuthentication, defined, 345 \\nAutomation silos (stovepipe systems) \\ndata discrepancies of, 130 \\neffects of, 65-66 \\nAvailability, application requirements \\ndocument, 116 \\nB \\nBack end, 17 \\nBackups \\noverview of, 345-347 \\nphysical database design, 203 \\nBandwidth, 348 \\nBI infrastructure architect \\nbook chapters of interest, xxi \\nHuman Resource Allocation Matrix, 379, 382, 385 \\nmeta data repository design, 256 \\nnontechnical enterprise infrastructure \\nevaluation, 77 \\nrelease evaluation, 371 \\nresponsibilities of, 22 \\ntechnical enterprise infrastructure \\nevaluation, 63 \\nBI target databases. see also Database design \\nbuilding, 206-207 \\ndesigning, 205-206 \\ndesigning load programs, 223-224 \\nETL implementation strategies, 213-215 \\noperational databases vs., 194 \\noverview of, 196 \\nphysical design of, 207-208 \\nas sources for data mining, 306-307 \\nBibliography/additional reading \\napplication development, 299 \\napplication prototyping, 167 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 560}, page_content='Index \\nbusiness case assessments, 50 \\ndata analysis, 146-147 \\ndata mining, 317 \\ndatabase design, 209-210 \\ndevelopment steps, 27 \\nenterprise infrastructure evaluation, 78-80 \\nETL design, 234-235 \\nETL development, 279 \\nimplementation, 356-357 \\nmeta data repository analysis, 190 \\nmeta data repository design, 257-258 \\nmeta data repository development, 335 \\nproject planning, 103 \\nproject requirements definition, 123-124 \\nrelease evaluation, 375 \\nBottom-up source data analysis, 133-136 \\nBrainstorming, 267—268 \\nBudget, 84-89, 114, 156, 364, 460, 468 \\nBusiness \\napplication prototyping and, 150-151, 155 \\narchitecture models, 69-70 \\nBusiness analysis stage \\ndefined, 6 \\ndevelopment steps in, 12 \\nissues, 35—37 \\nnontechnical infrastructure activities, 67 \\nparallel development tracks, 19 \\nstovepipe systems and, 65-66 \\nBusiness case assessment, 29-50 \\nactivities, 45—48 \\nActivity Dependency Matrix, 405 \\nadditional reading, 50 \\nbusiness analysis issues, 35-37 \\nbusiness drivers, 33-35 \\nbusiness justification, 31-33 \\nconsiderations about, 30-31 \\ncost-benefit analysis, 37-40 \\ndeliverable, 48 \\nEntry & Exit Criteria and Deliverables \\nMatrix, 387 \\nHuman Resource Allocation Matrix, 379 \\njustification stage, 11 \\noverview of, 29 \\nPractical Guidelines Matrix, 455-456 \\nrisk assessment, 40—45 \\nrisks of not performing, 49-50 \\nroles, 49 \\nTask/Subtask Matrix, 411-413 \\nBusiness-focused data analysis \\ndata domain rules, 134-135 \\n527 \\ndata integrity rules, 135-136 \\nmeta data, 131-133, 143 \\noverview of, 127 \\nBusiness representative \\napplication development, 298 \\napplication prototyping, 166 \\napplication release concept, 361 \\napplication release concept guidelines, \\n362-364 \\nbook chapters of interest, xxix \\nbusiness case assessment, 49 \\ndata analysis, 144 \\ndata mining, 316 \\nETL development, 278 \\nETL integration testing, 269 \\nguidelines for project planning, 460 \\nHuman Resource Allocation Matrix, 379-381, \\n383, 385 \\njustifying BI decision, 32-33 \\nlogical data modeling, 131 \\nmeta data repository development, 333 \\nnontechnical infrastructure needs, 67 \\nproject planning, 82, 101 \\nproject requirements definition, 114, 122 \\nrelease evaluation, 371 \\nresponsibilities of, 22 \\nBusiness sponsor \\nbook chapters of interest, xxix \\nbusiness case assessment, 49 \\nHuman Resource Allocation Matrix, 379, 385 \\npost-implementation review, 368 \\nproject-specific requirements of, 114 \\nrelease evaluation, 372 \\nresponsibilities of, 24 \\nC \\nCaching, DBMS, 60 \\nCalling card fraud, 312 \\nCampaigns, marketing, 312 \\nCASE tools \\ndefined, 241 \\nnontechnical infrastructure and, 64, 75, 459 \\npopulating meta data repository using, 322 \\nCentralized meta data repository, 242-244 \\nChange-control procedures \\napplication release guidelines, 363 \\npost-implementation review, 366 \\npractical guidelines for, 460 \\nproject planning, 88-89 \\nChaos, minimizing hardware, 54—55 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 561}, page_content='528 Index \\nCipher text, 345 need for nontechnical infrastructure, 66-68 \\nClassification, data mining, 309, 310-311 overview of, 8-11 \\nClassifications, meta data, 176-182 project-specific vs., 16 \\nCleansing data. see Data cleansing CRUD (create, read, update, delete) access, \\nClustering 207, 331 \\ndata mining technique, 309 customer relationship management (CRM), 9, 39 \\nphysical database design decisions, 202 Customers \\nCompetition, business case assessment, 47 market management of, 312 \\nCompilation, unit testing, 269 planning incremental rollouts, 339 \\nComplexity risk, 41 Customization \\nComputer utilization, 347 meta data repository design, 242-243 \\nConnectivity paths, 343 meta data repository development, 320 \\nConstraints, project \\noverview of, 86-88 D \\nplanning considerations, 84, 418 Data \\nConstruction stage accuracy, 140 \\ndefined, 6 application prototyping and, 153 \\ndevelopment steps in, 13-14 application requirements document and, 115 \\nparallel development tracks and, 19 business analysis issues, 35-37 \\nContingency plan, 86 conversion rules, 134 \\nCore team members domain rules, 134-135 \\nnontechnical enterprise infrastructure formats, 140 \\nevaluation, 65 integrity rules, 135 \\npost-implementation review, 367 managing growth in, 349-350 \\nrelease evaluation, 489 names, 132 \\nresponsibilities of, 21-23 naming standards, 72 \\nCost-benefit analysis policy, 133 \\nbusiness issues, 37—40 precision, 140 \\ndetermining ROI, 47 project requirements, 106 \\nETL tools and, 230 reliability, 140 \\nproject planning and, 82 resolving discrepancies, 143 \\nCosts sharing, 60 \\nconsiderations about, 30 transformation activities, 261—263 \\nconstraints, 84 values, 221-222 \\ndetermining or revising, 99 Data administrator \\njustifying, 31-33 book chapters of interest, xxi \\npost-implementation review of budget, 364 data analysis, 144 \\nPractical Guidelines Matrix, 455-456 database design, 208 \\nprototyping and, 151 Human Resource Allocation Matrix, 379-382, \\nrisk and, 42 385 \\nstandardizing of data and, 37 logical data modeling, 131 \\nCPM (critical path method), 95-96, 101 meta data repository analysis, 188 \\nCredit card fraud, 312 meta data repository design, 256 \\nCritical path method (CPM), 95-96, 101 nontechnical enterprise infrastructure \\nCritical success factors, 99 evaluation, 77 \\nCRM (customer relationship management), project planning, 101 \\n2) project requirements definition, 122 \\nCross-organizational integration release evaluation, 372 \\nimmature attempts to organize meta data, 240 responsibilities of, 22 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 562}, page_content='Index \\nData analysis, 125-148 \\nactivities, 141-143 \\nActivity Dependency Matrix, 406 \\nadditional reading, 146-147 \\nbottom-up source data analysis, 133-136 \\nbusiness analysis stage, 12 \\nbusiness-focused vs. traditional, 127 \\nconsiderations about, 126-127 \\ndata cleansing, 136-141 \\ndeliverables, 143-144 \\nEntry & Exit Criteria and Deliverables \\nMatrix, 392 \\nHuman Resource Allocation Matrix, 381 \\noverview of, 125 \\nPractical Guidelines Matrix, 464—466 \\nrisks of not performing, 145-146 \\nroles, 144-145 \\nTask/Subtask Matrix, 425-426 \\ntop-down logical data modeling, 128-133 \\nData cleansing, 136-141 \\napplication requirements document and, 115 \\ndata analysis and, 126 \\ndata mining and, 313 \\nestimates for, 461 \\nETL design and, 215-216 \\nETL development and, 262 \\noverview of, 136-141 \\ntools for, 241 \\nwriting specifications for, 143 \\nData content, 133. see also Domain \\nData control language. see DCL (data control \\nlanguage) \\nData definition, 132 \\nData definition language. see DDL (data defini- \\ntion language) \\nData dictionaries, 61, 239-240 \\nData identifier, 132-133 \\nData-in philosophy, 195 \\nData integration \\nETL transformation programs, 221 \\nlogical data modeling for, 127 \\nnormalization rules, 262 \\nprototyping best practices, 155 \\nData integrity \\nbusiness rules for, 135-136 \\nsource data selection and, 139 \\nData length \\ndefined, 133 \\ntechnical data conversion rules for, 134 \\n529 \\nData management middleware, 57 \\nData marts \\napproach, 351 \\nimplementation strategies, 213 \\nstaging area, 232, 475 \\nData mining, 301-318 \\nactivities, 313-315 \\nActivity Dependency Matrix, 409 \\nadditional reading, 317 \\napplications of, 311-313 \\nconsiderations about, 302—303 \\nconstruction stage, 13-14 \\ndefining, 303-307 \\ndeliverables, 315 \\nEntry & Exit Criteria and Deliverables \\nMatrix, 400 \\nHuman Resource Allocation Matrix, 383 \\noperations, 3]0-311 \\noverview of, 301 \\nPractical Guidelines Matrix, 483-484 \\nrisks of not performing, 316 \\nroles, 316 \\nTask/Subtask Matrix, 445-446 \\ntechniques, 307-310 \\ntools, 241, 302 \\nData mining expert \\nbook chapters of interest, xxxi \\ndata mining, 316 \\nHuman Resource Allocation Matrix, 383-385 \\nimplementation, 355 \\nrelease evaluation, 372 \\nresponsibilities of, 22 \\nData mining operations, 310-311 \\nData mining techniques, 307-310 \\nData-out philosophy, 195, 196 \\nData owners \\ndata analysis, 145 \\ndata quality, 137 \\nlogical data modeling, 131 \\nPractical Guidelines Matrix, 464 \\nresponsibilities of, 25 \\nData quality \\ndata analysis and, 126, 137, 142 \\ngeneral business requirements for, 110-111 \\nnormalization, 195 \\nplanning project for, 461 \\nstandards, 73 \\nData quality analyst \\nbook chapters of interest, xxxi \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 563}, page_content='530 Index \\nData quality analyst continued \\nbusiness case assessments, 49 \\ndata analysis, 144 \\nETL design, 233 \\nHuman Resource Allocation Matrix, 379-382, \\n385 \\nnontechnical enterprise infrastructure \\nevaluation, 77 \\nproject planning, 102 \\nproject requirements definition, 122 \\nrelease evaluation, 372 \\nresponsibilities of, 22 \\nData relationship, 132 \\nData rule, 133 \\nData types \\ndefined, 133 \\ntechnical data conversion rules for, 134 \\nDatabase administrator \\napplication development, 298 \\napplication prototyping, 153, 166 \\nbook chapters of interest, xxxi \\ndata mining, 316 \\ndatabase design, 193, 208-209 \\nETL design, 233 \\nETL development, 278 \\nHuman Resource Allocation Matrix, 379-385 \\nimplementation, 355 \\nmeta data repository development, 334 \\npersonnel utilization and, 348-349 \\nproject planning, 102 \\nrelease evaluation, 372 \\nresponsibilities of, 22 \\ntechnical enterprise infrastructure \\nevaluation, 63 \\nDatabase design, 191-210 \\nactivities, 204—207 \\nActivity Dependency Matrix, 407 \\nadditional reading, 209-210 \\nconsiderations about, 192-193 \\ndeliverables, 207—208 \\ndesign stage, 13 \\nEntry & Exit Criteria and Deliverables \\nMatrix, 395 \\nHuman Resource Allocation Matrix, 382 \\nlogical, 197-200 \\noverview of, 191 \\nphilosophies, 193-196 \\nphysical, 201-204 \\nPractical Guidelines Matrix, 472-474 \\nrisks of not performing, 209 \\nroles, 208-209 \\nTask/Subtask Matrix, 433-435 \\nDatabase management system. see DBMS (data- \\nbase management system) \\nDatabase segmentation, data mining, 311 \\nDatabases \\nbackup and recovery, 345-347 \\ndata mining, 311, 315 \\ndrivers, 58 \\nloading production, 353 \\nmaintaining, 207—208, 338 \\nmeta data repository, 331, 332-333 \\nOLAP architecture support of, 292 \\nDataset placement, 201-202 \\nDBMS (database management system) \\nconsiderations about, 53—54 \\ncriteria for selecting, 59-61 \\ndesign considerations, 192 \\ndictionaries, 322-323 \\ngateways, 57-59 \\nmeta data from tools, 241 \\nmeta data in, 240 \\nPractical Guidelines Matrix, 458 \\nquery resolution, 199 \\nscalability, 55 \\nsecurity, 343 \\ntechnical enterprise infrastructure evaluation \\nactivities, 61-62 \\nDCL (data control language) \\ndatabase security and, 206 \\ndefined, 208 \\nmeta data repository design and, 256 \\nDDL (data definition language) \\nbuilding BI target databases and, 206 \\ndefined, 208 \\nmeta data repository design and, 255 \\nDeadline management, 155 \\nDecentralized meta data repository, 244-245 \\nDecision-support initiatives \\nassessing business drivers, 33-35 \\ndynamics of, 10 \\njustifying, 31-33 \\noverview of, 5 \\nDecision-support system (DSS) solutions, 46—47 \\nDeleted records, processing, 218-219 \\nDeliverables. see also Entry & Exit Criteria and \\nDeliverables Matrix \\napplication development, 297 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 564}, page_content='Index \\napplication prototyping, 150, 155, 165 \\nbusiness case assessment, 48 \\ndata analysis, 143-144 \\ndata mining, 315 \\ndatabase design, 207-208 \\nenterprise infrastructure evaluation, \\nnontechnical, 76-77 \\nenterprise infrastructure evaluation, technical, \\n62-63 \\nETL design, 233 \\nETL development, 277 \\nimplementation, 354 \\nmeta data repository analysis, 188 \\nmeta data repository design, 255-256 \\nmeta data repository development, 332-333 \\nproject planning, 100-101 \\nproject requirements definition, 121 \\nrelease evaluation, 371 \\nDemo prototype, 158 \\nDemonstrations, prototype, 164 \\nDeployment stage \\ndefined, 6 \\ndevelopment steps in, 14 \\nparallel development tracks and, 19 \\nDerivation process, ETL development, 262 \\nDesign stage \\ndefined, 6 \\ndevelopment steps in, 13 \\nparallel development tracks and, 19 \\nDevelopers, 373, 385 \\nDevelopment approaches \\ncross-organizational, 8-11 \\noverview of, 5-6 \\npost-implementation review on, 366 \\ntraditional, 6-8 \\nDevelopment environment, 293-294 \\nDevelopment steps \\nActivity Dependency Matrix, 405-410 \\nadditional reading, 27 \\narbitration boards, 26 \\ncross-organizational integration, 8—11 \\ndecision-support initiatives, 5 \\ndefining, 4—5 \\ndevelopment approaches, 5-6 \\nengineering stages and, 11-16 \\nEntry & Exit Criteria and Deliverables Matrix, \\n387-403 \\nestablishing standards, 72 \\nHuman Resource Allocation Matrix, 379-385 \\n531 \\njustification for using, 26-27 \\nparallel development tracks, 17—20 \\nPractical Guidelines Matrix, 455-490 \\nproject team structures, 20-25 \\nTask/Subtask Matrix, 411-454 \\ntraditional development approach, 6-8 \\nDeviation detection, data mining, 311 \\nDictionaries, data \\nDBMS, 61, 322-323 \\noverview of, 239-240 \\nDimension tables, star schema, 198-199 \\nDirectory, meta data repository, 330 \\nDisplay, OLAP tools, 287 \\nDistributed logic middleware, defined, 57 \\nDistributed XML-enabled meta data solution, \\n245-247 \\nDistribution, data mining, 313 \\nDocumentation \\nmeta data repository, 333 \\nproduction, 354 \\nDomain. see also Data content \\nbusiness meta data and, 143, 177 \\nenforcements, 228 \\nviolations, 135, 479 \\nDomain counts, ETL reconciliation, 228, 265-266 \\nDouble maintenance, defined, 246 \\nDrivers, database, 58 \\nDrivers, of business, 30, 32, 33-35 \\nE \\nE-R (entity-relationship) meta data repository, \\n247-248, 254-255 \\nE-R (entity-relationship) modeling. see Logical \\ndata models \\nEase of use, defining, 469 \\nEdits, ETL unit testing, 269 \\nEIS (executive information system), 283, 305-306 \\nEncryption, 344, 345 \\nEngineering stages, 11-16 \\nBusiness analysis stage, 12 \\nConstruction stage, 13-14 \\ndependencies, 15 \\nDeployment stage, 14 \\nDesign stage, 13 \\ndevelopment approach, 5-6 \\nJustification stage, 11 \\nparallel development tracks and, 17—20 \\nPlanning stage, 11 \\nproject-specific vs. cross-organizational steps, 16 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 565}, page_content='532 \\nEnterprise architecture, 68—71 \\nEnterprise infrastructure evaluation, nontechni- \\ncal, 63-80 \\nactivities, 75-76 \\nActivity Dependency Matrix, 405 \\nadditional reading, 79-80 \\narchitecture components, 68-71 \\nconsiderations about, 64-65 \\ndeliverable, 76-77 \\nEntry & Exit Criteria and Deliverables \\nMatrix, 389 \\nHuman Resource Allocation Matrix, 379 \\nneed for, 66-68 \\noverview of, 52 \\nplanning stage, 11 \\nPractical Guidelines Matrix, 459 \\nrisks of not performing, 78 \\nroles, 77-78 \\nstandards for, 71-75 \\nstovepipe development effects and, 65-66 \\nTask/Subtask Matrix, 416-417 \\nEnterprise infrastructure evaluation, technical, \\n53-63 \\nactivities, 61-62 \\nActivity Dependency Matrix, 405 \\nadditional reading, 78-79 \\nconsiderations about, 53-54 \\nDBMS requirements, 58-61 \\ndeliverables, 62-63 \\nEntry & Exit Criteria and Deliverables \\nMatrix, 388 \\nhardware platform scalability, 54-57 \\nHuman Resource Allocation Matrix, 379 \\nmiddleware platform, 57-58 \\noverview of, 51 \\nplanning stage, 11 \\nPractical Guidelines Matrix, 457-458 \\nrisks of not performing, 63 \\nroles, 63 \\nTask/Subtask Matrix, 414-415 \\nEnterprise logical data model, 129-130, 142-144 \\nEntity-relationship (E-R) meta data repository, \\n247-248, 254-255 \\nEntity-relationship (E-R) modeling. see Logical \\ndata models \\nEntry & Exit Criteria and Deliverables Matrix, \\n387-403 \\napplication development, 399 \\napplication prototyping, 393 \\nIndex \\nbusiness case assessments, 387 \\ndata analysis, 392 \\ndata mining, 400 \\ndatabase design, 395 \\ndefined, xxvii \\nenterprise infrastructure evaluation, 388-389 \\nETL design, 396 \\nETL development, 398 \\nimplementation, 402 \\nmeta data repository analysis, 394 \\nmeta data repository design, 397 \\nmeta data repository development, 401 \\nproject planning, 390 \\nproject requirements definition, 391 \\nrelease evaluation, 403 \\nEnvironments \\napplication development, 292-295 \\nmulti-tier, 341-344 \\nproduction, 293-294, 353 \\nsetting up implementation, 353 \\nError-handling, ETL process flow design, 228 \\nEstimating techniques, 92-93 \\nETL developers \\nbook chapters of interest, xxxi \\nETL development, 278 \\nHuman Resource Allocation Matrix, 383-385 \\nimplementation, 355 \\nrelease evaluation, 373 \\nresponsibilities of, 24 \\nETL (extract/transform/load) design, 211-236 \\nactivities, 231-232 \\nActivity Dependency Matrix, 408 \\nadditional reading, 234-235 \\nconsiderations about, 212-213 \\ndeliverables, 233 \\ndesign stage, 13 \\nEntry & Exit Criteria and Deliverables \\nMatrix, 396 \\nevaluating tools for, 229-231 \\nextract programs, 219-220 \\nHuman Resource Allocation Matrix, 382 \\nimplementation strategies, 213-215 \\nload programs, 223-224 \\noverview of, 211 \\nPractical Guidelines Matrix, 475-476 \\npreparing for process, 215-219 \\nprocess flow, 225-229 \\nrisks of not performing, 234 \\nroles, 233-234 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 566}, page_content='Index 533 \\nTask/Subtask Matrix, 436-437 \\ntransformation programs, 221-223 \\nETL (extract/transform/load) development, \\n259-280 \\nactivities, 276-277 \\nActivity Dependency Matrix, 408 \\nadditional reading, 279 \\nconsiderations about, 260-261 \\nconstruction stage, 13-14 \\ndeliverables, 277 \\nEntry & Exit Criteria and Deliverables \\nMatrix, 398 \\nHuman Resource Allocation Matrix, 383 \\noverview of, 259 \\npeer reviews, 267 \\nPractical Guidelines Matrix, 479-480 \\nreconciliation, 263—267 \\nrisks of not performing, 279 \\nroles, 278 \\nsource data transformation, 261-263 \\nTask/Subtask Matrix, 440-441 \\nTesting, 268-273 \\nETL lead developer \\nbook chapters of interest, xxxi \\ndata analysis, 144 \\ndatabase design, 209 \\nETL design, 225-228, 234 \\nETL development, 278 \\nHuman Resource Allocation Matrix, \\n380-385 \\nimplementation, 355-356 \\nproject planning, 102 \\nrelease evaluation, 373 \\nresponsibilities of, 22 \\nETL process flow, 225-229 \\nETL program library, 277 \\nETL test plan, 273-275, 277 \\nEiiracksly, \\nEvaluation \\nnontechnical enterprise infrastructure. see \\nEnterprise infrastructure evaluation, \\nnontechnical \\ntechnical enterprise infrastructure. see \\nEnterprise infrastructure evaluation, \\ntechnical \\nExecutive information system (EIS), 283, \\n305-306 \\nExit criteria. see Entry & Exit Criteria and Deliv- \\nerables Matrix \\nExtended team members \\npost-implementation review, 367 \\nrelease evaluation, 489 \\nresponsibilities of, 23-25 \\nExternal data \\nanalyzing sources of, 141-142 \\nbusiness analysis issues, 36-37 \\nExtract programs, 219-220, 225 \\nExtract/transform/load (ETL) design. see ETL \\n(extract/transform/load) design \\nF \\nFacilitator \\nHuman Resource Allocation Matrix, 385 \\npost-implementation review, 368-369 \\nrelease evaluation, 373 \\nresponsibilities of, 25 \\nFact tables, star schema, 197-198 \\nFinancial investment risk, 42 \\nFinancial services, data mining, 312-313 \\nFinish to Finish, task dependencies, 94-95 \\nFinish to Start, task dependencies, 94-95 \\nForecasting technique, data mining, 309-310 \\nFormats \\npreparing for ETL process, 215 \\nresolution of differing, 222 \\nFormula-based estimations, 92—93 \\nFraud detection, data mining, 312 \\nFront end, 17-20 \\nFunctional project requirements, 106, 115 \\nFunctionality, application prototyping, 467 \\nG \\nGantt charts, 100, 101 \\nGap analysis security matrix, 343-344 \\nGateways, 57-59, 245-247, 485 \\nGeneral business requirements, 108-112 \\ndata quality requirements, 110-111 \\ninterviewees for, 109-110 \\noverview of, 108—109 \\nproject-specific requirements vs., 107 \\nreport, 111-112 \\nGoals \\ndata mining, 313 \\nproject, 85 \\nGroup IDs (group identifiers), 207 \\nGrowth management, 349-351 \\nGUI (graphic user interface) components, proto- \\ntypes, 161 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 567}, page_content='534 \\nGuidelines. see also Practical Guidelines Matrix \\nnontechnical enterprise infrastructure evalua- \\ntion, 64-65 \\nphysical database design, 201-204 \\nprototyping, 161-162 \\nusing application release concept, 362-363 \\nH \\nHardware \\ndata and usage growth and, 351 \\nplatform requirements, 54-57 \\nPractical Guidelines Matrix, 458 \\ntechnical enterprise infrastructure evaluation, \\n53, 61-62 \\nHelp desk (support) \\nimplementation and, 338-339, 353 \\nrole of extended team members, 24-25 \\nHelp function. see Online help function \\nHistorical load process, ETL, 217 \\nHistory \\nbasing project estimates on, 92-93 \\ndata requirements and, 106 \\nHomonyms, 222 \\nHuman Resource Allocation Matrix, 379-385, \\nXXVIl \\nI \\nImplementation, 337-358 \\nactivities, 352-354 \\nActivity Dependency Matrix, 409 \\nadditional reading, 356-357 \\nconsiderations about, 338-339 \\ndata backup and recovery, 345-347 \\ndeliverables, 354 \\ndeployment stage, 14 \\nEntry & Exit Criteria and Deliverables \\nMatrix, 402 \\ngrowth management, 349-351 \\nHuman Resource Allocation Matrix, 384 \\nincremental rollout, 339 \\nmonitoring utilization of resources, 347-349 \\noverview of, 337 \\nPractical Guidelines Matrix, 487-488 \\nrisks of not performing, 356 \\nroles, 355-356 \\nsecurity management, 340-345 \\nTask/Subtask Matrix, 450-452 \\nIncremental load process, ETL, 217-219 \\nIndex \\nIndexing \\napproaches to, 473-474 \\nmanaging growth in data through, 349 \\nphysical database design and, 202-203 \\npoor database performance and, 224 \\nInformation \\naccessibility of, 30 \\nneeds, 35 \\nInformation architecture, 67—68, 70, 73 \\nInfrastructure architect role. see BI infrastructure \\narchitect \\nInitial load programs, ETL, 216-217 \\nInstruction guides, 329, 353 \\nInsurance fraud, data mining, 312 \\nIntegration risk, 41 \\nIntegration testing \\napplication development, 296 \\nETL development, 270, 276 \\nmeta data repository development, 326-327, \\n332 \\nInterface \\nmeta data repository design, 238 \\nmeta data repository development, 324-325 \\nInternet access, security, 344-345 \\nInterviewing \\ngeneral business requirements, 109-110 \\noverview of process, 116-118 \\nproject-specific requirements, 113-114 \\nIntuitive estimating technique, 92-93 \\nInventory \\napplication, 70-71 \\ncontrolling through data mining, 313 \\nIssues log \\napplication prototypying using, 165 \\nguidelines for project planning, 460 \\nmanagement procedures using, 90-91 \\nIT (information technology) managers \\napplication release concept, 361, 362-364 \\njustifying BI decision, 32-33 \\nlogical data modeling, 131 \\nresponsibilities of, 24-25 \\nIterative releases. see also Application prototyp- \\ning; Release concept; Release evaluation \\nbuilding meta data repository projects in, 242 \\ncomparing BI applications with traditional, 7-8 \\ncross-organizational integration and, 9-11 \\nguidelines for, 467-469 \\nimplementation planning for, 339 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 568}, page_content='Index \\nJustification stage \\nassessing business case, 31-33, 45-46 \\nassessing business drivers, 33-35 \\ndefined, 6 \\ndevelopment step in, 11 \\nparallel development tracks and, 19 \\nK \\nKnowledge discovery, 305, 400, 483 \\nL \\nLibraries \\napplication program, 354 \\nETL program, 277, 354 \\nmeta data repository program, 328, 333, 354 \\nLicensing (buying), meta data repository, \\n242-245, 250-254 \\nLink analysis, data mining, 311 \\nLoad process, 60 \\nLoad programs, ETL design, 223-224 \\nLoad sequence, ETL design, 228 \\nLog data, Web, 294-295 \\nLogical data identifiers, 132-133 \\nLogical data models \\nbusiness meta data components of, 131-133 \\nenterprise, 129-130 \\nnontechnical enterprise infrastructure evalua- \\ntion and, 64 \\noverview of, 128 \\nparticipants in, 131 \\nproject-specific, 128-129 \\nrefining, 142 \\nrequirements for expanding, 120 \\nstandards for, 73 \\nLogical database design \\noverview of, 207 \\nsnowflake schema, 200 \\nstar schema, 197-200 \\nLogical meta model, 184-186 \\nLogon, 341 \\nM \\nManagement \\nof data growth, 349-350 \\ndata mining applications, 312-313 \\nManuals, meta data repository, 329 \\nMarket basket analysis \\ndefined, 308 \\nusing data mining tools for, 306-307 \\n535 \\nMarket management, data mining, 312 \\nMarketing \\ndata mining considerations, 302 \\nmultidimensional analysis factors, 288 \\nMDC (Meta Data Coalition), 325 \\nMerging utility, 225, 228 \\nMeta data \\ncapture, 73 \\nimmature attempts to organize, 239-240 \\nimportance of, 172-173 \\nmigration process, 331 \\npopulating meta data repository, 321-324 \\nsources of, 240-242 \\nMeta data administrator \\nbook chapters of interest, xxxi \\ndata analysis, 145 \\nHuman Resource Allocation Matrix, 379-385 \\nimplementation, 356 \\nmeta data repository analysis, 189 \\nmeta data repository design, 256 \\nmeta data repository development, 323, 334 \\nnontechnical enterprise infrastructure evalua- \\ntion, 78 \\nproject planning, 102 \\nproject requirements definition, 122 \\nrelease evaluation, 373 \\nresponsibilities of, 22 \\nMeta data classifications, 176-182 \\nMeta Data Coalition (MDC), 325 \\nMeta data repository \\nimplementation of, 354 \\nnontechnical infrastructure considerations, \\n64, 67 \\noverview of, 71 \\nstandards for, 73 \\nMeta data repository analysis, 169-190 \\nactivities, 186-188 \\nActivity Dependency Matrix, 407 \\nadditional reading, 190 \\nbusiness analysis stage, 12 \\nchallenges of implementing, 182-184 \\nconsiderations about, 170-171 \\ndeliverables, 188 \\nEntry & Exit Criteria and Deliverables \\nMatrix, 394 \\nHuman Resource Allocation Matrix, 381 \\nimportance of meta data, 172-173 \\nlogical meta model, 184-186 \\nmeta data classifications, 176-182 \\nas navigation tool, 174-176 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 569}, page_content='536 \\nMeta data repository analysis continued \\noverview of, 169 \\nPractical Guidelines Matrix, 470-471 \\nrisks of not performing, 189 \\nroles, 188-189 \\nTask/Subtask Matrix, 431—432 \\nMeta data repository design, 237-258 \\nactivities, 254—255 \\nActivity Dependency Matrix, 408 \\nadditional reading, 257—258 \\ncentralized, 242-244 \\nconsiderations about, 238-239 \\ndecentralized, 244-245 \\ndeliverables, 255-256 \\ndesign stage, 13 \\ndistributed XML-enabled, 245-247 \\nentity-relationship, 247-248, 254-255 \\nEntry & Exit Criteria and Deliverables \\nMatrix, 397 \\nHuman Resource Allocation Matrix, 382 \\nlicensing, 250-254 \\nmeta data silos, 239-242 \\nobject-oriented, 248-250, 254-255 \\noverview of, 237 \\nPractical Guidelines Matrix, 477-478 \\nrisks of not performing, 257 \\nroles, 256 \\nTask/Subtask Matrix, 438-439 \\nMeta data repository developers \\nbook chapters of interest, xxxi \\nHuman Resource Allocation Matrix, \\n383-385 \\nimplementation, 356 \\nmeta data repository development, 334 \\nrelease evaluation, 373 \\nresponsibilities of, 24 \\nMeta data repository development, 319-336 \\nactivities, 331-332 \\nActivity Dependency Matrix, 409 \\nadditional reading, 335 \\nconsiderations about, 320-321 \\nconstruction stage, 13-14 \\ndeliverables, 332—333 \\ndirectory, 330 \\nEntry & Exit Criteria and Deliverables \\nMatrix, 401 \\nHuman Resource Allocation Matrix, 383 \\ninterface processes, 324-326 \\noverview of, 319 \\nIndex \\npopulating, 321-324 \\nPractical Guidelines Matrix, 485-486 \\npreparing for rollout, 327-330 \\nrisks of not performing, 334 \\nroles, 333-334 \\nTask/Subtask Matrix, 447-449 \\ntesting, 326-327 \\nMeta data repository program library, 328, 333, \\n354 \\nMeta data repository test plan, 333 \\nMeta Data Repository Track, 18 \\nMeta-meta data, 186 \\nMiddleware. see also Gateways \\nplatform, 57-58 \\ntechnical enterprise infrastructure evaluation \\nof, 53, 61-62 \\nMigration process, meta data, 331 \\nMitigation plan, 86 \\nMnemonics, 223 \\nMock-up prototype, 156-157 \\nMOLAP (multidimensional OLAP) tools, 292 \\nMonitoring \\ndatabase performance, 207 \\nresource utilization, 347-348 \\nMulti-tier environment, security, 341-344 \\nMultidimensional database design \\nOLAP tools, 284-289, 292 \\noverview of, 195-196 \\nMultidimensional OLAP (MOLAP) tools, 292 \\nMultivariate analysis, 288 \\nN \\nNavigation tool, meta data, 174-176 \\nNegotiation skills, 365 \\nNetworks \\nDBMS selection criteria for, 60 \\nevaluating technical infrastructure, 53 \\nmonitoring utilization of, 347-348 \\nservices staff, 24—25 \\ntechnical enterprise infrastructure evaluation \\nactivities, 62 \\nNontechnical enterprise infrastructure evaluation. \\nsee Enterprise infrastructure evaluation, \\nnontechnical \\nNormalization rules \\nE-R modeling based on, 128 \\nETL development, 262 \\noperational databases and, 194-195 \\nNote-taking, interviewing process, 118 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 570}, page_content='Index 537 \\noO Peer reviews, 67, 267 \\nObject Management Group (OMG), 325 Performance \\nObject-oriented (OO) meta data repository, application requirements document content \\n248-250, 254-255 on, 115 \\nObjectives \\nproject, 47, 85 \\nprototype, 160, 467 \\nODBC (Open Database Connectivity), 58 \\nOLAP (online analytical processing) tools \\nadvantages of, 284-285 \\narchitecture, 289-292 \\ndata mining vs., 305 \\nfeatures of, 285-287 \\nmeta data, 241 \\nmultidimensional analysis factors, 287—289 \\noverview of, 283 \\npopulating meta data repository and, 323 \\npost-implementation review, 365 \\nPractical Guidelines Matrix, 457 \\nOMG (Object Management Group), 325 \\nOnline analytical processing. see OLAP (online \\nanalytical processing) tools \\nOnline help function \\napplication development, 296-297 \\nmeta data repository, 255-256, 327-328, \\n332, 477 \\nOO (object-oriented) meta data repository, \\n248-250, 254-255 \\nOpen Database Connectivity (ODBC), 58 \\nOperational data \\nassessing business cases, 47 \\nbusiness analysis issues, 36-37 \\nOperational databases \\nembedded process logic and, 222 \\noverview of, 193 \\nOperational prototype, 159 \\nOperational systems \\ncleansing, 141 \\ndata mining, 306-307 \\nOperations staff role, 24 \\nOrganization risk, 42 \\nP \\nParallel development tracks, 17—20 \\nParallel query execution, 204 \\nPartitioning, database design, 202 \\nPasswords \\ngap analysis matrix and, 343 \\nsecurity management and, 341 \\ndatabase design for, 192 \\nE-R meta data design for, 248 \\nETL design for, 212 \\nETL development testing for, 271-272, \\n276-277 \\nindexing schemes and, 224 \\nload, 225 \\nmonitoring database, 207 \\nproject requirements and, 107 \\nselecting DBMS based on, 60 \\nPerformance testing \\napplication development, 296 \\nETL development, 271-272, 276 \\nwith prototypes for, 152 \\nPersonnel utilization, 348 \\nPert charts, 100, 101 \\nPhysical database design, 201-204, 206 \\nPlacement, dataset, 201-202 \\nPlain text, defined, 345 \\nPlanning stage \\ndefined, 6 \\ndevelopment steps in, 11 \\nparallel development tracks and, 19 \\nPoint-to-point gateways, defined, 58 \\nPolicies, standards, 75 \\nPortfolio management, 313 \\nPost-implementation reviews, 364-369 \\nactivities, 369-370 \\norganizing, 366-368 \\nrelease evaluation considerations, 360 \\nsession flow, 368-369 \\ntopics for, 364-366 \\n“Power users’, 18, 110, 114, 173, 325 \\nPractical Guidelines Matrix, 455-490 \\napplication development, 481-482 \\napplication prototyping, 467-469 \\nbusiness case assessment, 455—456 \\ndata analysis, 464-466 \\ndata mining, 483-484 \\ndatabase design, 472-474 \\ndefined, xxvii \\nenterprise infrastructure evaluation, nontech- \\nnical, 459 \\nenterprise infrastructure evaluation, technical, \\n457-458 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 571}, page_content='538 \\nPractical Guidelines Matrix continued \\nETL design, 475-476 \\nETL development, 479-480 \\nimplementation, 487-488 \\nmeta data repository analysis, 470—47 1 \\nmeta data repository design, 477-478 \\nmeta data repository development, 485-486 \\nproject planning, 460-461 \\nproject requirements definition, 462—463 \\nrelease evaluation, 489-490 \\nPredictive modeling, data mining, 310-311 \\nPresentation services, OLAP, 290-291 \\nPrimary keys \\nlogical data identifiers vs., 133 \\nresolution of duplicate, 221 \\nPrivate data, 36-37 \\nProcedures, 64-65, 75 \\nProcess flow, ETL \\ncontents of, 233 \\ndesigning, 212, 225-229, 232 \\nintegration testing and, 269 \\npreparing for, 215-219 \\nProcess independence, 128-129 \\nProduct evaluation, 251-252 \\nProduction \\nenvironment, 293-294, 353 \\nmeta data repository development, 327-330, \\n362 \\nplanning implementation, 338 \\nProfit, cost-benefit analysis, 39 \\nProgramming specifications \\nETL design, 233 \\nmeta data repository design, 256 \\nPrograms \\napplication, 296 \\nETL, 232-233, 277 \\nmeta data repository, 332, 333 \\nProject charter, 99, 100-101 \\nProject core team members, 20-23 \\nProject manager \\nbook chapters of interest, xxx \\nbusiness case assessment, 49 \\nHuman Resource Allocation Matrix, 379-380, \\n385 \\npeer reviews, 267 \\npost-implementation review, 368 \\nproject planning, 82, 83-84, 102 \\nrelease evaluation, 373 \\nresponsibilities of, 22 \\nIndex \\nProject planning, 81-103 \\nactivities, 98-100 \\nActivity Dependency Matrix, 406 \\nadditional reading, 103 \\nconsiderations about, 82—83 \\ncritical path method, 95-96 \\ndefining the project, 84—90 \\ndeliverables, 100-101 \\nEntry & Exit Criteria and Deliverables \\nMatrix, 390 \\nestimating techniques, 92—93 \\nHuman Resource Allocation Matrix, 380 \\nmanaging the project, 83-84 \\noverview of, 81 \\nplanning stage, 11 \\nplanning the project, 90-98 \\nPractical Guidelines Matrix, 460-461 \\nresource assignments and, 93-94 \\nresource dependencies and, 95 \\nrisks of not performing, 103 \\nroles, 101—102 \\nscheduling, 96—98 \\ntask dependencies, 94-95 \\nTask/Subtask Matrix, 418—421 \\nProject requirements definition, 105-124 \\nactivities, 118-121 \\nActivity Dependency Matrix, 406 \\nadditional reading; 123-124 \\nbusiness analysis stage, 12 \\nconsiderations about, 106-107 \\ndeliverable, 121 \\nEntry & Exit Criteria and Deliverables \\nMatrix, 391 \\ngeneral business, 108-112 \\nHuman Resource Allocation Matrix, 380 \\ninterviewing process and, 116-118 \\noverview of, 105 \\nPractical Guidelines Matrix, 462-463 \\nproject-specific, 112-116 \\nrisks of not performing, 122-123 \\nrolesmiZI=109) \\nTask/Subtask Matrix, 422-424 \\nProject-specific requirements \\napplication requirements document and, 114-116 \\ncross-organizational developmental steps vs., 16 \\ngeneral business requirements vs., 107 \\ninterviewees for, 113-114 \\nlogical data models and, 128-129 \\noverview of, 112-113 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 572}, page_content='Index \\nProject team risk, 42 \\nPromotions, 312 \\nProof-of-concept prototype, 157 \\nPrototype charter \\ncontents of, 165 \\noverview of, 160-161 \\npreparing, 164 \\nPrototyping. see Application prototyping \\nQ \\nQA (Quality assurance) \\nanalyst, 24 \\nenvironment, 293-294 \\nQA testing \\napplication development, 296 \\nETL development, 272, 277 \\nmeta data repository development, 327 \\nQuality, project constraints and, 87 \\nQueries \\nbandwidth and, 348 \\ndatabase design for, 192 \\nDBMS selection criteria for, 60 \\ndesigning prototype for, 164 \\nmonitoring database performance of, 207 \\nOLAP and, 286, 291 \\nparallel execution design for, 204 \\nQuestionnaires, interview, 117 \\nR \\nReadiness assessment, 30 \\nReading, additional. see Bibliography/additional \\nreading \\nReconciliation, ETL, 263-267 \\nactivities of, 228 \\ncalculating totals, 264-266 \\ndesigning, 213 \\noverview of, 263-264 \\npreparing for, 215 \\nstandards, 74 \\nstoring statistics, 266-267 \\nRecord counts, ETL reconciliation, 228, \\n264-265 \\nRecords, processing deleted, 218-219 \\nRecovery \\noverview of, 345-347 \\nphysical database design, 203-204 \\nReference guides. see Instruction guides \\nReferential integrity (RI), 224, 473, 476 \\nRegression analysis, data mining, 309 \\n539 \\nRegression testing \\napplication development, 296 \\nETL development, 271-272, 276 \\nmeta data repository development, 326-327, \\n332 \\nRelational OLAP (ROLAP) tools, 292 \\nRelease concept, 5, 14, 361-364 \\nRelease evaluation, 359-376 \\nactivities, 369-370 \\nActivity Dependency Matrix, 410 \\nadditional reading, 375 \\napplication release concept, 361-364 \\nconsiderations about, 360 \\ndeliverables, 371 \\ndeployment stage, 14 \\nEntry & Exit Criteria and Deliverables \\nMatrix, 403 \\nHuman Resource Allocation Matrix, 385 \\noverview of, 359 \\npost-implementation reviews, 364-369 \\nPractical Guidelines Matrix, 489-490 \\nrisks of not performing, 374 \\nroles, 371-374 \\nTask/Subtask Matrix, 453-454 \\nReorganization, physical database design, 203 \\nReports \\nbusiness case assessment, 48 \\ndatabase design, 192 \\ndefining requirements for, 120 \\nearly meta data, 239 \\ngeneral business requirements, 111-112 \\nnontechnical infrastructure assessment, 76 \\nOLAP, 291 \\noperational system, 195 \\nprototype design, 164 \\ntechnical infrastructure assessment, 62 \\nRequest for information (RFI), 63 \\nRequest for proposal (RFP), 63 \\nResearch, interviewing process, 117 \\nResource dependencies, 95 \\nResources. see Bibliography/additional reading \\nReturn on investment. see ROI (return on \\ninvestment) \\nRevenue, 39 \\nReviews, post-implementation, 364-369 \\nRFI (request for information), 63 \\nRFP (request for proposal), 63 \\nRI (referential integrity), 224, 473, 476 \\nRisk management, data mining, 312 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 573}, page_content='540 \\nRisk, of omitting \\napplication development, 299 \\napplication prototyping, 166-167 \\nbusiness case assessment, 49-50 \\ndata analysis, 145-146 \\ndata mining, 316 \\ndatabase design, 209 \\nETL design, 234 \\nETL development, 279 \\nimplementation, 356 \\nmeta data repository analysis, 189 \\nmeta data repository design, 257 \\nmeta data repository development, 334 \\nnontechnical enterprise infrastructure \\nevaluation, 78 \\nproject planning, 103 \\nproject requirements definition, 122-123 \\nrelease evaluation, 374 \\ntechnical enterprise infrastructure evaluation, 63 \\nRisks \\nassessment, 40—45 \\nbusiness case assessment and, 456 \\ncommon project, 85-86 \\nconsiderations about, 30 \\ndata mining and, 312 \\njustifying, 33 \\nproject planning and, 99, 460 \\nsecurity standards minimizing, 74 \\nROI (return on investment) \\nactivities for determining, 45—47 \\nassessing risk on, 42 \\nconsiderations about, 30 \\ncost-benefit analysis of, 37-40 \\nhardware platforms and, 55 \\npost-implementation review of, 365 \\nROLAP (relational OLAP) tools, 292 \\nRoles \\napplication development, 298 \\napplication prototyping, 165-166 \\nBI arbitration board, 26 \\nbusiness case assessment, 49 \\ncore team members, 21—23 \\ndata analysis, 144-145 \\ndata mining, 316 \\ndatabase design, 208-209 \\nETL design, 233-234 \\nETL development, 278 \\nextended team members, 23-25 \\nHuman Resource Allocation Matrix, 379-385 \\nIndex \\nimplementation, 355-356 \\nlimited, 25 \\nmeta data repository analysis, 188-189 \\nmeta data repository design, 256 \\nmeta data repository development, 333-334 \\nnontechnical enterprise infrastructure \\nevaluation, 77—78 \\nproject planning, 101-102 \\nproject requirements definition, 121-122 \\nrelease evaluation, 371-374 \\ntechnical enterprise infrastructure evaluation, 63 \\nS \\nSavings, cost-benefit analysis, 39 \\nScalability \\nDBMS selection criteria for, 60 \\nhardware platforms and, 54-57 \\nPractical Guidelines Matrix, 457 \\nSchedules \\ndeadline management, 155 \\ninterview, 117 \\nmeta data repository rollout, 329 \\npost-implementation review, 364, 367 \\nproject, 96-97 \\nprototype activities, 152-153 \\nsetting up production, 353 \\nScope \\napplication development and, 282 \\ndefining requirements for, 120 \\npost-implementation review, 365 \\nScope, application prototyping \\nbuilding slimware to limit, 155 \\nconsiderations about, 150 \\ndetermining, 163-164 \\nlimiting, 153 \\nsystem analysis and, 159-160 \\nScope, project planning \\nchange-control and, 88-89 \\nconsiderations about, 82 \\ndetermining requirements for, 98-99 \\noverview of, 85 \\nScribe \\nHuman Resource Allocation Matrix, 385 \\npost-implementation review, 369 \\nrelease evaluation, 373 \\nresponsibilities of, 25 \\nSecurity, 340-345 \\napplication requirements document and, 115-116 \\ndatabase, 206 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 574}, page_content='Index 541 \\nDBMS selection criteria for, 61 \\nimplementation and, 338 \\nInternet access, 344-345 \\nmeasures for, 340-341 \\nmeta data repository, 328 \\nmulti-tier environments and, 341-344 \\nofficers, 24 \\nproject requirements and, 106 \\nstandards, 74 \\nWeb, 294 \\nSecurity gap analysis matrix, 343-344 \\nSequential pattern discovery technique, 308 \\nServer platforms, 328, 351 \\nService-level agreements. see SLAs (service-level \\nagreements) \\nServices, OLAP, 291 \\nShow-and-tell prototype, 156 \\n“Single-swim-lane” development practices, \\n7-8, 9 \\nSkills survey, 162-163 \\nSLAs (service-level agreements) \\ndefining preliminary, 120-121 \\nestablishing standards, 74-75 \\nnontechnical enterprise infrastructure \\nevaluation, 76 \\nSlimware, 155 \\nSnowflake schema, 200 \\nSoftware, application release concept, 361-362 \\nSorting utilities, ETL process, 225, 228 \\nSource data \\nanalyzing quality of, 142 \\nbottom-up analysis of, 133-136 \\ncreating inventory of, 67 \\ndata analysis considerations of, 126 \\nfor data mining, 306-307 \\ndefining requirements for, 120 \\ndetermining condition of, 99 \\nETL development, 260, 261-263 \\nguidelines for analyzing, 465-466 \\nselection process for, 137-139 \\ntransformation problems with, 221-222 \\nSource-to-target mapping document \\ncontents of, 233 \\ncreating, 231-232 \\noverview of, 225-226 \\nSpreadsheets, 322 \\nSQL (Structured Query Language) \\nE-R meta data repository design and, 248 \\ngateways using, 58 \\nobject-oriented meta data repository design \\nand, 249 \\nStaffing \\ndata mining, 302 \\ndatabase design, 193 \\nmeta data repository analysis, 171, 183 \\nmeta data repository design, 239 \\nmeta data repository development, 320-321 \\nparallel development tracks, 17-18 \\npost-implementation review, 365 \\nproject core team, 21 \\nproject planning, 82 \\nresource dependencies, 95 \\nstep core team, 21 \\nStaging area, ETL \\ncontents of, 233 \\ndesign considerations, 212 \\ndesigning for, 228-229 \\nsetting up, 232 \\nStakeholders \\napplication prototyping, 166 \\ndata analysis, 145 \\nHuman Resource Allocation Matrix, 381, 385 \\nproject-specific requirements, 114 \\nrelease evaluation, 374 \\nresponsibilities of, 24 \\nStand-alone systems, 7-8 \\nStandards \\nnontechnical, 64-65, 67, 71-75 \\ntechnical, 54 \\nStar schema, 197-200 \\nStart to Finish, task dependencies, 94-95 \\nStart to Start, task dependencies, 94-95 \\nStatistical analysis, 303-305 \\nStep core team members, 20-23 \\nStock performance, 313 \\nStored procedures, 60 \\nStovepipe systems (automation silos), 65-66, 130 \\nStrategic architect, 24 \\nStress testing, 271-272 \\nStructured Query Language (SQL) \\nE-R meta data repository design and, 248 \\ngateways using, 58 \\nobject-oriented meta data repository design \\nand, 249 \\nSubject matter expert \\napplication development, 298 \\napplication prototyping, 166 \\nbook chapters of interest, xxxi \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 575}, page_content='542 \\nSubject matter expert continued \\nbusiness case assessment, 49 \\ndata analysis, 145 \\ndata mining, 316 \\nETL design, 234 \\nETL development, 278 \\nETL integration testing, 269 \\nHuman Resource Allocation Matrix, 379-383, \\n385 \\nmeta data repository analysis, 189 \\nproject planning, 102 \\nproject requirements definition, 114, 122 \\nrelease evaluation, 374 \\nresponsibilities of, 22 \\nSubtask matrix. see Task/Subtask Matrix \\nSuccess, measuring, 360 \\nSummarization \\ndatabase design, 204, 206 \\ndefining, 285 \\nETL development, 262 \\nmanaging growth in data with, 350 \\nOLAP tools providing, 285 \\nSupport (help desk) \\nimplementation and, 338-339, 353 \\nrole of extended team members, 24 \\nSynonyms, 222 \\nSYSTABLES, 323 \\nT \\nTape recording, interviewing process, 118 \\nTask dependencies, 94-95 \\nTask/Subtask Matrix, 411-454 \\napplication development, 442-444 \\napplication prototyping, 427-430 \\nbusiness case assessment, 411-413 \\ndata analysis, 425-426 \\ndata mining, 445-446 \\ndatabase design, 433-435 \\ndefined, xxvii \\nenterprise infrastructure evaluation, 414-417 \\nETL design, 436—437 \\nETL development, 440-441 \\nimplementation, 450-452 \\nmeta data repository analysis, 431-432 \\nmeta data repository design, 438-439 \\nmeta data repository development, 447-449 \\nproject planning, 418-421 \\nproject requirements definition, 422-424 \\nrelease evaluation, 453-454 \\nIndex \\nTCP/IP (Transmission Control Protocol/Inter- \\nnet Protocol), 351 \\nTeam members \\nApplication track, 18 \\nassessing risk to, 42 \\nbook chapters of interest, xxxi \\ncore team. see Core team members \\ndatabase design, 193 \\nEllitrack, 17 \\nextended team. see Extended team members \\nMeta Data Repository track, 18 \\npost-implementation review, 367 \\nproject planning, 82 \\nprototyping, 154, 468 \\nresource assignment and, 93-94 \\nTechnical data conversion rules, 134 \\nTechnical enterprise infrastructure evaluation. see \\nEnterprise infrastructure evaluation, technical \\nTest logs, 274-275, 297, 327, 333 \\nTesters \\napplication development, 298 \\nbook chapters of interest, xxxi \\nETL development, 278 \\nHuman Resource Allocation Matrix, 383 \\nmeta data repository development, 326-327, 334 \\nresponsibilities of, 25 \\nTesting \\nacceptance, 268, 272, 277, 296, 326-327, 334 \\napplication development, 296-297 \\napplication prototypes, 154 \\nintegration (system), 268, 270, 276, 296, \\n326-327, 332 \\nmeta data repository development, 326-327, \\n331-333 \\nnontechnical enterprise infrastructure evalua- \\ntion, 65, 76 \\nperformance (stress), 268, 271-272, 276, 296 \\nquality (QA), 268, 272, 277, 296, 327 \\nregression, 268, 271-272, 276, 296, 326-327, 332 \\nstandards for, 73-74 \\nunit, 268-269, 276, 296, 326, 331 \\nTesting, ETL development, 268-275 \\nconsiderations about, 260 \\npeer reviews and, 267-268 \\nplan for, 273-275, 277 \\nTime \\nboxing, 152-153 \\nconstraints, 84 \\nsequence discovery, data mining, 309-310 \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 576}, page_content='Index 543 \\nTool administrators, 25 \\nTool interface process, meta data repository, \\n324-325 \\nTools. see also OLAP (online analytical process- \\ning) tools \\naccess and analysis, 282 \\napplication prototyping, 151, 164 \\ndata cleansing, 139 \\nmeta data sources, 240-242 \\nTools, ETL \\nconsiderations about, 212 \\nevaluating, 229-231 \\ntest functionality of, 232 \\nTop-down logical data modeling \\ndefine business rules, 465 \\noverview of, 128-133 \\nTraining \\napplication development, 296-297 \\nmaterials, 297, 333 \\nmeta data repository, 329-330, 332, 333 \\nplanning for, 338-339 \\npost-implementation review, 365 \\nTransformation programs \\ndesigning, 221-223 \\ndesigning ETL process flow, 228 \\nETL development, 261-263 \\nTriggers, 60, 86 \\nU \\nUnit testing \\napplication development, 296 \\nETL development, 269, 276 \\nmeta data repository development, 326, 331 \\nUniversal gateways, defined, 58 \\nUsage \\nDBMS selection criteria for, 60 \\nmanaging growth in, 350-351 \\nUtilization, of resources, 347-348 \\nV \\nValidation, 151 \\nVendor evaluation, 252-254 \\nVendors \\napplication release concept, 361-362 \\nevaluating ETL tools, 230-231 \\nlicensing meta data repository from, 242, 244, \\n250-254 \\npost-implementation review, 366 \\nVery large databases. see VLDBs (very large \\ndatabases) \\nVisual-design prototype, 157-158 \\nVLDBs (very large databases) \\ndata backup and recovery on, 346-347 \\ndesigning, 201 \\nhardware requirements for, 351 \\nPractical Guidelines Matrix, 457 \\nWwW \\nWaterfall deployment, 7-8 \\nWeb \\napplication development considerations, 283 \\nenvironment, 294-295 \\nsecurity, 344-345 \\nWeb developers \\napplication development, 297 \\nbook chapters of interest, xxxi \\nHuman Resource Allocation Matrix, 383-385 \\nimplementation, 356 \\nrelease evaluation, 373 \\nresponsibilities of, 25 \\nWeb master \\napplication development, 297 \\napplication prototyping, 166 \\nbook chapters of interest, xxxi \\nHuman Resource Allocation Matrix, 381, 383-385 \\nimplementation, 356 \\nrelease evaluation, 374 \\nresponsibilities of, 25 \\nWord processing files, 321-322 \\nxX \\nXML-enabled meta data solution, 245-247. see \\nalso Distributed XML-enabled meta data \\nsolution. \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 577}, page_content='| prea opr arerneegh power \\npeers “ee 7 ‘ae om ASS of ; \\neas on sith <i cagitten, cpp lenl m=. lI Pi Aha \\nr] eure eaintyetsh \\n: semepieed a \\nGs REA Mir ae \\nhk 6/4 ance \" \\nKiontore ah tN et. “4 \\notis ayire) ieuiliep : \\nj geese In lower yie » Hurd \\nioe (anid? daniel \\n07 E, patent ahr’ \\n£8 aetaalirs We \\nFads Widkeage \\njj Pnemat, | 0@ eae CEN v a 7) = \\nCe OS. soerayabews ee nied, VrpibAy ae Wil. gig tem % oboe a be ror ene \\nye geolierces™ eas? ia rf c \\nwe 6 eoiienaies! i \\na et wo ude eae 7 ry as \\nal Fallh oe Nhasigy pe ‘ ia 4 a ele } \\nSe) at 0 pnieenei™ Ce, ie “A tics \\nTi 4 x fh . 7 \\nepee: APY ond” (toe ie iinet wr 1&2 Is a, Ja, te) \\n~- 4 lalate GID. Laptorelges ! yee nora gap 1 ta —-.6==64) a. © ed oes (=the Vow, 6 di hid \\n| SS. SD GG ewe @ ~ me Crates: oA: 6 \\n| om $R avd Mn de at ~~ I? : | : Fee (Le | ated +S = vs. é a : = \\nwer’ a ; | _— on apts a j | ant bi a ee | ra ia A \\nSins > \\na \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 578}, page_content='NddO \\nOL \\nSNOILONULSNI \\nYOd \\nACIS \\nASAAAAA \\nFHS \\nASVATd \\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 579}, page_content=\"r e/Data Warehousing \\nBusiness Intelligence Roadmap \\nMoss ¢ Atre \\n“If you are looking for a complete treatment of business intelligence, then go no further than this book. Larissa \\nT. Moss and Shaku Atre have covered all the bases in a cohesive and logical order, making it easy for the reader \\nto follow their line of thought. From early design to ETL to physical database design, the book ties together all \\nthe components of business intelligence.” \\n—Bill Inmon, Inmon Enterprises \\nBusiness Intelligence Roadmap is a visual guide to developing an effective business intelligence (BI) decision- \\nsupport application. This book outlines a methodology that takes into account the complexity of developing \\napplications in an integrated BI environment. The authors walk readers through every step of the process— \\nfrom strategic planning to the selection of new technologies and the evaluation of application releases. The \\nbook also serves as a single-source guide to the best practices of BI projects. \\nPart I steers readers through the six stages of a BI project: justification, planning, business analysis, design, con- \\nstruction, and deployment. Each chapter describes one of sixteen development steps and the major activities, \\ndeliverables, roles, and responsibilities. All technical material is clearly expressed in tables, graphs, and diagrams. \\nPart II provides five matrices that serve as references for the development process charted in Part I. Management \\ntools, such as graphs illustrating the timing and coordination of activities, are included throughout the book. \\nThe authors conclude by crystallizing their many years of experience in a list of dos, don'ts, tips, and rules of \\nthumb. The accompanying CD-ROM includes a complete, customizable work breakdown structure. \\nBoth the book and the methodology it describes are designed to adapt to the specific needs of individual stake- \\nholders and organizations. The book directs business representatives, business sponsors, project managers, \\nand technicians to the chapters that address their distinct responsibilities. The framework of the book allows \\norganizations to begin at any step and enables projects to be scheduled and managed in a variety of ways. \\nBusiness Intelligence Roadmap is a clear and comprehensive guide to negotiating the complexities inherent in \\nthe development of valuable business intelligence decision-support applications. \\nShaku Atre \\nPresident, Atre Group, Inc. \\nhttp://www.atre.com \\nLarissa T. Moss \\nPresident, Method Focus, Inc. \\nhttp://www.methodfocus.com \\nhttp://www.awprofessional.com \\nCover photograph by Digital Vision \\n€ Text printed on recycled paper \\nvv Addison-Wesley \\nPearson Education \\n\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 0}, page_content=''),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 1}, page_content='Fundamentals\\nof\\nB U S I NESS\\nANALYTICS2nd Edition\\n2nd Edition\\nFUNDAMENTALS OF\\nBusiness Analytics'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 2}, page_content=''),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 3}, page_content='R. N. Prasad\\nSeema Acharya\\nFounder and Chief Practice Officer of Confluence Consulting Circle\\nFormerly, Senior Principal Consultant at Infosys, India\\nLead Principal, Education, Training and Assessment Department, \\nInfosys Limited\\n2nd Edition\\nFUNDAMENTALS OF\\nBusiness Analytics'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 4}, page_content='Copyright © 2016 by Wiley India Pvt. Ltd., 4435-36/7, Ansari Road, Daryaganj, New Delhi-110002.\\nCover Image from \\nAll rights reserved. No part of  this book may be reproduced, stored in a retrieval system, or transmitted in any form or by \\nany means, electronic, mechanical, photocopying, recording or scanning without the written permission of  the publisher.\\nLimits of  Liability: While the publisher and the authors have used their best efforts in preparing this book, Wiley and \\nthe authors make no representation or warranties with respect to the accuracy or completeness of  the contents of  this \\nbook, and specifically disclaim any implied warranties of  merchantability or fitness for any particular purpose. There are \\nno warranties which extend beyond the descriptions contained in this paragraph. No warranty may be created or \\nextended by sales representatives or written sales materials. The accuracy and completeness of  the information provided \\nherein and the opinions stated herein are not guaranteed or warranted to produce any particular results, and the advice \\nand strategies contained herein may not be suitable for every individual. Neither Wiley India nor the authors shall be liable \\nfor any loss of  profit or any other commercial damages, including but not limited to special, incidental, consequential, or \\nother damages.\\nDisclaimer:  The contents of  this book have been checked for accuracy. Since deviations cannot be precluded entirely, \\nWiley or its authors cannot guarantee full agreement. As the book is intended for educational purpose, Wiley or its \\nauthors shall not be responsible for any errors, omissions or damages arising out of  the use of  the information contained \\nin the book.  This publication is designed to provide accurate and authoritative information with regard to the subject \\nmatter covered. It is sold on the understanding that the Publisher is not engaged in rendering professional services. \\nTrademarks: All brand names and product names used in this book are trademarks, registered trademarks, or trade \\nnames of  their respective holders. Wiley is not associated with any product or vendor mentioned in this book.\\nOther Wiley Editorial Offices:\\nJohn Wiley & Sons, Inc. 111 River Street, Hoboken, NJ 07030, USA\\nWiley-VCH Verlag GmbH, Pappellaee 3, D-69469 Weinheim, Germany\\nJohn Wiley & Sons Australia Ltd, 42 McDougall Street, Milton, Queensland 4064, Australia\\nJohn Wiley & Sons (Asia) Pte Ltd, 2 Clementi Loop #02-01, Jin Xing Distripark, Singapore 129809\\nJohn Wiley & Sons Canada Ltd, 22 Worcester Road, Etobicoke, Ontario, Canada, M9W 1L1\\nFirst Edition: 2011\\nISBN: \\nwww.wileyindia.com\\nPrinted at: \\n© Sergey Nivens/Shutterstock\\nSecond Edition: 2016\\n978-81-265-6379-1\\nshutterstock_137180522\\nWiley Credit - Sergey Nivens/Shutterstock\\n2nd Edition\\nFUNDAMENTALS OF\\nBusiness Analytics\\nISBN: 978-81-265-8248-8 (ebk)\\nNote: CD is not part of ebook'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 5}, page_content='Business Analytics deals with the methodology of making available dependable ‘facts’ using large \\n volumes of high-quality data from multiple sources. The challenges are in ensuring that data are of good \\nquality, data in different formats are properly integrated, and aggregated data are stored in secure \\n systems, and then delivered to users at the right time in the right format. Businesses have gone past the \\ntraditional approaches of ‘MIS Reporting’ and moved into the realm of statistical /quantitative analysis \\nand predictive modeling. Organizations world-wide have evolved systems and processes to transform \\ntransactional data into business insights.  There are suites of technical as well as management concepts \\nthat have come together to deliver analytics relevant to the business.  \\nBusiness intelligence systems and analytical applications provide organizations with information \\nfrom the enormous amount of data hidden in their various internal systems, and equip the organization \\nwith abilities to influence the business direction.  They provide answers to complex business questions, \\nsuch as:\\n• How do we get more insights about our customers, partners and employee talents?\\n • What will be the products and services our customers will need?\\n • How do we target our products and services at the most profitable geographies, customers and \\nsegments?\\n • How do we detect and prevent frauds?\\n • How do we enhance the experience of ‘Doing Business with Us’ for all stakeholders?\\nThis book is an attempt at providing foundational knowledge associated with the domain of Business \\nAnalytics. It has basic and holistic coverage of the topics needed to handle data.  The coverage include \\norganizational perspectives, technical perspectives, as well some of the management concepts used in \\nthis field.\\nThis book aims to provide a good coverage of all the critical concepts including: \\n • What problems does the technology of Data Warehouse (DW)/Business Intelligence (BI)/ \\nAdvanced Analytics (AA) solve for businesses?\\n • When is an organization ready for DW/BI/AA projects?\\n • How do industries approach BI/DW/AA projects?\\nForeword'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 6}, page_content='vi • Foreword\\n • What is the significance of data, meta-data and data quality challenges, and data modeling?\\n • What data are to be analyzed? How do we analyze data? What are the characteristics of good \\nmetrics?\\n • How do we frame Key Performance Indicators (KPIs)?\\n • What makes for a good Dashboard and Analytical Report?\\n • What is the impact of mobile computing, cloud computing, ERP applications, and social net-\\nworks? \\nThe book is authored by team members with twenty person-years of good business, industry and cor-\\nporate - university experience. They have related their practical experiences in the field of business \\nanalytics in simple language. Hands-on experience may be gained by using the suggested open - source \\nsoftware tools and the step-by-step lab guide provided by the authors; the exercises and project ideas will \\nbring enhanced exposure.\\nThis book promises to get you started in the world of business analytics and harness the power \\ntherein for a fruitful and rewarding career. \\nProf R Natarajan\\nFormer Chairman, AICTE\\nFormer Director, IIT Madras'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 7}, page_content='The idea of a book was conceived owing to the demand by students and instructor fraternities alike, for \\na book which includes a comprehensive coverage of business intelligence, data warehousing, analytics \\nand its business applications. \\nSalient Features of the Book\\nThe following are few salient features of the book:\\n • The book promises to be a single source of introductory knowledge on business intelligence \\nwhich can be taught in one semester. It will provide a good start for first time learners typically \\nfrom the engineering and management discipline.\\n • The book covers the complete life cycle of BI/Analytics project: Covering operational/transac-\\ntional data sources, data transformation, data mart/warehouse design-build, analytical reporting \\nand dashboards.\\n • T o ensure that concepts can be practiced for deeper understanding at low cost or no cost, the \\nbook is accompanied with step by step Hands-On manual (in CD) on:\\n\\uf0a7 Advanced MS Excel to explain the concept of analysis\\n\\uf0a7 R Programming to explain analysis and visualization\\n • Business Intelligence subject cannot be studied in isolation. The book provides a holistic cover-\\nage beginning with an enterprise context, developing deeper understanding through the use of \\ntools, touching a few domains where BI is embraced and discussing the problems that BI can \\nhelp solve. \\n • The concepts are explained with the help of illustrations and real life industrial strength applica-\\ntion examples.\\n • The pre-requisites for each chapter and references to books currently available are stated.\\n • In addition the book has the following pedagogical features:\\n\\uf0a7 Industrial application case studies.\\n\\uf0a7 Cross word puzzles/do it yourself/exercises to help with self-assessment. The solutions to \\nthese have also been provided. \\nPreface'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 8}, page_content='viii • Preface\\n\\uf0a7 Glossary of terms.\\n\\uf0a7 Summary at the end of every chapter.\\n\\uf0a7 References/web links/bibliography – generally at the end of every concept.\\nTarget Readers\\nWhile designing this book, the authors have kept in mind the typical requirements of the undergradu-\\nate engineering/MCA/MBA students who are still part of the academic program in Universities.  The \\nattempt is to help the student fraternity gain sound foundational knowledge of “Analytics” irrespective \\nof the engineering discipline or special electives they may have chosen.  The best way to benefit from \\nthis book will be to learn by completing all the hands-on lab assignments, exploring the sources of \\nknowledge compiled in this book as well as studying one or two organizations in detail that are leverag-\\ning analytics for their business benefits.\\nStructure of the Book\\nThe book has 13 chapters. \\n • Chapter 1 introduces the readers to the enterprise view of IT applications and discusses some of \\nthe salient requirements of information users. \\n • Chapter 2 explains the types of digital data: structured, semi-structured and unstructured. The \\nreader will learn the nuances of storing, retrieving and extracting information from the various \\ntypes of digital data. \\n • Chapter 3 aims to differentiate between OLTP (On-line T ransaction Processing) and OLAP \\n(On Line Analytical Processing) systems. \\n • Chapters 4 and 5 set the stage for a novice BI learner by enunciating all the terms, concepts and \\ntechnology employed in the BI space.  \\n • Chapters 6, 7, 8 and 9 are core chapters that discuss the building of a data warehouse (Extraction \\nT ransformation Loading process), analyzing the data from multiple perspectives, comprehend-\\ning the significance of data quality and metrics, presenting the data in the apt format to the right \\ninformation users. \\n • Chapters 10 and 11 focus on the significance of statistics in analytics. They seek to explain \\nanalytics through discussing applications.\\n • Chapter 12 introduces data mining algorithms such as Market Basket Analysis, k-means clus-\\ntering and decisions trees with the subsequent implementation of the stated algorithms in R \\nstatistical programming tool.\\n • The book finally concludes with Chapter 13 on the confluence of BI with mobile technology; \\ncloud computing, social CRM, etc.\\nGlossary of terms is also provided at the end of the book.\\nCD Companion\\nThe companion CD consists of a collection of two step-by-step lab guides:\\n • Analysis using “Advanced Microsoft Excel”\\n • Introduction to R programming '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 9}, page_content='Preface • ix\\nHow to Get the Maximum Out of the Book\\nThe authors recommend that the chapters of the book be read in sequence from Chapter 1 to Chapter 13. \\nThe authors recommend that readers complete the pre-requisites stated for the chapter before plunging \\ninto the chapter. The authors have provided useful references at the end of each chapter that should be \\nexplored for deeper gains. After completing the chapter, the readers should solve the “T est Exercises”.\\nWe welcome your suggestions/feedback to assist us in our endeavors to help the learners gain a good \\nfoundation in this subject that is critical to the industry.\\nOur heartfelt gratitude to the teacher’s community who have adopted our book while teaching \\nand evangelizing Business Intelligence subject in their respective colleges. We heard your require-\\nments to include new topics related to Big Data, Statistics, Lab with R, Lab with Advanced \\nExcel and Industry examples of applications of Analytics. We have incorporated these topics \\nwhile retaining the original content to ensure utmost alignment with your college curriculum. \\nOur earnest hope that the Second Edition of the book will immensely benefit the student’s \\ncommunity.\\nRN Prasad\\nSeema Acharya\\nJuly 2016'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 10}, page_content=''),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 11}, page_content='We don’t remember having read the acknowledgement page in any book that we have read so far. And \\nwe have read quite a few!  Now as we pen down the acknowledgement for our book, we realize that this \\nis one of the most important pages. As is the case with any book, the creation of this one was an \\nextended collaborative effort. It’s a collection of ideas, case briefs, definitions, examples, and good prac-\\ntices from various points in the technology field. We have an army of people who have been with us on \\nthis journey and we wish to express our sincere gratitude to each one of them.\\nWe owe it to the student and the teacher community whose inquisitiveness and incessant queries on \\nbusiness intelligence and analytics led us to model this book for them.\\nWe would like to thank our friends – the practitioners from the field – for filling us in on the latest in \\nthe business intelligence field and sharing with us valuable insights on the best practices and methodol-\\nogy followed during the life cycle of a BI project.\\nA special thanks to Ramakrishnan for his unrelenting support and vigilant review.\\nWe have been fortunate in gaining the good counsel of several of our learned colleagues and advisors \\nwho have read drafts of the book at various stages and have contributed to its contents.\\nWe would like to thank Sanjay B. for his kind assistance. We have been extraordinarily fortunate \\nin the editorial assistance we received in the later stages of writing and final preparation of the book. \\nMeenakshi Sehrawat and her team of associates skillfully guided us through the entire process of prepa-\\nration and publication.\\nAnd finally we can never sufficiently thank our families and friends who have encouraged us through-\\nout the process, offering inspiration, guidance and support and enduring our crazy schedules patiently \\nas we assembled the book. \\nAcknowledgments'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 12}, page_content=''),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 13}, page_content='RN Prasad\\nRN Prasad is the founder and Chief Practice Officer of Confluence Consulting Circle with over 37 years \\nof IT industry experience. Prior to this, he was a Senior Principal Consultant at Infosys, India. He is a \\ntrusted advisor in BI & Analytics technology adoption and Product Management practices. He works \\nwith companies to develop data platforms, patent innovative ideas, and design smart-decision systems \\nleveraging SMAC.  \\nHis interest areas include Big Data applications, Business Analytics solutions, BI self-service por-\\ntals,  Data Virtualization, Digital T ransformation, Analytics & Big Data related executive education, \\nAnalytics certification assessments design, University curriculum innovation consulting and IGIP \\n(International Society for Engineering Pedagogy)-based faculty certification.\\nSeema Acharya\\nSeema Acharya is Lead Principal with the Education, T raining and Assessment Department of Infosys \\nLimited. She is an educator by choice and vocation, and has rich experience in both academia and the \\nsoftware industry.  She is also the author of the book, “Big Data and Analytics”, ISBN: 9788126554782, \\npublisher – Wiley India. \\nShe has co-authored a paper on “Collaborative Engineering Competency Development” for ASEE \\n(American Society for Engineering Education). She also holds the patent on “Method and system for \\nautomatically generating questions for a programming language”.\\nHer areas of interest and expertise are centered on Business Intelligence, Big Data and Analytics, tech-\\nnologies such as Data Warehousing, Data Mining, Data Analytics, T ext Mining and Data Visualization.\\nAbout the Authors'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 14}, page_content=''),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 15}, page_content='Contents\\nForeword v\\nPreface vii\\nAcknowledgments xi\\nAbout the Authors xiii\\n1 Business View of Information Technology Applications 1\\nBrief Contents 1\\nWhat’s in Store 1\\n1.1  Business Enterprise Organization, Its Functions, and Core Business Processes 2\\n1.1.1 Core Business Processes 3\\n1.2 Baldrige Business Excellence Framework (Optional Reading) 6\\n1.2.1 Leadership 7\\n1.2.2 Strategic Planning 7\\n1.2.3 Customer Focus 7\\n1.2.4  Measurement, Analysis, and Knowledge Management 7\\n1.2.5 Workforce Focus 8\\n1.2.6 Process Management 9\\n1.2.7 Results 9\\n1.3 Key Purpose of using IT in Business 11\\n1.4  The Connected World: Characteristics of  \\nInternet-Ready IT Applications 12\\n1.5  Enterprise Applications (ERP/CRM, etc.) and Bespoke IT Applications 14\\n1.6 Information Users and Their Requirements 17\\nUnsolved Exercises 18\\nCase Study Briefs 19\\nGoodLife HealthCare Group 19\\nIntroduction 19'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 16}, page_content='xvi • Contents\\nBusiness Segments 20\\nOrganizational Structure 20\\nQuality Management 20\\nMarketing 20\\nAlliance Management 21\\nFuture Outlook 21\\nInformation T echnology at GoodLife Group 21\\nHuman Capital Management & T raining Management 21\\nGoodFood Restaurants Inc. 23\\nIntroduction 23\\nBusiness Segments 23\\nImpeccable Processes and Standard Cuisine 23\\nMarketing 24\\nSupplier Management 24\\nQuality Management 24\\nOrganization Structure 24\\nFuture Outlook 25\\nInformation T echnology at GoodFood 25\\nT enT oT en Retail Stores 27\\nIntroduction 27\\nBusiness Segments 27\\nOrganizational Structure 27\\nMarketing 28\\nSupplier Management 28\\nQuality Management 28\\nFuture Outlook 28\\nInformation T echnology at T enT oT en Stores 29\\n2 Types of Digital Data 31\\nBrief Contents 31\\nWhat’s in Store 31\\n2.1 Introduction  31\\n2.2 Getting into “GoodLife” Database  32\\n2.3 Getting to Know Structured Data 33\\n2.3.1 Characteristics of Structured Data 33\\n2.3.2 Where Does Structured Data Come From?  34\\n2.3.3 It’s So Easy With Structured Data 34\\n2.3.4 Hassle-Free Retrieval 35\\n2.4 Getting to Know Unstructured Data 36\\n2.4.1 Where Does Unstructured Data Come From?  37\\n2.4.2 A Myth Demystified  37\\n2.4.3 How to Manage Unstructured Data?  38\\n2.4.4 How to Store Unstructured Data?  39'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 17}, page_content='Contents • xvii\\n2.4.5 Solutions to Storage Challenges of Unstructured Data  40\\n2.4.6 How to Extract Information from Stored Unstructured Data? 41\\n2.4.7 UIMA: A Possible Solution for Unstructured Data  42\\n2.5 Getting to Know Semi-Structured Data 43\\n2.5.1 Where Does Semi-Structured Data Come From?  45\\n2.5.2 How to Manage Semi-Structured Data?  47\\n2.5.3 How to Store Semi-Structured Data?  47\\n2.5.4 Modeling Semi-Structured Data (The OEM Way)  48\\n2.5.5 How to Extract Information from Semi-Structured Data?  49\\n2.5.6 XML: A Solution for Semi-Structured Data Management  50\\n2.6  Difference Between Semi-Structured and Structured Data 51\\nUnsolved Exercises 56\\n3 Introduction to OLTP and OLAP 59\\nBrief Contents 59\\nWhat’s in Store 59\\n3.1 OLTP (On-Line T ransaction Processing) 59\\n3.1.1 Queries that an OLTP System can Process 60\\n3.1.2 Advantages of an OLTP System 61\\n3.1.3 Challenges of an OLTP System 61\\n3.1.4 The Queries that OLTP cannot Answer 61\\n3.2 OLAP (On-Line Analytical Processing) 62\\n3.2.1 One-Dimensional Data 63\\n3.2.2 Two-Dimensional Data 64\\n3.2.3 Three-Dimensional Data 65\\n3.2.4 Should We Go Beyond the Third Dimension? 65\\n3.2.5 Queries that an OLAP System can Process 66\\n3.2.6 Advantages of an OLAP System 66\\n3.3 Different OLAP Architectures 66\\n3.3.1 MOLAP (Multidimensional On-Line Analytical Processing) 66\\n3.3.2 ROLAP (Relational On-Line Analytical Processing) 67\\n3.3.3 HOLAP (Hybrid On-Line Analytical Processing) 68\\n3.4 OLTP and OLAP 68\\n3.5 Data Models for OLTP and OLAP 70\\n3.5.1 Data Model for OLTP 70\\n3.5.2 Data Model for OLAP 70\\n3.6 Role of OLAP T ools in the BI Architecture 73\\n3.7  Should OLAP be Performed Directly on Operational Databases? 74\\n3.8  A Peek into the OLAP Operations on Multidimensional Data 74\\n3.8.1 Slice 75\\n3.8.2 Dice 75\\n3.8.3 Roll-Up 75\\n3.8.4 Drill-Down 76\\n3.8.5 Pivot 76'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 18}, page_content='3.8.6 Drill-Across 77\\n3.8.7 Drill-Through 77\\n3.9 Leveraging ERP Data Using Analytics 77\\nSolved Exercises 83\\nUnsolved Exercises 86\\n4 Getting Started with Business Intelligence 87\\nBrief Contents 87\\nWhat’s in Store 87\\n4.1 Using Analytical Information for Decision Support  88\\n4.2 Information Sources Before Dawn of BI? 88\\n4.3  Definitions and Examples in Business Intelligence, Data Mining, Analytics,  \\nMachine Learning, Data Science 89\\n4.4 Looking at “Data” from Many Perspectives 95\\n4.4.1 Data Lifecycle Perspective 96\\n4.4.2 Data Storage (Raw) for Processing 97\\n4.4.3 Data Processing and Analysis Perspective 97\\n4.4.4 Data from Business Decision Support Perspective 100\\n4.4.5 Data Quality Management Aspects 101\\n4.4.6 Related T echnology Influences of Data 103\\n4.5 Business Intelligence (BI) Defined 104\\n4.5.1 Visibility into Enterprise Performance  105\\n4.6 Why BI? How Can You Achieve Your Stated Objectives? 106\\n4.7  Some Important Questions About BI - Where, When and What 107\\n4.7.1 Where is BI being used? 107\\n4.7.2 When should you use BI? 107\\n4.7.3 What can BI deliver? 107\\n4.8  Evolution of BI and Role of DSS, EIS, MIS, and Digital Dashboards 107\\n4.8.1 Difference Between ERP (Enterprise Resource Planning) and BI  109\\n4.8.2 Is Data Warehouse Synonymous with BI? 109\\n4.9 Need for BI at Virtually all Levels  110\\n4.10 BI for Past, Present, and Future  110\\n4.11 The BI Value Chain  111\\n4.12 Introduction to Business Analytics 112\\nUnsolved Exercises 116\\n5 BI Definitions and Concepts 117\\nBrief Contents 117\\nWhat’s in Store 117\\n5.1 BI Component Framework 117\\n5.1.1 Business Layer 118\\n5.1.2 Administration and Operation Layer 120\\n5.1.3 Implementation Layer 123\\nxviii • Contents'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 19}, page_content='5.2 Who is BI for? 126\\n5.2.1 BI for Management 127\\n5.2.2 Operational BI 127\\n5.2.3 BI for Process Improvement 128\\n5.2.4 BI for Performance Improvement 128\\n5.2.5 BI to Improve Customer Experience 128\\n5.3 BI Users 129\\n5.3.1 Casual Users 130\\n5.3.2 Power Users 130\\n5.4 Business Intelligence Applications 131\\n5.4.1 T echnology Solutions 131\\n5.4.2 Business Solutions 133\\n5.5 BI Roles and Responsibilities 135\\n5.5.1 BI Program T eam Roles 135\\n5.5.2 BI Project T eam Roles 137\\n5.6 Best Practices in BI/DW 141\\n5.7 The Complete BI Professional 144\\n5.8 Popular BI T ools 146\\nUnsolved Exercises 148\\n6 Basics of Data Integration 151\\nBrief Contents 151\\nWhat’s in Store 151\\n6.1 Need for Data Warehouse 152\\n6.2 Definition of Data Warehouse 154\\n6.3 What is a Data Mart? 155\\n6.4 What is then an ODS? 155\\n6.5 Ralph Kimball’s Approach vs. W .H. Inmon’s Approach 155\\n6.6 Goals of a Data Warehouse 157\\n6.7 What Constitutes a Data Warehouse? 157\\n6.7.1 Data Sources 159\\n6.8 Extract, T ransform, Load 159\\n6.8.1 Data Mapping 159\\n6.8.2 Data Staging 159\\n6.9 What is Data Integration? 164\\n6.9.1 Two Main Approaches to Data Integration 164\\n6.9.2 Need and Advantages for Data Integration 167\\n6.9.3 Common Approaches of Data Integration 167\\n6.10 Data Integration T echnologies 170\\n6.11 Data Quality 175\\n6.11.1 Why Data Quality Matters? 175\\n6.11.2 What is Data Quality? 176\\n6.11.3 How Do We Maintain Data Quality? 180\\n6.11.4 Key Areas of Study 181\\nUnsolved Exercises 182\\nContents • xix'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 20}, page_content='6.12  Data Profiling 182\\n6.12.1 The Context 182\\n6.12.2 The Problem 183\\n6.12.3 The Solution 183\\n6.12.4 What is Data Profiling? 184\\n6.12.5 When and How to Conduct Data Profiling? 184\\nSummary 187\\nA Case Study from the Healthcare Domain 187\\nSolved Exercises 201\\nUnsolved Exercises 203\\n7 Multidimensional Data Modeling 205\\nBrief Contents 205\\nWhat’s in Store 205\\n7.1 Introduction 206\\n7.2 Data Modeling Basics 207\\n7.2.1 Entity 207\\n7.2.2 Attribute 207\\n7.2.3 Cardinality of Relationship 207\\n7.3 Types of Data Model 207\\n7.3.1 Conceptual Data Model 208\\n7.3.2 Logical Data Model 208\\n7.3.3 Physical Model 215\\n7.4 Data Modeling T echniques 219\\n7.4.1 Normalization (Entity Relationship) Modeling 219\\n7.4.2 Dimensional Modeling 222\\n7.5 Fact Table 225\\n7.5.1 Types of Fact 225\\n7.6 Dimension Table 229\\n7.6.1 Dimension Hierarchies 229\\n7.6.2 Types of Dimension T ables 230\\n7.7 Typical Dimensional Models 237\\n7.7.1 Star Schema 237\\n7.7.2 Snowflake Schema 239\\n7.7.3 Fact Constellation Schema 243\\n7.8 Dimensional Modeling Life Cycle 246\\n7.8.1 Requirements Gathering 247\\n7.8.2 Identify the Grain 249\\n7.8.3 Identify the Dimensions 250\\n7.8.4 Identify the Facts 250\\nDesigning the Dimensional Model 251\\nSolved Exercises 253\\nUnsolved Exercises 255\\nxx • Contents'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 21}, page_content='8 Measures, Metrics, KPIs, and Performance Management 257\\nBrief Contents 257\\nWhat’s in Store 257\\n8.1 Understanding Measures and Performance 258\\n8.2 Measurement System T erminology 258\\n8.3  Navigating a Business Enterprise, Role of Metrics, and Metrics Supply Chain 259\\n8.4 “Fact-Based Decision Making” and KPIs 264\\n8.5 KPI Usage in Companies 266\\n8.6 Where do Business Metrics and KPIs Come From? 267\\n8.7  Connecting the Dots: Measures to Business Decisions and Beyond 268\\nSummary 269\\nUnsolved Exercises 270\\n9 Basics of Enterprise Reporting 273\\nBrief Contents 273\\nWhat’s in Store 273\\n9.1  Reporting Perspectives Common to All Levels of Enterprise 274\\n9.2 Report Standardization and Presentation Practices 275\\n9.2.1 Common Report Layout Types 277\\n9.2.2 Report Delivery Formats 280\\n9.3 Enterprise Reporting Characteristics in OLAP World 281\\n9.4 Balanced Scorecard 282\\n9.4.1 Four Perspectives of Balanced Scorecard 283\\n9.4.2 Balanced Scorecard as Strategy Map 284\\n9.4.3 Measurement System 284\\n9.4.4 Balanced Scorecard as a Management System 285\\n9.5 Dashboards 290\\n9.5.1 What are Dashboards? 290\\n9.5.2 Why Enterprises Need Dashboards? 291\\n9.5.3 Types of Dashboard 291\\n9.6 How Do You Create Dashboards? 293\\n9.6.1 Steps for Creating Dashboards 293\\n9.6.2 Tips For Creating Dashboard 294\\n9.7 Scorecards vs. Dashboards 296\\n9.7.1 KPIs: On Dashboards as well as on Scorecards 297\\n9.7.2 Indicators: On Dashboards as well as on Scorecards 297\\n9.8 The Buzz Behind Analysis… 298\\n9.8.1 Funnel Analysis 298\\n9.8.2 Distribution Channel Analysis 300\\n9.8.3 Performance Analysis 301\\nUnsolved Exercises 307\\nContents • xxi'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 22}, page_content='10 Understanding Statistics 309\\nBrief Contents 309\\nWhat’s in Store? 309\\n10.1 Role of Statistics in Analytics 309\\n10.2 Data, Data Description and Summarization 311\\n10.2.1 Getting to Describe “Categorical Data” 311\\n10.2.2 Getting to Describe “Numerical Data” 314\\n10.2.3 Association between Categorical Variables 316\\n10.2.4 Association between Quantitative Variables 317\\n10.3 Statistical T ests 319\\n10.3.1 Paired and Unpaired Data Sets 319\\n10.3.2 Matched Pair Groups in Data Sets 319\\n10.3.3 Common Statistical T esting Scenarios 320\\n10.4 Understanding Hypothesis and t-T est 321\\n10.4.1 The t-T est 322\\n10.4.2 The p-Value 322\\n10.4.3 Z-T est 322\\n10.5 Correlation Analysis 323\\n10.6 Regression 324\\n10.7 ANOVA 325\\n10.8 The F-T est 325\\n10.9 Time Series Analysis 327\\n11 Application of Analytics 331\\nBrief Contents 331\\nWhat’s in Store? 331\\n11.1 Application of Analytics 331\\n11.1.1 Analytics in Business Support Functions 332\\n11.2 Analytics in Industries 334\\n11.2.1 Analytics in T elecom 334\\n11.2.2 Analytics in Retail 335\\n11.2.3 Analytics in Healthcare (Hospitals or Healthcare Providers) 337\\n11.2.4 Analytical Application Development 338\\n11.3 Widely Used Application of Analytics  339\\n11.3.1 Anatomy of Social Media Analytics 339\\n11.3.2 Anatomy of Recommendation Systems 342\\n11.3.3 Components of Recommendation Systems 343\\n12 Data Mining Algorithms 347\\nBrief Contents 347\\nWhat’s in Store? 347\\n12.1 Association Rule Mining  347\\n12.1.1 Binary Representation 349\\nxxii • Contents'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 23}, page_content='  • xxiii\\n12.1.2 Itemset and Support Count 350\\n12.1.3 Implementation in R 351\\n12.2 k-Means Clustering 355\\n12.2.1 Implementation in R 356\\n12.3 Decision T ree 357\\n12.3.1 What is a Decision Tree? 360\\n12.3.2 Where is it Used? 361\\n12.3.3 Advantages from Using a Decision Tree 361\\n12.3.4 Disadvantages of Decision Trees 361\\n12.3.5 Decision Tree in R 361\\nUnsolved Exercises 367\\n13 BI Road Ahead 369\\nBrief Contents 369\\nWhat’s in Store 369\\n13.1 Understanding BI and Mobility 369\\n13.1.1 The Need for Business Intelligence on the Move 370\\n13.1.2 BI Mobility Timeline 370\\n13.1.3 Data Security Concerns for Mobile BI 373\\n13.2 BI and Cloud Computing 373\\n13.2.1 What is Cloud Computing? 373\\n13.2.2 Why Cloud Computing? 375\\n13.2.3 Why Business Intelligence should be on the Cloud? 375\\n13.3 Business Intelligence for ERP Systems 377\\n13.3.1 Why BI in ERP? 378\\n13.3.2 Benefits of BI in ERP 379\\n13.3.3 ERP Plus BI Equals More Value 379\\n13.4 Social CRM and BI 380\\nUnsolved Exercises 384\\nGlossary 385\\nIndex 397'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 24}, page_content=''),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 25}, page_content=\"WHAt's in store\\nWelcome to the “world of data”. Whatever profession you may choose for your career, there will be an \\nelement of Information T echnology (IT) in your job. The competence to harness the power of data will \\nbe among the critical competencies that you will be required to develop in your career. This competency \\ncould potentially be one of the differentiators in your career. As already stated in the preface, the content \\nof this book aims to provide basic but holistic knowledge needed to leverage the power of data using \\ntechnologies, processes, and tools.\\nWhile designing this book, we have kept in mind the typical requirements of the undergraduate \\n engineering/MCA/MBA students who are still part of the academic program in universities. Our attempt \\nis to help you gain sound foundational knowledge of “Analytics” irrespective of the engineering  discipline \\nor special electives you have chosen. The best way to benefit from this book is to learn hands-on by \\ncompleting all lab assignments, explore the sources of knowledge included in this book and study in \\ndetail one or two organizations which are leveraging analytics for their business benefits.\\nIn this chapter, we intend to familiarize you with the complete context or the environment of a typical \\nbusiness enterprise which leverages IT for managing its business.\\nBrief Contents\\nWhat’s in Store \\nBusiness Enterprise Organization, Its \\n Functions, and Core Business Processes \\nBaldrige Business Excellence Framework  \\n(Optional Reading) \\nKey Purpose of Using IT in Business \\nThe Connected World: Characteristics of \\nInternet-ready IT Applications \\nEnterprise Applications (ERP/CRM, etc.) \\nand Bespoke IT Applications \\nInformation Users and Their Requirements \\nUnsolved Exercises \\nBusiness View of Information \\nTechnology Applications\\n1\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 26}, page_content='The topics included are:\\n • Business enterprise organization, its functions, and core business processes.\\n • Key purpose of using IT in business.\\n • The connected world: Characteristics of Internet-ready IT applications.\\n • Enterprise applications (ERP/CRM and Bespoke IT applications, systems, software, and  network \\nheterogeneity.\\n • Information users and their requirements.\\nNo prior IT knowledge is assumed. This chapter is suggested as a “Must Read” for all readers as we \\nintend to create the “big picture” where “Business Analytics” will be deployed and used. It will be a good \\nidea to explore, collect, and delve into case studies of applications of Business Intelligence/Analytics/  \\nData Warehousing in the domain/discipline of your interest to develop your own mental model of the \\nenterprise. Learning in teams by discussing the above topics across different disciplines will expand \\nyour interest and throw light on the ever increasing possibilities of leveraging data. This is the reason for \\nreferring to data as “corporate asset”.\\nOne last noteworthy fact – As enterprises grow and expand their business, they acquire larger com-\\nputers, change operating systems, database management systems, connect systems by digital network, \\nand migrate to powerful database management systems. They never discard any data! Historical data is \\nlike the “finger print” or DNA of an enterprise and can potentially be a smart guidance system.\\nSo, let’s begin our exploration of the modern enterprise.\\n1.1  Business enterprise orgAnizAtion, its Functions, And \\ncore Business processes\\nNo matter which industry domain you choose – retail, banking, manufacturing, transport, energy, etc. \\n– you will find similarities in their organizational structure. In general, businesses serve their customers \\neither with products or services or both. This immediately creates the need for functions such as prod-\\nuct/service research, product manufacture or service delivery, quality assurance, purchase, distribution, \\nsales, marketing, finance, and so on. As the product or service consumption increases, we will find func-\\ntions like support, planning, training, etc. being added. The business will depend on its workforce to \\ncarry out all the functions identified so far, creating the need for human resources management, IT \\nmanagement, customer relationship management, partner management, and so on. As the business \\nexpands into multiple product/service lines and starts global operations, new requirements emerge, and \\neach function realigns its own “internal services” to meet the new demands. You will also notice that \\nsome functions like HR, T raining, Finance, Marketing, R&D, and IT management cut across various \\nproduct/service lines and could be termed as “Support Units”. However, such product or service line \\nfunctions that generate revenue could be termed as “Business Units”. T oday, businesses, irrespective of \\ntheir size, leverage IT as enabler to achieve market leadership or unique position. The organization of a \\ntypical business could be represented as shown in Figure 1.1.\\nMost businesses design standard enterprise-level processes for their core functions. The basic idea \\nbehind creating standard processes is to ensure repeatable, scalable, and predictable customer expe-\\nrience. Well-designed processes make customer experience independent of people and geography/ \\nlocation. Here a good example is the common dining experience in any McDonald’s outlet anywhere \\nin the world! You will come across processes that are contained in one department or involve multiple \\n2 • Fundamentals of Business Analytics'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 27}, page_content='Business View of Information T echnology Applications • 3\\n departments. For example, a process like “Hire graduates from campuses” will be managed only by HR. \\nBut a process like “Order to Delivery” in a computer manufacturing company will involve functions \\nof sales, order fulfillment, shipment, and finance. It is these processes that will be automated by the use  \\nof IT . We will focus on the automation of business processes using IT in subsequent sections.\\n1.1.1 core Business processes\\nWhy do we need core business functions? The answer is for a smooth day-to-day functioning of the \\norganization and for performing tasks efficiently and on time. Given below is the list of a few common \\ncore business functions.\\n • Sales and Marketing\\n • Product/Service Delivery\\n • Quality\\n • Product Development\\n • Accounting\\n • T echnology\\n • Human Resource Management\\n • Supplier Management\\n • Legal and Compliance\\n • Corporate Planning\\n • Procurement (Purchases)\\nAll the core business functions listed above might not be used in all organizations. There could be  \\nseveral factors for not using a core business function; for example, shortage of resources or in a small \\norganization, a particular process can be easily managed manually, etc.\\nFigure 1.1 The organization of a typical enterprise.\\nCompany Planning Marketing Sales Finance\\nEnterprise\\nInformation Management\\nHuman Resources\\nCustomer Relationship\\nManagement '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 28}, page_content='4 • Fundamentals of Business Analytics\\npicture this…\\nAn assumed organization “Imagination” is an IT products and services company. The number of \\nemployees working for it is roughly 550. Within a short time of its inception, the company has done \\nquite well for itself. It has 32 clients spread across the globe. T o manage its customers, “Imagination” has \\na Sales and Marketing function. As you will agree, in any business it is just not enough to have custom-\\ners; you should be able to retain your customers and grow your customer base. “Imagination” has real-\\nized this and believes that the relationship with its customers’ needs to be managed. The aim is to have \\nloyal customers coming back to the company with repeat business. Besides, they should also advocate \\nabout the company’s product and services on whichever forum they get invited to. Next in the line of \\nthe company’s core business processes is Product/Service Delivery. The company makes its revenue \\neither by rendering service or by selling their products or both. And while they do the business, they \\nwant to be ahead of their competitors. Very likely, Quality will come into play and they would like it \\nto be their key differentiator in the days to come.\\n“Imagination”, the company in our example, is into Product Development and is looking for inno-\\nvative ways to develop innovative products. It could be the same proprietary product but developed \\nusing innovative ways which could be use of automation, reduced cost, better processes. The company \\nis into business and they have customers, so it is not unusual for cash to come in for the products sold \\nor the services rendered. The company needs to account for the cash flow and also file the tax returns, \\nwhich brings us to another of the company’s core business function, Accounting. The Accounting \\nfunction relies heavily on technology to be able to manage the transactions accurately and timely. So, \\nTechnology becomes another of its core business functions.\\nT o manage its present employee base of 550 (the number is likely to double next year), the company \\nhas a core support function in Human Resource Management (HR). The HR is responsible for hiring, \\ntraining, and managing the employees.\\n“Imagination” has a few vendor partners, to manage relationship with them the Supplier Manage-\\nment process is in place. In the years to come, if the company grows to a big size, it might be worthwhile \\nto consider “Corporate Planning” that looks at the allocation of resources (both tangible and non-\\ntangible) and manpower to the various functions/units. The last business process but not the least is the \\nProcurement process, very much relevant for an IT company such as “Imagination”. This process deals \\nwith the procurement of hardware/software licenses and other technical assets.\\nLet’s move to the next step and start thinking of generalizing or abstracting the commonalities between \\ndifferent businesses in different industries. What is common in the HR function, for example, relating \\nto a bank, an electronics goods manufacturing plant, and a large retail chain like McDonald’s? They all \\nhire new employees, train the employees in their functions, pay for the employees, evaluate employees’ \\non-the-job performance, maintain relationship with the suppliers and employees by way of programs \\nsuch as “employee competency development”, “employee loyalty program”, etc., communicate strategic \\nmessages, reward employees, and so on. They also measure their own contribution to business. Think \\non similar lines about the other functions. For example, a bank may view home loan as a product, credit \\ncards as product, etc. A large CT scanner manufacturer may view installation of equipment as a service \\nassociated with their product that generates additional revenue.\\nBusiness functions design core business processes that are practiced within the function or cut \\nacross several business and support functions. Refer to Table 1.1 for few of the common core business \\nprocesses.\\nCan we represent all businesses in some common model? The answer is YES!'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 29}, page_content='Acquire to Retire (Fixed Assets) This end-to-end scenario includes processes such as \\nAsset Requisition, Asset Acquisition, Asset utilization \\nenhancement, Asset Depreciation, and Asset Retirement.\\nHire to Retire An end-to-end process adopted by the HR unit/function \\nof enterprises. It includes processes such as Recruitment, \\nHire, Compensation management, Performance \\nmanagement, T raining, Promotion, T ransfer, and Retire.\\nResource Management\\nTable 1.1 Few Core Business Processes\\nProcess Explanation\\nProcure to Pay\\n(Also referred to as \\nPurchase to Payment)\\nThis end-to-end process encompasses all steps from purchasing goods from a \\nsupplier, to paying the supplier. The steps in the process include: determination of \\nrequirement → vendor selection (after comparison of quotations) → preparation of \\npurchase order → release of purchase order → follow-up/amendments on purchase \\norder → good received and inventory management → inspection of goods received \\n→ verification of invoice → issuance of payment advice\\nIdea to Offering This entails research → concept, concept → commit, design → prototype, validate \\n→ ramp-up, monitor → improve, improve → end of life cycle\\nMarket to Order\\n(Also referred to as \\nMarket to prospect)\\nThis end-to-end process is as follows: research → market identification, market \\nidentification → plan, campaigning → lead, lead → order, account strategy → \\nrelationship management\\nOrder to Cash The basic activities of this core business process include:\\n•• Create or maintain customer\\n•• Create or maintain material master\\n•• Create or maintain condition records for pricing\\n•• Enter and authorize sales order\\n•• Convert quote to order\\n•• Validate product configuration\\n•• Verify billing, shipping, payment details\\n•• Apply discounts\\n•• Review credit of customer\\n•• Verify stock\\n•• Plan delivery schedule\\n•• Pack and ship product\\n•• Billing and cash receipt\\n•• Contract to renewal\\nQuote to Cash This process essentially is a two step process:\\n•• Generation of quotations\\n•• Order to cash (described above)\\nIssue to Resolution The basic steps here are: detection of an issue → identification of the problem →•\\ndevelopment of solution → return/replace → closed loop feedback\\nBusiness Process Management\\nBusiness View of Information T echnology Applications • 5'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 30}, page_content='6 • Fundamentals of Business Analytics\\nWe would like to present a simple but generic model from the “Malcolm Baldrige Performance \\nExcellence Program”. This is a US national program based on the Baldrige Criteria for Performance \\nExcellence. The Baldrige Criteria serves as a foundation for a performance management system. In this \\nchapter, our focus is on the “Measurement, Analysis, and Knowledge Management” part of the Baldrige \\nCriteria that helps you understand the strategic role of business analytics.\\nFigure 1.2 depicts the Malcolm Baldrige Criteria for Performance Excellence Framework. The Mal-\\ncolm Baldrige Criteria for Performance Excellence Award was instituted in the USA to recognize busi-\\nnesses that achieve world-class quality and demonstrate excellence in business performance. It represents \\na common model to represent business enterprises. Successful enterprises have a great leadership \\nteam. They focus on strategic planning (to deliver products or services or both). They study markets \\nand customers intensely whom they serve. They set targets, measure achievements with rigor. They \\nare highly focused on human capital management. They deploy processes (and automate using \\nIT) and achieve planned business results. They repeat these steps every time consistently as well as \\nconstantly improve each of these components\\nNote: This section provides little deeper insight into \\nthe Baldrige business excellence framework. This is \\noptional reading material.\\nThe Baldrige Criteria for Performance Excellence, \\ndepicted in Figure 1.2, are described below.\\n1. Leadership\\n2. Strategic Planning\\n3. Customer and Market Focus\\n4.  Measurement, Analysis, and Knowledge \\nFocus\\n5. Workforce Focus\\n6. Process Management\\n7. Results\\nFigure 1.2 Malcolm Baldrige Criteria for Performance Excellence framework.\\n1. Leadership\\nOrganizational Profile:\\nEnvironment, Relationships, and Challenges\\n4. Measurement, Analysis, and Knowledge Management\\n5. Workforce Focus\\n6. Process Management\\n7. Results\\n3. Customer and Market Focus\\n2. Strategic Planning\\n1.2 BAldrige Business excellence FrAmeWork \\n(optionAl\\xa0reAding)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 31}, page_content='We now discuss each one of them.\\n1.2.1 leadership\\nThe Leadership criterion describes how personal \\nactions of the organization’s senior leaders guide \\nand sustain the organization and also how the \\norganization fulfils its social, ethical, and legal \\nresponsibilities.\\nSenior Leadership\\nSenior leadership includes the following:\\n • Guide the organization.\\n • Create a sustainable organization.\\n • Communicate and motivate employees.\\n • Focus on organizational performance.\\nGovernance and Social Responsibility\\nCorporate Governance and Corporate’s social \\nresponsibility focus on\\n • Addressing organizational governance\\n a.  T ransparency in operations and disclosure \\npractices.\\n b. Accountability for management’s actions.\\n c.  Evaluating the performance of CEO and \\nmembers of governance board.\\n • Promoting legal and ethical behavior.\\n • Support of key communities.\\n1.2.2 strategic planning\\nThe Strategic Planning criterion examines how \\nthe organization develops its strategic objectives \\nand how these objectives are implemented.\\nStrategy Development\\nThe strategy development process of Strategic \\nPlanning includes the following:\\n • Determination of key strategic objectives with \\ntimelines.\\n • Balancing the needs of all stakeholders.\\n • Assessing organization’s strengths, weaknesses, \\nopportunities, and threats.\\n • Risk assessment.\\n • Changes in technology trends, markets, com-\\npetition, and regulatory environment.\\nStrategy Deployment\\nThe strategy deployment process of Strategic \\nPlanning includes the following:\\n • Action plan development and deployment\\n a.  Allocating resources for accomplishment of \\nthe action plan.\\n b.  Allocating human resources to accomplish \\nshort-term or long-term goals.\\n c.  Developing performance measures or in-\\ndicators for tracking the effectiveness and \\nachievement of the action plan.\\n • Performance projection: Addressing current \\ngaps in performance with respect to competi-\\ntion.\\n1.2.3 customer Focus\\nThe Customer Focus criterion determines cus-\\ntomer requirements, builds customer relation-\\nships, and uses customer feedback to improve and \\nidentify new opportunities for innovation.\\nCustomer and Market Knowledge\\n • Identification and determination of target cus-\\ntomers and market segments.\\n • Using feedback to become more focused and \\nsatisfy customer needs.\\nCustomer Relationship and Satisfaction\\n • Acquire new customers, meet, and exceed cus-\\ntomer expectations.\\n • Implement processes for managing customer \\ncomplaints effectively and efficiently.\\nLeadership, Strategic Planning, and Customer \\nand Market Focus constitute the Leadership  \\nTriad shown in Figure 1.3.\\n1.2.4  measurement, Analysis, and \\nknowledge management\\nThe Measurement, Analysis, and Knowledge \\nManagement criterion determines how the orga-\\nnization selects, gathers, analyzes, and improves its \\ndata, information, and knowledge assets and how \\nit manages its information technology.\\nBusiness View of Information T echnology Applications • 7'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 32}, page_content='8 • Fundamentals of Business Analytics\\nMeasurement, Analysis, and Improvement of \\nOrganizational Performance\\n • Performance Measurement\\n a.  Collecting, aligning, and integrating data \\nand information.\\n b.  T racking the overall performance of the or-\\nganization and the progress relative to stra-\\ntegic objectives and action plans.\\n • Performance Analysis, Review, and  \\nImprovement\\n a.  Assessing the organization’s success, com-\\npetitive performance, and progress on stra-\\ntegic objectives.\\n b.  Systematic evaluation and improvement of \\nvalue creation processes.\\nMeasurement of Information Resources, \\nInformation T echnology, and Knowledge\\n • Management of Information Resources\\n a.  Making needed data and information avail-\\nable and providing access to workforce.\\n b.  Keeping data and information availabil-\\nity mechanisms, including software and \\n hardware systems, in tune with business \\nneeds and technological changes in the  \\noperating environment.\\n • Data, Information, and Knowledge  \\nManagement\\n Ensuring the following properties of the orga-\\nnizational data, information, and knowledge:\\n a. Accuracy\\n b. Integrity and reliability\\n c. Security and confidentiality\\n1.2.5 Workforce Focus\\nThe Workforce Focus criterion examines the abil-\\nity to assess the workforce capability and builds a \\nworkforce environment conducive to high perfor-\\nmance.\\nWorkforce Environment\\n • Focusing on maintaining a good working \\nenvironment for the employees.\\n • Recruiting, hiring, and retaining new employees.\\n • Managing and organizing the workforce.\\n • Ensuring and improving workplace health, \\nsafety, and security.\\nLeadership\\nTriad\\n1. Leadership\\nOrganizational Profile:\\nEnvironment, Relationships, and Challenges\\n4. Measurement, Analysis, and Knowledge Management\\n5. Workforce Focus\\n6. Process Management\\n7. Results\\n3. Customer and Market Focus\\n2. Strategic Planning\\nFigure 1.3 The Leadership T riad.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 33}, page_content='Workforce Engagement\\n • Fostering an organizational culture conducive to \\nhigh performance and a motivated workforce.\\n • Focusing on the training and education sup-\\nport in the achievement of overall objectives, \\nincluding building employee knowledge, \\nskills, and contributing to high performance.\\n • Reinforcing new knowledge and skills on job.\\n • Developing personal leadership attributes.\\n1.2.6 process management\\nThe Process Management criterion examines how \\nthe organization manages and improves its work \\nsystems and work processes to deliver customer \\nsatisfaction and achieve organizational success and \\nsustainability.\\nWork System Design\\n • Determines core competencies of the organi-\\nzation.\\n • Identifies key work processes.\\n • Determines key work process requirements \\nincorporating inputs from customers.\\n • Designs and innovates work processes to meet \\nkey requirements.\\nWork Process Management and Improvement\\n • Implementing the work processes to ensure \\nthat they meet design requirements.\\n • Using key performance measures or indicators \\nfor control and improvement of work processes.\\n • Preventing defects, service errors, and re-work.\\n1.2.7 results\\nThe Business Results criterion examines the orga-\\nnization’s performance and improvement in all the \\nkey areas – product and process outcomes, cus-\\ntomer focused outcomes, human resource out-\\ncomes, leadership outcomes, and financial \\noutcomes. The performance level is examined \\nagainst that of the competitors and other organi-\\nzations with similar product offering.\\nWorkforce Focus, Process Management, and \\nResults represent the Results Triad as shown in \\nFigure 1.4.\\nResults Triad\\n1. Leadership\\nOrganizational Profile:\\nEnvironment, Relationships, and Challenges\\n4. Measurement, Analysis, and Knowledge Management\\n5. Workforce Focus\\n6. Process Management\\n7. Results\\n3. Customer and Market Focus\\n2. Strategic Planning\\nFigure 1.4 The Results T riad.\\nBusiness View of Information T echnology Applications • 9'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 34}, page_content='10 • Fundamentals of Business Analytics\\n\\u2003 Remind\\u2003Me\\u2003\\n•   The Malcolm Baldrige Criteria for Perfor-\\nmance Excellence is a framework that any \\norganization can use to improve its overall \\nperformance and achieve world-class quality.\\n•   The criteria for performance excellence frame-\\nwork are:\\n a. Leadership\\n b. Strategic Planning\\n c. Customer and Market Focus\\n d.  Measurement, Analysis, and Knowledge \\nFocus\\n e. Business Focus\\n f. Process Management\\n g. Results\\n • The Leadership criterion describes how per-\\nsonal actions of the organization’s senior lead-\\ners guide and sustain the organization and \\nalso how the organization fulfils its social, \\nethical, and legal responsibilities.\\n • The Strategic Planning criterion examines \\nhow the organization develops strategic objec-\\ntive and how these objectives are implemented.\\n • The Customer Focus criterion determines \\ncustomer requirements, builds customer \\nrelationships and use customer feedback to \\nimprove and identify new opportunities for \\ninnovation.\\n • The Measurement, Analysis, and Knowledge \\nManagement criterion determines how the \\norganization selects, gathers, analyzes, and \\nimproves it data, information, and knowl-\\nedge assets and how it manages its informa-\\ntion technology.\\n • The Workforce Focus criterion examines \\nthe ability to assess workforce capability and \\nbuild a workforce environment conducive to \\nhigh performance.\\n • The Process Management criterion examines \\nhow the organization manages and improves \\nits work systems and work processes to deliver \\ncustomer satisfaction and achieve organiza-\\ntional success and sustainability.\\n • The Results criterion examines the organiza-\\ntion’s performance and improvement in all \\nthe key areas.\\n • Leadership, Strategic Planning, and Customer \\nand Market Focus constitute the Leadership \\nT riad.\\n • Workforce Focus, Process Management, and \\nResults represent the Results T riad.\\n • The horizontal arrow in the center of the \\nframework (Figures 1.3 and 1.4) links the \\nLeadership T riad to the Results T riad, a link-\\nage critical to organizational success.\\nPoint\\u2003Me\\u2003(Books)\\n•   Comparing ISO 9000, Malcolm Baldrige, and \\nthe SEI CMM for Software: A Reference and \\nSelection Guide [Paperback], Michael O Tingey.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 35}, page_content='1.3 key purpose oF using it in Business\\nAt the outset we will start with the idea that IT is used to automate business processes of departments/\\nfunctions of the enterprise or core business processes of the enterprise that span across functions. The \\nuse of IT to innovate new ways of doing business results in huge benefits for the enterprise and gives it \\nleadership position in the market.\\nAll of us have used software like email, Google search tool, word processor, spreadsheet and pre-\\nsentation tools that enhance personal productivity. These are “office productivity/office automation” \\nIT applications. Some office productivity applications may focus on team productivity and these are \\ntermed as “Groupware”. Intra-company email, team project management software, intranet portals, \\nand knowledge management systems are typical examples of Groupware.\\nConsider an IT application like “Payroll processing”. We could consider payroll as a key IT applica-\\ntion for HR function. The core purpose of the payroll IT application is to calculate the salary payable \\nto all employees, generate pay slips, and inform the bank for funds transfer to the respective employee \\naccounts. The same work can definitely be done manually. But the manual system works well when the \\nnumber of employees is small and salary computation is simple. When you have, say, 10,000 employees \\nto pay and the salary calculation needs to take care of several data pieces like leave, overtime, promo-\\ntions, partial working, and so on, and the entire work needs to be done very quickly, you will face \\nchallenges. There could be computational errors and wrong assumptions that would lead to delay and \\ndissatisfaction. However, when the salary calculation is automated, the benefits gained will be speed, \\naccuracy, and the ability to repeat the process any number of times. These IT applications also help in \\nfast information retrieval and generate statutory reports immediately. Such a type of application could \\nbe termed as Departmental IT Applications. A payroll IT application generates computed data, and \\nthe volume of such data increases with every successive payroll run. This kind of historical data is very \\nuseful in business analytics.\\nTest\\u2003Me\\u2003Exercises\\n1.  _______ Baldrige Criteria serves as a foun-\\ndation for the performance management \\n system.\\n2. The _______ Baldrige criterion assesses \\nworkforce capability and capacity needs and \\nbuilds a workforce environment conducive to \\nhigh performance.\\n3. The Customer and Market Focus Baldrige \\ncriterion examines which of the following?\\n a.  The requirements, needs, expectations of \\nthe customers\\n b. Customer satisfaction and loyalty\\n c. Customer retention\\n d. All the options are valid\\nSolution:\\n1. Measurement, Analysis, and Knowledge \\nManagement\\n2. Workforce Focus\\n3. All the options are valid.\\nBusiness View of Information T echnology Applications • 11'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 36}, page_content='12 • Fundamentals of Business Analytics\\nYou may have come across some common IT applications like train/bus/ airline ticket reservation sys-\\ntems. These are called On-line Transaction Processing Systems. On an on-line train ticket reservation \\nsystem, you will never face the problem of duplicate seat allocation (that is, allocation of the same seat to \\nmore than one passenger) and more allocation than the capacity, assuming that the data entered into the \\nsystem is correct. The online transaction processing systems also generate large volumes of data, typically \\nstored in RDBMS (relational database management system). You can imagine the volume of data which \\ngets accumulated over one year, say, for all trains for all passengers who would have travelled! Again, this \\ntype of historical data is very useful for business analytics. When you enter your personal details to register \\nyourself in a website, the data you provide will be stored in similar ways. This category of IT applications \\ntoo provides benefits like speed, accuracy, search capability, status inquiry, easy update ability, and so on.\\nLet’s turn our attention to newer types of applications such as the Amazon book store. This book \\nstore, through the combination of the Internet technology and book store software management, has \\ncompletely changed the way you shop for a book. Here there is really no book store(no physical book \\nstore) that you could visit, stand in front of the book collections in an aisle, browse through the catalog \\nor search the book shelves, pick a book, get it billed, and carry it home, as you do in a normal book \\nstore. Applications like the one used at the Amazon book store are called Business Process/Model \\nInnovation applications. The ability to transfer money across the globe to any bank account from \\nhome is a new innovation. Lastly, let’s look at the IT applications that help us in decision making. These \\napplications provide facts that enable us make objective decisions. Suppose you would like to buy a new \\ntwo-wheeler. One option for you is to visit showrooms of all brands, test-drive different vehicles, and \\ncollect data sheets of various options. Another option is to feed in an IT system inputs like your budget, \\nexpected mileage, availability, etc. and the system would present the best options as a comparison. Cer-\\ntainly, the second option would help you make informed decisions faster. This is possibly one of the \\nbest possible ways to use IT . The IT applications which help in decision-making are called Decision \\nSupport applications. These IT applications need to gather data from various sources, fit them into \\nthe user preferences, and present recommendations with the ability to show more details when the user \\nneeds it. These applications are very useful in business analytics.\\nSummarizing this topic, we can say IT applications are of various categories. Office productivity/office \\nautomation IT applications, Departmental IT applications, Enterprise level on-line transaction process-\\ning applications, Business Process or Model Innovation applications, and Decision Support applications. \\nAll these generate data of varying quality. The data is likely to be in different formats. These applications \\nmay be developed using different programming languages like C, Pascal, C++, Java, or COBOL and run \\non different operating systems. They may even use different vendors for the RDBMS package like MS \\nSQL, Oracle, Sybase, or DB2. We will examine these issues in subsequent sections.\\n1.4  tHe connected World: cHArActeristics oF  \\ninternet-reAdy it ApplicAtions\\nComputer systems have evolved from centralized mainframes with connected terminals to systems con-\\nnected in Local Area Network (LAN) to distributed computing systems on the Internet. A large enter-\\nprise may have all these generations of computing resources.\\nWe live in the connected world today. Computer networks are the basic foundation platform on \\nwhich the entire IT infrastructure is built. From the enterprise perspective, majority of users access the \\nenterprise and departmental applications either over LAN or through Internet in a secure fashion. Most '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 37}, page_content='individual-centric data is stored in laptops or tablet computers. All enterprise data that is critical to the \\nbusiness is invariably stored on server systems spread across several locations with built-in mechanisms \\nfor disaster recovery in the event of failure of any server. These servers are secured with several hardware/\\nsoftware security solutions so that unauthorized access and theft of the enterprise data is prevented. Not \\neveryone can install any software or copy any data on to these secure servers. Special software distribution \\nand installation as well as anti-virus solutions are used to protect the servers from malicious hackers.\\nRefer to Figure 1.5. In the mainframe computing world, the system software consisted of an operating \\nsystem and IT applications. T oday, the scenario is entirely different. You will see several layers of system \\nsoftware that run on servers. These include operating system, network operating system, RDBMS software, \\napplication server software, middleware software products, and IT applications. In a typical enterprise with \\nglobally spread users, the IT infrastructure may consist of several data networks, routers, multi-vendor serv-\\ners, multi-vendor OS, security servers, multiple RDBMS products, different types of application servers, \\nand specific IT applications. Most users access enterprise data over LAN or secure Internet (VPN).\\nEnterprises strive to provide “single window” or “one-stop” access to several applications using tech-\\nniques like “single sign-on”. In “single sign-on” once you have successfully logged onto the machine’s OS \\nusing a username and password, from that point forward any access to any application will automati-\\ncally use the same username and password. There is a great emphasis on common look and feel or “user \\nexperience”. Gone are the days of command-driven user interface. It’s all about context sensitive menus, \\nonline help, navigation using touch screen/mouse, high resolution graphical displays. The “user experi-\\nence” is a key driver for bringing computing facilities close to all types of users. Refer to Figure 1.6.\\nOS OS OS\\nCUSTOM \\nAPPLICATIONS\\nCUSTOM \\nAPPLICATIONS\\nDB Server DB Server\\nCUSTOM \\nAPPLICATIONS\\nApplication Server\\nNetwork\\n1965–1980 1980–1995 1995– 2000 2000–Future\\nOS\\nDB Server\\nOS\\nWeb Services\\nCUSTOM \\nAPPLICATIONS\\nApplication Framework\\nApplication Server\\nFigure 1.5 T echnology Centric Applications – From 1965 to 2000 to future.\\nBusiness View of Information T echnology Applications • 13'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 38}, page_content='14 • Fundamentals of Business Analytics\\nInternet-ready applications do have several advanced common capabilities like:\\n • Support large number of users of different interests and abilities.\\n • Provides display on multiple devices and formats.\\n • Deployed on large secure servers through license management software.\\n • Support single sign-on and support special authentication and authorization requirements.\\n • Ability to run on any operating system.\\n • Ability to use/connect to any RDBMS for data storage.\\n • Could be implemented in multiple programming languages or combinations as well.\\n • Leverages enterprise storage capabilities and back-up systems.\\n • Supports extensive connectivity to different types of networks and Internet services.\\nIn the context of our topic of interest, that is, business analytics, it’s important to know that the data we \\nare looking for may exist on any or many servers or different RDBMS products in different locations \\nconnected over different networks and very likely will be in different formats!!\\n1.5  enterprise ApplicA tions (erp/crm, etc.) And Bespoke it \\nApplicAtions\\nLarge businesses have hundreds of business processes and frontier areas to be enabled by IT for com-\\npetitive advantage. This results in several IT applications being deployed in the enterprise. There are \\nseveral ways in which we could look at the classification of these IT applications. We have already \\nseen in the previous section a classification based on function and purpose such as office automation, \\nbusiness innovation, decision support, etc. We could also look at classifying IT applications based on \\nthe hardware platform they run like mainframe, open system, or Internet (distributed servers).\\nProcess Re-engineering\\nGeneral Ledger\\nBusiness Continuity\\nOLTP\\nEnhanced ERP\\nLess\\nMore\\nUsage – Heavy\\nNovice to Power Users\\nUsage – Moderate\\nTrained Users\\nUsage – Low\\nPower Users\\nBenefit–Cost Saving Benefit– Productivity Benefit– Innovation\\nDepartment Apps\\nEmpowering the User (OLAP)\\nDSS/Analytics\\nIT Application Category\\nIT Application Benefits\\nEnterprise Mobility/Cloud\\nSelf-service Portals\\nFunctional Augmentation\\nNew Products/Services\\nFigure 1.6 IT applications: Cost focus, productivity focus, and opportunity focus.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 39}, page_content='Another key classification parameter for IT applications is the application users. It’s common to \\nlook at applications as customer facing, partner/supplier facing, and employee facing applications. This \\nclassification has also resulted in bringing focus on core processes that enable the enterprise to serve \\nthe customer. Customer relationship management, supply chain management, human capital manage-\\nment, financial accounting, customer order processing, customer order fulfillment, product distribu-\\ntion management, procurement management, corporate performance management, business planning, \\ninventory management, innovation management, and service or repair order management are some of \\nthe commonly chosen areas for IT enablement.\\nWhen it comes to IT enablement of any chosen business area, there are four different approaches enter-\\nprises typically follow. Each approach has its own merits and associated benefits as well as investments. \\nAn enterprise may choose to develop and implement an IT application with its dedicated team, as they \\nare the ones who understand business process steps very well. Such enterprises will invest in hardware, \\nsoftware, development tools and testing tools, and own the entire software lifecycle responsibility. This \\nis termed as bespoke application development. Alternately, an enterprise may design an IT application \\nand implement the tested application with its team but outsource the software development part. Some \\nenterprises may choose to procure licenses for globally standard software and implement it with some \\ncustomization. This approach is faster, brings global processes experience in the package but may not be \\nentirely flexible to meet enterprise processes. The new trend is to entirely outsource the processes so that \\nthe chosen partner will take care of hardware, software, tools, development and maintenance team, and so \\non. It is not uncommon to find an enterprise that uses a hybrid model leveraging all these approaches.\\nEnterprise Resource Planning (ERP) is the critical business IT applications suite that many enter-\\nprises choose to procure, customize, and implement. The most attractive element of ERP is the inte-\\ngrated nature of the related applications. Let’s understand the usefulness of integrated applications. \\nConsider a large enterprise that has several functions to be enabled by IT applications, like human \\ncapital management, purchase management, inventory management, and so on. One approach could \\nbe to identify each of the business areas through business analysis and follow the software engineering \\nlifecycle to develop IT application for each of the areas. Of course, different teams will work on dif-\\nferent business areas. Refer to Figure 1.7. All IT applications will invariably have application-specific \\nuser interface, business logic associated with the areas of business operation, and a data store that holds \\nmaster and transaction data of the applications. It is not hard to imagine that the business processes \\nare not isolated. This approach results in many islands of information and lots of redundant data being \\nstored in each application. ERP prevents this by designing common integrated data stores and applica-\\ntions  that can smoothly exchange data across them.\\nIt is important to understand that enterprises maintain different IT infrastructure platforms to preserve \\ncontinuity of IT applications, their availability and performance. It is a common scenario in enterprises to \\nhave three or more IT application-related infrastructures. Typically an IT application development infra-\\nstructure will have smaller capacity servers but powerful software development and testing tools. The devel-\\nopment environment will also have team project management, communication, and knowledge repository \\nmanagement software. Enterprises dedicate independent IT infrastructure for IT application software test-\\ning. The test set-up will have more facilities for testing functionality, adherence to standards, performance \\ntesting, and user experience testing. Production systems of enterprises have large capacity robust IT infra-\\nstructure. Much like data centres, these will have large memory, storage, administration tools supported by \\nservice desks, security management systems, and so on. The production systems are hardly visible to the \\nusers but they can get their tasks accomplished in a smooth fashion. Enterprises take utmost care to protect \\nthe production environment from hackers; they migrate applications using tools from test environment to \\nproduction environment with facility to roll-back in the event of malfunctioning of IT applications.\\nBusiness View of Information T echnology Applications • 15'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 40}, page_content='16 • Fundamentals of Business Analytics\\nFrom the several ideas about enterprise IT applications discussed above, you can start visualizing that:\\n • All IT applications required to run an enterprise will never be created at the same time. There \\nwill be several generations of applications developed or purchased over several years.\\n • All IT applications need maintenance as business rules and business environment change, and \\neach IT application will be at a different stage of maintenance at any given point of time. Enter-\\nprises migrate from small IT applications to more robust integrated suites as businesses grow.\\n • Enterprises choose the optimum hardware, software, OS, RDBMS, network and programming \\nlanguage available at the time of making build or buy decision. This results in heterogeneous \\nhardware and multi-vendor software products in the same enterprise. Also, enterprises may \\n acquire other businesses to expand their growth in non-linear ways, and this may again result in \\nmultiple technologies to co-exist in the same enterprise.\\n • The same way, enterprises may have ERP , home-grown applications, partially outsourced to fully \\nout-sourced IT application development, etc.\\n • Enterprises may loosely bring together several applications in an enterprise portal but may have \\nlimitations in terms of data exchange across IT applications.\\n • Enterprises may design new applications to combine data from several critical data sources for \\nthe management information system (MIS).\\nAgain we are emphasizing the data coming from different IT applications. Sometimes even though \\ndata is stored in a purchased application, it may be stored in a proprietary form and may not be acces-\\nsible at all. You need to know the RDBMS schema in order to understand the organization of data and \\nPresentation\\nFirewallThin Client\\nRich Client\\nDatabases\\nExternal \\napplications\\nLegacy\\nsystems \\nSystem Servcies\\nTools\\nBusiness Logic\\nBusiness Logic Data\\nFigure 1.7 A typical enterprise application architecture.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 41}, page_content='design mechanisms to access such data. Data in different applications could be in different formats, \\nduplicated or inconsistent in many ways. Unless we can get error-free data into one place, it will be \\n difficult to use in a business analytics application that is of value to users.\\n1.6 inFormA tion users And tHeir requirements\\nFirst of all, IT applications have matured to such a state today that it can typically be used by anyone. \\nConsidering the requirements of the enterprise to deliver right information to the right authorized user \\nat the right time, users of IT applications may need to be given lots of attention. We have already \\n indicated that “data” is really an asset of any enterprise and is a key ingredient in the recipe for a success-\\nful business. IT application users in the Internet age can be a whole lot of people roughly categorized \\ninto the following groups:\\n • Employees, partners, suppliers, customers, investors, analysts, prospective employees, and gen-\\neral public interested in the business affairs of the enterprise.\\n • Office goers, mobile users, home office users, remote securely connected users, casual visitors to \\nwebsite, and digital users who conduct transactions using the Internet.\\n • Business leaders, decision makers, operations managers, project managers, junior executives, and \\ntrainees who have a hierarchy.\\n • Role-based users who have access to certain category of IT applications, certain level of clas-\\nsified information, access to specific systems, and even specific operations they are allowed to \\nperform.\\n • Securely connected users who may be allowed to access specific servers from a specific location \\nduring specified hours.\\n • Administrative users, who configure the IT environment, manage users’ access control, execute \\nanti-virus programs, perform anti-theft checks, install updates/upgrades, back-up enterprise \\ndata, and restore in the event of data corruption.\\n • Users who have permission to read or update or have full control over the enterprise information.\\n • Knowledge workers/analytical users who discover new patterns in the enterprise data to help \\nbusinesses make innovative moves in the market place for competitive advantage.\\n • Multi-device access users who sometimes work in the office, move in the field, use different \\ndevices ranging from desktop systems to hand held smartphones to connect to the enterprise IT \\napplications.\\nNo matter how users access the enterprise data from various locations, they have certain common \\nexpectations. Some of these include:\\n • Smooth authentication and access to authorized resources.\\n • Availability of IT applications 24 × 7, 365 days.\\n • Speed of information delivery without having to wait long for response from systems.\\n • Ease-of-navigation and simple “user experience” with personalization capabilities.\\n • Secure delivery and transport of data to and from the IT applications.\\n • Secure transaction completion and roll-back especially involving monetary transactions.\\n • Consistent, accurate information, and ability to recover/restart from faults.\\n • Anytime, anywhere, any device-centric information delivery.\\nBusiness View of Information T echnology Applications • 17'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 42}, page_content='18 • Fundamentals of Business Analytics\\nunsolved exercises\\n1. Think of an industry of your choice such as retail, manufacturing, telecommunications, finance, \\netc. Identify the core business processes for the chosen industry.\\n2. Briefly explain the information users and their requirements.\\n3. Explain any Department IT application of your choice.\\n4. Explain the On-Line T ransaction Processing system with a suitable example.\\n5. Explain any Decision Support application that you have come across.\\n6. What is your understanding of the connected world? Explain.\\n7. What is your understanding of business analytics? Explain.\\n8. Think about your college/university. What according to you are the applications that can be \\nautomated? Explain giving suitable examples.\\n9. What are some of the automated IT applications that are a great help to your college/university \\nin its day-to-day functioning? Explain.\\n10. Can you think of one manual process/function that you wish were automated in your school/\\ncollege/university?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 43}, page_content='This section presents three case briefs:\\n • GoodLife HealthCare Group\\n • GoodFood Restaurants Inc.\\n • T enT oT en Retail Stores\\nSeveral examples/illustrations/assignments in the chapters to follow (Chapter 2–10) will refer to these \\ncase briefs. It will help to revisit these case briefs as and when you read the chapters that refer to them.\\nGoodLife HeaLtHCare Group\\nCase Study Briefs\\nintroduCtion\\n“GoodLife HealthCare Group” is one of India’s leading healthcare groups. The group began its opera-\\ntions in the year 2000 in a small town off the south-east coast of India, with just one tiny hospital build-\\ning with 25 beds. T oday, the group owns 20 healthcare centers across all the major cities of India. The \\ngroup has witnessed some major successes and attributes it to its focus on assembly line operations and \\nstandardizations. The group believes in making a “Dent in Global Healthcare”. A few of its major mile-\\nstones are as listed below in chronological sequence:\\n • Year 2000 – the birth of the GoodLife HealthCare Group. Functioning initially from a tiny \\nhospital building with 25 beds.\\n • Year 2002 – built a low cost hospital with 200 beds in India.\\n • Year 2004 – gained foothold in other cities of India.\\n • Year 2005 – the total number of healthcare centres owned by the group touched the 20 mark.\\n • The next five years saw the group’s dominance in the form of it setting up a GoodLife Health-\\nCare Research Institute to conduct research in molecular biology and genetic disorders.\\n • Year 2010 witnessed the group bag the award for the “Best HealthCare Organization of the \\nDecade”.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 44}, page_content='20 • Fundamentals of Business Analytics\\nBusiness seGments\\nGoodLife HealthCare offers the following facilities:\\n • Emergency Care 24 × 7.\\n • Support Groups.\\n • Support and help through call centers.\\nThe healthcare group also specializes in orthopedic surgeries. The group has always leveraged IT to offer \\nthe best possible and affordable services to their patients. It has never hesitated in spending money on \\nprocuring the best possible machines, medicines, and facilities to provide the finest comfort to the \\npatients. The doctors, surgeons, nurses and paramedical staff are always on the lookout for ground-\\nbreaking research in the field of medicine, therapy and treatment. Year 2005 saw the group establish its \\nown Research Institute to do pioneering work in the field of medicine.\\norGanizationaL struCture\\nGoodLife HealthCare Group has a Board of Company’s Directors at its helm. They are four in all – each \\nbeing an exceptional leader from the healthcare industry. The group lives by the norm that a disciplined \\ntraining is the key to success. The senior doctors and paramedical staff are very hands-on. They walk the \\ntalk at all times. Strategic decisions are taken by the company’s board after cautious consultation, thor-\\nough planning and review. The strategic decisions are then conveyed to all the stakeholders such as the \\nshareholders, vendor partners, employees, external consultants, etc. The group has acute focus on the \\nquality of service being offered.\\nQuaLity manaGement\\nThe healthcare group spends a great deal of time and effort in ensuring that its people are the best. They \\nbelieve that the nursing and paramedical staff constitute the backbone of the organization. They have a \\nclearly laid out process for recruitment, training and on-the-job monitoring. The organization has its \\nown curriculum and a grueling training program that all the new hires have to religiously undertake. \\nSenior doctors act as mentors of the junior doctors. It is their responsibility to groom their junior part-\\nners. Every employee is visibly aware of the organization’s philosophy and the way of life prevalent in \\nthe organization.\\nmarketinG\\nGoodLife HealthCare Group had long realized the power of marketing. They have utilized practically \\nall channels to best sell their services. They regularly advertise in the newspapers and magazines and \\nmore so when they introduce a new therapy or treatment. They have huge hoardings speaking about \\ntheir facilities. They advertise on television with campaigns that ensure that viewers cannot help but sit \\nthrough it. They have had the top saleable sportsperson to endorse their products. Lastly the group \\nunderstands that “word of mouth” is very powerful and the best advertisers are the patient themselves \\nwho have been treated at one of the group’s facilities.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 45}, page_content='Case Study Briefs • 21\\naLLianCe manaGement\\nOver the years the GoodLife HealthCare Group has established a good alliance with specialist doctors, \\nconsultants, surgeons and physiotherapists, etc. The group has also built a strong network of responsible \\nand highly dependable supplier partners. There is a very transparent system of communication to all its \\nsupplier partners. All it vendor partners are aware of the values and organization’s philosophy that defines \\nthe healthcare group. The group believes in a win–win strategy for all. It is with the help and support from \\nthese vendor partners that the group is able to stock just the required amount of inventory and is able to \\nprocure the emergency inventory supplies at a very short notice. The group focuses only on its core business \\nprocesses and out-sources the remaining processes to remain in control and steer ahead of competition.\\nfuture outLook\\nGoodLife HealthCare Group is looking at expansion in other countries of the world too. They are also \\nlooking at growing in the existing markets. They are 27,000 employees today and are looking at grow-\\ning to 60,000 in the next 5 years. The group already has a dedicated wing for the treatment of bone \\ndeformities. It aspires to set up a chemist store within its premises to make it convenient for their \\npatients. They would like to set up an artificial limb center for the production of artificial limbs and \\nrehabilitation of patients of orthopedic surgeries. The GoodLife group realizes its social obligation too \\nand is looking forward to setting up a free hospital with 250 beds in a couple of year’s time.\\ninformation teCHnoLoGy at GoodLife Group\\nWeb presence\\n • GoodLife group has excellent web presence: leveraging website, social networking and mobile \\ndevice banner ads.\\n • Leverages Internet technology for surveys, targeted mailers.\\n • Self-help portal for on-line registration for treatment of ailments.\\nfront office management\\n • Patient relationship management.\\n • Alliance Management.\\n • Registration and discharge of patients.\\n • Billing.\\n • Help Desk.\\nHuman CapitaL manaGement & traininG manaGement\\n • Employee satisfaction surveys.\\n • Employee retention program management.\\n • Employee training and development program management.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 46}, page_content='22 • Fundamentals of Business Analytics\\ndata Center Hosted application\\n • Finance and Accounting, Corporate performance.\\n • Inventory Management.\\n • Suppliers and Purchase.\\n • Marketing and Campaign Management.\\n • Funnel and Channel analysis application.\\npersonal productivity\\n • Email, web access, PDA connect.\\n • Suggestions.\\n • Quick surveys.\\n • Feedback from communities of patients and also the communities of specialist doctors, consul-\\ntants and physiotherapists.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 47}, page_content='Goodfood restaurants inC.\\nintroduCtion\\nGoodFood Restaurants is a very well known concept restaurants chain head quartered in the USA. It \\nstarted its operations in the year 1999 in the USA, the UK, and Australia. The restaurant chain is led by \\na team of five experienced professionals; their leaders are amongst the best in the hospitality industry. \\nThe new group has had several significant triumphs and is an established benchmark in the industry for \\nits “Quality of Dining Experience”. Some of the major milestones in the growth of GoodFood \\nRestaurants’s business include:\\n • Year 1999 – Launch of 8 concept restaurants.\\n • Year 2001 – Serves over 100 popular standard items across the chain.\\n • Year 2002 – Leveraging IT in 5 strategic functions, globally.\\n • Year 2003 – Awarded the “Global Dining Experience Award”.\\n • Year 2005 – T ouched 100 restaurants with IPO.\\n • Year 2006 – Set-up “International Master Chefs School”.\\n • Year 2009 – Completed expansion to 10 countries. \\nBusiness seGments\\nServing only Continental, Chinese, and Italian cuisines during its initial launch days, it is a different \\nworld today at GoodFood Restaurants. The dynamic management team was always listening to the voice \\nof the customers and made several quick moves to expand its business. They were the first to introduce \\n“Dial your Dinner” for take-away service. GoodFood delivered to customers’ expectations providing \\n“fast turnaround time” for orders especially during the weekend evenings when almost all from today’s \\nworkforce desired a quick pack home. No complaints were received about wrong items, short supplied \\nitems, or any customization requests. Take-away segment is a separate line with pre- defined menu, ser-\\nvice charges, and multi-channel approach to customer order processing, delivery, feedback collection. IT \\napplications track accurately all transactions and monitor the delivery carefully to ensure customer satis-\\nfaction. Its dine-in restaurants are a great crowd puller and boast of massive reservations for theme din-\\nners that are advertised. GoodFood has leveraged technology to ensure that customers are able to make \\ntheir choice of restaurant, menu, table, etc. prior to coming into the restaurant. This is the main cash \\ncow for the chain. The recent entry into catering in cruise liners has given a boost to GoodFood’s busi-\\nness. Looking at the sharp peaking growth during holiday seasons, GoodFood has established specialized \\nprocesses and has leveraged IT to ensure zero-defects catering across several ports in the world.\\nimpeCCaBLe proCesses and standard Cuisine\\nGoodFood invested a lot into standardization of recipe, equipment, and training of chefs. The auto-\\nmated kitchens, access to standard processes, continuous tracking of quality has helped the restaurant \\nchain to consistently deliver “Dining Experience” across the chain. Customers would never be caught \\nCase Study Briefs • 23'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 48}, page_content='24 • Fundamentals of Business Analytics\\nby “surprise” and the stewards on the floor were empowered to make decisions to delight the  \\ncustomer. The team of chefs constantly exchange best practices, pit falls, innovations, and improvements. A \\nlot of data has been collected over years that serve as a goldmine for new chefs entering into the system. \\nMaster Chefs have developed their own innovations that have received global awards and recognition.\\nmarketinG\\nGoodFood systematically invests in marketing its brand, listens to customers, and develops campaigns \\nto attract different segments of customers. The campaigns are known for personalization, fast and \\nimpactful briefing, and demonstrating value for money. In the year 2005, the Management changed its \\ncorporate priorities. The order became (a) customer delight, (b) return on assets, and (c) market share. All \\nregions began reposting in standard formats and reviews were fact-based. All investment decisions were \\nbased on data. The chain effectively leveraged customers as their brand ambassadors, globally. Every \\nfunction made innovations to enhance customer delight and maximize return on assets that led to the \\nrealization of the third goal (that of increasing their market share).\\nsuppLier manaGement\\nGoodFood has continually relied on loyal and collaborative suppliers to help achieve success in their \\nendeavors. They have consciously kept the number of supplier’s low, automated the purchasing pro-\\ncesses, and enhanced trust, to the extent of sometimes enjoying access to each other’s accounting records. \\nThis has helped GoodFood to maintain low levels of inventory, get the best available ingredients, replen-\\nish items quickly, plan lead times collaboratively, and alert each other of any changed situations. The \\nteam even benchmarked inventory management practices of auto spare parts dealers and drew inspira-\\ntion from their innovative practices. The IT infrastructure management and mission-critical IT applica-\\ntions production run were all outsourced with standard service level agreements. The teams handled \\nglobal expansion projects and delivered operating facilities ahead of schedule.\\nQuaLity manaGement\\nThe Management team at GoodFood is credited with conceptualizing and developing a “Leadership \\nthrough Quality” program within 3 years of inception. The program has achieved global recognition \\nseveral times. They are regarded “a quality company”. The focus has always been on providing both \\ninternal and external customers with products/services that duly meet their requirements. Quality is the \\nprerogative of every employee. All functions have pre-defined performance standards, quality targets, \\nrigor in data collection, and systematic analysis of deviation and tracking of corrective actions. Process \\nmetrics data represents a large body of knowledge at GoodFood.\\norGanization struCture\\nThe head quarter focuses on strategic areas and collaborates with country operations by empowering the \\ncountry management. Finance constantly provides the much-needed fuel for growth and shares the '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 49}, page_content='corporate performance with investors. The planning and competition watch were integrated into the \\nFinance function. IPO project was again led by Finance in collaboration with Marketing. Human \\ncapital management became a role model for hiring, empowerment, training, and internationalization \\nof operations. Flat organization structure helped in enhanced transparency, sharing of knowledge, and \\ncollaborative workforce development. Management persistently leverages technology for fast decision \\nmaking and remaining on-the-same-page with global leaders. Standard formats, frequency of informa-\\ntion sharing, and objective communication have helped GoodFood retain its competitive edge and \\ninnovate constantly.\\nfuture outLook\\nGoodFood is a socially conscious enterprise that has networked with communities to reduce food wast-\\nage, recycle waste to ensure safety and hygiene, etc. Given its firm belief for equal opportunity employ-\\nment, global accounting standards, human capital management excellence, GoodFood is likely to \\nacquire restaurants in theme parks, high-end resorts, and flight kitchen operations management.\\ninformation teCHnoLoGy at Goodfood\\nWeb presence\\n • GoodFood has excellent web presence: leveraging website, social networking and mobile device \\nbanner advertisements.\\n • Leverages Internet technology for surveys, targeted mailers, personalized invites, loyalty program \\nmanagement.\\n • Self-help portal for reservation, choice of seating tables, pre-ordering selections.\\nfront office management\\n • Wireless Kitchen Order Tickets, guest relationship management, loyalty programs.\\n • POS, Billing, Charging, Promotion points redemption.\\n • Messaging, email, ambience control including piped-in music, video, news, alerts, weather.\\nteam Collaboration\\n • Intranet, Scheduling, Search.\\n • Collaboration.\\ndata Center Hosted application\\n • Finance and Accounting, Corporate performance.\\n • Human Capital Management and T raining Management.\\n • Inventory Management.\\n • Suppliers and Purchase.\\n • Marketing and Campaign Management.\\n • Menu, recipe, and global (product) descriptions.\\nCase Study Briefs • 25'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 50}, page_content='26 • Fundamentals of Business Analytics\\npersonal productivity\\n • Email, web access, PDA connect.\\n • Networking printing.\\n • Suggestion.\\n • Quick surveys.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 51}, page_content='introduCtion\\nTenToTen Retail Stores is one of the world’s leading distribution groups. The group began its opera-\\ntions in the year 1990 with just one grocery store setup titled “Traditional Supermarkets”. Headquartered \\nin the USA, the group now also operates out of the UK. Currently, it has four major grocery store \\nsetups: “Hypermarkets & Supermarkets”, “T raditional Supermarket”, “Dollar Store”, and “Super \\nWarehouse”. In the 20 years since its inception, the group owns close to 10,000 stores either company \\noperated or franchises. The group has witnessed some major successes and attributes them to its focus \\non enhancing the “quality of customer experience”. The group believes in becoming “Better and not \\njust Bigger”. A few of its major milestones are as listed below in chronological sequence:\\n • Year 1990 – the birth of the T enT oT en Retail Stores. Initially operated only out of the USA.\\n • Year 2000 – awarded the honour of “Best Managed Small-Sized Business”.\\n • Year 2000 – gained foothold in the UK.\\n • Year 2005 – the total number of stores owned by the group touched the 5000 mark.\\n • The next five years saw the group’s dominance in the form of it acquiring another 5000 stores.\\n • Year 2010 witnessed the group bag the award for the “Best Employer of the Decade”.\\nBusiness seGments\\nThe grocery Stores initially used to stock-up only grocery items such as confectionaries, food items such \\nas grains, pulses, breads (Indian and Italian), fresh fruits, fresh vegetables, tinned food, dairy products, \\netc. Slowly and gradually, it started stock-piling garments for men, women, kids, and infants; electronic \\ngizmos; video games; CDs/DVDs; gardening appliances; cosmetics; etc. T oday, it also has fresh vegetable \\nand fruit juice corners and a couple of fast food joints within each of its setup. The group has always \\nbelieved in leveraging information technology to serve its customers better. They maintain a list of their \\npremium customers and accord special discounts to their premium community. They have constantly \\npaid heed to the customers’ demands and desires through their “Hear Me – Voice of Consumer” service \\nprogram. The group has a team of dedicated analysts who work round the clock to provide “Competitive \\nIntelligence”, “Customer Intelligence”, etc. to help run the business smoothly and efficiently.\\norGanizationaL struCture\\nT enT oT en Stores has a Board of Directors at its helm. They are six in all, each being an exceptional leader \\nfrom the retail industry. The group lives by the norm that the top leaders will mentor their middle level, \\nwhich in turn will mentor their operational managers. Strategic decisions are taken by the company’s \\nboard after careful consultation, meticulous planning, and review. The strategic decisions are then con-\\nveyed to all the stakeholders such as the shareholders, vendor partners, employees, external consultants, \\ncustomers, etc. The group has acute customer and market focus. Before launching a new product, the \\nsenior executives conduct a detailed study of the market and the various customer segments. The group \\nalso uses the services of a few external consultants to keep them abreast of competition.\\ntentoten retaiL stores\\nCase Study Briefs • 27'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 52}, page_content='28 • Fundamentals of Business Analytics\\nmarketinG\\nT enT oT en Stores had realized the power of marketing while taking its baby steps into the business \\nworld. They have utilized practically all channels to best sell their products. They regularly advertise in \\nthe newspapers and magazines and more so when they introduce a new product or announce a promo-\\ntional scheme. They have huge hoardings speaking about their products and the shopping experience \\nthat awaits the customers. They advertise on television with campaigns that ensure that viewers cannot \\nhelp but sit through it. They have had the top saleable cinestars and sportsperson to endorse their prod-\\nucts. Lastly the group understands that “word of mouth” is very powerful and the best advertisers are the \\ncustomers themselves. A lot has gone into making customers their brand ambassadors.\\nsuppLier manaGement\\nT enT oT en Stores has built a strong network of trustworthy and highly reliable supplier partners. Their’s \\nis a very transparent system of communication to all the supplier partners. All their vendor partners are \\naware of the values and principles that define this group. The group believes in a win–win strategy for \\nall. The group focuses only on its core business processes and out-sources the remaining processes to \\nremain in control and steer ahead of competition.\\nQuaLity manaGement\\nT enT oT en Stores has quality processes in place to assess the quality of products. They have clearly laid \\nout processes to house the inventory – how much and where. They have clear guidelines on how to \\nstock the various products – market basket. The products are classified very well and are stocked in \\nseparate sections such as “Dairy Products”, “Electronic Goods”, “T raveller’s accessories”, “Home \\nAppliances”, etc. Clear guidelines also exist for on-boarding employees before releasing them to the \\nshop floor. Clearly, “Quality is the differentiator”. The group also hires services of external agencies to \\ngarner customer feedback and employee satisfaction feedback.\\nfuture outLook\\nThe group has employed several analysts, whose major tasks involve studying the markets, studying the \\ncustomers buying behavior, the customer’s demographics, when to announce discounts, how much \\ndiscount to offer, which customer segment to target, etc. They are looking at growing in the existing \\nmarkets as well as expansion to new territories such as Middle East. They have 57,000+ employees \\ntoday and are looking at growing to 1,00,000 employees in the next 5 years.\\nT enT oT en Stores is also aware of its social responsibilities and is constantly looking at means to con-\\nserve power/energy, reducing the use of polythene/plastic bags, etc. They have started the practice of \\nusing recycled paper bags. Several tourists and travellers also visit the stores owned by T enT oT en Stores. \\nThe group wants to make it easy for them to make their purchases by allowing the “Money/T ravellers \\nCheques Exchange” at their stores. T oday is an era of digital consumers; T enT oT en Stores will be focus-\\ning on creating brand ambassadors in the digital space too.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 53}, page_content='information teCHnoLoGy at tentoten stores\\nWeb presence\\n • T enT oT en group has excellent web presence: leveraging website, social networking, and mobile \\ndevice banner ads.\\n • Leverages Internet technology for surveys, targeted mailers, personalized invites, loyalty program \\nmanagement.\\n • Self-help portal for on-line purchases.\\nfront office management\\n • Customer relationship management.\\n • POS, Billing, Charging, Promotion points redemption.\\n • Customer Help Desk.\\nHuman Capital management and training management\\n • Employee satisfaction surveys.\\n • Employee retention program management.\\n • Employee training and development program management.\\ndata Center Hosted application\\n • Finance and Accounting, Corporate performance.\\n • Inventory Management.\\n • Suppliers and Purchase.\\n • Marketing and Campaign Management.\\n • Funnel and Channel analysis application.\\n • Voice of Consumer application – to collect feedback.\\npersonal productivity\\n • Email, web access, PDA connect.\\n • Suggestions.\\n • Quick surveys.\\nCase Study Briefs • 29'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 54}, page_content=''),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 55}, page_content='What’s in store\\nT oday, data undoubtedly is an invaluable asset of any enterprise (big or small). Even though professionals \\nwork with data all the time, the understanding, management and analysis of data from heterogeneous \\nsources remains a serious challenge.\\nThis chapter is a “Must Read” for first-time learners interested in understanding the role of data in busi-\\nness intelligence. In this chapter, we will introduce you to the various formats of digital data (structured, \\nsemi-structured and unstructured data), data storage mechanism, data access methods, management of data, \\nthe process of extracting desired information from data, challenges posed by various formats of data, etc.\\nWe suggest you refer to some of the learning resources suggested at the end of this chapter and also \\ncomplete the “T est Me” exercises. You will get deeper knowledge by interacting with people who have \\nshared their project experiences in blogs. We suggest you make your own notes/bookmarks while read-\\ning through the chapter.\\n2.1 introduction \\nData growth has seen exponential acceleration since the advent of the computer and Internet. In fact, \\nthe computer and Internet duo has imparted the digital form to data. Digital data can be classified into \\nthree forms:\\nBrief Contents\\nWhat’s in Store\\nIntroduction \\nGetting into “GoodLife” Database \\nGetting to Know Structured Data \\nGetting to Know Unstructured Data\\nGetting T o Know Semi-Structured Data\\nDifference Between Semi-Structured  \\nand Structured Data \\nUnsolved Exercises \\nTypes of Digital Data\\n2'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 56}, page_content='32 • Fundamentals of Business Analytics\\n10% 10%\\n80%\\nUnstructured data\\nSemi-structured data\\nStructured data\\nFigure 2.1 Distribution of digital data in three forms.\\n • Unstructured.\\n • Semi-structured.\\n • Structured.\\nUsually, data is in the unstructured format which makes extracting information from it difficult. \\nAccording to Merrill Lynch, 80–90% of business data is either unstructured or semi-structured.  \\nGartner also estimates that unstructured data constitutes 80% of the whole enterprise data. Here is a \\npercent distribution of the three forms of data as shown in Figure 2.1. A detailed explanation of these \\nforms will follow subsequently.\\n • Unstructured data: This is the data which does not conform to a data model or is not in a form \\nwhich can be used easily by a computer program. About 80–90% data of an organization is in \\nthis format; for example, memos, chat rooms, PowerPoint presentations, images, videos, letters, \\nresearches, white papers, body of an email, etc.\\n • Semi-structured data: This is the data which does not conform to a data model but has some \\nstructure. However, it is not in a form which can be used easily by a computer program; for \\nexample, emails, XML, markup languages like HTML, etc. Metadata for this data is available \\nbut is not sufficient.\\n • Structured data: This is the data which is in an organized form (e.g., in rows and columns) and \\ncan be easily used by a computer program. Relationships exist between entities of data, such as \\nclasses and their objects. Data stored in databases is an example of structured data.\\n2.2 GettinG into “GoodLife” database \\nRefer to the case brief on “GoodLife HealthCare Organization”. Everyday “GoodLife” witnesses enor-\\nmous amounts of data being exchanged in the following forms:\\n • Doctors’ or nurses’ notes in an electronic report.\\n • Emails sharing information about consultations or investigations.\\n • Surveillance system reports.\\n • Narrative portions of electronic medical records.\\n • Investigative reports.\\n • Chat rooms.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 57}, page_content='Types of Digital Data • 33\\n“GoodLife” maintains a database which stores data only in a structured format. However, the  \\norganization also has unstructured and semi-structured data in abundance.\\nLet us try to understand the following aspects of GoodLife data: Where is each type of its data present? \\nHow is it stored? How is the desired information extracted from it? How important is the information \\nprovided by it? How can this information augment public health and healthcare services?\\n2.3 GettinG to KnoW structured data\\nLet us start with an example of structured data. The patient index card shown in Figure 2.2 is in a struc-\\ntured form. All the fields in the patient index card are also structured fields.\\n“GoodLife” nurses make electronic records for every patient who visits the hospital. These records \\nare stored in a relational database. For example, nurse Anne records the body temperature and blood \\npressure of a patient, Dexter, and enters them in the hospital database. Dr. Brian, who is treating Dexter, \\nsearches the database to know his body temperature. Dr. Brian is able to locate the desired information \\neasily because the hospital data is structured and is stored in a relational database.\\n2.3.1 characteristics of structured data\\nStructured data is organized in semantic chunks (entities) with similar entities grouped together to form \\nrelations or classes. Entities in the same group have the same descriptions, i.e. attributes. \\nFigure 2.2 A snapshot of structured data.\\nGoodLife Healthcare\\nPatient Index Card\\nPatient ID <> Date <>\\nNurse Name <>\\nPatient Name <> Patient Age <>\\nBody Temperature <> Blood Pressure <>\\nFigure 2.3 Characteristics of structured data.\\nConforms to a\\ndata model\\nSimilar entities\\nare grouped\\nAttributes in a\\ngroup are the\\nsame Definition,\\nformat, and\\nmeaning of data\\nis explicitly known\\nData resides in\\nfixed fields\\nwithin a record\\nor file\\nData is stored in\\nthe form of rows\\nand columns, e.g.\\nrelational database\\nStructured\\ndata'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 58}, page_content='34 • Fundamentals of Business Analytics\\nFigure 2.4 Sources of structured data.\\nStructured data \\nDatabases, e.g. Access\\nSpreadsheets\\nOLTP systems\\nSQL\\nDescriptions for all entities in a group (schema)\\n • have the same defined format,\\n • have a predefined length,\\n • and follow the same order.\\nFigure 2.3 depicts the characteristics of structured data.\\n2.3.2 Where does structured data come from? \\nData coming from databases such as Access, OLTP systems, SQL as well spreadsheets such as Excel, etc. \\nare all in the structured format. Figure 2.4 depicts the sources of structured data.\\nT o summarize, structured data\\n • Consists of fully described data sets.\\n • Has clearly defined categories and sub-categories.\\n • Is placed neatly in rows and columns.\\n • Goes into the records and hence the database is regulated by a well-defined structure.\\n • Can be indexed easily either by the DBMS itself or manually.\\n2.3.3 it’s so easy With structured data\\nWorking with structured data is easy when it comes to storage, scalability, security, and update and \\ndelete operations (Figure 2.5):\\n • Storage: Both defined and user-defined data types help with the storage of structured data.\\n • Scalability: Scalability is not generally an issue with increase in data.\\n • Security: Ensuring security is easy.\\n • Update and Delete: Updating, deleting, etc. is easy due to structured form.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 59}, page_content='2.3.4 hassle-free retrieval\\nYou won’t get headache while retrieving desired information from structured data thanks to its follow-\\ning features (Figure 2.6):\\n • Retrieving information: A well-defined structure helps in easy retrieval of data.\\n • Indexing and searching: Data can be indexed based not only on a text string but also on other \\nattributes. This enables streamlined search.\\n • Mining data: Structured data can be easily mined and knowledge can be extracted from it.\\n • BI operations: BI works extremely well with structured data. Hence data mining, warehousing, \\netc. can be easily undertaken.\\nFigure 2.5 Ease with structured data.\\nEase with structured\\ndata\\nStorage\\nScalability\\nSecurity\\nUpdate and\\ndelete\\nFigure 2.6 Ease of retrieval of structured data.\\nBI operations\\nMining data\\nRetrieving\\ninformation\\nIndexing and\\nsearching \\nEase with structured\\ndata\\nTypes of Digital Data • 35'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 60}, page_content='36 • Fundamentals of Business Analytics\\n2.4 GettinG to KnoW unstructured data\\nPicture this…\\nDr. Ben, Dr. Stanley, and Dr. Mark work at the medical facility of “GoodLife”. Over the past few days, \\nDr. Ben and Dr. Stanley had been exchanging long emails about a particular case of gastro-intestinal \\nproblem. Dr. Stanley has chanced upon a particular combination of drugs that has successfully cured \\ngastro-intestinal disorders in his patients. He has written an email about this combination of drugs  \\nto Dr. Ben.\\nDr. Mark has a patient in the “GoodLife” emergency unit with quite a similar case of gastro-intestinal \\ndisorder whose cure Dr. Stanley has chanced upon. Dr. Mark has already tried regular drugs but with no \\npositive results so far. He quickly searches the organization’s database for answers, but with no luck. The \\ninformation he wants is tucked away in the email conversation between two other “GoodLife” doctors, \\nDr. Ben and Dr. Stanley. Dr. Mark would have accessed the solution with few mouse clicks had the \\nstorage and analysis of unstructured data been undertaken by “GoodLife”.\\nAs is the case at “GoodLife”, 80–85% of data in any organization is unstructured and is growing at \\nan alarming rate. An enormous amount of knowledge is buried in this data. In the above scenario, Dr. \\nStanley’s email to Dr. Ben had not been successfully updated into the medical system database as it fell \\nin the unstructured format.\\nUnstructured data, thus, is the one which cannot be stored in the form of rows and columns as in \\na database and does not conform to any data model, i.e. it is difficult to determine the meaning of the \\ndata. It does not follow any rules or semantics. It can be of any type and is hence unpredictable. The \\ncharacteristics of unstructured data are depicted in Figure 2.7.\\nFigure 2.7 Characteristics of unstructured data.\\nUnstructured\\ndata \\nDoes not\\nconform to\\nany data\\nmodel Cannot be\\nstored in the\\nform of rows and\\ncolumns as in\\na database\\nNot in any\\nparticular\\nformat or\\nsequence\\nNot easily\\nusable by a\\nprogram \\nDoes not\\nfollow any\\nrules or\\nsemantics\\nHas no easily\\nidentifiable\\nstructure'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 61}, page_content='Figure 2.8 Sources of unstructured data.\\nWord document\\nPowerPoint presentations\\nChats\\nReports\\nWhite papers\\nSurveys\\nWeb pages\\nMemos\\nVideos (MPEG, etc.)\\nImages (JPEG, GIF, etc.)\\nBody of an email\\nUnstructured data\\n2.4.1 Where does unstructured data come from? \\nBroadly speaking, anything in a non-database form is unstructured data. It can be classified into two \\nbroad categories:\\n • Bitmap objects: For example, image, video, or audio files.\\n •  Textual objects: For example, Microsoft Word documents, emails, or Microsoft Excel spread-\\nsheets.\\nRefer to Figure 2.8. Let us take the above example of the email communication between Dr. Ben and \\nDr. Stanley. Even though email messages like the ones exchanged by Dr. Ben and Dr. Stanley are orga-\\nnized in databases such as Microsoft Exchange or Lotus Notes, the body of the email is essentially raw \\ndata, i.e. free form text without any structure.\\nA lot of unstructured data is also noisy text such as chats, emails and SMS texts. The language of \\nnoisy text differs significantly from the standard form of language.\\n2.4.2 a Myth demystified \\nWeb pages are said to be unstructured data even though they are defined by HTML, a markup language \\nwhich has a rich structure. HTML is solely used for rendering and presentations. The tagged elements \\ndo not capture the meaning of the data that the HTML page contains. This makes it difficult to auto-\\nmatically process the information in the HTML page.\\nAnother characteristic that makes web pages unstructured data is that they usually carry links and \\nreferences to external unstructured content such as images, XML files, etc. Figure 2.9 is the pictorial \\nrepresentation of a typical web page.\\nTypes of Digital Data • 37'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 62}, page_content='38 • Fundamentals of Business Analytics\\n2.4.3 how to Manage unstructured data? \\nLet us look at a few generic tasks to be performed to enable storage and search of unstructured data:\\n • Indexing: Let us go back to our understanding of the Relational Database Management System \\n(RDBMS). In this system, data is indexed to enable faster search and retrieval. On the basis of \\nsome value in the data, index is defined which is nothing but an identifier and represents the \\nlarge record in the data set. In the absence of an index, the whole data set/document will be \\nscanned for retrieving the desired information.\\nIn the case of unstructured data too, indexing helps in searching and retrieval. Based on text \\nor some other attributes, e.g. file name, the unstructured data is indexed. Indexing in unstruc-\\ntured data is difficult because neither does this data have any pre-defined attributes nor does it \\nfollow any pattern or naming conventions. T ext can be indexed based on a text string but in case \\nof non-text based files, e.g. audio/video, etc., indexing depends on file names. This becomes a \\nhindrance when naming conventions are not being followed.\\n • Tags/Metadata: Using metadata, data in a document, etc. can be tagged. This enables search \\nand retrieval. But in unstructured data, this is difficult as little or no metadata is available. Struc-\\nture of data has to be determined which is very difficult as the data itself has no particular format \\nand is coming from more than one source.\\n • Classification/Taxonomy: Taxonomy is classifying data on the basis of the relationships that \\nexist between data. Data can be arranged in groups and placed in hierarchies based on the \\nFigure 2.9 A typical web page.\\nImage map\\nMultimedia XML\\nDatabase\\nWeb page\\nText'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 63}, page_content='taxonomy prevalent in an organization. However, classifying unstructured data is difficult as \\nidentifying relationships between data is not an easy task. In the absence of any structure or \\nmetadata or schema, identifying accurate relationships and classifying is not easy. Since the data \\nis unstructured, naming conventions or standards are not consistent across an organization, thus \\nmaking it difficult to classify data.\\n • CAS (Content Addressable Storage): It stores data based on their metadata. It assigns a unique \\nname to every object stored in it. The object is retrieved based on its content and not its location. \\nIt is used extensively to store emails, etc.\\nData management, however, does not end with the performance of above-mentioned tasks. This is \\nmerely the beginning. Provisions now need to be made to store this data as well. So the next question \\nthat comes to mind is: How to store this unstructured data?\\n2.4.4 how to store unstructured data? \\nThe challenges faced while storing unstructured data are depicted in Figure 2.10 and listed below.\\n • Storage space: It is difficult to store and manage unstructured data. A lot of space is required to \\nstore such data. It is difficult to store images, videos, audios, etc.\\n • Scalability: As the data grows, scalability becomes an issue and the cost of storing such data \\ngrows.\\n • Retrieve information: Even if unstructured data is stored, it is difficult to retrieve and recover \\nfrom it.\\n • Security: Ensuring security is difficult due to varied sources of data, e.g. emails, web pages, etc.\\n • Update and delete: Updating and deleting unstructured data are very difficult as retrieval is \\ndifficult due to no clear structure.\\n • Indexing and searching: Indexing unstructured data is difficult and error-prone as the structure \\nis not clear and attributes are not pre-defined. As a result, the search results are not very accurate. \\nIndexing becomes all the more difficult as the volume of data grows.\\nFigure 2.10 Challenges faced while storing unstructured data.\\nChallenges faced\\nSecurity\\nUpdate and\\ndelete\\nIndexing\\nand\\nsearching \\nStorage\\nSpace\\nScalability\\nRetrieve\\ninformation\\nTypes of Digital Data • 39'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 64}, page_content='40 • Fundamentals of Business Analytics\\n2.4.5 solutions to storage challenges of unstructured data \\nNow that we understand the challenges in storing unstructured data, let us look at a few possible solu-\\ntions depicted in Figure 2.11 and described below:\\n • Changing format: Unstructured data may be converted to formats which are easily managed, \\nstored and searched. For example, IBM is working on providing a solution which will convert \\naudio, video, etc. to text.\\n • Developing new hardware: New hardware needs to be developed to support unstructured data. It \\nmay either complement the existing storage devices or may be a stand-alone for unstructured data.\\n • Storing in RDBMS/BLOBs: Unstructured data may be stored in relational databases which sup-\\nport BLOBs (Binary Large Objects). While unstructured data such as video or image file cannot \\nbe stored fairly neatly into a relational column, there is no such problem when it comes to storing \\nits metadata, such as the date and time of its creation, the owner or author of the data, etc.\\n • Storing in XML format: Unstructured data may be stored in XML format which tries to give \\nsome structure to it by using tags and elements.\\n • CAS (Content Addressable Storage): It organizes files based on their metadata and assigns a \\nunique name to every object stored in it. The object is retrieved based on its content and not its \\nlocation. It is used extensively to store emails, etc.\\nXML or eXtensible Markup Language will be explained in detail in the “Semi-structured Data” section.\\nWe are now at a juncture where we have successfully made provisions to store as well as manage data \\nthat comes in unstructured format. But would merely the presence of this data in a database be suffi-\\ncient to enable Dr. Mark give adequate medical treatment to his patient at the right time? The answer is \\n“no”, because management and storage of unstructured data is not enough; we need to extract informa-\\ntion from this data as well.\\nFigure 2.11 Possible solutions for storing unstructured data.\\nPossible solutions RDBMS/\\nBLOBs\\nXML\\nCAS\\nChange\\nformats\\nNew\\nhardware'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 65}, page_content='2.4.6 how to extract information from stored unstructured data?\\nLet us again start off by looking at some of the challenges faced while extracting information from \\nunstructured data. These challenges are depicted in Figure 2.12 and described below:\\n • Interpretation: Unstructured data is not easily interpreted by conventional search algorithms.\\n • Classification/Taxonomy: Different naming conventions followed across the organization \\nmake it difficult to classify data.\\n • Indexing: Designing algorithms to understand the meaning of the documents and then tagging \\nor indexing them accordingly is difficult.\\n • Deriving meaning: Computer programs cannot automatically derive meaning/structure from \\nunstructured data.\\n • File formats: Increasing number of file formats makes it difficult to interpret data.\\n • Tags: As the data grows, it is not possible to put tags manually.\\nThe possible solutions to the challenges just mentioned are depicted in Figure 2.13 and described \\nbelow:\\n • Tags: Unstructured data can be stored in a virtual repository and be automatically tagged. For \\nexample, Documentum provides this type of solution.\\n • Text mining: T ext mining tools help in grouping as well as classifying unstructured data and \\nassist in analyzing by considering grammar, context, synonyms, etc.\\n • Application platforms: Application platforms like XOLAP help extract information from email \\nand XML-based documents.\\n • Classification/Taxonomy: Taxonomies within the organization can be managed automatically \\nto organize data in hierarchical structures.\\nFigure 2.12 Challenges faced while extracting information from stored unstructured data.\\nChallenges faced\\nDeriving meaning\\nFile formats\\nClassification/\\ntaxonomy\\nInterpretation\\nTags\\nIndexing\\nTypes of Digital Data • 41'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 66}, page_content='42 • Fundamentals of Business Analytics\\n • Naming conventions/standards: Following naming conventions or standards across an organi-\\nzation can greatly improve storage, retrieval, index, and search.\\n2.4.7 uiMa: a Possible solution for unstructured data \\nUIMA (Unstructured Information M anagement Architecture) is an open source platform from IBM \\nwhich integrates different kinds of analysis engines to provide a complete solution for knowledge dis-\\ncovery from unstructured data. In UIMA (depicted in Figure 2.14), the analysis engines enable inte-\\ngration and analysis of unstructured information and bridge the gap between structured and \\nunstructured data.\\nUIMA stores information in a structured format. The structured resources can be then mined, \\nsearched, and put to other uses. The information obtained from structured sources is also used for sub-\\nsequent analysis of unstructured data. Various analysis engines analyze unstructured data in different \\nways such as:\\n • Breaking up of documents into separate words.\\n • Grouping and classifying according to taxonomy.\\n • Detecting parts of speech, grammar, and synonyms.\\n • Detecting events and times.\\n • Detecting relationships between various elements.\\nFor more information refer to: \\nhttp://www.research.ibm.com/UIMA/UIMA%20Architecture%20Highlights.html\\nAt this point we have discussed the management, storage, and analysis of unstructured data. But we \\nare yet to deal with another prevalent digital data format, namely, semi-structured data.\\nFigure 2.13 Possible solutions for extracting information from stored unstructured data.\\nPossible solutions\\nTags\\nText mining\\nApplication\\nplatforms\\nClassification/\\ntaxonomy\\nNaming conventions/\\nstandards'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 67}, page_content='2.5 GettinG to KnoW seMi-structured data\\nPicture this…\\nDr. Marianne of “GoodLife HealthCare” organization usually gets a blood test done for migraine \\npatients visiting her. It is her observation that patients diagnosed with migraine usually have a high \\nplatelet count. She makes a note of this in the diagnosis and conclusion section in the blood test report \\nof patients. One day another “GoodLife” doctor, Dr. B. Brian, searches the database when he is unable \\nto find the cause of migraine in one of his patients, but with no luck! The answer he is looking for is \\nnestled in the vast hoards of data.\\nAs depicted in Figure 2.1, only about 10% of data in any organization is semi-structured. Still it \\nis important to understand, manage, and analyze this semi-structured data coming from heteroge-\\nneous sources. In the above case of migraine patients, Dr. Marianne’s blood test reports on patients \\nwere not successfully updated into the medical system database as they were in the semi-structured \\nformat.\\nSemi-structured data, as depicted in Figure 2.15, does not conform to any data model, i.e. it is dif-\\nficult to determine the meaning of this data. Also, this data cannot be stored in rows and columns as in \\na database. Semi-structured data, however, has tags and markers which help group the data and describe \\nhow the data is stored, giving some metadata, but they are not sufficient for management and automa-\\ntion of data. In semi-structured data, similar entities are grouped and organized in a hierarchy. The \\nattributes or the properties within a group may or may not be the same.\\nFigure 2.14 Unstructured Information Management Architecture (UIMA).\\nSubjected\\nto\\nsemantic analysis\\nStructured\\ninformation\\nQuery &\\npresentation\\nStructured\\ninformation\\naccess\\nUsers\\nUnstructured data\\nsuch as chat, email, images, etc.\\nTransformed into\\nAnalysis\\nDelivery\\nAcquired\\nfrom\\nvarious sources\\nTypes of Digital Data • 43'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 68}, page_content='44 • Fundamentals of Business Analytics\\nFor example, two addresses may or may not contain the same number of properties/attributes: \\nAddress 1\\n<house number><street name><area name><city>\\nAddress 2\\n<house number><street name><city>\\nOn the other hand, an email follows a standard format such as\\nT o: <Name>\\nFrom: <Name>\\nSubject: <T ext>\\nCC: <Name>\\nBody: <T ext, Graphics, Images, etc. >\\nThough the above email tags give us some metadata, the body of the email contains no format. Nei-\\nther does it convey the meaning of the data it contains.\\nNow, consider the blood test report prepared by Dr. Marianne as shown in Figure 2.16. The blood \\ntest report is semi-structured. It has structured fields like Date, Department, Patient Name, etc. and \\nunstructured fields like Diagnosis, Conclusion, etc.\\nAnother example of semi-structured data are web pages. These pages have content embedded within \\nHTML and often have some degree of metadata within tags. This automatically implies certain details \\nabout the data being presented.\\nRemember, there is a very fine line between unstructured and semi-structured data!!! Email, XML, \\nTCP/IP packets, zipped files, etc. are semi-structured data as all have certain amount of metadata.\\nFigure 2.15 Characteristics of semi-structured data.\\nSemi-\\nstructured\\ndata \\nDoes not\\nconform to a\\ndata model but\\ncontains tags and\\nelements\\n(metadata) \\nCannot be\\nstored in the\\nform of rows and\\ncolumns as in\\na database\\nThe tags and\\nelements\\ndescribe data\\nis stored\\nNot sufficient\\nmetadata\\nAttributes in a\\ngroup may not\\nbe the same\\nSimilar entities\\nare grouped'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 69}, page_content='2.5.1 Where does semi-structured data come from? \\nThe sources of semi-structured data are depicted in Figure 2.17. Characteristics of semi-structured data \\nare summarized below:\\n • It is organized into semantic entities.\\n • Similar entities are grouped together.\\n • Entities in the same group may not have same attributes.\\nFigure 2.16 The blood test report, an example of semi-structured data.\\nABC Healthcare\\nBlood Test Report\\nDate <>\\nDepartment <> Attending Doctor <>\\nPatient Name <> Patient Age <>\\nHemoglobin content <>\\nRBC count <>\\nWBC count <>\\nPlatelet count <>\\nDiagnosis    <notes>\\nConclusion  <notes>\\nFigure 2.17 Sources of semi-structured data.\\nBinary\\nexecutables\\nMark-up languages\\nIntegration of data\\nfrom heterogeneous\\nsources\\nSemi-structured\\ndata\\nEmail\\nXML\\nTCP/IP packets\\nZipped files\\nTypes of Digital Data • 45'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 70}, page_content='46 • Fundamentals of Business Analytics\\n • The order of attributes is not necessarily important.\\n • Not always all attributes are required.\\n • Size of the same attributes in a group may differ.\\n • Type of the same attributes in a group may differ. \\nLet us see with an example how entities can have different set of attributes. The attributes may also have \\ndifferent data types and most certainly can have different sizes. For example, names and emails of dif-\\nferent people can be stored in more than one way as shown below:\\nOne way is:\\nName: Patrick Wood\\nEmail: ptw@dcs.abc.ac.uk, p.wood@ymail.uk\\nAnother way is:\\nFirst name: Mark\\nLast name: Taylor\\nEmail: MarkT@dcs.ymail.ac.uk\\nYet another way is:\\nName: Alex Bourdoo\\nEmail: AlexBourdoo@dcs.ymail.ac.uk\\nIntegration of data from heterogeneous sources (depicted in Figure 2.18) leads to the data being \\nsemi-structured. Because it is likely that data from one source may not have adequate structure while \\nothers may have information which is not required or the required information missing from them.\\nThe problems arising because of the nature of semi-structured data are evident in Dr. Brian’s failure \\nto deliver good healthcare to his patient. The reason behind his failure is that the information he seeks \\nis in the semi-structured format of a blood test report prepared by Dr. Marianne. This could have been \\navoided had adequate semi-structured data management been undertaken by GoodLife.\\nFigure 2.18  Integration of data from heterogeneous sources. Each source (RDBMS, Object Oriented \\nDBMS, Structured file, Legacy system) represents data differently. They may conform to \\n different data models/different schemas.\\nUser\\nMediator: uniform access to multiple data sources\\nRDBMS OODBMS Structured\\nfile\\nLegacy\\nsystem'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 71}, page_content='2.5.2 how to Manage semi-structured data? \\nListed below are few ways in which semi-structured data is managed and stored.\\n • Schemas: These can be used to describe the structure of data. Schemas define the constraints on \\nthe structure, content of the document, etc. The problem with schemas is that requirements are \\never changing and the changes required in data also lead to changes in schema.\\n • Graph-based data models: These can be used to describe data. This is “schema-less” approach \\nand is also known as “self-describing” as data is presented in such a way that it explains itself. \\nThe relationships and hierarchies are represented in the form of a tree-like structure where the \\nvertices contain the object or entity and the leaves contain data.\\n • XML: This is widely used to store and exchange semi-structured data. It allows the user to define \\ntags to store data in hierarchical or nested forms. Schemas in XML are not tightly coupled to \\ndata.\\nThis brings us to the next topic – How to store semi-structured data?\\n2.5.3 how to store semi-structured data? \\nSemi-structured data usually has an irregular and partial structure. Data from a few sources may have \\npartial structure while some may have none at all. The structure of data from some sources is implicit \\nwhich makes it very difficult to interpret relationships between data.\\nIn the case of semi-structured data, schema and data are usually tightly coupled. Same queries may \\nupdate both schema and data with the schema being updated very frequently. Sometimes the distinction \\nbetween schema and data is very vague. For example, in some cases the data from source may contain \\nthe “status”, i.e. married or single as true or false and consider it as a separate attribute. But in some \\nsources it may be an attribute of a larger set or class. These problems complicate the designing of struc-\\nture for the data. Figure 2.19 illustrates the challenges faced in storing semi-structured data.\\nFigure 2.19 Challenges faced in storing semi-structured data.\\nStorage Cost\\nRDBMS\\nIrregular  and\\npartial structure\\nImplicit structure\\nEvolving schemas\\nDistinction between\\nschema and data\\nChallenges faced\\nTypes of Digital Data • 47'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 72}, page_content='48 • Fundamentals of Business Analytics\\nFigure 2.21 Object Exchange Modeling. Nodes are objects; labels on the arcs are attribute names.\\nLabeled directed graphs (from Object Exchange Model)\\nb03\\nauthor author\\nauthor2\\nFirstName\\n“Scott” “Jeff”\\n“Weasel” “http: // ”\\nLastName\\n1997“DBMS”\\nurl\\nauthor1\\ntitle\\nyear\\nThe possible solutions to the challenges faced in storing semi-structured data are indicated in  \\nFigure 2.20.\\n2.5.4 Modeling semi-structured data (the oeM Way) \\nOEM (Object Exchange Model) is a model for storing and exchanging semi-structured data. It struc-\\ntures data in the form of graphs. In OEM, depicted in Figure 2.21, the objects are the entities. The \\nlabels are the attributes and the leaf contains the data. It models the hierarchies, nested structures, etc. \\nIndexing and searching a graph-based data model is easier and quicker as it easy to traverse to the \\ndata.\\nThis brings us to the next question – How do we extract information from this data?\\nFigure 2.20 Possible solutions for storing semi-structured data.\\nPossible solutions\\nSpecial\\npurpose\\nDBMS\\nOEM\\nXML\\nRDBMS\\nXML allows to define tags and attributes to store \\ndata. Data can be stored in a hierarchical/nested \\nstructure\\nSemi-structured data can be stored in a relational \\ndatabase by mapping the data to a relational \\nschema which is then mapped to a table\\nData can be stored and exchanged in the form of\\ngraph where entities are represented as objects \\nwhich are the vertices in a graph\\nDatabases which are specifically designed to \\nstore semi-structured data'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 73}, page_content='2.5.5 how to extract information from semi-structured data? \\nData coming from heterogeneous sources contain different structures (in some cases none at all!). And, \\nit is difficult to tag and index them. The various challenges faced while extracting information from \\nsemi-structured data has been summarized in Figure 2.22.\\nNow that we have the list of challenges before us, how do we overcome these concerns with semi-\\nstructured data? The possible solutions to the challenges are depicted in Figure 2.23 and listed below.\\nFigure 2.22 Challenges faced while extracting information from semi-structured data.\\nHeterogeneous\\nsources\\nIncomplete/\\nirregular\\nstructure\\nChallenges faced\\nFlat files\\nExtracting structure when there is none and\\ninterpreting the relations existing in the \\nstructure which is present is a difficult task\\nSemi-structured is usually stored in flat files \\nwhich are difficult to index and search\\nData comes from varied sources which is \\ndifficult to tag and search\\nFigure 2.23 Possible solutions for extracting information from semi-structured data.\\nXML\\nMining tools\\nPossible solutions\\nIndexing\\nOEM\\nTypes of Digital Data • 49'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 74}, page_content='50 • Fundamentals of Business Analytics\\n • Indexing: Indexing data in a graph-based model enables quick search.\\n • OEM: This data modeling technique allows for the data to be stored in a graph-based data \\nmodel which is easier to index and search.\\n • XML: It allows data to be arranged in a hierarchical or tree-like structure which enables indexing \\nand searching.\\n • Mining tools: Various mining tools are available which search data based on graphs, schemas, \\nstructures, etc.\\n2.5.6 XML: a solution for semi-structured data Management \\nXML (eXtensible Markup Language) is an open source markup language written in plain text. It is inde-\\npendent of hardware and software. It is designed to store and transport data over the Internet. It allows \\ndata to be stored in a hierarchical/nested fashion. In XML, the user can define tags to store data. It also \\nenables separation of content (eX tensible Markup Language) and presentation (eX tensible Stylesheet \\nLanguage). XML is slowly emerging as a solution for semi-structured data management.  Figure 2.24 \\nsummarizes the role of XML in semi-structured data management.\\nXML has no pre-defined tags. The words in the < > (angular brackets) are user-defined tags (Figure \\n2.25). XML is known as self-describing as data can exist without a schema and schema can be added \\nlater. Schema can be described in the XSLT or XML schema.\\nIn brief, the characteristics of XML language are as follows:\\n • XML (eXtensible Markup Language) is slowly emerging as a standard for exchanging data over \\nthe Web.\\n • It enables separation of content (eXtensible Markup Language) and presentation (eXtensible \\nStylesheet Language).\\n • DTD’s (Document Type Descriptors) provide partial schemas for XML documents.\\nFigure 2.24 XML – A solution for semi-structured data management.\\nXML eXtensible Markup Language\\nWhat is XML? Open-source markup language written in plain\\ntext. It is hardware and software independent\\nDoes  what? Designed to store and transport data over the\\nInternet\\nHow?\\nIt allows data to be stored in a hierarchical/\\nnested structure. It allows user to define tags\\nto store the data'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 75}, page_content='Figure 2.25 An example of XML.\\n<library>\\n<book year=“2005”>\\n<title> Database Systems </title>\\n<author> <lastname> Date </lastname> </author>\\n<publisher> Addison-Wesley </publisher>\\n</book>\\n<book year=“2008”>\\n<title> Foundation for Object/Relational Databases </title>\\n<author> <lastname> Date </lastname> </author>\\n<author> <lastname> Darson</lastname> </author>\\n<ISBN> <number> 01-23-456 </number > </ISBN>\\n</book>\\n</library>\\nConsists of attributes Consists of tags\\nConsists of objects Consists of elements\\nAtomic values are the constituents CDATA (characters) are used.\\nSemi-Structured Data XML\\nTable 2.1 Semi-structured data vs. XML\\nThe differences between semi-structured data and XML are highlighted in Table 2.1.\\n2.6  difference betWeen seMi-structured and  \\nstructured data\\nSemi-structured data is the same as structured data with one minor exception: semi-structured data \\nrequires looking at the data itself to determine structure as opposed to structured data that only requires \\nexamining the data element name. Figure 2.26 illustrates the difference between semi-structured and \\nstructured data. Semi-structured data is one processing step away from structured data. From a data \\nmodeler’s point of view, there is no difference between structured and semi-structured data. However, \\nfrom an analyst’s point of view, there is a huge difference because the analyst needs to create the data \\nelement source/target mapping, which is traditionally much more complex with semi-structured data.\\nConsider the following example taken for semi-structured data:\\nname: Patrick Wood\\nemail: ptw@dcs.abc.ac.uk, p.wood@ymail.uk\\nname:\\nfirst name: Mark\\nlast name: Taylor\\nemail: MarkT@dcs.ymail.ac.uk\\nTypes of Digital Data • 51'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 76}, page_content='52 • Fundamentals of Business Analytics\\nname: Alex Bourdoo\\nemail: AlexBourdoo@dcs.ymail.ac.uk\\nThis semi-structured data when stored in the structured format will be in the form of rows and columns \\neach having a defined format as shown in Figure 2.26.\\nFigure 2.26 Difference between semi-structured and structured data.\\nSemi-structured\\nName Email Email Id Alternate\\nEmail Id\\nFirst Name Last Name\\nPatrick Wood\\nfirst name: Mark\\nlast name: Taylor\\nAlex Bourdoo AlexBourdoo@dcs.ymail\\n.ac.uk\\nAlexBourdo\\no@dcs.ymail\\nl.ac.uk\\nMarkT@dcs.ymail.ac.uk MarkT@dcs.\\nymail.ac.uk\\nptw@dcs.abc.ac.uk,\\np.wood@ymail.uk\\np.wood@ymail.ukptw@dcs.ab\\nc.ac.uk\\nStructured\\nPatrick\\nMark\\nAlex Bourdoo\\nTaylor\\nWood\\n\\u2003 Remind\\u2003Me\\n•   Unstructured Data: Data which does not \\nconform to a data model or is not in a form \\nwhich can be used easily by a computer \\nprogram.\\n•   Semi-structured Data: For this data, metadata \\nis available but is not sufficient.\\n • Structured Data: Data which is in an orga-\\nnized form, e.g. in rows and columns or data \\nstored in a database.\\n • Anything that is in a non-database form is \\nunstructured data.\\n • Unstructured data can be classified into \\nBitmap Objects or T extual Objects.\\n • Web pages are said to be unstructured data \\neven though they are defined by the HTML \\nmarkup language, which has a rich structure.\\n • CAS: Content Addressable Storage.\\n • UIMA: Unstructured Information Manage-\\nment Architecture.\\n • UIMA uses analysis engines to analyze the \\nunstructured content to extract implicit \\ninformation. This information is stored in a \\nstructured format.\\n • XML (eXtensible Markup Language) is an \\nopen source markup language and is indepen-\\ndent of hardware and software.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 77}, page_content='\\u2003 Connect\\u2003Me\\u2003(Internet\\u2003Resources)\\nUnstructured Data  • http://www.information-management.com/issues/20030201/6287-1.html\\n • http://www.enterpriseitplanet.com/storage/features/article.\\nphp/11318_3407161_2\\n • http://domino.research.ibm.com/comm/research_projects.nsf/pages/\\nuima.index.html\\n • http://www.research.ibm.com/UIMA/UIMA%20Architecture%20\\nHighlights.html\\nSemi-Structured Data\\n • http://queue.acm.org/detail.cfm?id=1103832\\n • http://www.computerworld.com/s/article/93968/Taming_T ext\\n • http://searchstorage.techtarget.com/generic/0,295582,sid5_\\ngci1334684,00.html\\n • http://searchdatamanagement.techtarget.com/generic/0,295582,sid91_\\ngci1264550,00.html\\n • http://searchdatamanagement.techtarget.com/news/\\narticle/0,289142,sid91_gci1252122,00.html\\nStructured Data\\n • http://www.govtrack.us/articles/20061209data.xpd\\n • http://www.sapdesignguild.org/editions/edition2/sui_content.asp\\n • XML is known as self-describing because data \\nin XML can exist without a schema.\\n • Semi-structured data is the same as struc-\\ntured data with one minor exception: semi-\\n structured data requires looking at the data \\nitself to  determine structure as opposed to \\nstructured data that only requires examining \\nthe data element name.\\nTest\\u2003Me\\u2003Exercises\\nClassify the given data into three categories: Structured, Semi-Structured, and Unstructured\\nHTMLVideo\\nResearch paper Web page Email\\nA zipped file\\nA SQL tableChatsExcel sheet\\nXML An OLTP interface\\nTypes of Digital Data • 53'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 78}, page_content='54 • Fundamentals of Business Analytics\\nSolution:\\nSemi-Structured  \\nVideo HTML An OLTP interface\\nChats XML A SQL table\\nResearch paper Zipped files\\nWeb page Email\\nUnstructured Structured\\nChallenge\\u2003Me\\n1.  What are the biggest sources of unstructured \\ndata in an enterprise?\\n2.  Describe some major challenges associated \\nwith unstructured data?\\n3. What can an enterprise do to tackle the prob-\\nlem of unstructured data?\\n4. What is one key challenge with semi- \\nstructured data?\\n5. Why semi-structured data?\\n6. Should structured data stores be confined to \\ncontain/hold only structured data?\\nSolution:\\n1. Email and file services; both generate a lot of \\ndata. With email, whenever we “Reply to All” \\nand forward messages, the Exchange Server \\nduplicates and proliferate a message many \\ntimes over – often with attachments.\\n2. Volume of data and the continuing tremen-\\ndous growth of data figure among major chal-\\nlenges of unstructured data. Another chal-\\nlenge is to identify the unstructured data in \\norder to manage it. For example, the only way \\nto identify bitmap images, seismic data, audio \\nor video, is by their filename and extension – \\nthere is no way to “look” at the data and know \\nthat a given piece of data comprises an image \\nor other data type. This makes essential man-\\nagement tasks, like data identification, classifi-\\ncation, legal discovery and even basic searches, \\nvery challenging for an enterprise.\\n3. Enterprises need to realize the sheer enormity \\nof unstructured data and the knowledge that \\nlies buried in it. They need to come up with \\npolicies like naming conventions and stan-\\ndards to be followed across the enterprise. This \\nwill bring about some amount of consistency \\nin data. Enterprises need to classify and cat-\\negorize data according to archival, production \\nbased, daily queried data types, etc. and then \\nuse technology to manage unstructured data.\\n4. A schema is one key challenge in the case of \\nsemi-structured data. It is not given in  advance \\n(often implicit in the data). It is descriptive \\nnot prescriptive, partial, rapidly evolving and \\nmay be large (compared to the size of the \\ndata). Also, types are not what they used to be: \\nobjects and attributes are not strongly typed \\nas well as objects in the same collection have \\ndifferent representations.\\n5. Semi-structured data because:\\n a. raw data is often semi-structured.\\n b. convenient for data integration.\\n c. websites are ultimately graphs.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 79}, page_content=' d. rapidly evolving schema of the website.\\n e. schema of website does not enforce typing.\\n f. iterative nature of website construction.\\n6. Enterprises today have 80% of their data in \\nunstructured form and only about 10–20% \\ndata is either semi-structured or structured. \\nInformation from all the data formats is \\n required to acquire knowledge. A lot of work \\nis in progress to make storage and retrieval of \\nunstructured, semi-structured, and structured \\ndata in a single repository possible.\\nBI\\u2003Crossword\\n5\\n4\\n3\\n1\\n2\\n6\\nTypes of Digital Data • 55'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 80}, page_content='56 • Fundamentals of Business Analytics\\nunsoLved eXercises\\n1. Compare and contrast structured, semi-structured, and unstructured data.\\n2. Can semi-structured data be stored as structured data? Explain with the help of an example.\\n3. T race the growth of data in any sector (e.g. manufacturing, retail, etc.) or in an area of your \\ninterest.\\n4. Give an example of data, from your life, that has increased to unmanageable levels and that takes \\nconsiderable amount of your time to manage and store.\\n5. State an instance where inconsistent data formats caused problems in the integration of data.\\n6. Can you think of an instance where you came across data that was stored or presented to you in \\nan unstructured, semi-structured, and structured data format?\\n7. Give an example of data being collected and stored in an unstructured format in your college/\\nuniversity.\\n8. Suggest a way to add some structure to data that is being collected and stored in an unstructured \\nformat in your college/university.\\n9. Say “Yes” or “No”:\\na. Is the receipt given to you at the petrol pump in an unstructured form?\\nb. Is the billing of the items purchased at the supermarket done in a structured form?\\nc. Is the form required to be filled for online reservation of railway tickets semi-structured?\\nd. Did your flight ticket have details in a structured format?\\ne. Is the blog entry you made in a structured form?\\nf. Is the discussion you read in the newsroom in a structured form?\\ng. Is the article you read in the e-newspaper in a semi-structured form?\\n10. Is it important to analyze unstructured data? Explain your answer with an example.\\n11. How can unstructured data be stored in a relational database?\\n12. State two ways in which we can extract information from unstructured data.\\n13. State three ways to store unstructured data.\\nACROSS\\n5. In a relational database, unstructured data \\nmay be stored in _______. (4)\\n6. It organizes files based on their metadata and \\nassigns a unique name to every object stored \\nin it. (25)\\nDOwN\\n1. Enables separation between content and pre-\\nsentation. (24)\\n2. Provides partial schema for XML document. \\n(23)\\n3. This data format uses atomic value for its \\ncharacters. (14)\\n4. A model for storing semi-structured data in \\nthe form of graphs. (19)\\nSolution:\\n1. eXtensible Markup Language\\n2. Document Type Descriptors\\n3. Semi Structured\\n4. Object Exchange Model\\n5. BLOB\\n6. Content Addressable Storage'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 81}, page_content='14. Web pages are said to be unstructured data even though they are defined by the HTML markup \\nlanguage which has a rich structure. Why?\\n15. What is semi-structured data? List three sources of semi-structured data.\\n16. How can one manage semi-structured data?\\n17. Explain OEM (Object Exchange Model) with the help of an example.\\n18. What is XML? Explain with the help of an example.\\n19. What are the sources of structured data?\\n20. How can structured data retrieval be facilitated?\\n21. What can you say about data in an email? Is it structured, semi-structured, or unstructured? Give \\nreasons in support of your answer.\\n22. What can you say about data generated in chat conversations? Is it structured, semi-structured, \\nor unstructured? Give reasons in support of your answer.\\n23. Can XML data be converted into a structured format? Explain with an example.\\n24. You call up a customer care representative to place a complaint about one of their product offer-\\nings. The customer care representative takes down your complaint. What can you say about the \\nformat of data in the complaint?\\n25. Under which category (structured, semi-structured, or unstructured) does a PowerPoint presen-\\ntation fall?\\n26. Under which category (structured, semi-structured, or unstructured) does a text file fall?\\n27. Discuss two best practices for managing the growth of unstructured data.\\n28. What according to you is the impact of unstructured data on backup and recovery?\\n29. Under which category (structured, semi-structured, or unstructured) does a census survey form \\nfall?\\n30. Picture this… A newly opened restaurant wants to collect feedback from its customers on the \\nambience of the restaurant, the quality and quantity of food served, the hospitality of the restau-\\nrant staff, etc. Design an appropriate feedback form for the restaurant and comment on the type \\n(structured, semi-structured, unstructured) of data that will be collected therein.\\nTypes of Digital Data • 57'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 82}, page_content=''),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 83}, page_content='wHAT’S IN STORE\\nWe assume that you are already familiar with commercial database systems. In this chapter, we will try \\nto build on that knowledge to help you understand and differentiate between OLTP (On-Line \\nTransaction Processing) systems and OLAP (On-Line Analytical Processing) systems. In addition, we \\nwill discuss the role of OLAP tools in the BI (data warehousing) architecture and explain why it is not \\nadvisable to perform OLAP on operational databases. We will also enhance your knowledge by a brief \\nexplanation of ERP and how it is different from OLTP .\\nWe suggest you refer to some of the learning resources suggested at the end of this chapter and also \\ncomplete the “T est Me” exercises.\\n3.1 OLTP (ON-LINE TRANSACTION PROCESSING)\\nPicture yourself at a point-of-sale (POS) system in a supermarket store. You have picked a bar of choco-\\nlate and await your chance in the queue for getting it billed. The cashier scans the chocolate bar’s bar \\nBrief Contents\\nWhat’s in Store \\nOltp (On-line transaction processing) \\nOlap (On-line analytical processing) \\nDifferent Olap architectures \\nOltp and Olap \\nData Models for Oltp and Olap \\nRole of Olap tools in the Bi architecture \\nShould Olap be performed Directly on  \\nOperational Databases? \\na peek into the Olap Operations on  \\nMultidimensional Data\\nleveraging ERp Data Using analytics\\nSolved Exercises\\nUnsolved Exercises\\nIntroduction to OLTP  \\nand OLAP\\n3'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 84}, page_content='60 • Fundamentals of Business Analytics\\ncode. Consequent to the scanning of the bar code, some activities take place in the background – the \\ndatabase is accessed; the price and product information is retrieved and displayed on the computer \\nscreen; the cashier feeds in the quantity purchased; the application then computes the total, generates \\nthe bill, and prints it. You pay the cash and leave. The application has just added a record of your pur-\\nchase in its database. This was an On-Line Transaction Processing (OLTP) system designed to support \\non-line transactions and query processing. In other words, the POS of the supermarket store was an \\nOLTP system.\\nOLTP systems refer to a class of systems that manage transaction-oriented applications. These appli-\\ncations are mainly concerned with the entry, storage, and retrieval of data. They are designed to cover \\nmost of the day-to-day operations of an organization such as purchasing, inventory, manufacturing, \\npayroll, accounting, etc. OLTP systems are characterized by a large number of short on-line transac-\\ntions such as INSERT (the above example was a case of insertion wherein a record of final purchase by \\na customer was added to the database), UPDATE (the price of a product has been raised from $10 to \\n$10.5), and DELETE (a product has gone out of demand and therefore the store removes it from the \\nshelf as well as from its database).\\nAlmost all industries today (including airlines, mail-order, supermarkets, banking, insurance, etc.) \\nuse OLTP systems to record transactional data. The data captured by OLTP systems is usually stored in \\ncommercial relational databases. For example, the database of a supermarket store consists of the follow-\\ning tables to store the data about its transactions, products, employees, inventory supplies, etc.:\\n • T ransactions.\\n • ProductMaster.\\n • EmployeeDetails.\\n • InventorySupplies.\\n • Suppliers, etc.\\nLet us look at how data is stored in the ProductMaster table. First, a look at the table structure (also \\ncalled the schema) depicted in Table 3.1. Then we will have a quick look at a few sample records of the \\nProductMaster table listed in Table 3.2.\\n3.1.1 Queries that an OLTP System can Process\\nLet us reconsider our example of the supermarket store POS system, which is an OLTP system. Given \\nbelow are a set of queries that a typical OLTP system is capable of responding to:\\nColumnName Data Type and Length Constraint Description\\nProductID Character, 7 Primary Key It is not null and unique\\nProductName Character, 35 Not Null Name of the product must be specified\\nProductDescription Character, 50 Not Null A brief description of the product\\nUnitPrice Numeric 8,2 The price per unit of the product\\nQtyInStock Numeric 5 The units of the product in stock\\nTable 3.1 Table structure or schema of the ProductMaster table\\nColumn Name  Description'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 85}, page_content='Introduction to OLTP and OLAP • 61\\n • Search for a particular customer’s record.\\n • Retrieve the product description and unit price of a particular product.\\n • Filter all products with a unit price equal to or above $25.\\n • Filter all products supplied by a particular supplier.\\n • Search and display the record of a particular supplier.\\n3.1.2 Advantages of an OLTP System\\n • Simplicity: It is designed typically for use by clerks, cashiers, clients, etc.\\n • Efficiency: It allows its users to read, write, and delete data quickly.\\n • Fast query processing: It responds to user actions immediately and also supports transaction \\nprocessing on demand.\\n3.1.3 Challenges of an OLTP System\\n • Security: An OLTP system requires concurrency control (locking) and recovery mechanisms \\n(logging).\\n • OLTP system data content not suitable for decision making: A typical OLTP system man-\\nages the current data within an enterprise/organization. This current data is far too detailed to \\nbe easily used for decision making.\\n3.1.4 The Queries that OLTP cannot Answer\\nYet again, we go back to our point-of-sale system example. That system helps us perform transactions \\n(such as INSERT , UPDATE, and DELETE) and do simple query processing (locate the record of a \\nparticular customer/product/supplier, etc.). How about using this system to handle some complex que-\\nries like the ones listed below:\\n • The supermarket store is deciding on introducing a new product. The key questions they are \\ndebating are: “Which product should they introduce?” and “Should it be specific to a few cus-\\ntomer segments?”\\n • The supermarket store is looking at offering some discount on their year-end sale. The questions \\nhere are: “How much discount should they offer?” and “Should different discounts be given to \\ndifferent customer segments?”\\nTable 3.2 A few sample records of the ProductMaster table\\nProductName ProductDescription UnitPrice\\nP101 Glucon D Energy Drink 120.50 250\\nP102 Boost Energy Drink 135.00 300\\nP103 Maxwell DVD DVD 45.00 500\\nP104 Poison Perfume 425.00 100\\nP105 Reynolds Pen 15.00 125\\nP106 Maggie Sauce T omato Sauce 54.00 250\\nProductID QtyInStock'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 86}, page_content='62 • Fundamentals of Business Analytics\\n • The supermarket is looking at rewarding its most consistent salesperson. The question here is: \\n“How to zero in on its most consistent salesperson (consistent on several parameters)?”\\nAll the queries stated above have more to do with analysis than simple reporting. Ideally these queries \\nare not meant to be solved by an OLTP system. Let us look at our next topic – OLAP .\\n3.2 OLAP (ON-LINE ANALYTICAL PROCESSING)\\nOLAP differs from traditional databases in the way data is conceptualized and stored. In OLAP data is \\nheld in the dimensional form rather than the relational form. OLAP’s life blood is multi-dimensional \\ndata. OLAP tools are based on the multi-dimensional data model. The multi-dimensional data model \\nviews data in the form of a data cube. Let us get started with dimensional data.\\nWe will use the data of a supermarket store, “AllGoods” store, for the year “2001” as given in Table 3.3. \\nThis data as captured by the OLTP system is under the following column headings: Section, Product-\\nCategoryName, YearQuarter, and SalesAmount. We have a total of 32 records/rows. The Section column \\ncan have one value from amongst “Men”, “Women”, “Kid”, and “Infant”. The ProductCategoryName \\ncolumn can have either the value “Accessories” or the value “Clothing”. The YearQuarter column can \\nhave one value from amongst “Q1”, “Q2”, “Q3”, and “Q4”. The SalesAmount column records the sales \\nfigures for each Section, ProductCategoryName, and YearQuarter.\\n(Continued)\\nTable 3.3 Sample data of “AllGoods” store for the year 2001\\nSection ProductCategoryName YearQuarter SalesAmount\\nMen Accessories Q1 3000.50\\nMen Accessories Q2 1000.50\\nMen Accessories Q3 3500.50\\nMen Accessories Q4 2556.50\\nWomen Accessories Q1 1250.50\\nWomen Accessories Q2 1000.50\\nWomen Accessories Q3 1500.50\\nWomen Accessories Q4 1556.50\\nKid Accessories Q1 1234.50\\nKid Accessories Q2 5678.50\\nKid Accessories Q3 1233.50\\nKid Accessories Q4 1567.50\\nInfant Accessories Q1 1555.50\\nInfant Accessories Q2 2000.50\\nSection SalesAmount'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 87}, page_content='3.2.1 One-Dimensional Data\\nLook at Table 3.4. It displays “AllGoods” store’s sales data by Section, which is one-dimensional data. \\nAlthough Table 3.4 shows data in two dimensions (horizontal and vertical), in OLAP it is considered \\nto be one dimension as we are looking at the SalesAmount from one particular perspective, i.e. by \\nSection ProductCategoryName YearQuarter SalesAmount\\nInfant Accessories Q3 3425.50\\nInfant Accessories Q4 1775.50\\nMen Clothing Q1 2000.50\\nMen Clothing Q2 1230.50\\nMen Clothing Q3 1456.50\\nMen Clothing Q4 3567.50\\nWomen Clothing Q1 4536.50\\nWomen Clothing Q2 2345.50\\nWomen Clothing Q3 3200.50\\nWomen Clothing Q4 1550.50\\nKid Clothing Q1 1000.50\\nKid Clothing Q2 6789.50\\nKid Clothing Q3 8889.50\\nKid Clothing Q4 7676.50\\nInfant Clothing Q1 2345.50\\nInfant Clothing Q2 2000.50\\nInfant Clothing Q3 3456.50\\nInfant Clothing Q4 5564.50\\nTable 3.3 (Continued)\\nSection SalesAmount\\nInfant 22124.00\\nKid 34070.00\\nMen 18313.00\\nWomen 16941.00\\nTable 3.4 One-dimensional data by Section\\nSection SalesAmount\\nIntroduction to OLTP and OLAP • 63'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 88}, page_content='64 • Fundamentals of Business Analytics\\nSection. We may choose to look at the data from a different perspective, say, by \\nProductCategoryName.\\nTable 3.5 presents the sales data of the “AllGoods” stores by ProductCategoryName. This data is \\nagain in one dimension as we are looking at the SalesAmount from one particular perspective, i.e. by \\nProductCategoryName.\\nOne of the most important factors while performing OLAP analysis is time. Table 3.6 presents the \\n“AllGoods” sales data by yet another dimension, i.e. YearQuarter. However, this data is yet another \\nexample of one-dimensional data as we are looking at the SalesAmount from one particular perspective, \\ni.e. by YearQuarter.\\n3.2.2 Two-Dimensional Data\\nSo far it has been good. One-dimensional data was easy. What if, the requirement was to view the com-\\npany’s data by calendar quarters and product categories? Here, two-dimensional data comes into play. \\nTable 3.7 gives you a clear idea of the two-dimensional data. In this table, two dimensions (YearQuarter \\nand ProductCategoryName) have been combined.\\nTable 3.7 T wo-dimensional data by YearQuarter and ProductCategoryName\\nTable 3.5 One-dimensional data by ProductCategoryName\\nAccessories 33837.00\\nClothing 57611.00\\nProductCategoryName SalesAmount\\nTable 3.6 One-dimensional data by YearQuarter\\nQ1 16924.00\\nQ2 22046.00\\nQ3 26663.00\\nQ4 25815.00\\nProductCategoryName SalesAmount\\nColumnName Accessories Clothing Description\\nQ1 7041 9883 16924\\nQ2 9680 12366 22046\\nQ3 9660 17003 26663\\nQ4 7456 18359 25815\\nTotal 33837 57611 91448\\nYearQuarter SalesAmount'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 89}, page_content='The two-dimensional depiction of data allows one the liberty to think about dimensions as a kind \\nof coordinate system. In Table 3.7, data has been plotted along two dimensions as we can now look at \\nthe SalesAmount from two perspectives, i.e. by YearQuarter and ProductCategoryName. The calendar \\nquarters have been listed along the vertical axis and the product categories have been listed across the \\nhorizontal axis. Each unique pair of values of these two dimensions corresponds to a single point of \\nSalesAmount data. For example, the Accessories sales for Q2 add up to $9680.00 whereas the Cloth-\\ning sales for the same quarter total up to $12366.00. Their sales figures correspond to a single point of \\nSalesAmount data, i.e. $22046.\\n3.2.3 Three-Dimensional Data\\nWhat if the company’s analyst wishes to view the data – all of it – along all the three dimensions (Year-\\nQuarter, ProductCategoryName, and Section) and all on the same table at the same time? For this the \\nanalyst needs a three-dimensional view of data as arranged in Table 3.8. In this table, one can now look at \\nthe data by all the three dimensions/perspectives, i.e. Section, ProductCategoryName, YearQuarter. If the \\nanalyst wants to look for the section which recorded maximum Accessories sales in Q2, then by giving a \\nquick glance to Table 3.8, he can conclude that it is the Kid section.\\nTable 3.8 Three-dimensional data by Section, ProductCategoryName, and YearQuarter\\nYearQuarter Men Women Kid Infant\\nAccessories Q1 3000.5 1250.5 1234.5 1555.5 7041\\nQ2 1000.5 1000.5 5678.5 2000.5 9680\\nQ3 3500.5 1500.5 1233.5 3425.5 9660\\nQ4 2556.5 1556.5 1567.5 1775.5 7456\\nClothing Q1 2000.5 4536.5 1000.5 2345.5 9883\\nQ2 1230.5 2345.5 6789.5 2000.5 12366\\nQ3 1456.5 3200.5 8889.5 3456.5 17003\\nQ4 3567.5 1550.5 7676.5 5564.5 18359\\nTotal  18313 16941 34070 22124 91448\\n3.2.4 Should we Go Beyond the Third Dimension?\\nWell, if the question is “Can you go beyond the third dimension?” the answer is YES! If at all there is \\nany constraint, it is because of the limits of your software. But if the question is “Should you go beyond \\nthe third dimension?” we will say it is entirely on what data has been captured by your operational/\\ntransactional systems and what kind of queries you wish your OLAP system to respond to.\\nNow that we understand multi-dimensional data, it is time to look at the functionalities and char-\\nacteristics of an OLAP system. OLAP systems are characterized by a low volume of transactions that \\ninvolve very complex queries. Some typical applications of OLAP are: budgeting, sales forecasting, sales \\nreporting, business process management, etc.\\nProductCategoryName T otal\\nIntroduction to OLTP and OLAP • 65'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 90}, page_content='66 • Fundamentals of Business Analytics\\nExample: Assume a financial analyst reports that the sales by the company have gone up. The next \\nquestion is “Which Section is most responsible for this increase?” The answer to this question is usu-\\nally followed by a barrage of questions such as “Which store in this Section is most responsible for the \\nincrease?”or “Which particular product category or categories registered the maximum increase?” The \\nanswers to these are provided by multidimensional analysis or OLAP .\\n3.2.5 Queries that an OLAP System can Process\\nLet us go back to our example of a company’s (“AllGoods”) sales data viewed along three dimensions: \\nSection, ProductCategoryName, and YearQuarter. Given below are a set of queries, related to our exam-\\nple, that a typical OLAP system is capable of responding to:\\n • What will be the future sales trend for “Accessories” in the “Kid’s” Section?\\n • Given the customers buying pattern, will it be profitable to launch product “XYZ” in the “Kid’s” \\nSection?\\n • What impact will a 5% increase in the price of products have on the customers?\\n3.2.6 Advantages of an OLAP System\\n • Multidimensional data representation.\\n • Consistency of information.\\n • “What if” analysis.\\n • Provides a single platform for all information and business needs – planning, budgeting, fore-\\ncasting, reporting, and analysis.\\n • Fast and interactive ad hoc exploration.\\n3.3 DIFFERENT OLAP ARCHITECTURES\\nDifferent types of OLAP architecture are:\\n • Multidimensional OLAP (MOLAP).\\n • Relational OLAP (ROLAP).\\n • Hybrid OLAP (HOLAP).\\n3.3.1 MOLAP (Multidimensional On-Line Analytical Processing)\\nIn MOLAP , data is stored in a multidimensional cube (Figure 3.1). The storage is in proprietary formats \\nand not in the relational database.\\nFigure 3.1 OLAP cube with Time, Product, and Section dimensions.\\nSection\\nTime\\nProduct'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 91}, page_content='Advantages\\n • Fast data retrieval.\\n • Optimal for slicing and dicing.\\n • Can perform complex calculations. All calculations are pre-generated when the cube is created.\\nDisadvantages\\n • Limited in the amount of data that it can handle. The reason being as all calculations are pre-\\ngenerated when the cube is created, it is not possible to include a large amount of data in the \\ncube itself. The cube, however, can be derived from a large amount of data.\\n • Additional investment in human and capital resources may be required as the cube technology \\nis proprietary and might not exist in the enterprise.\\n3.3.2 ROLAP (Relational On-Line Analytical Processing)\\nIn ROLAP , data is stored in a relational database (Figure 3.2). In essence, each action of slicing and \\ndicing is equivalent to adding a “WHERE” clause in the SQL statement.\\nAdvantages\\n • Can handle large amount of data (limited only by the data size of the underlying database).\\n • Can leverage functionalities inherent in the relational database.\\nDisadvantages\\n • Difficult to perform complex calculations using SQL.\\n • Performance can be slow. As each ROLAP report is essentially an SQL query (or multiple SQL \\nqueries) in the relational database, the query time can be long if the underlying data size is \\nlarge.\\nFigure 3.2 Data stored in relational database (ROLAP).\\nProductID PCategory Qty UnitPrice ($)\\nP101 Nuts 4 10.50\\nP102 Bolts 5 35.50\\nP103 Screws 71 2\\nCustID CustName City\\nC101 Alex NY\\nC102 Fletcher LA\\nC103 Marian NY\\nRDBMS\\nIntroduction to OLTP and OLAP • 67'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 92}, page_content='68 • Fundamentals of Business Analytics\\n3.3.3 HOLAP (Hybrid On-Line Analytical Processing)\\nHOLAP technologies attempt to combine the advantages of MOLAP and ROLAP (Figure 3.3). On the \\none hand, HOLAP leverages the greater scalability of ROLAP . On the other, HOLAP leverages the cube \\ntechnology for faster performance and for summary-type information. However, HOLAP can also “drill \\nthrough” into the underlying relational data from the cube.\\n3.4 OLTP AND OLAP\\nAs depicted in Figure 3.4, OLTP helps in the execution of day-to-day operations (in alignment with the \\nbusiness strategy) of an organization/enterprise. It helps keep record of each and every transaction taking \\nplace on day-to-day basis. The transaction records are stored in commercial relational database systems. \\nData from multiple disparate transactional systems is then brought together in an enterprise data ware-\\nhouse after successful extraction, cleansing (error detection and rectification), and transformation (data \\nconverted from legacy or host format to warehouse format). This data is then used for analysis, for \\nFigure 3.3 HOLAP .\\nRelational database\\nHOLAP User View\\nSection\\nTime\\nProduct\\nFigure 3.4 OLTP vs. OLAP .\\nBusiness process\\nEnterprise data warehouse\\nOLTP\\nOLAP\\nOperations\\nInformation\\nBusiness strategy Master data\\ntransactions\\nData mining\\nanalytics\\nDecision making'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 93}, page_content='unravelling hidden patterns and trends, and for decision-making. The decisions so taken further help \\nbring efficiency in the operations of the organization/enterprise. A comparison of the features of OLTP \\nand OLAP has been given in Table 3.9.\\nTable 3.9 Comparison of features of OLTP and OLAP\\n(Continued)\\nOLTP\\n(On-Line Transaction Processing)\\n \\nFocus Data in Data out\\nSource of data Operational/T ransactional Data Data extracted from various \\noperational data sources, transformed \\nand loaded into the data warehouse\\nPurpose of data Manages (controls and executes) basic \\nbusiness tasks\\nAssists in planning, budgeting, \\nforecasting, and decision making\\nData Contents Current data. Far too detailed – not \\nsuitable for decision making\\nHistorical data. Has support for \\nsummarization and aggregation. Stores \\nand manages data at various levels \\nof granularity, thereby suitable for \\ndecision making\\nInserts and updates Very frequent updates and inserts Periodic updates to refresh the data \\nwarehouse\\nQueries Simple queries, often returning fewer \\nrecords\\nOften complex queries involving \\naggregations\\nProcessing speed Usually returns fast Queries usually take a long time \\n(several hours) to execute and return\\nSpace requirements Relatively small, particularly when \\nhistorical data is either purged or \\narchived\\nComparatively huge because of the \\nexistence of aggregation structures and \\nhistorical data\\nDatabase design Typically normalized tables. \\nOLTP system adopts ER (Entity \\nRelationship) model\\nTypically de-normalized tables; uses \\nStar or Snowflake schema \\nAccess Field level access Typically aggregated access to data of \\nbusiness interest\\nOperations Read/write Mostly read\\nBackup and recovery Regular backups of operational data \\nare mandatory. Requires concurrency \\ncontrol (locking) and recovery \\nmechanisms (logging)\\nInstead of regular backups, data \\nwarehouse is refreshed periodically \\nusing data from operational data \\nsources\\nIndexes Few Many\\nJoins Many Few\\nFeature OLAP\\n(On-Line Analytical Processing)\\nIntroduction to OLTP and OLAP • 69'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 94}, page_content='70 • Fundamentals of Business Analytics\\n3.5 DATA MODELS FOR OLTP AND OLAP\\nAn OLTP system usually adopts an Entity Relationship (ER) model whereas an OLAP system adopts either \\na Star or a Snowflake model. We assume that you are familiar with the ER model. The Star and Snowflake \\nmodels will be covered subsequently in Chapter 7, “Multidimensional Data Modeling”. For now, we will \\nleave you with the ER design and brief introduction of the Star and Snowflake models.\\n3.5.1 Data Model for OLTP\\nFigure 3.5 depicts an Entity Relationship (ER) data model for OLTP . In this model, we have considered \\nthe following three entities:\\n1. Employee (EmployeeID is the primary key).\\n2.  EmployeeAddress (EmployeeID is a foreign key referencing to the EmployeeID attribute of \\nEmployee entity).\\n3.  EmployeePayHistory (EmployeeID is a foreign key referencing to the EmployeeID attribute of \\n Employee entity).\\nWe see the following two relationships:\\n • There is a (1: M cardinality) between Employee and EmployeeAddress entities. This means that \\nan instance of Employee entity can be related with multiple instances of EmployeeAddress entity.\\n • There is also a (1: M cardinality) between Employee and EmployeePayHistory entities. This \\nmeans that an instance of Employee entity can be related with multiple instances of Employee-\\nPayHistory entity.\\n3.5.2 Data Model for OLAP\\nA multidimensional model can exist in the form of a Star schema, a Snowflake schema, or a Fact \\nConstellation/Galaxy schema. We consider here two models – Star and Snowflake. As already stated, \\ndetailed explanation about these models will be given in Chapter 7. Here a brief explanation is provided \\nfor easy comprehension.\\nOLTP\\n(On-Line Transaction Processing)\\n \\nDerived data and aggregates Rare Common\\nData structures Complex Multidimensional\\nFew sample queries  • Search & locate student(s) \\nrecord(s)\\n • Print students scores\\n • Filter records where student(s) \\nhave scored above 90% marks\\n • Which courses have productivity \\nimpact on-the-job?\\n • How much training is needed on \\nfuture technologies for non-linear \\ngrowth in BI?\\n • Why consider investing in DSS \\nexperience lab?\\nFeature OLAP\\n(On-Line Analytical Processing)\\nTable 3.9 (Continued)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 95}, page_content='Just before we explain the Star and the Snowflake models, we need to understand two terms – fact \\nand dimensions. In general, a dimension is a perspective or entity with respect to which an  organization \\nwants to keep records. For example, “AllGoods” store wants to keep records of the store’s sale with \\nrespect to “time”, “product”, “customer”, “employee”. These dimensions allow the store to keep track of \\nthings such as the quarterly sales of products, the customers to whom the products were sold, and the \\nemployees of the store who were involved in materializing the sales. Each of these dimensions may have \\na table associated with it, called the dimension table. A dimension table such as “Product” may have \\nattributes like “ProductName”, “ProductCategory”, and “UnitPrice”. Now let us look at what are facts. \\nFacts are numerical measures/quantities by which we want to analyze relationships between dimensions. \\nExamples of facts are “T otal (sales amount in dollars)”, “Quantity (number of units sold)”, “Discount \\n(amount in dollars of discount offered)”, etc.\\nStar Model\\nFigure 3.6 depicts the Star data model for OLAP . This model has a central fact table which is connected to \\nfour dimensions. Each dimension is represented by only one table and each table has a set of attributes.\\nFigure 3.5 ER data model for OLTP .\\nEmployeeID\\nNationalIDNumber\\nContactID\\nManagerID\\nTitle\\nBirthDate\\nMaritalStatus\\nGender\\nHireDate\\nVacationHours\\nSickLeaveHours\\nModifiedDate\\nEmployeeAddress\\nEmployeeID\\nAddressID\\nModifiedDate\\nEmployeePayHistory\\nEmployeeID\\nRateChangeDate\\nRate\\nPayFrequency\\nModifiedDate\\nEmployee (HumanResources)\\nIntroduction to OLTP and OLAP • 71'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 96}, page_content='72 • Fundamentals of Business Analytics\\nFigure 3.6 Star data model for OLAP .\\nOrderID\\nOrderDate\\nYear\\nQuarter\\nMonth\\nProductID\\nOrderID\\nCustomerD\\nEmployeeID\\nTotal\\nQuantity\\nDiscount\\nCustomerID\\nCustomerName\\nAddress\\nCity\\nZipCode\\nProductID\\nProductName\\nProductCategory\\nUnitPrice\\nEmployeeID\\nEmployeeName\\nTitle\\nDepartment\\nRegion\\nTerritory\\nTime Dimension Product Dimension\\nEmployee Dimension\\nFact Table\\nCustomer Dimension\\nFigure 3.7 Snowflake data model for OLAP .\\nOrderID\\nOrder Date\\nYear\\nQuarter\\nMonth\\nProductID\\nOrderID\\nCustomerID\\nEmployeeID\\nTotal\\nQuantity\\nDiscount\\nCustomerID\\nCustomerName\\nAddress\\nCityID\\nProductID\\nProductName\\nProductCategoryID\\nEmployeeID\\nEmployeeName\\nTitle\\nDepartmentID\\nRegion\\nTerritory\\nTime Dimension Product Dimension\\nEmployee Dimension\\nFact Table\\nCustomer Dimension\\nCityID\\nCityName\\nZipcode\\nState\\nCountry\\nCity Dimension\\nDepartmentID\\nName\\nLocation\\nDepartment\\nDimension\\nProductCategoryID\\nName\\nDescription\\nUnitPrice\\nProductCategory\\nDimension'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 97}, page_content='Snowflake Model\\nIn the Snowflake schema of Figure 3.7, there is a central fact table connected to four dimensions. The \\n“Product” dimension is further normalized to “ProductCategory” dimension. Similarly, the “Employee” \\ndimension is further normalized to the “Department” dimension. By now, you would have guessed that \\nnormalization of the dimension tables definitely helps in reducing redundancy; however, it adversely \\nimpacts the performance as more joins will be needed to execute a query.\\n3.6 ROLE OF OLAP TOOLS IN THE BI ARCHITECTURE\\nThe Business Intelligence (BI) architecture of a typical enterprise has a multitude of applications. Most \\nof these applications execute in silos. More often, these applications will have their own backend data-\\nbases. Refer to Figure 3.8. Data has to be brought/extracted from these multifarious database systems \\nscattered around the enterprise, cleansed (error detection and rectification), transformed (conversion of \\ndata from a legacy or host format to the data warehouse format), and loaded into a common business \\ndata warehouse. The OLAP system then extracts information from the data warehouse and stores it in \\na multidimensional hierarchical database using either a relational OLAP (ROLAP) or multidimensional \\nOLAP (MOLAP). Once the data is safely housed in the cube, users can use OLAP query and reporting \\nFigure 3.8 OLAP in BI.\\nOperational/\\nTransactional\\nDatabase\\nOperational/\\nTransactional\\nDatabase\\nOperational/\\nTransactional\\nDatabase\\nOperational/\\nTransactional\\nDatabase\\nExtract, Transform, & Load\\nBusiness Data Warehouse\\nQuerying Tools\\nReporting Tools\\nOLAP Cube\\nOLAP Access Tools\\nIntroduction to OLTP and OLAP • 73'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 98}, page_content='74 • Fundamentals of Business Analytics\\ntools, analysis tools, and/or data mining tools (e.g. trend analysis, unearthing hidden patterns, alerts, \\npredictions, etc.).\\nAn OLAP system with its adequate tools can help produce Roll-up reports (e.g. if you are view-\\ning the quarterly sales data of your company, you may want to go one level up in the hierarchy and \\nview the annual sales data), Drill-down reports (e.g. if you are viewing the quarterly sales data of your \\ncompany, you may want to go one level down in the hierarchy and view the sales data for months in a \\nparticular quarter), Drill-through reports (e.g. sometimes it may be required to trace back to the data in \\nthe operational relational database system), aggregations, summaries, pivot tables, etc. – all focused on \\nvaried views/perspectives on the data.\\n3.7  SHOULD OLAP BE PERFORMED DIRECTLY ON OPERATIONAL \\nDATABASES?\\nOnce again, if the question is “Can you perform OLAP directly on operational databases?” The \\nanswer is “Yes!” But if the question is “Should you perform OLAP directly on operational  \\ndatabases?” The answer is “No!” Why? This is to ensure the high performance of both the systems. \\nBoth the systems (OLTP and OLAP) are designed for different functionalities. We recommend \\nseparate databases for OLTP and OLAP systems. OLTP queries can run on operational databases \\nwhile the OLAP systems will need a separate data warehouse to be built for then. (Building a data \\nwarehouse will be explained in detail in subsequent chapters. However, for now, you should know \\nthat a data warehouse houses the data extracted from multiple data sources after cleansing and \\ntransformation.)\\nOLTP is to help with the running of the day-to-day operations of an enterprise/organization. It is \\ndesigned to search for particular records using indexing, etc. On the other hand, OLAP systems deal \\nwith the computations of large groups of data at the summarized level. If you perform OLAP queries \\non operational databases, it will severely degrade the performance of operational tasks.\\nOLTP systems support multiple concurrent transactions. Therefore OLTP systems have support \\nfor concurrency control (locking) and recovery mechanisms (logging). An OLAP system, on the other \\nhand, requires mostly a read-only access to data records for summarization and aggregation. If concur-\\nrency control and recovery mechanisms are applied for such OLAP operations, it will severely impact \\nthe throughput of an OLAP system.\\n3.8  A PEEK INTO THE OLAP OPERATIONS ON  \\nMULTIDIMENSIONAL DATA\\nThere are a number of OLAP data cube operations available that allow interactive querying and analy-\\nsis of data. Some common OLAP operations on multidimensional data are:\\n • Slice.\\n • Dice.\\n • Roll-up or Drill-up.\\n • Drill-down.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 99}, page_content=' • Pivot.\\n • Drill-across.\\n • Drill-through.\\nHere is a brief explanation of the above-stated operations.\\n3.8.1 Slice\\nSlicing is filtering/selecting the data using one dimension of the cube. In Figure 3.9, data is sliced/ \\nfiltered along the Section dimension using the criterion Section = “Infant” or Section = “Kid”.\\nSum of SalesAmount ProductCategoryName\\nAccessories Clothing\\n8757 13367 22124\\n9714 24356 34070\\n18471 37723 56194\\nKid\\nGrand Total\\nGrand TotalSection\\nInfant\\nFigure 3.9 Slicing the data on the Section dimension.\\nFigure 3.10 Dicing the data on the YearQuarter, ProductCategoryName, and Section dimensions.\\nProductCategoryNameYearQuarter\\nQ3 Total\\nQ4 Total\\nGrand Total\\nSum of SalesAmount\\nQ3−\\nQ4−\\nSection\\nInfant Grand TotalKid\\nClothing 3456.5 8889.5 12346\\n12346\\n13241\\n13241\\n25587\\n8889.5\\n7676.5\\n7676.5\\n16566\\n3456.5\\n5564.5\\n5564.5\\n9021\\nClothing\\n3.8.2 Dice\\nDicing is also about filtering the data but using two or more dimensions. In Figure 3.10, the data is sliced/\\nfiltered along three dimensions – Section, ProductCategoryName, and YearQuarter. The selection criteria \\nused for these dimensions are: (YearQuarter = “Q3” or YearQuarter = “Q4”), (ProductCategoryName = \\n“Clothing”), and (Section = “Infant” or Section = “Kid”).\\n3.8.3 Roll-Up\\nThe Roll-up operation is also called as Drill-up operation. In roll-up the data is viewed at a higher \\nlevel of hierarchy of a dimension. For example, let us consider the YearQuarter dimension. The hier-\\narchy in the “AllGoods” stores data (Table 3.3) is Year > YearQuarter, i.e. Year is at a higher level than \\nIntroduction to OLTP and OLAP • 75'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 100}, page_content='76 • Fundamentals of Business Analytics\\nYearQuarters. A year has four quarters, i.e. quarter 1 (Q1), quarter 2 (Q2), quarter 3 (Q3), and quar-\\nter 4 (Q4). We can view the data by quarters (at a lower level of hierarchy). If we so desire we can also \\ndrill-up or roll-up and view the data by year (at a higher level of hierarchy).\\nTable 3.10 shows the “AllGoods” stores data along the YearQuarter (Q1, Q2, Q3, and Q4) and  \\nProductCategoryName dimensions. The data of Table 3.10 is shown or rolled-up in Table 3.11 at a \\nhigher level of hierarchy of the YearQuarter dimension.\\nTable 3.11  Sales data of “AllGoods” stores viewed along the ProductCategoryName dimension for the \\nYear 2001 (inclusive of all quarters: Q1, Q2, Q3, and Q4)\\nAccessories 33837.00\\nClothing 57611.00\\nProductCategoryName SalesAmount\\n3.8.4 Drill-Down\\nIn this case, the data is viewed at a lower level of hierarchy of a dimension. In other words, drill-down \\nis the reverse of roll-up. It navigates from less detailed data to more detailed data. In Figure 3.11, the \\ndata is seen at a lower level of hierarchy of the YearQuarter dimension. Here, the total is also viewed by \\nYearQuarter.\\n3.8.5 Pivot\\nPivot is also called Rotate. In order to provide an alternative representation of the data, the pivot opera-\\ntion rotates the data axes in view. Let us again observe Figure 3.11. Here the data is displayed along the \\nYearQuarter and ProductCategoryName axes. In the pivot table (Figure 3.12), the ProductCategoryName \\nand YearQuarter axes are rotated.\\nColumnName Accessories Clothing Description\\nQ1 7041 9883 16924\\nQ2 9680 12366 22046\\nQ3 9660 17003 26663\\nQ4 7456 18359 25815\\nTotal 33837 57611 91448\\nTable 3.10  Data of “AllGoods” stores viewed along the YearQuarter and ProductCategoryName  \\ndimensions\\nYearQuarter SalesAmount'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 101}, page_content='3.8.6 Drill-Across\\nIn drill-across, the data is viewed across two or more fact tables.\\n3.8.7 Drill-Through\\nIn drill-through, the data is traced back to the operational data source usually commercial databases.\\n3.9 LEVERAGING ERP DATA USING ANALYTICS\\nA typical enterprise usually has a chaotic mix of business applications; for example, an application for \\nmanaging the inventory, another for managing the purchases, yet another for managing the manufac-\\nturing, and so on. While a few of them exist in silos, a few others are tied together with the help of \\ncomplex interface programs. Owing to some applications’ existence in silos, there is a huge probability \\nthat the same data may exist at more than one place, raising the question on the accuracy and consis-\\ntency of data. Here is a need for a system that could integrate and automate the business processes from \\nend to end, for example from planning to manufacturing to sales. Enter the ERP software.\\nYearQuarter\\n− Q2\\n− Q1\\n+ Q3\\n+ Q4\\nQ2 Total\\nQ1 Total\\nSum of SalesAmount ProductCategoryName\\nSection\\nInfant 1555.5\\n1234.5\\n3000.5\\n1250.5\\n2000.5\\n5678.5\\n1000.5\\n1000.5\\n9660\\n7456\\n33837\\n9680\\n7041\\n2345.5\\n1000.5\\n2000.5\\n4536.5\\n2000.5\\n6789.5\\n1230.5\\n2345.5\\n17003\\n18359\\n57611\\n12366\\n9883\\n3901\\n2235\\n5001\\n5787\\n4001\\n12468\\n2231\\n3346\\n26663\\n25815\\n91448\\n22046\\n16924\\nKid\\nMen\\nWomen\\nInfant\\nKid\\nMen\\nWomen\\nAccessories Grand Total\\nGrand Total\\nClothing\\nFigure 3.11 Drilling down the data on the YearQuarter dimension.\\n+ + +\\nYearQuarterSum of SalesAmount Section\\nAccessories 1555.5\\n2345.5\\n3901\\n1234.5\\n1000.5\\n2235\\n3000.5\\n2000.5\\n5001\\n1250.5\\n4536.5\\n5787\\n7041\\n9883\\n16924\\n9680\\n12366\\n22046\\n9660\\n17003\\n26663\\n7456\\n18359\\n25815\\n33837\\n57611\\n91448\\nClothing\\nGrand Total\\nGrand TotalQ4Q3Q2Q1 Total\\nProductCategoryName\\n− Q1\\nInfant Kid MenW omen\\nFigure 3.12 Pivot table.\\nIntroduction to OLTP and OLAP • 77'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 102}, page_content='78 • Fundamentals of Business Analytics\\nLet us start by understanding what is an ERP system. ERP (Enterprise Resource Planning) systems \\ntypically automate transaction processes. Here is an example how an ERP system processes a customer’s \\norder through various transaction processes. As depicted in Figure 3.13, a customer places an order. \\nThe finance department checks the credit line for the customer to either accept the customer’s order or \\nreject it depending on whether the customer has outstanding dues against him. The order, if accepted, \\nis passed to the sales department. The sales department checks to find out whether the ordered goods \\nare in stock or, whether the production/manufacturing needs to be informed to fulfil the order. If the \\ngoods are not in stock, the production/manufacturing comes back with a date on which they will be \\nable to ship the order. This way the transaction processes occur to fulfil a customer’s order in an ERP \\nsystem.\\nThough ERP provides several business benefits, here we enumerate the top three:\\n • Consistency and reliability of data across the various units of the organization.\\n • Streamlining the transactional process.\\n • A few basic reports to serve the operational (day-to-day) needs.\\nAn ERP system is able to solve some, if not all, information needs of the organization. It is also able \\nto successfully integrate several business processes across the organization’s supply chain. It is adept at \\ncapturing, storing, and moving the data across the various units smoothly. However, an ERP system is \\ninept at serving the analytical and reporting needs of the organization. Why? Because it has limitations \\nin terms of integrating data from existing applications and data from external sources. This integration \\nof the organization’s internal transactional data with data from existing applications and external data is \\nimperative if it is to serve the analytical and reporting needs of the organization. So, as a solution to the \\nERP system shortcomings emerged BI (Business Intelligence) that can effect the desired data integra-\\ntion and do much more.\\nOur next chapter is on Getting Started with Business Intelligence.\\nFigure 3.13 Customer order processing in an ERP system.\\nFinance Resource\\nManagement\\nManufacturing\\nResource Planning\\nSupply Chain\\nManagement\\nCustomer order\\ninformation\\nOrder\\namount\\ninformation\\nOrder quantity\\ninformation\\nOrder\\ndispatch\\ninformation\\nERP'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 103}, page_content='OLAP http://www.dwreview.com/OLAP/Introduction_OLAP .html\\nData warehousing http://www.dwreview.com/DW_Overview.html\\nhttp://www.dwreview.com/Articles/index.html\\nConnect Me (Internet Resources)\\nRemind Me\\n•   OLTP – Simple queries, often returning fewer \\nrecords.\\n•   OLAP – Often complex queries involving ag-\\ngregations.\\n•   OLTP – Operational/ T ransactional Data.\\n • OLAP – Data extracted from various opera-\\ntional data sources, transformed and loaded \\ninto the data warehouse.\\n • Examples of OLTP – CRM, SCM, ERP , etc.\\n • Examples of OLAP – Data mining, text min-\\ning, Web mining.\\n • ER (Entity Relationship) is the data model \\nfor OLTP systems whereas Star and Snow-\\nflake are the data models for OLAP systems.\\n • Some OLAP operations on multidimensional \\ndata are: Slice, Dice, Roll-up, Drill-down, \\nDrill-through, Drill-across, Pivot/rotate, etc.\\n • OLAP queries on operational databases  \\nseverely degrade the performance of opera-\\ntional tasks.\\n • ERP (Enterprise Resource Planning) typically \\nautomates the transaction processes of the \\n organization.\\n • ERP systems are adept at capturing, storing \\nand moving the data across the various units \\nsmoothly. They are, however, inept at serv-\\ning the analytical and reporting needs of the \\n organization.\\nPoint Me (Books)\\n•    Business Intelligence for Dummies by Swain \\nScheps.\\n•   Data Mining – Concepts and T echniques by \\n Jiawei Han and Micheline Kamber.\\nIntroduction to OLTP and OLAP • 79'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 104}, page_content='80 • Fundamentals of Business Analytics\\nTest Me Exercises\\nArrange the following features into their respective categories: OLTP or OLAP\\nSubject Centric\\nNormalized Storage\\nHistorical Data\\nAd hoc Queries\\nField Level Access\\nComplex Queries \\nFrequent updates & Inserts\\nSolution:\\n \\n1. Complex Queries 1. Field Level Access\\n2. Ad Hoc Queries 2. Frequent Updates and Inserts\\n3. Historical Data 3. Normalized Storage\\n4. Subject Centric\\nOLAP OLTP\\nSolve Me\\n1.  List a few examples of OLTP transactions \\ntaking place in your neighborhood.\\n2.  Give an example where you think that data \\nbeing collected from an OLTP system might/\\nshould be warehoused.\\n3.  List what you think an OLTP system might \\nbe recording for every transaction that you \\nmake at a supermarket store.\\n4.  An XYZ airline maintains a data warehouse \\nstoring all its OLTP transactions with its cus-\\ntomers along with their preferences based on \\ntheir feedback. Think of ways in which this \\ndata can help the airline.\\n5.  Which data is being warehoused in your \\nworkplace/organization and why?\\n6.  Think of how performing data mining on \\nthe data stored in your workplace might be \\nof help to your organization.\\n7.  Suppose X keeps all his bills and payment \\nslips of the various transactions he makes in \\na month. Can this data be of any use to X? \\nWhy and how can it be used?\\n8.  List the various types of data that you have \\narchived or stored in the past.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 105}, page_content=' 9.  Can you derive some meaning and informa-\\ntion from the archived data which will help \\nyou in any way in the future?\\n10.  List the services or sectors where you think \\ndata should be warehoused and data mining \\ncould be used to make predictions.\\nWho am I?\\nThe following are a set of six clues to help you \\nguess me.\\n1. Mostly read-only operations    √\\n2. Current data          X\\n3. Focuses on information out    √\\n4. Database design – ER-based   X\\n5. Summarizations and aggregations √\\n6. Complex query         √\\nSolution:\\nOLAP systems\\nIntroduction to OLTP and OLAP • 81\\nChallenge Me\\nScenario-Based Question\\n1.  Picture an enterprise “XYZ” which is witness-\\ning a mammoth growth in the volume of data. \\nThe enterprise has recognized that the data it \\npossesses is its most valuable resource. The en-\\nterprise had a few OLTP applications running \\nin silos. Just last year, the enterprise purchased \\nan ERP system. The ERP system has solved \\nsome, if not all, information needs of the en-\\nterprise. It is able to successfully integrate sev-\\neral business processes across enterprise’s sup-\\nply chain. It is adept at capturing, storing, and \\nmoving the data across various units smoothly. \\nIt is, however,  inept at serving the analytical \\nand reporting needs of the enterprise.\\nWhy is ERP unable to serve the analytical and \\nreporting needs of the enterprise “XYZ”?\\nSolution: ERP is unable to solve the ana-\\nlytical and reporting needs of the enterprise \\n because it fails to integrate the data from \\nsome of the existing applications and also the \\ndata from some external sources.\\nIndividual Activity\\n2.  Given the pivot table in Figure 3.12, rotate \\nthe data such that you have the Product-\\nCategoryName and Section along the vertical \\naxes and YearQuarter along the horizontal axes.\\nSolution: See Table 3.12.\\nSum of SalesAmount YearQuarter\\nProductCategoryName Section Q1 Q2 Q3 Q4 Grand Total\\nAccessories Total\\nClothing\\nClothing Total\\nGrand Total\\nInfant\\nKid\\nMen\\nWomen\\nInfant\\nKid\\nMen 2000.5\\nWomen 4536.5\\n9883\\n16924\\n1555.5\\n1234.5\\n3000.5\\n1250.5\\n2345.5\\n1000.5\\n7041\\n1230.5\\n2345.5\\n12366\\n22046\\n2000.5\\n5678.5\\n1000.5\\n1000.5\\n2000.5\\n6789.5\\n9680\\n1456.5\\n3200.5\\n17003\\n26663\\n3425.5\\n1233.5\\n3500.5\\n1500.5\\n3456.5\\n8889.5\\n9660\\n3567.5\\n1550.5\\n18359\\n25815\\n1775.5\\n1567.5\\n2556.5\\n1556.5\\n5564.5\\n7676.5\\n7456\\n8255\\n11633\\n57611\\n91448\\n8757\\n9714\\n10058\\n5308\\n13367\\n24356\\n33837\\nAccessories−\\n−\\nTable 3.12  Individual Activity\\n(Continued)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 106}, page_content='82 • Fundamentals of Business Analytics\\n(Continued)\\nTable 3.12 (Continued)\\nSum of SalesAmount YearQuarter\\nProductCategoryName Section Q1 Q2 Q3 Q4 Grand Total\\nAccessories Total\\nClothing\\nClothing Total\\nGrand Total\\nInfant\\nKid\\nMen\\nWomen\\nInfant\\nKid\\nMen 2000.5\\nWomen 4536.5\\n9883\\n16924\\n1555.5\\n1234.5\\n3000.5\\n1250.5\\n2345.5\\n1000.5\\n7041\\n1230.5\\n2345.5\\n12366\\n22046\\n2000.5\\n5678.5\\n1000.5\\n1000.5\\n2000.5\\n6789.5\\n9680\\n1456.5\\n3200.5\\n17003\\n26663\\n3425.5\\n1233.5\\n3500.5\\n1500.5\\n3456.5\\n8889.5\\n9660\\n3567.5\\n1550.5\\n18359\\n25815\\n1775.5\\n1567.5\\n2556.5\\n1556.5\\n5564.5\\n7676.5\\n7456\\n8255\\n11633\\n57611\\n91448\\n8757\\n9714\\n10058\\n5308\\n13367\\n24356\\n33837\\nAccessories−\\n−\\nTeam Activity\\n3. Pair up with a colleague and analyze the sample data in Table 3.13.\\nTable 3.13 A sample data set\\nVehicleID SourceCity DestinationCity YearQuarter\\n101 V111 Mysore Bangalore Q1 1500\\n102 V211 Bangalore Mysore Q1 1500\\n103 V311 Bangalore Mangalore Q1 2500\\n104 V411 Mangalore Bangalore Q1 2575\\n105 V511 Mysore Mangalore Q1 3200\\n106 V611 Mysore Bangalore Q2 1500\\n107 V711 Mysore Bangalore Q2 1500\\n108 V811 Mysore Bangalore Q2 1500\\n109 V911 Mysore Bangalore Q3 1500\\n110 V111 Mysore Bangalore Q3 1500\\n111 V211 Bangalore Mysore Q4 1500\\n112 V311 Bangalore Mysore Q4 1500\\n113 V411 Bangalore Mysore Q4 1500\\n114 V511 Bangalore Mysore Q4 1500\\n115 V611 Bangalore Mysore Q4 1500\\n116 V711 Mangalore Bangalore Q4 2800\\n117 V811 Mangalore Bangalore Q1 2800\\n118 V911 Mangalore Bangalore Q1 2800\\n119 V111 Mangalore Bangalore Q1 2800\\n120 V211 Mangalore Bangalore Q1 2800\\n121 V311 Mysore Bangalore Q1 1600\\n122 V411 Mysore Bangalore Q2 1500\\n123 V511 Mysore Bangalore Q2 1500\\n124 V611 Mysore Bangalore Q2 1600\\n125 V711 Mumbai Pune Q3 2000\\nOrderID AmountCharged'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 107}, page_content='OrderID AmountCharged\\nTable 3.13 (Continued)\\nVehicleID SourceCity DestinationCity YearQuarter\\n126 V811 Pune Mumbai Q3 2000\\n127 V911 Pune Mumbai Q4 2000\\n128 V111 Pune Mumbai Q4 2000\\n129 V211 Pune Mumbai Q4 2000\\n130 V311 Mumbai Pune Q4 2000\\n131 V411 Mumbai Pune Q4 2000\\n132 V511 Mumbai Pune Q4 2000\\nSum of Amountcharged\\nSourceCity DestinationCity V111 V411\\n1500\\n1500\\n2000\\n1500\\n2000\\n2000\\n2000\\n5000\\n2000\\n2000\\n8000\\n1500\\n1500\\n1500\\n1500\\n1500\\n1500\\n1500\\n1500\\n1500\\n1500\\n1500\\n3000\\n3000\\n3000\\n1500 1500\\nV711 Grand Total\\nVehicle ID\\nMysore Bangalore\\nBangalore\\nMumbai\\nMysore Total\\nMysore\\nMysore Total\\nPune\\nPune Total\\nYearQuarter\\nQ1 Total\\nQ2 Total\\nQ4 Total\\nGrand Total\\n+ Q3\\nQ4\\nQ1− −\\n−\\n−\\nQ2−\\n−\\nPerform the following OLAP operations on the \\ndata in Table 3.13:\\n(a) Slice\\n(b) Dice\\n(c) Pivot\\nSolution: We provide below the output of a Dice \\noperation. Here the data has been diced/filtered \\nalong three dimensions: SourceCity, Destinati-\\nonCity, and VehicleID.\\nThe criteria are where (SourceCity = “Mysore” \\nor SourceCity = “Pune”), (DestinationCity = \\n“Bangalore” or DestinationCity = “Mumbai”) \\nand (VehicleID = “V111” or VehicleID = “V411” \\nor VehicleID = “V711”).\\nPerform the Slice and Pivot operations on the \\ndata in Table 3.13.SOLVED EXERCISES\\nProblem: Construct an ER diagram and dimensional model for the following scenario: There is a pub-\\nlishing house which operates from its offices spread across the country. For their convenience, the pub-\\nlishing house classifies the country into four regions (North, South, East, and West). Each of their \\noffices belongs to one of the regions. Several authors are in contract with the publishing house for the \\nIntroduction to OLTP and OLAP • 83\\nOrderID AmountCharged'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 108}, page_content='84 • Fundamentals of Business Analytics\\npublication of their work. An author can be associated with more than one publishing house. An author \\ncan be in contract for publication of one or more of their works (books), either with the same publish-\\ning house or multiple publishing houses. But a particular book by an author can be published by only \\none publishing house. It can also happen that the book has been co-authored.\\nSolution: The steps to create an ER diagram as follows:\\nStep 1: Identify all possible entities\\nThe entities are:\\n • Book.\\n • Author.\\n • Publisher.\\n • Region. \\nStep 2: Identify all the relationships that exist between all the entities\\nRelationships between entities are as follows:\\n •  An author could have written several books. A book could also have been co-authored (more than \\none author for the book).\\nBook AuthorMN\\n •  A publishing house publishes several books. However, a particular book can be published by only \\none publishing house.\\nBook PublisherN1\\n •  A publishing house has several authors in contract with it. An author can have contract with \\nseveral publishing houses.\\nPublisher AuthorMN\\n •  A publishing house has its presence in several regions. Likewise, a region has several publishing \\nhouses.\\nPublisher RegionNM\\nStep 3: Identify the cardinality of the relationships (such as 1:1, 1:M, M:N)\\nThe cardinalities of the relationships are as follows:\\n • M:N from Book to Author.\\n • N:1 from Book to Publisher.\\n • M:N from Publisher to Author.\\n • N:M from Publisher to Region.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 109}, page_content='Book\\nPublisher\\nAuthor\\nRegion\\nN\\n1\\nMN\\nM\\nN\\nN\\nM\\nStep 4: Draw the ER diagram\\nThe dimensional model: Let us look at the Star schema for the above scenario.\\nDim.Book\\nBookId\\nBookTitle\\nNoOfPages\\nISBN\\nEdition\\nYearOfPub\\nDim.Author\\nAuthorId\\nAuthorName\\nAddress\\nState\\nEmailId\\nPhone\\nDim.Publisher\\nPublisherId\\nPublisherName\\nAddress\\nPhone\\nEmailId\\nRegionId\\nRegionId\\nRegionDescription\\nFact Table\\nBookId\\nAuthorId\\nPublisherId\\nRegionId\\nUnitsSold\\nSalesAmount\\nIntroduction to OLTP and OLAP • 85'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 110}, page_content='86 • Fundamentals of Business Analytics\\nUNSOLVED EXERCISES\\n1. How is OLTP different from ERP?\\n2. Should OLAP be performed directly on operational databases?\\n3. How is OLAP different from OLTP?\\n4. Explain the multidimensional data using an example.\\n5. How is MOLAP different from ROLAP?\\n6. State two advantages and two disadvantages of ROLAP .\\n7. Explain with an example the terms “Aggregations” and “Summarizations”.\\n8. What are fact and dimension tables?\\n9. Explain the slice and dice operations on data using an example.\\n10. Explain the drill-through and drill-across operations using an example.\\n11. How is a Snowflake schema different from a Star schema?\\n12. State the difference in data models for OLTP and OLAP .\\n13. Construct an ER diagram for a car insurance company that has a set of customers, each of \\nwhom owns one or more cars. Each car has associated with it zero to any number of recorded \\naccidents.\\n14. Construct an ER diagram to illustrate the working of a bank. Make all the necessary assumptions.\\n15. Picture a retail company that sells a variety of products. The company would like to analyze their \\nsales data by region, by product, by time, and by salesperson. Draw Star and Snowflake schema \\nto depict it.\\n16. Explain the role of OLAP tools in the BI architecture.\\n17. What is a fact constellation?\\n18. What are the challenges faced by an OLTP system?\\n19. Comment on the type of data (structured, semi-structured, or unstructured) that is generated by \\nOLTP system.\\n20. Which system (OLTP/OLAP) has support for concurrency control and recovery and why?\\n21. State a scenario where there is a requirement for an OLAP system.\\n22. State an instance from your daily life where an OLTP system is being used.\\n23. Why OLTP database designs are not generally a good idea for a data warehouse?\\n24. Is it important to have your data warehouse on a different system than your OLTP system?  \\nExplain your answer.\\n25. Compare data warehouse database and OLTP database.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 111}, page_content='What’s in store\\nYou are now familiar with the big picture of a business enterprise and the role of IT in an enterprise. You \\ncan also now distinguish between OLTP and OLAP systems. Let’s get to the heart of the subject matter \\nof this book, viz., analytics that support business decisions. This is also referred to as Business Intelligence.\\nIn this chapter we will familiarize you with the definition of Business Intelligence and the associated \\nterminologies and the evolution of business intelligence technology domain to its current state. We will \\nexplain why businesses choose to leverage analytics for decision making. We will share several examples \\nof industries like retail and hotel and about situations that are very familiar to us. You will be able to \\ncompare and contrast business analytics with ERP and data warehousing.\\nWe suggest you conduct self-research in your area of interest leveraging the information available on \\nthe Internet.\\nBrief Contents\\nWhat’s in Store?\\nUsing Analytical Information for Decision \\nSupport\\nInformation Sources before Dawn of BI?\\nDefinitions and Examples in Business Intel-\\nligence, Data Mining, Analytics, Machine \\nLearning, Data Science\\nLooking at “Data” from Many Perspectives\\nBusiness Intelligence (BI) Defined\\nWhy BI?\\nWhere is BI being used?; When should you \\nuse BI?; What can BI deliver?\\nEvolution of BI and Role of DSS, EIS, MIS, \\nand Digital Dashboards\\nNeed for BI at Virtually all Levels\\nBI for Past, Present, and Future\\nThe BI Value Chain\\nIntroduction to Business Analytics\\nUnsolved Exercises\\nGetting Started with \\nBusiness Intelligence\\n4'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 112}, page_content='88 • Fundamentals of Business Analytics\\n4.1 Using analytical information for Decision sUpport \\nIn the past, leading market research firms noticed that often senior executives in businesses leveraged \\n“numerical information” to support their decisions. They started using the term “Business Intelligence” \\n(BI) for the set of concepts and processes that allows a business executive to make informed decisions. \\nThe IT applications providing such “numerical information” were commonly called “analytical \\n applications” to distinguish them from transaction-oriented applications. The decision making became \\ninformed decision making with the use of BI. What is an “informed decision”? It is a decision based on \\nfact and fact alone. Why is it required to make informed decisions? The simple reason is informed deci-\\nsions based on fact, not on gut feeling, more often than not are the correct decisions. It’s easy to com-\\nmunicate “facts” to the large number of stakeholders. A large dispersed set of decision makers can arrive \\nat the same conclusion when facts are presented and interpreted the same way. This type of decision \\nmaking will lead to business benefits. It will provide insight into the operational efficiencies; it will help \\nexplore untapped opportunities; and above all it will serve as a window to the business dynamics and \\nperformance. It will help provide answers to questions, like “Who are my most profitable customers ?”, \\n“Which are our most profitable products? ”, “Which is the most profitable marketing channel? ”, “What are \\nthe various up-sell and cross-sell opportunities? ”, “Who are my best performing employees?”, “How is my \\ncompany performing in terms of the customer expectations?”, etc.\\nIt’s is true that business executives, operations staff, and planning analysts all made decisions even \\nwhen “Business Intelligence” or Business Analytics were not there. The evolution of BI made decision \\nmaking faster, reliable, consistent, and highly team oriented.\\n4.2 information soUrces Before Da Wn of Bi?\\nDecision makers invest in obtaining the market facts and internal functions such as finance and market-\\ning sales to evolve business plans. Some of the frequently used information sources are as follows:\\n • Marketing research: This analysis helps understand better the marketplace in which the en-\\nterprise in question is operating. It is about understanding the customers, the competitors, the \\nproducts, the changing market dynamics, etc. It is to answer questions such as “Whether the \\nlaunch of product X in region A will be successful or not?”, “Will the customers be receptive to \\nthe launch of product X?”, “Should we discontinue item Z?”, “Where should items A and B be \\nplaced on the shop shelves?”, etc.\\n • Statistical data: This is essentially about unravelling hidden patterns, spotting trends, etc.\\nthrough proven mathematical techniques for understanding raw data. For example, variance in \\nproduction rate, correlation of sales with campaigns, cluster analysis of shopping patterns, etc. \\nhelp decision makers see new opportunities or innovate products or services.\\n • Management reporting: Most enterprises have their own IT teams dedicated to churn out ad \\nhoc reports for the management. Often times they invest in specialized tools to prepare reports \\nin graphical format.\\n • Market survey: Enterprises also employ third-party agencies to conduct consumer surveys and \\ncompetitive analysis. They also use benchmark data to understand their strengths, weaknesses, \\nand specific market opportunities they could exploit as well as risks that might reduce their \\nrevenue or market share.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 113}, page_content='Getting Started with Business Intelligence • 89\\nIn fact, enterprises use one or more of the above methods but in more systematic ways, thanks to the \\navailability of data in digital form and emergence of new delivery channels like the Internet and mobile \\ndevices.\\n4.3  Definitions anD examples in BUsiness  \\nintelligence, Data mining, analytics,  \\nmachine learning, Data science\\n1.  Online Transaction Processing (OLTP): OLTP systems refer to a class of IT applications \\nthat process and manage transaction-oriented digital data coming as inputs to the system and \\nproduce updated databases and management reports for routine decision making. \\n    Example: An invoicing IT application will take inputs such as customer name, shipping ad-\\ndress, products purchased, product price, tax rates and other parameters like date to generate a \\ndatabase (RDBMS Table) of invoices and also provide management a summary report of daily \\nor weekly invoices raised by the company (Figure 4.1).\\n2.  Online Analytics Processing (OLAP): OLAP is the system software used to combine data \\nfrom several IT applications and provide business users with analyzed information to make \\ninformed business decisions. While relational databases are considered to be two-dimensional, \\nOLAP data is multidimensional, meaning the information can be compared in many different \\nways. Thus, OLAP allows business users to easily and selectively extract and view data from \\ndifferent points of view.\\nTOOLS\\nThin client\\nThick client\\nDB\\nSystem services\\nOnline transaction processing (OLTP) system\\nData store\\nBusiness logic\\nPresentation\\nFigure 4.1 A typical OLTP application.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 114}, page_content='90 • Fundamentals of Business Analytics\\n    Example: A sales OLAP application will analyze product sales data from different perspec-\\ntives like sales by product, sales by region, sales by sales person, sales by partners and so on and \\ncompute on-the-fly totals, averages, etc. to support decision making (Figure 4.2).\\n3.  Business Intelligence (BI): BI can be defined as a set of concepts and methodologies to improve \\nthe decision making in businesses through the use of facts and fact-based IT systems. Thus the \\ngoal of BI is improved business decisions. It is more than technologies. It encompasses core con-\\ncepts such as Extract-Transform-Load (ETL), Data Warehousing, Datamarts, Metadata, Metrics \\nand KPIs, Scorecards, Dashboards and OLAP Reporting as well as methodologies specific to ETL, \\nData Warehousing, Master Data Management and Data Governance. BI uses technology tools \\nfor ETL, Data Warehousing, Reporting, OLAP and Dashboards to achieve the decision sup-\\nport goals.\\n    Example: A Human Capital Management data mart will get data from many IT applications \\nholding employee-specific data such as employee profile, payroll, training, compensation, proj-\\nect performance and analyze employee productivity by department, management level, years of \\nexperience, sex and qualification. Such data marts will need ETL and OLAP reporting tools to \\nfunction. Larger data warehouses will store centralized multi-dimensional data for several data \\nmarts.\\n    Data Warehouse is a federated repository for all the data that an enterprise’s various business \\nsystems collect. Typically the historical data of the enterprise is organized by subject areas such \\nas employee, marketing, customer, product and so on. The purpose of creating data warehouse \\nis to guide management in decision making with integrated and summarized facts. Such data \\nwarehouse creation will also need ETL tools, multi-dimensional data storage and OLAP \\nreporting or data mining tools. \\n    Example: An enterprise data warehouse in a bank will hold extracted summarized data taken \\nfrom several OLTP IT applications in subject areas of loans, forex, corporate banking, personal \\nbanking, treasury, etc. Knowledge workers analyze the data in the warehouse from multiple \\nperspectives like time (Day/Week/Month/Year), Bank location, Customer category to make \\nbusiness decisions and stay ahead of competition (Figure 4.3).\\nMarket dimension\\nW.Bengal\\nDelhi\\nMaharashtra\\nChennai\\nQ1 Q2 Q3\\nMulti-dimensional data perspective\\nonline analytical processing (OLAP)\\nQ4\\nOrange\\nApple\\nMango\\nProduct dimension\\nFigure 4.2  Multidimensional data structure.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 115}, page_content='Getting Started with Business Intelligence • 91\\n4.  Data Mining: Data mining is the computational process of sifting through existing business \\ndata to identify new patterns and establish relationships that will help in strategic decision mak-\\ning. This process of data mining will require pre-processing of data by ETL or getting data from \\ndata warehouse as well as post-processing for displaying the new insights found. Data mining \\nuses the following techniques to discover new patterns in data:\\n • Association: looking for patterns where one event is connected to another event.\\n • Sequence analysis: looking for patterns where one event leads to another later event.\\n • Classification: looking for new patterns and groups that could be of business value.\\n • Clustering: finding and visually documenting groups of facts not previously known.\\n •  Forecasting: discovering patterns in data that can lead to reasonable predictions about the \\nfuture business events, conditions, etc.\\n •  Anomaly detection: Finding unusual patterns in data sets.\\n    Example: A data-mining specialist looking at online retail store purchases with buyer demo-\\ngraphic and psychographic data may find new segments of buyers like individuals in old age \\nhomes, patients needing home healthcare services, children in residential schools and custom-\\nize product/service offerings for them (Figure 4.4).\\n5.  Big Data: Big data is a high volume, high velocity, high variety information asset that demands \\ncost-effective and innovative forms of information processing for enhanced business insight \\nand decision making. Hence, big data involves homogeneous voluminous data that could be \\nstructured (as in RDBMS) or unstructured (as in blogs, tweets, Facebook comments, emails) \\nand the content is in different varieties (audio, pictures, large text). Handling this type of data \\nwill need newer and innovative technologies for capturing, storing, searching, integrating, ana-\\nlyzing and presenting newly found insights. \\n    Example: A big data application in telecom industry could be to analyze millions of calls \\ndata, billing data, marketing data, competitive data, carrier usage data, data usage and customer \\nDW\\nSchema\\nData\\nwarehouse\\nMetadata Scheduler ETL\\nBI solutions\\nERP\\nCRM\\nEXT\\nProduction\\nTest\\nDevelopment\\nData warehouse and datamarts in BI solution\\nReformat data\\nFigure 4.3 An enterprise data warehouse.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 116}, page_content='92 • Fundamentals of Business Analytics\\nData refinement needed for data mining\\nData sources\\nData extracts\\nTransformed\\ndata\\nSample\\ndata\\nFilter rules\\nData\\nmining\\nBusiness\\ninsight\\nFigure 4.4 Data mining process: From data to insights.\\nBig data in real-world\\nFigure 4.5 Big data: Data from multiple disparate sources.\\nprofiles to accurately recommend a service that will meet the needs of the customer. In this \\nsituation, the volume and split second response by the big data analytics application is critical \\nto engage the customer on call and close deals (Figure 4.5).\\n6.  Analytics: Analytics is the computational field of examining raw data with the purpose of find-\\ning, drawing conclusions and communicating inferences. Data analytics focuses on inference - \\nthe process of deriving a conclusion based solely on what is already known by the researcher. \\nAnalytics relies on the simultaneous application of statistics, operations research, programming '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 117}, page_content='Getting Started with Business Intelligence • 93\\nto quantify observations. Analytics often uses data visualization techniques to communicate \\ninsight. Enterprises apply analytics to business data to describe (Exploratory analytics), predict \\n(Predictive analytics) and automate to improve business operations (Prescriptive analytics). In-\\ncreasingly, “Business analytics” is used to describe statistical and mathematical data analysis that \\nclusters, segments, scores and predicts what scenarios are most likely to happen in businesses.\\n    Example: HR analytics can be seen as the application of statistical techniques (like factor \\nanalysis, regression and correlation) and the synthesis of multiple sources to create meaning-\\nful insights – say, employee retention in office X of the company is driven by factors Y and Z \\n(Figure 4.6). \\nPredictive\\nmodel(s)\\nHR analytics using predictive modeling\\nNew outcome\\nprediction\\nEmployee\\ndatabase\\nGlobal\\nbenchmark data\\nGroups and behaviors\\nSocial media\\ndata\\nFigure 4.6 Applying analytics to business data to describe, predict and prescribe.\\n7.  Data Science: This is the science of extracting knowledge from data. The aim of data science is \\nagain to bring out hidden patterns amongst datasets using statistical and mathematical modeling \\ntechniques. Data science is an interdisciplinary field (Artificial Intelligence, Algorithms, Pattern \\nrecognition, NLP , Machine learning, Analytics, Computer science, Programming, Data mining, \\nBusiness domain knowledge, etc.) about processes and systems to extract knowledge or insights \\nfrom data. Data scientists use their data and analytical ability to find and interpret rich data sourc-\\nes, manage large amounts of data, combine data sources, ensure datasets quality, create visualiza-\\ntions to communicate understanding of analysis build mathematical models using the data, and \\nenhance specific industry vertical business performance. The data scientist processes more hetero-\\ngeneous, incomplete, messy and unstructured data than the highly curated data of the past. Digi-\\ntized text, audio, and visual content, like sensor and blog data, etc. are the sources. As individuals \\nmay not easily acquire all these competencies, it is generally approached as a team competence.\\n  Example: Data science solution for electricity company could encompass areas such as:\\n • Improve their monitoring and forecasts of energy consumption.\\n • Predict potential power outages and equipment failures.\\n • Drastically reduce their operational costs.\\n • Pinpoint inefficiencies.\\n • Manage energy procurement with greater precision. '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 118}, page_content='94 • Fundamentals of Business Analytics\\n  This will need expertise to leverage smart grid data and model capacity, consumption, losses, \\nand outages and suggest measures for optimum and profitable operations (Figure 4.7).\\nSkills of a data scientist\\nComputer\\nscienceMachine\\nlearning\\nData\\nscience\\nStatistical\\nresearch\\nData\\nprocessing\\nDomain\\nexpertise\\nMathematics\\nFigure 4.7 Data science: Coming together of various skills. \\n8.  Machine Learning: Machine learning is a type of artificial intelligence (AI) that provides com-\\nputers with the ability to learn without being explicitly programmed. Machine learning focuses \\non the development of computer programs that can teach themselves to grow and change when \\nexposed to new data. Machine learning is about building algorithms that build a model out of \\nthe input samples and make data driven decisions. Machine learning leverages concepts like \\ndecision trees, regression, clustering, collaborative filtering, artificial neural networks, inductive \\nlogic programming, support vector machines, etc. to develop algorithms to automate analytical \\nmodel building to solve a particular type of problem. Here, as models are exposed to new data, \\nthey are able to independently adapt. \\n    Example: Online recommendations that we see when you buy a book from online book \\nstore use machine learning. Here the algorithms look for people with similar profile and inter-\\nests and their buying habits to build a model. As and when users buy new books from the store, \\nit applies the filtering and ranking techniques to select high probability buyers. Most often it \\nwill be a very successful recommendation. This is today used for suggesting restaurants, hotel \\nrooms to stay, electronics as well as gifts. Thus, machine learning can promote quick and smart \\nactions without human intervention in real-time (Figure 4.8).\\n9.  Data Lake: A data lake is a storage repository that holds a vast amount of collected raw data \\nin its native format until it is needed for processing. The concept of a data lake is closely tied \\nto Apache Hadoop and its ecosystem of open source projects extensively used in big data ap-\\nplications. Data lakes reduce data integration challenges. The data lake supports the following \\ncapabilities to: \\n • Capture and store raw data at scale for a low cost.\\n • Store many types of data (Structured to unstructured) in the same repository.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 119}, page_content='Getting Started with Business Intelligence • 95\\n• Perform transformations on the data.\\n• Schema on read design rather than schema at write time.\\n•  Allow different communities of users like data scientists to gain access to raw data for their \\nprocessing needs without much latency.\\nIn many enterprises, the EDW (enterprise data warehouse) was created to consolidate information \\nfrom many different sources so that reporting, data mining and analytics could serve decision mak-\\ners. The enterprise data warehouse was designed to create a single version of the truth that could \\nbe used over and over again. \\n4.4 looking at “Data” from many perspectives\\nGlobally, organizations have harnessed the power of “business, science or commerce facts or data” to \\nmake strategic decisions by using information technology. Over the years the data has posed several \\nchallenges such as volume, growth rate, variety of data, storage of data, retrieval of information, process-\\ning of data including complex computation, searching, ordering, merging, protecting, sharing, archival, \\nbackup and restoration. Many tools have been developed to solve these data-related challenges. In this \\nsection let us look at data from several perspectives before we start learning about different technologies \\nand tools associated with data handling. Here are some perspectives to consider:\\n1. Data lifecycle perspective.\\n2. Data storage for processing.\\n3. Data processing and analysis perspective.\\n4. Data from business decision support perspective.\\nTraining set\\nFeature\\nextraction\\nLearning\\nphase\\nClassifier Spammer\\nMachine learning can identify email spam\\nNon-spammer\\nFeature\\nextraction\\nTest set\\nClassifier\\nFigure 4.8 Machine learning: AI in action.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 120}, page_content='96 • Fundamentals of Business Analytics\\n5. Data quality management aspects.\\n6. Related technology influences of data. \\nEach of these perspectives will help you understand the current state-of-the-industry and appreciate the \\ndifferent data technologies and management trends.\\n4.4.1 Data lifecycle perspective\\nThe data lifecycle stretches through multiple phases as data is created, used, shared, updated, stored and \\neventually either archived or disposed. Every business whether it is a bank, utility company, airline, \\ntelecom carrier, hotel or hospital will be generating business data each second. Picture these typical \\ntransactions we do that the businesses have to remember:\\n1. Withdrawal of cash in an ATM\\n2. Pay our electricity bill online\\n3. Cancel an airline ticket\\n4. Change the postpaid mobile phone plan\\n5. Check-in into a hotel\\n6. Download music from online store\\n7. Request for a lab test in a hospital\\n8. Shopping check-out at a retail store and payment\\n9. Post a comment in Facebook\\nThe data could be viewed from a lifecycle perspective going through phases such as creation, storage, \\nbackup, processing like computation, share, update, archive and dispose (rarely). \\nOne thing that will occur to us immediately is about the type of the data we deal with. The data in \\nthe current day context can be of different types or variety like numeric data, alphanumeric text, long \\ntext, date, currency, picture, audio segment, video clip, news feed, survey response, machine generated \\ndata (location) and so on. Modern data management is about handling the entire data lifecycle. That is \\neverything that happens to a piece of data from the moment it is created to the moment it is destroyed. \\nData management involves several activities like planning, collecting, assuring, describing, preserv-\\ning, searching, integrating, securing, analyzing, formatting, sharing and archival. \\nWe have witnessed six distinct phases in data management. \\nPhase I: Initially, data was processed manually including recording computing, reporting. \\nPhase II: This phase used punched-card equipment and electro-mechanical machines to sort and tabu-\\nlate millions of records. \\nPhase III: The third phase was the age of stored data on magnetic tapes or disks and used computers to \\nperform batch processing on sequential files.\\nPhase IV: The fourth phase introduced the concept of a Relational Database Management Systems \\n(RDBMS) with a database schema and online access to the stored data. \\nPhase V: This phase automated access to relational databases and added distributed and client-server \\nprocessing. \\nPhase VI: We are now in the early stages of sixth generation systems that store richer data types, such as \\ncomplex eBooks, images, voice and video data. '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 121}, page_content='Getting Started with Business Intelligence • 97\\n4.4.2 Data storage (raw) for processing\\nWe all agree that we need to store data for processing or back-up or archiving for later use. We need to \\nunderstand the TYPES of data that need to be stored as well as VOLUME. Let us look at the data explo-\\nsion we are witnessing in the era of Internet.\\nAccording to the 2014 EMC/IDC Digital Universe report, data is doubling in size every two \\nyears. In 2013, more than 4.4 zeta bytes of data had been created; by 2020, the report predicts \\nthat number will explode by a factor of 10 to 44 zeta bytes - 44 trillion gigabytes. The report \\nalso notes that people - consumers and workers - created some two-thirds of 2013’s data; in the \\nnext decade, more data will be created by things - sensors and embedded devices. In the report, \\nIDC estimates that the IoT had nearly 200 billion connected devices in 2013 and predicts that \\nnumber will grow 50% by 2020 as more devices are connected to the Internet - smartphones, \\ncars, sensor networks, sports tracking monitors and more. \\nWe could look at the data storage from the user angle as well. We as individuals need to store data - \\ndocuments we author, slides we prepare, spreadsheets we model, audio files we record/collect, videos we \\nuse, images we like and so on as well as keep a backup. We use hard disks, USB, cloud storage as per-\\nsonal data stores.\\nWhen it comes to a team working in a business office, they rely on network servers, public cloud, \\nprivate cloud for storage at a function or department level. When it comes to enterprise level, there will \\nbe a huge storage facility on the network as well as cloud along with sophisticated backup, restore and \\narchival facilities running to several terabytes or petabytes. Typically enterprises store critical data across \\nmultiple external storage systems. Many are using virtualized storage systems with automatic provision-\\ning. Enterprises implement storage groups in order to plan, deploy, operate and administer storage \\nsystems. Storage technology segments today include Storage Area Networks (SAN), Backup-recovery-\\narchival systems, remote replication, storage virtualization, cloud storage and local replication.\\nSome of the critical activities enterprises take-up to reliably store data include:\\n1. Managing data storage growth by increasing capacity.\\n2. Designing and implementing disaster recovery processes.\\n3. Deploying virtual storage environment.\\n4. Consolidating servers.\\n5. Implementing data archival solutions.\\n6. Moving data to cloud.\\nEnterprises consider availability, capacity, reliability, price-performance, power consumption (eco-\\nfriendly) and noise while deploying enterprise storage solutions. The applications used in the enterprise \\ndetermine the user access performance needs. Figure 4.9 gives a snapshot of the applications demanding \\nstorage performance in a modern-day enterprise.\\n4.4.3 Data processing and analysis perspective\\nLet us now look at the computing platforms that the businesses have used to extract meaningful infor-\\nmation from data. Here also we can see several generations of computer hardware used for data process-\\ning starting with the mainframe computers, mini computers (IBM AS400), then client-server based \\nopen computing systems using Unix operating system, personal computers, laptops and at present '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 122}, page_content='98 • Fundamentals of Business Analytics\\nsmartphones and tablets. While laptops, PCs, smartphones and tablets are used for personal computing, \\nnetworked PCs, Internet connected smart devices can access even enterprise applications. Enterprises \\nthat serve thousands to millions of users tend to run large-scale applications on data center computers. \\nThe next extension of such computing is the cloud computing. The IT applications that run in enter-\\nprises could be classified as in Figure 4.10.\\nOLTP systems refer to a class of IT applications that process and manage transaction-oriented digital \\ndata coming as inputs to the system and produce updated databases and management reports for rou-\\ntine decision making. OLTP applications use RDBMS (such as Oracle, SQL Server, and DB2) as the \\nmain system for application data management. RDBMS provides SQL language interface for extract-\\ning, updating and combining data from different sources.\\nData Analysis T echnologies\\nEnterprises have discovered the value of “Data” as one of the key corporate assets. IT product companies \\nhave continuously invented solutions to address data handling problems in areas of volume, structure, \\ncomputation capabilities, data integration, data analysis using statistical principles, ad-hoc querying, \\ndata replication, data security, discovering new patterns of data, using data to create self-learning models \\nand so on. Let us look at these technological developments that have influenced the use of historical \\ndata for smart decision making across all levels in enterprises.\\n1.  Spreadsheets: Spreadsheets represent the use of software from PCs to tablets for manipulation \\nof data using the structure of rows and columns. This digital document helps in numerical data \\nentry, computation, sorting, searching, aggregating, perform statistical analysis, graph datasets \\nand even create basic data mining tasks. MS Excel is an example of spreadsheet.\\nLong-tail content\\nstorage\\nCold storage\\nArchiving\\nCapacity\\nBig data storage\\nSocial\\nnetworks\\nCloud storage (objects)Cloud computing\\n/Virtualized\\nserver\\nCloud gaming\\nContent serving\\nDatabase\\n/OLTP\\nPerformance\\nUser\\ndatabases\\nBig data\\nanalytics\\nHF trading\\nFigure 4.9 Various Data Storage: Their capacity and performance.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 123}, page_content='Getting Started with Business Intelligence • 99\\n2.  Ad-hoc Query Tools: In any enterprise not all decision makers are satisfied with standard \\nreports. They do not want to wait too long for the IT function to extract data from multiple \\nsources and prepare a new report to their specification. Ad-hoc query tools allow extracting \\ndata from several RDBMS and other types of files and extract needed information as and when \\nrequired. Crystal reports, BIRT , etc. are some examples of ad-hoc query tool.\\n3.  ETL Tools: Extract-T ransform-Load (ETL) is the process of combining selected data from \\nmultiple forces, re-format them and create a new database or a data warehouse. They support \\na library of standard transformations needed to handle different data types and even automate \\ndata transformation. Informatica is an example of such ETL tool.\\n4.  Business Intelligence (BI) and Reporting Tools: When the enterprise creates data marts and \\ndata warehouses, the users will need sophisticated reporting tools that can show insights us-\\ning scorecards, dashboards, pivot charts, etc. BI reporting tools allow end users to leverage the \\npower of data warehouse by building role-specific visualizations. It is important to note that \\nmany of these tools support mobile devices like smartphones and tablets and alert users when-\\never there is a threshold breach. \\n5.  Data Mining Tools: Data mining is the computational process of sifting through existing busi-\\nness data to identify new patterns and establish relationships that will help in strategic decision \\nmaking. Such tools use principles of association, classification and clustering of data to discover \\nnew patterns. SAS miner is an example of data mining tool.\\n6.  Big Data Analytics Tools: According to the Gartner IT Glossary, Big Data is high-volume, \\nhigh-velocity and high-variety information asset that demands cost-effective, innovative forms \\nTotal quality management\\nFunctional enhancement\\nGeneral ledger\\nDisaster recovery\\nDominant\\nLow\\nHigh\\nOccasional Seldom\\nUtility\\nCost focus Productivity focus Opportunity focus\\nEnhancement Frontler\\nNew services\\nBusiness process re-engineering\\nEnhanced data access\\nGraphic user interface\\nOnline transaction\\nprocessing\\nUtility functions\\nUser empowerment\\nProcess redesign\\nFigure 4.10 Classification of IT applications of an enterprise.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 124}, page_content='100 • Fundamentals of Business Analytics\\nof information processing for enhanced insight and decision making. Volume refers to the \\namount of data. Many factors contribute to high volume: sensor and machine-generated data, \\nnetworks, social media and much more. Enterprises are awash with terabytes and, increasingly, \\npetabytes of big data. Variety refers to the number of types of data. Big data extends beyond \\nstructured data such as numbers, dates and strings to include unstructured data such as text, \\nvideo, audio, click streams, 3D data and log files. Velocity refers to the speed of data processing. \\nThe pace at which data streams in from sources such as mobile devices, clickstreams, high- \\nfrequency stock trading, and machine-to-machine processes is massive and continuously fast \\nmoving. Big data mining and analytics help uncover hidden data patterns, unknown correlations \\nand other useful business information. However, big data tools can analyze high-volume, high-\\nvelocity and high-variety information assets far better than conventional tools than RDBMS \\nwithin a reasonable response time. R, Weka, Talend, Pentaho, BIRT/Actuate, Rapid miner, \\nHive, Mahout are some examples of big data analytics tools.\\n4.4.4 Data from Business Decision support perspective\\nIn most businesses, data moves from function to function to support business decision making at all \\nlevels of the enterprise. The age of the data and its value is highly related; data has the highest value as \\nsoon as it is created. But considering the challenges like big data, distributed storage, parallel processing, \\nthe trend is to find business value while the data is still in computer memory. This concept is evolving \\nin the form of in-memory databases and stream processing.\\nWe also need to see adding context and aggregation refines data progressively. Here is the value of \\nrefining data to move up in the value chain. \\nThe true potential of data is realized through business results. While computer systems are capable of \\ndelivering both data and refined data or information to end users, they need to apply that information \\nto take actions. Data mining can produce new knowledge about employee attrition, new market seg-\\nments that can be targeted expanding the enterprise knowledge. For example, increasing cross-channel \\nsales which is a business value, requires data about your current customers and the products they own.\\nWe can take the value process to the next level using applied analytics. Here we use data mining \\nas well as concepts of analytics like forecasting, predicting and even prescribing best action in a given \\nbusiness context. In this situation decision makers are influencing their future business performance \\nby leveraging analytics. Analytics will also help in building enterprise smart decision framework based \\non very large datasets and high speed processing like Hadoop and MapReduce in big data processing.\\nThe fast data segment of the enterprise addresses a number of critical requirements, which include \\nthe ability to ingest and interact with the data feed, make decisions on each event in the feed, and apply \\nreal-time analytics to provide visibility into fast streams of incoming data. \\nAnother way to look at the value of information is shown in Figure 4.11.\\nFirst, let us look at the left-hand side of the figure. We can infer that all enterprises care about some \\nentities or objects about which they would like to capture data to support business decisions. This is \\ninformation/knowledge they have. While running business transactions, data gets generated and this \\n“data” is stored in computer systems. Now we move to the right-hand side of the figure. This digital data \\ncould be shared with decision makers directly or aggregated, analyzed and interpreted by different roles \\nin the enterprise. This processed data in general can be termed information useful for decision making. \\nThere can be various subject areas (as used in data warehousing terminology) of this “Information” and \\ndifferent consumers of such information. '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 125}, page_content='Getting Started with Business Intelligence • 101\\nWhatever be the “Processing” or “Analysis” we perform on the stored data (real-time to historical \\ndata), decision makers will find use for this. Hence analytics is termed as “The oil of the 21st century”.\\n4.4.5 Data Quality management aspects\\nThe quality of the data has total impact on the “Findings” from the data set and has a huge potential to \\nmisguide decision makers if the quality of the data is poor. Enterprises spend significant money to track \\nand correct the quality of the data generated at different sources, departments, purchased, imported \\nfrom other external sources.\\nLet us look at some of the common data problems or causes of poor data in companies.\\n1.  Typographical errors: Often times the names, descriptions, etc. manually entered into com-\\nputers may have typographical errors or be misspelled.\\n2.  Duplicates: There could duplicate records occurring that have the same information. Such du-\\nplicates will pose problems when columns with numeric information such as invoice amount, \\nsalary, etc. are totaled generating erroneous totals. RDBMS can automatically check such errors \\nif set-up properly.\\n3.  Wrong codes: Sometimes company may have given codes to entities like Employees, Items, etc. \\nand that could be entered wrongly into computer systems. Such records will be hard to trace.\\n4.  Missing fields or records: Data for some of the columns may be missing or not entered at all. \\nRDBMS avoids such problems by making data fields mandatory. Sometimes an entire entry \\ncould have been missed in the file system.\\n5.  Computed using incorrect formulae: Sometimes incorrect formulae may have been entered \\ninto worksheets that are used for data capture. \\n6.  Non-conformance entries: It is always possible to enter numeric data into an alphanumeric \\ncolumn type. If such errors have occurred during data merge or bulk transfer, they may go \\nundetected.\\n7.  Data accuracy: It is possible that during data capture one may enter numeric data, say, with \\n2 decimal places but while storing the system may just store as integer. We lose the accuracy/\\nprecision during such errors.\\n8.  Data correctness: When you have several numeric fields or alphanumeric fields defined in a \\nsequence and data is shifted by one column, you can see the problems it can create.\\n9.  Un-updated data: Some of the data sources could have become obsolete and data may not be \\ncurrent. Taking data from obsolete sources will provide wrong business picture to users.\\nAge of data\\nData value\\nValue of individual\\ndata item\\nAggregate\\ndata value\\nData value chain\\nFigure 4.11 Age of data vs. its value.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 126}, page_content='102 • Fundamentals of Business Analytics\\n10.  Swapped fields: Data like first name, last name could have got interchanged while processing \\nand can result in mismatches.\\n11.  Varying default values: System generated defaults for some columns pose data analysis challenges.\\nIn order to control the quality of your analysis and output results, you will need to make thorough \\nchecks on the data set. While it may not be possible to check for errors in billions of records, you will \\nneed robust data quality management processes. Some of the attributes of data quality are:\\n1. Relevance: Data meet the needs of users at different levels.\\n2. Accuracy: Data values obtained are close to the true values.\\n3. Credibility: Users have confidence in the statistics and trust the objectivity of the data.\\n4. Accessibility: Data can be readily located and accessed by authorized users using tools.\\n5. Validity: It refers to the correctness and reasonableness of data.\\n6.  Integrity: What data is missing important relationship linkages? The inability to link related \\nrecords together may actually introduce duplication across your systems.\\n7.  Interpretability: Users can readily understand, use and analyze the data as well as describe the \\nlimitations of the data set.\\n8.  Coherence: Statistical definitions and methods are consistent and any variations in methodol-\\nogy that might affect data values are made clear.\\n9.  Timeliness: Delays between data collection and availability are minimized, without compro-\\nmising accuracy and reliability.\\n10.  Periodicity: Vital statistics are shared regularly so that they serve the ongoing needs of policy-\\nmakers for up-to-date information.\\n11.  Confidentiality: Data-management practices are aligned with established confidentiality stan-\\ndards for data storage, backup, transfer and retrieval.\\nIt is very important to assess the quality of the data before taking up data analysis work as it may be \\nfollowing in GIGO paradigm (Garbage-In-Garbage-Out).\\nThe quality, reliability, security and usability of enterprise data dictate the business performance goals \\nof the organization in driving new business opportunities, enhancing customer base, managing risk and \\ncompliance, generating smart decision support models, and reducing operating costs. The practice used \\nto achieve these results is termed as “Data Governance”.\\nThe scope of data governance covers areas like:\\n1. Defining data policies related to creation, storage, security, transmission, sharing, etc.\\n2. Communication of data policies with IT and business functions.\\n3. Be the central agency for managing data requirements for all key functions.\\n4. Documentation structural data standards.\\n5. Development of unified standard data models for persistence and sharing.\\n6. Active monitoring of data policy applications to data expectations.\\n7. Assessing the requirements from across the line of business landscape. \\n8. Driving information security at all levels of the enterprise.\\n9. Single agency for selection of data management tools in the enterprise.\\n10. Data architecture formulation, regulatory compliance and audits.\\n11. Promote the value of enterprise data assets.\\n12. Data risks management.\\n13. Metadata and business glossary management.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 127}, page_content='Getting Started with Business Intelligence • 103\\n4.4.6 related technology influences of Data\\nLet us focus our attention on some of the technologies that are closely associated with data technologies \\nand the synergy is creating a larger business impact. These include social media, cloud and mobility. \\nSome of the key technology trends of 2015 for these technologies are indicated here. \\nT rends shaping data landscape include:\\n1.  Data Democratization: Knowledge workers at all levels in the enterprise will have access to the \\ninformation they need to perform their roles.\\n2.  Internet of Things (IoT): More and more sensors will be capturing data at its source and huge \\namounts of data will be available for the enterprise to make use of.\\n3.  Algorithmic Decision Making: Enterprises will code the “Learning algorithms” with patterns \\nof decision making and automate decision making in several areas.\\n4.  Unstructured and Real-time Data: Enterprises tend to focus on near real-time data with \\ntechnologies for in-memory processing for reducing the latency of information availability for \\ndecision-making. Globally, enterprises are looking at social media analytics and real-time ana-\\nlytics for gaining competitive advantage in the marketplace. \\n5.  NOSQL Adoption Will Increase: Enterprises do not want to focus on the structure of the \\ndata to be predefined as schema but would like to interpret data at runtime and store data \\nwithout predefined structure.\\n6.  Increasing Cloud Storage: Enterprises will be using cloud for data integration and sharing to \\nfacilitate real-time analytics.\\n7.  Data Architecture and Data Lakes: Enterprises will dedicate teams to build reliable data plat-\\nforms and data lakes will be built to address analytics needs.\\nSome of the social media trends include:\\n1.  In-the-moment-updates: Enterprises will support near real-time updates about the areas of \\ninterest for the user groups or live streaming. \\n2.  Visual Search: Facilities to search content visually and with context will increase. Rich media \\nand cross social media platforms through integration will also increase.\\n3.  Enhanced Mobile Commerce: Social media aps will allow more In-app interaction features \\nincluding purchase. \\n4.  Data privacy Challenges: Users will witness more challenges with regard to their personal data \\nand security threats.\\n5.  Growing Importance of Content: Social connections will leverage the interaction platform for \\nexchanging content of common interest.\\nSome of the cloud computing trends include:\\n1.  Hybrid Cloud Environments: Enterprises will use combination of public and private clouds \\nto reduce costs, support mobile workforce securely.\\n2.  Cloud-based Decision Frameworks: With data integration and real-time data coming to cloud, \\nmany decision-making frameworks for connected users are likely to happen in cloud platforms.\\n3.  Cloud Service Brokers: It is likely that agencies will be the intermediaries who will negotiate \\nthe services quality delivered by cloud service providers.\\n4.  Applications Design Alignment: Enterprises will align many applications to cloud environ-\\nments to realize benefits of cloud.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 128}, page_content='104 • Fundamentals of Business Analytics\\nSome of the mobility trends include:\\n1.  Mobile-first Applications: Enterprises will develop mobile apps that will exploit the core \\ncapabilities of the mobile devices and sensors. \\n2.  Powerful Work-life Integrations: Applications will provide smooth handoff to multiple \\ndevices to enable users working on multiple devices to complete tasks.\\n3.  Mobile Security: Enterprises continue to focus on security considerations of mobile centric \\napplications to ensure no data assets are lost to hackers.\\n4.5 BUsiness intelligence (Bi) DefineD\\nHoward Dresner, of the Gartner Group, in 1989 coined the term BI. He defined BI as “a set of concepts \\nand methodologies to improve decision making in business through use of facts and fact-based \\nsystems.” Let us take a while to understand the terms used in the definition:\\n • The goal of BI is improved decision making. Yes, decisions were made earlier too (without BI). \\nThe use of BI should lead to improved decision making.\\n • BI is more than just technologies. It is a group of concepts and methodologies.\\n • It is fact-based. Decisions are no longer made on gut feeling or purely on hunch. They have to \\nbe backed by facts.\\nBI uses a set of processes, technologies, and tools (such as Informatica/IBM Datastage/Ab initio \\nfor extracting the data, SAS/IBM SPSS for analyzing the data, and IBM Cognos/Business Object for \\nreporting the data) to transform raw data into meaningful information. BI mines the information to \\nprovide knowledge (KDD – Knowledge Discovery from Data) and uses the knowledge gained to pro-\\nvide beneficial insights; the insights then lead to impactful decision making which in turn provides busi-\\nness benefits such as increased profitability, increased productivity, reduced costs, improved operations, \\netc. The transformation of raw data to business benefits through BI may be depicted as\\n Raw Data ã Meaningful Information ã Knowledge Discovery ã Beneficial Insights ã \\nImpactful Decisions ã Business Benefits\\nIn short, Business Intelligence is about providing the right information in the right format to the \\nright decision makers at the right time. Some important features of Business Intelligence have been \\ndescribed below:\\n • Fact-based decision making: Decisions made through Business Intelligence are based purely on \\nfact and history. It is about staying in tune with the data flowing through your business systems.\\nRefer to the case study brief on “GoodFood Restaurants Inc.”. Let us try to understand fact-\\nbased decision making using the example of our “GoodFood” restaurant. Every restaurant will \\nreport the quantity of food wasted across the globe within six hours from the closing hour of \\nrestaurant. This data is aggregated and shared among all chefs, back office staff, operations man-\\nager, and marketing campaign teams. A team analyzes reasons and spot drivers of variance and \\nset target to reduce wastage week-by-week. The same team tracks data and initiates actions to \\ncorrect the process to reduce waste and achieve set target.\\n • Single version of truth: Put simply, a single version of truth means that if the same piece of \\ndata is available at more than one place, all the copies of the data should agree wholly and in \\nevery respect. BI helps provide single version of truth.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 129}, page_content='Getting Started with Business Intelligence • 105\\nIn our above example of the restaurant, picture a customer walking into the restaurant a little \\nlate for lunch. He asks at the reception about the availability of a particular cuisine (say, Thai \\ncuisine) at the buffet lunch. The receptionist confirms the availability after checking on the \\nnetworked computer system, and the customer proceeds to the dining area. On the way, the \\ncustomer comes across the head waiter and asks the same question. The head waiter too confirms \\nthe availability, checking on his PDA (Personal Digital Assistant). This is the “single version of \\ntruth” wherein the same piece of information shared by multiple persons (the receptionist and \\nthe head waiter in our case) agrees wholly and in every respect.\\n • 360 degree perspective on your business: BI allows looking at the business from various per-\\nspectives. Each person in the project/program team will look at the data from his/her role and \\nwill look for attributes that add value for decision making in his/her role.\\nIn the GoodFood example, a “reservation table number” helps the steward escort guests to the \\nright place in the dining area, helps the chef visit the guests to describe the “day’s speciality”, and \\nhelps the service staff reach for cleaning and rearrange table whenever needed. Similarly, the food \\nwastage will be viewed by different departments with different perspectives – the finance by cost \\nof wastage, the housekeeping by disposal methods, chefs by reason for rejection by guests, the \\nquality team for finding innovative approaches to reduction, and the information systems team \\nfor devising measures that indicate improvement in processes.\\n • Virtual team members on the same page: In today’s business context, not all stakeholders or \\ndecision makers will be in the same building/geographic location. Businesses are highly distrib-\\nuted in nature and executives travel extensively. The team of people who work on a common \\npurpose/project/business goal but are spread across geographic locations is termed as a virtual \\nteam. T echnologies like BI bring them together and provide them the same facts at the speed of \\nlight in personalized forms.\\npicture this…\\nThe GoodFood Restaurant chain team members are now spread across 10 countries but they are highly \\nwired in the digital world. The chefs discuss new recipes, procurement teams find new suppliers, mar-\\nketing team members share campaign innovations, and all operations managers and executives hold \\nconference calls and video-based meetings anytime in planned ways. Every member is trained to use the \\nrestaurant portal, critical applications, and the email system. The performance dashboards are used to \\nprovide key business metrics based on their role for all executives. Even customers interact over mail, \\nportal, Facebook, and T witter.\\n4.5.1 v isibility into enterprise performance \\nBusiness Intelligence provides a clear insight into the enterprise’s performance. This is by way of an op-\\nerational dashboard. An operational dashboard makes use of visual forms such as charts, gauges, tables, \\nmatrix, indicators, etc.\\nIn our example of the GoodFood Restaurant, the restaurant owner views the progress of the chain \\nof restaurants on a single dashboard. This quickly tells him, with relevant data, which branch is doing \\nexcellent business, where the business is average with data, etc. Timely information as provided by the \\ndashboard leads to early remedial procedures.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 130}, page_content='106 • Fundamentals of Business Analytics\\nBI supports decision making at all levels in the enterprise as described below and as depicted in \\nFigure 4.12.\\n • Strategic level: BI helps enterprises see the “big picture”. It supports decision making for the long \\nterm. Such decisions affect the entire organization. For the GoodFood Restaurants Inc., strategic \\ndecisions may include: “Where could be the next 5 restaurants?”, “Is cruise liner catering more \\nattractive than flight kitchen management opportunity?”, etc.\\n • Tactical level: Tactical decisions in comparison to strategic decisions are made more frequently. \\nIn terms of the impact of decisions, tactical decisions affect a single unit(s)/department(s). For \\nthe GoodFood Restaurants Inc., tactical decisions may include: “How much discount should we \\noffer for holidaying cruise liner guests?”, “What are the right months in the year for encouraging \\ncustomers redeem loyalty points?”, etc.\\n • Operational level: Operational decisions are made even more frequently. The impact, however, \\nis restricted to a single unit/department or function. These decisions help in conducting the day-\\nto-day operations of business. For the GoodFood Restaurants Inc., an operational level decision \\nmay be: What menu item needs to be dropped this week to handle bad weather?\\nFigure 4.12 Types of decisions supported by BI.\\nOperational\\nTactical\\nStrategic\\nLow\\nHigh\\nHigh\\nLow\\nImpact Frequency \\nTypes of decisions\\n4.6 Why Bi? hoW can yoU achieve yoUr stateD oBjectives?\\n1.  You want to gain competitive advantage in the marketplace (based on better, faster and fact \\nbased decisions).\\n2.  You want to retain your customers by making relevant recommendations of products and ser-\\nvices to them.\\n3. You want to improve employee productivity by identifying and removing bottleneck processes.\\n4. You want to optimize your service offerings.\\n5. You want to bring NEW value to your business.\\nThe above stated objectives can be achieved by harnessing the power of Business Intelligence (BI).'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 131}, page_content='Getting Started with Business Intelligence • 107\\n4.7  some important QUestions aBoUt Bi - Where, \\nWhen anD What\\n4.7.1 Where is Bi being used?\\n1. Netflix\\n2. Google\\n3. Yahoo\\n4. LinkedIn\\n5. Walmart\\n6. Facebook, etc.\\n4.7.2 When should you use Bi?\\nIf the answer to one or several of the below questions is “Yes”, you should consider BI:\\n1.  Do you find yourself in situations where either you lack information to make the right deci-\\nsions or you experience too much information but not enough insight?\\n2.  Do you often end up discussing and debating the validity and accuracy of your reporting? \\n3.  Are you unsure whether the key indicators on which you base your decisions are correct and \\nwhether they are up to date?\\n4.  Do you spend a fair amount of time finding the needed information, classifying and structur-\\ning it and then distributing it to the right people at the right time?\\n5.  Do you find yourself “drowning in spreadsheets” and do you find it tedious and cumbersome \\nto integrate and consolidate data flowing in from multiple disparate sources?  \\n6.  Do you find it difficult and time-consuming to conduct ad-hoc analyses yourself?\\n7.  Do you face problems of “information inaccessibility”; or is access dependent on one or two \\nkey persons?\\n4.7.3 What can Bi deliver?\\n1. BI can deliver “single version of the truth”.\\n2. BI can deliver information that is actionable.\\n3. BI can glean “insights” from corporate data.\\n4.8  evolUtion of Bi anD role of Dss, eis, mis, anD Digital \\nDashBoarDs\\nYou may be interested to know how large businesses that have several IT systems (OLTP systems) \\nprovided “management information” for decision makers. Figure 4.13 illustrates the process typically \\nfollowed for provision of “management information” to decision makers.\\nThe IT function team members typically used to take responsibility for MIS (Management Infor-\\nmation System). The new report preparation would involve all the phases of software lifecycle, viz., \\nrequirements gathering, analysis, design of new schema to combine data from several IT applications, \\nprogramming to read data from existing IT applications, populating new schema, and then generating \\nthe required report. The major challenges associated with this approach include:'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 132}, page_content='108 • Fundamentals of Business Analytics\\n • Long delay between the request for and delivery of reports.\\n • Inaccurate figures as the data would have been copied to a new schema while IT applications \\ncould be updating their own databases resulting in multiple versions of truth.\\n • The copies of data (called extracts) could not serve any new requirement and had to be  \\ndiscarded. T oo many versions can be totally confusing!\\n • Executives’ requirements would have changed by the time the report is taken to them, resulting \\nin dissatisfaction of the service delivered. This increased the divide between those manning IT \\nand management staff in many situations.\\nSeveral external forces started taking interest in tackling these challenges as the “solution” would be \\nof high commercial value. First, IT function within enterprises started looking at new tools to connect \\nto heterogeneous databases and pull data from them quickly. RDBMS vendors started offering adapters \\nto connect to different vendor RDBMS products/versions but were expensive. Second, the new soft-\\nware companies started developing and marketing multidimensional databases, hardware solutions for \\nhandling queries faster (Netezza...), and new reporting tools that could seamlessly combine data from \\nmultiple sources. Third, in academia, research demonstrated newer approaches to de-normalization, \\nOLAP , and data integration concepts with middleware. Business Intelligence solutions are a product \\nof all these three developments. Some vendors integrated all the BI functionality into specific problem \\ndomain such as sales analysis and started delivering domain-customized BI tools. T oday, we are in the \\nthird generation of BI tools. Some BI solutions are described below:\\n • Ad hoc reporting: Ad hoc reporting systems are used to meet the requirements of individual de-\\ncision makers in the form, data set collection, and frequency. They are different from the regular \\nmanagement information systems as they are used to analyze the other information systems that \\nare employed in the operational activities of the organization. The terms “MIS” and “information \\nFigure 4.13 Passing on “management information” to decision makers.\\nNeed1 Need2 Need3\\nSales\\nMarketing\\nFinance\\nOperations\\nHuman\\nResources'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 133}, page_content='Getting Started with Business Intelligence • 109\\nsystems” are often used interchangeably, rather incorrectly though. Information systems are \\nnot intended to support decision making, but MIS is there to support management functions. \\nThe reporting tools typically have the ability to combine data from multiple sources, store  \\nmetadata, store report specifications for faster re-runs, and deliver reports in multiple forms such \\nas PDF , Document, or worksheet formats.\\n • DSS (Decision Support System): In the 1970s, DSS became an area of research. It is an infor-\\nmation system which supports business decision making activities. Also called knowledge-based \\nsystem, DSS is known to support decision making that is required to run day-to-day operations. \\nDSS supports applications such as inventory, point of sales systems, etc. It essentially supports \\noperational decision making. The emphasis is on use of business graphics to present information \\nfrom multiple sources.\\n • EIS (Executive Information System): EIS comes with powerful reporting and analytical abili-\\nties. It supports decision making at the senior management level, i.e. strategic decisions. It pro-\\nvides easy access to not just the internal data but also external data which are relevant in realizing \\nthe strategic goals of the enterprise. EIS typically focuses on metrics or KPI (discussed later in \\nthe book) that indicates the health of the functions/projects or business performance. It enables \\norganizations to integrate and coordinate business process and has support for metric-based \\nperformance. Often times it is considered as a specialized form of DSS.\\n4.8.1 Difference Between erp (enterprise resource planning) and Bi \\nIn Chapter 3, we briefly discussed ERP (Enterprise Resource Planning). Now, that we understand BI, \\nit is worthwhile to look at a few points of difference, outlined in Table 4.1, between ERP and BI as an \\nenterprise application.\\n4.8.2 is Data Warehouse synonymous with Bi?\\nSometimes we see the terms data warehouse and BI being used interchangeably. Although used inter-\\nchangeably, the term data warehouse is not a synonym for BI. Well, an organization might have a data \\nERP is for data gathering, aggregation, search, \\nupdate, etc.\\nBI is for data retrieval.\\nEssentially an operational/transactional/OLTP \\nsystem.\\nEssentially OLAP .\\nSupports the capture, storage, and flow of data \\nacross multiple units of an organization.\\nSupports the integration of data from varied data sources, \\ntransforms the data as per business requirements, and \\nstores it in the business data warehouse.\\nHas support for a few pre-built reports which \\nusually help meet the transactional needs of the \\norganization.\\nSupports advanced form of reporting (boardroom quality) \\nand visualization. Has support for dynamic reports, drill \\ndown reports, drill across reports, etc.\\nHas little or no support for analytical needs of \\nthe organization.\\nSupports the analytical needs of the organization.\\nERP BI as an Enterprise Application\\nTable 4.1 Differences between ERP and BI\\nGetting Started with Business Intelligence • 109'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 134}, page_content='110 • Fundamentals of Business Analytics\\nwarehouse but if adequate front-end tools are not made available to the people, what use is the data \\nwarehouse? In other words, BI is the front-end while DW (data warehouse) is the back-end. Yes, DW stores \\ndata but if the stored data is not converted to meaningful information and action is not based on the \\ninformation, what use is the data? BI is more than just data warehouse. BI is also about analytics and \\nreporting. BI is an umbrella term which encompasses marketing research, analytics, reporting, dash-\\nboards, data warehouse, data mining, etc.\\n4.9 neeD for Bi at virtUally all levels \\n • There is too much data, but too little insight!\\nWe have humungous amount of data and the volume and velocity of it continues to grow by \\nleaps and bounds. There is a greater need than ever before to manage this data. There is a real-\\nization by enterprises/organizations that they do not have the information required to run their \\nbusinesses efficiently. Data and information exists but more often in silos and its accuracy cannot \\nalways be trusted. More often, how the information is entered differs markedly from how it needs \\nto be used to make business decisions. The definitions of data (the data schema) might vary from \\nsilos to silos. There is a need to integrate this data, and convert it into meaningful information \\nthat can be utilized effectively to drive business.\\n • Business Intelligence has been there in the boardroom for long. There is a need to expand \\nbusiness intelligence from the boardroom to the front lines!\\nCompanies have to react faster to changing market conditions. This entails integrating busi-\\nness intelligence into operational processes. For example, in view of the prevailing market condi-\\ntions, there may be an urgent need of alerting a call center worker to offer a particular promotion \\nto a targeted customer segment. This is made possible by the availability of business intelligence \\ntools at almost all levels of the corporations.\\n • Structured and unstructured data need to converge!\\nUnstructured data such as emails, voicemail messages, memos, etc. are rich sources of infor-\\nmation. Along with the data that is available in the conventional rows and columns format \\n(structured data), there is a need to blend the unstructured data to support better decision \\nmaking. For example, adding suggestions/complaints/comments and other inputs from custom-\\ners into a BI application can allow retailers to better their market segmentation analysis.\\n4.10 Bi for past, present, anD fUtUre \\nBI is not only for the present context and scenario but also takes into consideration the past and the \\nfuture. As indicated in Figure 4.14, BI with its set of standard reports helps answer questions such as \\n“What happened?”, “When did it happen?”, “Where did it happen?”, etc. These are the reports that are \\ngenerated on a regular basis, e.g. monthly or quarterly reports. These reports are useful in the short term \\nand not necessarily seen as a support for long-term decisions.\\nBI with its statistical analysis capabilities allows us to dig deep into the current and past data to  determine \\n“Why is this happening?”, “Are we missing out on opportunities?”, etc. For example, retail stores can use \\nstatistical analysis to determine: Why the customers prefer a particular brand over another?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 135}, page_content='Getting Started with Business Intelligence • 111\\nFigure 4.14 BI for past, present, and future.\\nWhat happened?\\nWhy did it happen?\\nWhat is happening?\\nWhy is it happening?\\nWhat will happen?\\nKnow the past\\nPredict the future\\nAnalyze the present\\nBI also helps in forecasting and predictive modelling. It helps get answers to questions like “What if \\nthe trend continues?”, “What is likely to happen next?”, “How much inventory will be needed and by \\nwhen?”, “What will be in demand?”, etc.\\nLet us again get back to our now very familiar restaurant example. Every quarter, the restaurant owner \\nalong with his managers from the various restaurant branches looks through the spending on inventory \\nsupplies (food raw materials and soft drinks) by every restaurant branch. This way they are able to get \\na clear picture on which branch/branches spends the maximum on inventory supplies and the possible \\nreason behind it. (The reason could be: There was a greater influx of customers on certain days, or there \\nwas a huge wastage owing to the food being spoilt.) This is a simple case of knowing the past.\\npicture yet another scenario…\\nOne of the branch managers has raised a concern with the restaurant owner saying that of late (the last \\ncouple of weeks) he has observed a decline in the number of customers. He has also checked the pos-\\nsible reason behind it and found that a new ice-cream parlour has started service in the vicinity and is \\ndrawing a good crowd. The youth who use to frequent the restaurant for a quick bite are now slowly \\nbecoming a regular at the parlour. This is a simple case of analyzing the present.\\nNow let us look at predictive modelling in the light of our restaurant example. It has been observed \\nby almost all restaurant branch managers that business picks up during the festive season. There is a \\nsurge in the number of people who prefer to eat out. Going by the trend and with the festive season \\n(“Christmas” and “New Year”) round the corner, it is the right time to think about stockpiling the \\ninventory supplies. Now, the simple question is: “What to stockpile?” and “How much?”\\n4.11 the Bi v alUe chain \\nLet us try and understand the BI value chain. We would like to depict it as follows:\\nTransformation ã Storage ã Delivery\\nData from different OLTP/transactional systems is brought together into an enterprise data warehouse \\n(it could have been very easily a data mart as well). This is after the data has been cleansed and is free of \\nall errors/defects. The data has also been transformed. One of the reasons behind transformation is to \\nconvert the data existing in different formats in the various data sources to a unified format. The data is \\nGetting Started with Business Intelligence • 111'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 136}, page_content='112 • Fundamentals of Business Analytics\\nthen loaded into the data warehouse. The next step in the BI value chain is data/information delivery. \\nThis topic will be dealt with in greater depths in the chapters to follow.\\n4.12 introDUction to BUsiness analytics\\nBusiness analytics is heavily dependent on data. For its successful implementation, business analytics \\nrequires a high volume of high quality data. The challenges faced by business analytics are: storage, \\nintegration, reconciliation of data from multiple disparate sources across several business functions, and \\nthe continuous updates to the data warehouse. Let us take a while to understand the difference between \\nbusiness intelligence and business analytics (Table 4.2).\\nTable 4.2 Differences between business intelligence and business analytics\\nBusiness Intelligence  \\nAnswers the questions:  • What happened?\\n • When did it happen?\\n • Who is accountable for what  \\nhappened?\\n • How many?\\n • How often?\\n • Where did it happen?\\n • Why did it happen?\\n • Will it happen again?\\n • What will happen if we change x ?\\n • What else does the data tell us that we \\nnever thought to ask?\\n • What is the best that can happen?\\nMakes use of:  • Reporting (KPIs, metrics)\\n • Automated Monitoring/Alerting \\n(thresholds)\\n • Dashboards/Scorecards\\n • OLAP (Cubes, Slice & Dice, Drilling)\\n • Ad hoc query\\n • Statistical/Quantitative Analysis\\n • Data Mining\\n • Predictive Modeling\\n • Design of experiments to extract \\nlearning out of business data\\n • Multivariate T esting\\nBusiness Analytics\\nWhat benefits does analysis of business data lead to? It can help businesses optimize existing pro-\\ncesses, better understand customer behavior, help recognize opportunities, and also help in spotting \\nproblems before they happen.\\nGartner defines an “analytic” application as packaged BI capabilities for a particular domain \\nor business problem. [http://www.gartner.com/technology/research/it-glossary/]\\nLet us look at a few basic domains within business analytics:\\n • Marketing analytics.\\n • Customer analytics.\\n • Retail sales analytics.\\n • Financial services analytics.\\n • Supply chain analytics.\\n • T ransportation analytics, etc.\\nGoodFood Restaurants Inc. has always relied on analytics for driving its decisions. We discuss here \\nthe food quality domain of GoodFood Restaurants. The decision to set up “International Master Chefs \\nSchool” in 2006 was based on the analysis of feedback which was collected from customers. Some of its \\noutlets in the USA and UK had received very good feedback from the customers with a special mention \\non the awesome quality of food and good dining experience. However, a few outlets in the USA, UK, '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 137}, page_content='Getting Started with Business Intelligence • 113\\nConnect Me (Internet Resources)\\n • http://searchbusinessanalytics.techtarget.com/news/1507222/T ext-analytics-search-bolster-\\nbusiness-intelligence-software-stack-says-TDWI\\n • http://searchbusinessanalytics.techtarget.com/news/2240019695/BI-search-platform-eyes-\\nmiddle-ground-between-BI-and-unstructured-data\\n • http://www.dwreview.com/DW_Overview.html\\n \\nRemind Me (Forget Me Not!)\\n•   OLTP systems refer to a class of IT applica-\\ntions that process and manage transaction-\\noriented digital data coming as inputs to the \\nsystem and produce updated databases and \\nmanagement reports for routine decision \\nmaking. \\n•   Data mining is the computational process of \\nsifting through existing business data to iden-\\ntify new patterns and establish relationships \\nthat will help in strategic decision making.\\n•   Data Science is the science of extracting \\nknowledge from data.  \\n•   Machine learning is a type of artificial intel-\\nligence (AI) that provides computers with the \\nability to learn without being explicitly pro-\\ngrammed.\\nPoint Me (Books)\\n•   Predictive Analytics: The Power to Predict Who \\nWill Click, Buy, Lie, or Die by Eric Siegel and \\nThomas H. Davenport (2013).\\n•   Data Science for Business: What you need to \\nknow about Data Mining and Data-Analytic \\nThinking by Foster Provost and T om Fawcett \\n(2013).\\nGetting Started with Business Intelligence • 113\\nand most of its outlets in Australia had received mixed feedback ranging from “Good” to “Average” to \\n“Poor”. An analysis of the feedback data led the management of GoodFood Restaurants Inc. to make \\nthe decision on setting up “International Master Chefs School” where all the chefs in service at the \\nvarious outlets can come together to learn a consistent approach in preparing and serving the various \\ncuisines and share their best practices. The decision paid off and today, GoodFood Restaurants Inc. is \\na name to reckon with.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 138}, page_content='114 • Fundamentals of Business Analytics\\nTest Me Exercises\\nMatch me\\nERP Data Retrieval\\nBI Filtering of data\\nSingle version of truth Dashboards\\nData slicing BI\\nCharts, gauges, pivot table Data input\\nColumn A Column B\\nSolution:\\nERP Data input\\nBI Data retrieval\\nSingle version of truth BI\\nData slicing Filtering of data\\nCharts, gauges, pivot table Dashboards\\nColumn A Column B'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 139}, page_content='Getting Started with Business Intelligence • 115\\nBI Crossword\\nDOWN\\nIntroduction to BI\\n12\\n3\\n4\\n5\\nACROSS\\n1. An act of piling up\\n3. An act of pulling out data\\n5. A company or a corporate\\n2. A place where the inventory of data resides\\n4. Process of getting a metal from its ore\\nSolution:\\n1. Loading 4. Mining\\n2. Data warehouse 5. Enterprise\\n3. Extract\\nGetting Started with Business Intelligence • 115'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 140}, page_content='116 • Fundamentals of Business Analytics\\nUnsolveD exercises\\n1. What is Business Intelligence (BI)?\\n2. Why is BI required by businesses?\\n3. What is fact-based decision making? Explain with the help of examples.\\n4. What is the single version of truth? Explain with the help of an example.\\n5. How are DSS, EIS, and MIS related to Business Intelligence?\\n6. How is ERP different from BI?\\n7. Can the terms BI and data warehouse be used interchangeably? Justify your answer.\\n8. Is BI required for operational decision making? Explain.\\n9. Can reports be drawn on OLTP system?\\n10. How do you think BI contributes to the future?\\n11. Is BI used only to analyze past data? Comment.\\n12. Explain how BI contributes to providing visibility into the enterprise performance?\\n13. Give a few examples of strategic, tactical and operational decisions.\\n14. How can BI be leveraged to provide a 360 degree perspective on the business?\\n15. Describe the BI value chain.\\n16. What is business analytics?\\n17. Assume you are in the hospitality business. What are the key questions that BI will help you \\nanswer?\\n18. Assume you are the owner of an automobile store. What are the key questions that BI will help \\nyou answer?\\n19. Think of an example from your college life where you ran into difficulty because of the single \\nversion of truth being compromised.\\n20. Picture this scenario… An enterprise has an ERP system in place, which has been running  \\nsuccessfully. Would you still suggest them to go for Business Intelligence and why?\\n21. Explain a few techniques of Data Mining to discover new patterns in data.\\n22. Explain the difference between descriptive, predicative and prescriptive analytics.\\n23. What is exploratory analysis? Explain with an example.\\n24. What are the skills required to transform into a Data Scientist?\\n25. What is Internet of Things (IoT)?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 141}, page_content='What’s in store\\nChapter 4, “Getting Started with Business Intelligence”, has familiarized you with the industry defini-\\ntion of Business Intelligence, the key terms used in the BI technology domain, the evolution of BI, and \\ndifferent methods adopted to serve managements with the information requested by them. This chapter \\nleads you to learn about BI in depth.\\nThis chapter will introduce you to the BI framework and the various layers that constitute the BI \\narchitecture; familiarize you with casual and power users of BI; introduce you to BI applications, etc. \\nWe suggest the topics “Best Practices in BI/DW” and “The Making of a Complete BI Professional” as \\na “Must Read” for those who wish to gain a good understanding of the BI space.\\nWe suggest you refer to the learning resources suggested at the end of almost every topic and also \\ncomplete the “T est Me” exercises. You will get deeper knowledge by interacting with people who have \\nshared their project experiences in blogs. We suggest you make your own notes/bookmarks while read-\\ning through the chapter.\\n5.1 Bi Component FrameWork\\nIn today’s warehouse environment, the organizations which are successful are those with sound archi-\\ntectures. Ever wondered, why architectures are important? The answer is simple: They support the \\nBrief Contents\\nWhat’s in Store\\nBI Component Framework \\nWho is BI for? \\nBI Users \\nBusiness Intelligence Applications \\nBI Roles and Responsibilities \\nBest Practices in BI/DW \\nThe Complete BI Professional \\nPopular BI T ools \\nUnsolved Exercises\\nBI Definitions and Concepts\\n5'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 142}, page_content='118 • Fundamentals of Business Analytics\\nfunctional, technical, and data needs of the enterprise. In other words, they help the organization/\\nenterprise become better equipped to respond to the business questions/queries posed by the users.\\nAs depicted in Figure 5.1 the BI component framework can be divided into three major layers:\\n • Business layer.\\n • Administration and Operation layer.\\n • Implementation layer.\\n5.1.1 Business Layer\\nFigure 5.2 depicts the business layer of the BI component framework. This layer consists of four com-\\nponents – business requirements, business value, program management, and development.\\nBusiness Requirements\\nThe requirements are a product of three steps of a business process, namely, Business drivers, Business \\ngoals, and Business strategies:\\nFigure 5.1 The BI component framework.\\nBUSINESS LAYER\\nIMPLEMENTATION LAYER\\nADMINISTRATION AND OPERATION LAYER\\nDATA RESOURCE\\nADMINISTRATION\\nBUSINESS REQUIREMENT\\nPROGRAM MANAGEMENT\\nDEVELOPMENT\\nBUSINESS VALUE\\nBI ARCHITECTURE\\nBI AND DW\\nOPERATIONS\\nBUSINESS APPLICATIONS\\nDATA\\nWAREHOUSING\\nINFORMATION\\nSERVICES'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 143}, page_content='BI Definitions and Concepts • 119\\n • Business drivers: These are the impulses that initiate the need to act. A few examples of \\nbusiness drivers are: changing workforce, changing labour laws, changing economy, changing \\ntechnology, etc.\\n • Business goals: These are the targets to be achieved in response to business drivers. A few ex-\\namples of business goals are: increased productivity, improved market share, improved profit \\nmargins, improved customer satisfaction, cost reduction, etc.\\n • Business strategies: These are the planned course of action that will help achieve the set goals. \\nA few examples of business strategies are: outsourcing, global delivery model, partnerships, cus-\\ntomer retention programs, employee retention programs, competitive pricing, etc.\\nBusiness Value\\nWhen a strategy is implemented against certain business goals, then certain costs (monetary, time, \\neffort, information produced by data integration and analysis, application of knowledge from past expe-\\nrience, etc.) are involved. However, the final output of the process should create such value for the busi-\\nness whose ratio to the costs involved should be a feasible ratio. The business value can be measured in \\nterms of ROI (Return on Investment), ROA (Return on Assets), TCO (T otal Cost of Ownership), TVO \\n(T otal Value of Ownership), etc. Let us understand these terms with the help of a few examples:\\n • Return on Investment (ROI): We take the example of “Digicom”, a digital electronics goods \\ncompany which has an online community platform that allows their prospective clients to en-\\ngage with their users. “Digicom” has been using social media (mainly T witter and Facebook) to \\nhelp get new clients and to increase the number of prospects/leads. They attribute 10% of their \\ndaily revenue to social media. Now, that is an ROI from social media!\\n • Return on Asset (ROA): Suppose a company, “Electronics T oday”, has a net income of $1 mil-\\nlion and has total assets of $5 million. Then, its ROA is 20%. So, ROA is the earning generated \\nfrom invested capital (assets).\\n • Total Cost of Ownership (TCO): Let us understand TCO in the context of a vehicle. TCO de-\\nfines the cost of owning a vehicle from the time of purchase by the owner, through its operation \\nand maintenance to the time it leaves the possession of the owner.\\n • Total Value of Ownership (TVO): TVO has replaced the simple concept of Owner’s Equity in \\nsome companies. It could include a variety of subcategories such as stock, undistributed divi-\\ndends, retained earnings or profit, or excess capital contributed. In its simplest form, the basic \\naccounting equation containing TVO as a component is\\nAssets = Liabilities + Owner’s Equity, or if you like TVO\\nFigure 5.2 The business layer.\\nBUSINESS\\nREQUIREMENTS BUSINESS VALUE\\nBUSINESS\\nLAYER\\nDEVELOPMENTPROGRAM\\nMANAGEMENT'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 144}, page_content='120 • Fundamentals of Business Analytics\\nProgram Management\\nThis component of the business layer ensures that people, projects, and priorities work in a manner in \\nwhich individual processes are compatible with each other so as to ensure seamless integration and \\nsmooth functioning of the entire program. It should attend to each of the following:\\n • Business priorities.\\n • Mission and goals.\\n • Strategies and risks.\\n • Multiple projects.\\n • Dependencies.\\n • Cost and value.\\n • Business rules.\\n • Infrastructure.\\nDevelopment\\nThe process of development consists of database/data warehouse development (consisting of ETL, data \\nprofiling, data cleansing, and database tools), data integration system development (consisting of data \\nintegration tools and data quality tools), and business analytics development (about processes and various \\ntechnologies used).\\n5.1.2 administration and operation Layer\\nFigure 5.3 depicts the administration and operation layer of the BI component framework. This layer \\nconsists of four components – BI architecture, BI and DW operations, data resource administration, \\nand business applications.\\nBI Architecture\\nThe various components of BI architecture are depicted in Figure 5.4.\\nBI and DW Operations\\nData warehouse administration requires the usage of various tools to monitor the performance and \\nusage of the warehouse, and perform administrative tasks on it. Some of these tools are:\\n • Backup and restore.\\nFigure 5.3 The administration and operation layer.\\nBI ARCHITECTURE\\nBI AND DW (DATA\\nWAREHOUSE)\\nOPERATIONS\\nADMINISTRATION\\nAND OPERATION\\nLAYER\\nBUSINESS\\nAPPLICATIONS\\nDATA RESOURCE\\nADMINISTRATION'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 145}, page_content=' • Security.\\n • Configuration management.\\n • Database management.\\nData Resource Administration\\nIt involves data governance and metadata management.\\nData Governance\\nIt is a technique for controlling data quality, which is used to assess, improve, manage, and maintain \\ninformation. It helps define standards that are required to maintain data quality. The distribution of \\nroles for data governance is as follows:\\n • Data ownership.\\n • Data stewardship.\\n • Data custodianship.\\nMetadata Management\\nPicture yourself looking at a CD/DVD of music. What do you notice? Well, there is the date of record-\\ning, the name of the artist, the genre of music, the songs in the album, copyright information, etc. All \\nthis information constitutes the metadata for the CD/DVD of music. In the context of a camera, the \\ndata is the photographic image. The metadata then is the date and time when the photograph was \\nFigure 5.4 The components of BI architecture.\\n\\x7f Should follow design standards\\n\\x7f Must have a logically apt data model\\n\\x7f Metadata should be of high standard\\n\\x7f Performed according to business semantics and rules\\n\\x7f During integration, certain processing standards have to be\\n   followed\\n\\x7f Data must be consistent\\n\\x7f Information derived from data that has been integrated should be\\n  usable and findable as per the requirements\\n\\x7f Consists of the different roles and responsibilities, like\\n  management, development, support, and usage rolesORGANIZATION\\nTECHNOLOGY\\nINFORMATION\\nINTEGRATION\\nDATA\\n\\x7f Technology used for deriving information must be accessible\\n\\x7f Also, it should have a good user-interface\\n\\x7f Should support analysis, decision-making, data and storage\\n  management\\nBI Definitions and Concepts • 121'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 146}, page_content='122 • Fundamentals of Business Analytics\\ntaken. In simple words, metadata is data about data. When used in the context of a data warehouse, it \\nis the data that defines the warehouse objects. Few examples of metadata are timestamp at which the \\ndata was extracted, the data sources from where metadata has been extracted, and the missing fields/\\ncolumns that have been added by data cleaning or integration processes. Metadata management involves \\ntracking, assessment, and maintenance of metadata. Metadata can be divided into four groups:\\n • Business metadata.\\n • Process metadata.\\n • T echnical metadata.\\n • Application metadata.\\nLet us understand the various types of metadata with the help of an example:\\npicture this…\\n“ElectronicsForAll” is an India-based company with branches in all the major cities of India. Each \\nbranch has its own set of databases. The company has a data warehouse which is sourced from these \\nseveral databases physically located at different locations (major cities of India such as Delhi, Mumbai, \\nChennai, etc.). The company also has a dashboard (a web application) that projects the daily and quar-\\nterly revenue earnings of the various branches. Let us now look at some of the technical details:\\nA partial structure of table “RevenueEarnings” existing in the databases at various branches of  \\n“ElectronicsForAll” is shown in Table 5.1. Remember, it is only a partial structure.\\nTable 5.1 RevenueEarnings\\nBranchID LocationID Quarter Year RevenueEarned CostIncurred Profit ProfitMargins\\nTable 5.1 has columns such as “BranchID”, “LocationID”, “Quarter”, “Year”, “RevenueEarned”, \\n“CostIncurred”, “Profit”, “ProfitMargins”, etc. Each of these columns has a data type and a data size \\nsuch as:\\nColumnName Data Type and Data Size Description\\nBranchID Varchar(15) Not Null\\nLocationID Varchar(30) Not Null\\nQuarter Varchar(2) Not Null\\nColumn Name Constraints\\nFurther, Table 5.1 is indexed on “BranchID”. The following constitutes the technical metadata:\\n • Data locations.\\n • Data formats.\\n • T echnical names.\\n • Data sizes (in the example above, 15 as the maximum length for “BranchID”).\\n • Data types (in the example above, Varchar(15) for “BranchID”).\\n • Indexing (in the example above, the index on “BranchID”).\\n • Data structures, etc.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 147}, page_content='The data warehouse for the company “ElectronicsForAll” is asynchronously and incrementally \\nupdated by using the data updates from the data sources to the data warehouse.\\nThe following constitutes the process metadata:\\n • Source/target maps.\\n • T ransformation rules.\\n • Data cleansing rules.\\n • Extract audit trail.\\n • T ransform audit trail.\\n • Load audit trail.\\n • Data quality audit, etc.\\nThe company’s dashboard is built on top of the data warehouse. The dashboard is accessible by all \\nthe branch heads and senior executives of the company.\\nThe following constitutes the application metadata:\\n • Data access history such as:\\n \\x83 Who is accessing? Who has accessed?\\n \\x83 Frequency of access?\\n \\x83 When was it accessed?\\n \\x83 How was it accessed?, etc.\\nBusiness metadata captures information such as business definitions, structure, and hierarchy of the \\ndata, aggregation rules, ownership characteristics (who are the data stewards/data owners/data custodi-\\nans), subject areas (such as finance, market share, etc.), and business rule-based descriptions of transfor-\\nmation rules and definitions of business metrics (such as which branch is the top revenue grosser, which \\nbranch has incurred the maximum expenses, how many branches are there in each location, etc.).\\nBusiness Applications\\nThe application of technology to produce value for the business refers to the generation of information \\nor intelligence from data assets like data warehouses/data marts. Using BI tools, we can generate strategic, \\nfinancial, customer, or risk intelligence. This information can be obtained through various BI applica-\\ntions, such as DSS (decision support system), EIS (executive information system), OLAP (on-line \\nanalytical processing), data mining and discovery, etc.\\nFew of the BI applications are discussed in the section “Business Intelligence Applications” later in \\nthis chapter.\\n5.1.3 implementation Layer\\nThe implementation layer of the BI component framework is depicted in Figure 5.5. This layer consists \\nof technical components that are required for data capture, transformation and cleaning, converting \\ndata into information, and finally delivering that information to leverage business goals and produce \\nvalue for the organization.\\nData Warehousing\\n • It is the process which prepares the basic repository of data (called data warehouse) that becomes \\nthe data source where we extract information from.\\nBI Definitions and Concepts • 123'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 148}, page_content='124 • Fundamentals of Business Analytics\\n • A data warehouse is a data store. It is structured on the dimensional model schema, which is \\noptimized for data retrieval rather than update.\\n • Data warehousing must play the following five distinct roles:\\n \\x83 Intake.\\n \\x83 Integration.\\n \\x83 Distribution.\\n \\x83 Delivery.\\n \\x83 Access.\\nLet us look at the example of “AllGoods” company. “AllGoods” company is a global company with \\npresence in all the major countries of the world. The company has several branches in each country. \\nEach branch has its own set of databases. The President of “AllGoods” company’s US division has asked \\nhis analyst to present the company’s sales per product category (such as “Accessories”, “Clothing”, etc.) \\nper section (such as “Men”, “Women”, “Kids”, and “Infant”) per branch for the first quarter. The chal-\\nlenge here is to collate data spread out over several databases across several cities. In case of “AllGoods” \\ncompany this task doesn’t pose much of a challenge as the company has a data warehouse depicted in \\nFigure 5.6.\\nA data warehouse is built by extracting data from multiple heterogeneous and external sources, clean-\\ning to detect errors in the data and rectify them wherever possible, integrating, transforming the data \\nfrom legacy format to warehouse format, and then loading the data after sorting and summarizing. The \\ndata warehouse is also periodically refreshed by propagating the updates from the data sources to the \\nwarehouse. Refer to Figure 5.6.\\nDetails on building a data warehouse are covered in Chapter 6.\\nInformation Services\\nThe following information related tasks are performed in the information services layer of the BI com-\\nponent framework:\\n • It is not only the process of producing information; rather, it also involves ensuring that the \\ninformation produced is aligned with business requirements and can be acted upon to produce \\nvalue for the company.\\n • Information is delivered in the form of KPIs, reports, charts, dashboards or scorecards, etc., or \\nin the form of analytics.\\n • Data mining is a practice used to increase the body of knowledge.\\n • Applied analytics is generally used to drive action and produce outcomes.\\nFigure 5.5 The implementation layer.\\nData\\nSources\\nData\\nStores\\nData acquisition,\\nCleaning and\\nIntegration\\nInformation Delivery\\nBusiness Analytics\\nData Warehousing Information Services'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 149}, page_content='Figure 5.6 Data warehouse framework of “AllGoods” company.\\nData source in New York\\nData source in Washington\\nData source in Philadelphia\\nData source in Chicago\\nExtract\\nClean\\nTransform\\nLoad\\nRefresh\\nData Warehouse\\nQuery/\\nReport/\\nAnalysi\\ns\\nBI Definitions and Concepts • 125\\nRemind Me \\n•   The BI component framework can be divided \\ninto 3 layers:\\n\\u2003\\u2003\\x83   The business layer.\\n\\u2003\\u2003\\x83   The administration and operations layer.\\n\\u2003\\u2003\\x83   The implementation layer.\\n • Business drivers are the impulses that initiate \\nthe need to act.\\n • Business goals are the targets to be achieved in \\nresponse to the business drivers.\\n • Business strategies are the planned course of \\naction that will help achieve the set goals.\\n • Data governance is a technique for control-\\nling data quality.\\n • Metadata management involves tracking, \\nassessment, and maintenance of metadata.\\n • A data warehouse is a data store.\\n • A data warehouse is structured on the dimen-\\nsional model schema, which is optimized for \\ndata retrieval rather than updates.\\n • Applied analytics is used to drive action and \\nproduce outcomes.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 150}, page_content='126 • Fundamentals of Business Analytics\\nAfter understanding the BI framework, let us now move towards knowing the users in the BI space \\nand how BI can be leveraged for process and performance improvement.\\n5.2 Who is Bi For?\\nIt is a misnomer to believe that BI is only for managers or the executive class. T rue, it is used more often by \\nthem. But does that mean that BI can be used only for management and control? The answer is: NO! Let us \\ntry to unravel this myth by looking at a few areas (listed below) where BI has made/is making an impact:\\n • BI for management.\\n • Operational BI.\\n • BI for process improvement.\\n • BI for performance improvement.\\n • BI to improve customer experience (QCE – Quality of Customer Experience).\\nFigure 5.7 depicts business solutions provided by Business Intelligence.\\nConnect Me (Internet Resources)\\n • http://www.tdwi.org/\\nTest Me Exercises\\nFill me\\n1.  _______ is a data store, optimized for data \\nretrieval rather than updates.\\n2. _______ are the impulses/forces that initiate \\nthe need to act.\\n3. _______ is a technique for controlling data \\nquality.\\n4.  The _______ layer consists of technical com-\\nponents that are required for data capture, \\ntransformation and cleaning, converting data \\ninto information and finally delivering that \\ninformation to leverage business goals and \\nproduce value for the organization.\\n5. The expansion for EIS is _______ _______ \\n_______.\\n6. The expansion for DSS is _______ _______ \\n_______.\\n7. Using BI tools, we can generate _______, \\n_______, _______, or _______ intelligence.\\nSolution:\\n1. Data warehouse\\n2. Business drivers\\n3. Data governance\\n4. Implementation\\n5. Executive Information System\\n6. Decision Support System\\n7. Customer, strategic, financial, risk'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 151}, page_content='5.2.1 Bi for management\\nBI is a very powerful weapon in the hands of managers. With the help of BI front-end tools, they are \\nable to use the information made available to gain business value. Gone are the days when managers had \\nto wait for the end of the quarter to take stock of the situation. And more often than not, it was a tad \\ntoo late to take action. Now with BI, it is right information at the right time. There is no need to wait \\ntill the end of the quarter when the quarter results would indicate whether business is going the profit \\nway or the loss way. BI helps report:\\n • How sales are in the various regions?\\n • Whether the project is on budget or is overshooting?\\n • Whether costs are exceeding budgets?\\n • Whether customers are dissatisfied with a particular service or product offering?\\n • What items customers buy the most?\\n • Whether employees are dissatisfied with the changes in the company’s policies?\\n • Whether imparting technical training to employees before placing them on a project is likely to \\nenhance their productivity?\\n • What is it that your company is best at?\\n5.2.2 operational Bi\\nWhoever said BI relied on historical data only, needs to think again. Does BI help in the daily operations \\nof a company? Yes it does. How?  Let us explain with an example. Assume a typical manufacturing-to-\\nshipment scenario. A customer places an order. Before accepting the order, the customer service repre-\\nsentative might want to check whether adequate inventory is available. For this he may look at a report \\ngenerated within an order inventory system or furnished through a BI solution. \\nWhat is the primary difference between BI for management and operational BI? Operational BI will have \\nto interact either directly with a transaction system or be sourced by a data warehouse that is updated \\nFigure 5.7 Business solutions provided by Business Intelligence.\\nContinuous\\nimprovement\\nCompetitive\\nadvantage\\nCostreduction\\nEfficiency\\nimprovement\\nProcess\\nimprovementBusiness\\nsolutions\\nBI Definitions and Concepts • 127'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 152}, page_content='128 • Fundamentals of Business Analytics\\nin near real time several times in a day. This is not to say that BI for management will not use near real \\ntime data. It may, but it can also be based on weekly or monthly data.\\n5.2.3 Bi for process improvement\\nWe have heard often times that BI leads to enhancement in the performance of enterprises. But the \\nquestion to ask here is: Does it also contribute to improvement of processes? The answer again is: \\n“Yes!” Sometimes the process itself can be a bottleneck. Here is an example to explain the same. A \\nretail store was running into the cash flow problem. Goods from the retail store were delivered to \\nthe customers on time. So on-time delivery was not a problem. The invoice was sent to the cus-\\ntomer after about a week but before 10 days. If the delivery-to-invoice time could be curtailed, \\nchances were that the retail store might not experience the cash flow problem. BI had helped the \\ncompany to monitor this process and identify the road-block. Using the BI-generated informa-\\ntion, the store was able to act to reduce the delivery-to-invoice time to a couple of days and come \\nout victorious.\\n5.2.4 Bi for performance improvement\\nLet us begin by understanding “What is the measure for business performance?” The obvious measures are: \\nrevenue, margin, profitability, etc. “How does BI help to boost revenue?” Let us try to understand this with \\nan example. BI helps a leather shoe company – XYZ – identify customers who are regular buyers of \\nleather shoes. The company’s representative makes it a point to send across catalogs of other leather \\naccessories from various brands to the identified customers. This is essentially cross-selling. A BI-driven \\ninvestigation of sales history data can help determine the products that customers are likely to buy \\ntogether, for example “bread and egg” or “bread and butter” or “butter and jelly”, etc. These are few \\nother examples of cross-selling. Cross-selling is also called “Market Basket Analysis”. “How does BI help \\ncompanies maintain a steady cash-flow?” The answer is: by identifying late-paying customers. “How does \\nBI help increase profitability?” A company can use BI tools to understand the customer demographics \\nbefore deciding to launch a product in a particular region. The launch of the right product will mean \\nbetter profits as there will be more customers for it.\\n5.2.5 Bi to improve Customer experience\\nBusinesses are all about providing an enhanced quality of customer experience. Let us take an example. \\nBI can help an airlines identify frequent fliers. The airlines can then come up with schemes such as \\nupgradation from economy to business class based on availability, giving preference to frequent fliers \\nclub. A car dealer can use BI to monitor its warranty program and track down the root causes for war-\\nranty problems. A telecom company can make use of BI tools to determine the customers who are fre-\\nquent in sending out text messages and then can target those customers either for cross-sell or up-sell. \\nBI will help all these companies serve the customers better and win the customers satisfaction, loyalty, \\nand advocacy. This will definitely do wonders for the business.\\nDecision making is not new. It existed even without IT support. But it was more of a gut-feel kind \\nof stuff and less based on facts. Now, IT and businesses have joined hands to make BI a mission-critical \\nendeavor, and one of the essentials for successful businesses.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 153}, page_content='5.3 Bi Users\\nOne can broadly classify BI users into two broad categories:\\n • Casual users.\\n • Power users.\\nTable 5.2 distinguishes casual users from power users.\\nRemind Me\\n•   BI is not only for senior management/ex-\\necutive class. BI is also for monitoring and \\nmanaging the day-to-day operations of the \\norganization.\\n•   BI is for process improvement.\\n•   BI is for performance improvement.\\n • BI is for understanding your customers.\\n • BI is for recognizing the opportunities to \\ncross-sell and up-sell.\\n • BI is both an “art” and a “science”.\\n • BI has to be supported at all levels by both the \\nIT and business executives.\\nPoint Me (Books)\\n•   Business Intelligence for dummies – Swain \\nScheps.\\n•   Successful Business Intelligence: Secrets to \\nMaking Killer BI Applications by Cindi \\nHowson.\\nTest Me Exercises\\nFill me\\n1.  For BI to be successful in an organization, \\nboth _______ and _______ executives must \\ncome together.\\n2. Operational BI might be required to interact \\ndirectly with _______ systems.\\n3. Cross-selling is also called _______.\\nSolution:\\n1. IT , business\\n2. T ransaction\\n3. Market Basket Analysis\\nBI Definitions and Concepts • 129'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 154}, page_content='130 • Fundamentals of Business Analytics\\n5.3.1 Casual Users\\nThese users are the consumers of information in pre-existing reports. They are usually executives, man-\\nagers, field/operations workers, customers, or suppliers. They might base their decisions/actions on the \\nacquired information. They do not create the reports. They make do with the reports/dashboards tai-\\nlored to meet the needs of their respective roles and created by power users by sourcing data from data \\nwarehouse/data marts.\\n5.3.2 power Users\\nThese users are the producers of information. They produce information either for their own needs or \\nto satisfy the information needs of others. Developers, administrators, business analysts, analytical mod-\\nelers (SAS, SPSS developers, etc.), IT professionals, etc. belong to this category. The power users take \\ndecisions on issues such as “What information should be placed on the report?”, “What is the best way \\nto present the information?”, “Who should see what information (access rights)?”, “How the informa-\\ntion should be distributed (distribution channels)?”, etc. Developers can develop reports, write simple/\\ncomplex queries, fix/tweak/optimize queries, slice/dice the information, and analyze information/data \\nto gain better insights. They usually use powerful analytical and authoring tools to access data from data \\nwarehouses/data marts and other sources both inside and outside the organization.\\nTable 5.2 Distinction between casual users and power users\\nExample of Such Users Data Access T ools\\n Casual users/ \\nInformation \\nconsumers\\nExecutives, managers, \\ncustomers, suppliers, \\nfield/operation \\nworkers, etc\\nTailor-made to suit \\nthe needs of their \\nrespective roles\\nPre-defined \\nreports/\\ndashboards\\nData \\nwarehouse/data \\nmarts\\n Power users/ \\nInformation \\nproducers\\nSAS, SPSS developers, \\nadministrators, \\nbusiness analysts, \\nanalytical modelers, IT \\nprofessionals, etc.\\nAd hoc/exploratory Advanced \\nanalytical/ \\nauthoring tools\\nData \\nwarehouse/data \\nmarts (both \\ninternal and \\nexternal)\\nType of User Sources\\nRemind Me \\n•   Power users decide on what information \\nshould be made available to other knowledge \\nworkers.\\n•   Casual users or information consumers make \\ndo with pre-defined and pre-existing reports/ \\ndashboards.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 155}, page_content='5.4 BUsiness inteLLigenCe appLiCations\\nBI applications can be divided into two categories – technology solutions and business solutions.\\n • T echnology solutions\\n \\x83 DSS\\n \\x83 EIS\\n \\x83 OLAP\\n \\x83 Managed query and reporting\\n \\x83 Data mining\\n • Business solutions\\n \\x83 Performance analysis\\n \\x83 Customer analytics\\n \\x83 Marketplace analysis\\n \\x83 Productivity analysis\\n \\x83 Sales channel analysis\\n \\x83 Behavior analysis\\n \\x83 Supply chain analytics\\n5.4.1 t echnology solutions\\n • DSS stands for Decision Support System. It supports decision making at the operational and \\ntactical levels. DSS is discussed in Chapter 4.\\n • EIS stands for Executive Information System. It supports decision making at the senior manage-\\nment level. It is a specialized form of DSS. It provides relevant internal and external information \\nto senior executives so that they can evaluate, analyze, compare, and contrast, recognize trends, \\nidentify opportunities and problems, etc. The emphasis with EIS has been to provide an easy to \\nuse graphical interface with strong reporting capabilities. EIS is discussed in Chapter 4.\\n • OLAP stands for On-Line Analytical Processing. The lifeline of OLAP systems is multidimen-\\nsional data. OLAP access tools allow the slicing and dicing of data from varied perspectives. \\nRead more about OLAP in Chapter 3.\\nLet us understand On-Line Analytical Processing as depicted in Figure 5.8. We start at the bottom \\ntier. Let us label it as the data warehouse server layer. This tier houses the enterprise-wide data  warehouse \\nTest Me Exercises\\nFill me\\n1.  _______ users decide “who should see what \\ninformation (access rights)”.\\n2.  _______ users make do with reports created by  \\ndevelopers.\\nSolution:\\n1. Power\\n2. Information consumers\\nBI Definitions and Concepts • 131'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 156}, page_content='132 • Fundamentals of Business Analytics\\n(DW). This data warehouse is sourced from multiple heterogeneous internal data sources and a few \\nexternal data sources. There are few tools (back-end tools and utilities) that are used at the layer to \\ncleanse, transform, and load the data into the DW . The DW is also periodically refreshed to propagate \\nthe updates from the data sources to the DW . This layer also has the presence of a metadata repository \\nthat stores information about the data warehouse and its contents.\\nNow let us look at the middle tier. Let us label it as the OLAP server layer. This layer usually has a \\nROLAP (relational OLAP) or a MOLAP (multidimensional OLAP) server. The top tier is the client \\nfront-end layer. This layer is adequately supported by query, reporting, and analysis tools.\\n • Managed query and reporting: This tool includes predefined standard reports, report wizards, \\nand report designer which are essentially used by developers to create reports. Then there is re-\\nport builder, essentially used by business users to quickly create a report according to the given \\nreport template.\\nFigure 5.8 On-Line Analytical Processing.\\nOperational/\\nTransactional\\nDatabase\\nOperational/\\nTransactional\\nDatabase\\nOperational/\\nTransactional\\nDatabase\\nExtract, Clean, Transform, Load, & Refresh\\nBusiness Data Warehouse\\nOLAP Cube\\nOLAP Access Tools\\nExternal sources of data\\nMetadata Repository Data Marts\\nQuery/Report Analysis Data Mining\\nTop tier:\\nFront end tools\\nMiddle tier:\\nOLAP Server\\nBottom tier:\\nDW Server'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 157}, page_content=' • Data mining: Data mining is about unravelling hidden patterns; spotting trends, etc. Anybody \\nwho has ever visited the Amazon site would have realized that the moment a person makes a \\nselection, suggestions such as “those who bought this book also bought…” show up. This is \\npossible owing to an analysis of customers buying behavior. Another example is that of market \\nbasket analysis. Those who bought bread also bought butter and eggs.\\n5.4.2 Business solutions\\nThe business solutions mentioned earlier are described below:\\n • Customer analytics: Customer analytics plays a vital role in predicting the customer’s behaviour, \\nhis/her buying pattern, etc. Essentially, customer analytics helps capture data about customer’s \\nbehaviour and enabling businesses to make decisions such as direct marketing or improving re-\\nlationships with customers (CRM). This analytics is supported by metrics to measure customer \\nloyalty, customer satisfaction, etc.\\n • Marketplace analysis: This analysis helps understand the marketplace better. It is about under-\\nstanding the customers, the competitors, the products, the changing market dynamics, etc. It is \\nperformed to answer questions such as “Whether the launch of product X in region A will be \\nsuccessful?”, “Will the customers be receptive to the launch of product X?”, “Should we discon-\\ntinue item Z?”, “Where should items A and B be placed on the shop shelves?”, etc.\\n • Performance analysis: This analysis facilitates optimum utilization of employees, finance, re-\\nsources, etc. Once you do the performance analysis of your employees, you will know about \\nthe employees that you will want to retain, the employees whom you want to reward, etc. The \\nperformance analysis of your business will provide clear insights into the areas that are a cause \\nfor concern and need your immediate attention.\\n • Behavior analysis: This analysis helps predict trends such as purchasing patterns, on-line buy-\\ning patterns (digital consumers), etc.\\n • Supply chain analytics: This analysis helps optimize the supply chain from planning → manufac-\\nturing → sales. Supply chain analytics helps spot trends, identify problems and opportunities in the \\nsupply chain functions such as sourcing, inventory management, manufacturing, sales, logistics, etc.\\n • Productivity analysis: In economics, productivity is defined as the ratio of output produced per \\nunit of input. Productivity can be affected by several factors such as workforce efficiency, product \\nquality, process documentation, resources availability, some external influences, etc. This analysis is \\naimed at enhancing the enterprise profitability. In order to perform productivity analysis, the orga-\\nnization will need to collect data, perform aggregations/summarizations, compare the actual against \\nthe estimated or planned, etc. It is based on business metrics that enables the enterprise to increase its \\nprofitability. Productivity analysis goes a long way in evaluating the performance of the enterprise.\\n • Sales channel analysis: This analysis will help decide the best channel for reaching out your \\nproduct/services for use or consumption by the customers/consumers. A good “marketing mix” \\ncomprises 4 Ps: Product, Price, Place (distribution), and Promotion. An enterprise on road to \\nachieving profitability will consider all the 4 Ps. It will decide on “what product to produce”, \\n“what services to offer”, etc. It will decide on the price – “when to increase/decrease the price \\nof the product or service”, etc. It will decide on how to distribute/reach out to the customers \\nwith its products or service. It will decide on how to offer the product/service – “whether in a \\nphysical store or through an online virtual store”, etc. It will also look at promotion – “personal \\nselling”, “advertising”, etc. The sales channel analysis provides insights that help decide which \\nsales  channel are the most profitable and which sales channel should be done away with.\\nBI Definitions and Concepts • 133'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 158}, page_content='134 • Fundamentals of Business Analytics\\nConnect Me (Internet Resources)\\n • http://www.tdwi.org\\n • http://www.infosys.com/offerings/industries/high-technology/white-papers/\\nDocuments/supply-chain-analytics.pdf\\n • http://en.wikipedia.org/wiki/Customer_analytics\\nRemind Me\\n•   BI applications can be divided into technol-\\nogy solutions and business solutions.\\n•   Examples of technology solutions: DSS, EIS, \\nmanaged query and reporting, data mining, etc.\\n•   Examples of business solutions: customer analyt-\\nics, marketplace analysis, behaviour analysis, sales \\nchannel analytics, productivity analysis, etc.\\n • Multidimensional data is the lifeline of OLAP \\nsystems.\\n • EIS is a specialized version of DSS, meant \\nto assist senior executives in their decision \\nmaking.\\n • Productivity analysis is performed to help the \\nenterprise increase its profitability.\\n • Marketplace analysis helps understand the \\ncustomers, the competitors and the market \\ndynamics, etc.\\nTest Me Exercises\\nMatch me\\nEssentially for senior management DSS\\nHelps in operational tasks EIS\\nHelps optimize supply chain functions Customer analytics\\nIs the ratio of output produced per unit of work Supply chain analytics\\nHelps in improving relationship with customers Productivity\\nColumn A Column B'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 159}, page_content='5.5 Bi roLes and responsiBiLities\\nBI roles can be broadly classified into two categories – program roles and project roles – as listed in Table 5.3. \\nFor a BI project to succeed, one requires executive level sponsorship. It should be backed by the senior \\nleadership of the organization. This level of sponsorship will garner enough support from all the related \\nproject teams and will also be responsible to generate/allocate the requisite funds.\\nThe program team lays down the strategy of how the BI project will execute. The program team \\nmembers are responsible for coordination and integration. The project team executes the program \\nteam’s strategy.\\n5.5.1 Bi program team roles\\nBI Program Manager\\nThe BI program manager is responsible for several projects. He etches out the BI strategy. The following \\nare the key responsibilities of the BI program manager:\\nSolution:\\nEssentially for senior management EIS\\nHelps in operational tasks DSS\\nHelps optimize supply chain functions Supply chain analytics\\nIs the ratio of output produced per unit of work Productivity \\nHelps in improving relationship with customers Customer analytics\\nColumn A Column B\\nTable 5.3 T wo categories of BI roles\\nBusiness Manager\\nBI Program Manager BI Business Specialist\\nBI Data Architect BI Project Manager\\nBI ETL Architect Business Requirements Analyst\\nBI T echnical Architect Decision Support Analyst\\nMetadata Manager BI Designer\\nBI Administrator ETL Specialist\\nData Administrator\\nProgram Roles Project Roles\\nBI Definitions and Concepts • 135'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 160}, page_content='136 • Fundamentals of Business Analytics\\n • The program manager has a clear understanding of the organization’s strategic objective and \\naligns the objectives of the BI project with it.\\n • He explicitly defines metrics to measure and monitor the progress on each objective/goal.\\n • He plans and budgets the projects, distributes tasks, allocates/de-allocates resources, and follows \\nup on the progress of the project.\\n • He identifies measures of success.\\n • He measures success/ROI.\\nBI Data Architect\\nThe BI data architect\\n • Owns accountability for the enterprise’s data.\\n • Ensures proper definition, storage, distribution, replication, archiving, and management of data.\\nHe not only optimizes data for current usage but also takes into account the future needs in both design \\nand content.\\nBI ETL Architect\\nFor building a data warehouse, data needs to be extracted from multiple disparate sources. An ETL \\narchitect has the responsibility of\\n • Determining the optimal approach for obtaining data from different operational source systems/\\nplatforms and loading it into the data warehouse.\\n • T raining project ETL specialists on data acquisition, transformation, and loading.\\nBI T echnical Architect\\nThe chief responsibilities of a BI technical architect are\\n • Interface with operations staff.\\n • Interface with technical staff.\\n • Interface with DBA staff.\\n • Evaluate and select BI tools (ETL, analysis and reporting tools, etc).\\n • Assess current technical architecture.\\n • Estimate system capacity to meet near- and long-term processing requirements.\\n • Define BI strategy/processes for\\n \\x83 Definition of technical architecture for BI environment.\\n \\x83 Hardware requirements.\\n \\x83 DBMS requirements.\\n \\x83 Middleware requirements.\\n \\x83 Network requirements.\\n \\x83 Server configurations.\\n \\x83 Client configurations.\\n • Define the strategy and process for data back-up and recovery, and disaster recovery.\\nMetadata Manager\\nMetadata is “data about data”. Metadata helps understand data. The metadata manager keeps track of \\nthe following activities:'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 161}, page_content=' • Structure of data (technical metadata).\\n • Level of details of data.\\n • When was the ETL job performed? (ETL audit)\\n • When was the data warehouse updated?\\n • Who accessed the data and when? (Application metadata)\\n • What is the frequency of access? (Application metadata)\\nBI Administrator\\nThe BI administrator has the following set of responsibilities:\\n • Design and architect the entire BI environment.\\n • Architect the metadata layer.\\n • Monitor the health/progress of the entire BI environment.\\n • Manage the security of the BI environment.\\n • Monitor all scheduled jobs such as ETL jobs, scheduled reports for business users, etc.\\n • Monitor and tune the performance of the entire BI environment.\\n • Maintain the version control of all objects in the BI environment.\\n5.5.2 Bi project team roles\\nBusiness Manager\\nThe business manager plays the role of monitoring the project team from the user group perspective. \\nThe roles performed by him/her can be listed as follows:\\n • T o act as the sponsor representing the user group (the target customer of the project).\\n • Monitoring the activities of project team.\\n • Addressing the business issues identified by the project manager.\\nBI Business Specialist\\nEach project team requires at-least one FTE (Full Time Employee) resource having expertise in the busi-\\nness area of focus. BI business specialist helps in identifying the suitable data usage and structure for the \\nbusiness functional area. The knowledge of BI specialist ensures that\\n • Information is identified correctly at the required level itself.\\n • All the modes of accessing and analyzing data are enabled.\\nThe BI business specialist is also the lead in data stewardship and quality programs.\\nBI Project Manager\\nThe BI project manager takes up the responsibility of leading the project and ensuring delivery of all \\nproject needs. Also, the project manager translates business needs into technical terms and ensures \\nadherence to all business standards and BI processes. It is the BI project manager’s responsibility to\\n • Understand existing business processes.\\n • Analyze existing decision support and executive information systems to understand their  \\nfunctionality.\\n • Understand subject matter.\\nBI Definitions and Concepts • 137'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 162}, page_content='138 • Fundamentals of Business Analytics\\n • Anticipate and judge what users will/may want.\\n • Manage expectations of the project.\\n • Scope an increment.\\n • Develop project plan for an increment/project.\\n • Motivate team members.\\n • Evaluate team members.\\n • Assess risk.\\n • Manage expectations.\\n • Understand information architecture.\\n • Understand technical architecture.\\n • Manage project.\\n • Coordinate with the program manager to ensure standards.\\n • Coordinate with other project managers.\\n • Understand organizational architecture.\\n • Implement warehousing specific standards.\\n • Communicate with all other team members.\\nBusiness Requirements Analyst\\nThe business requirements analyst maintains a synchronized handshake between the end-users and the \\nBI project team, and performs requirements gathering. It is the business requirements analyst’s respon-\\nsibility to\\n • Question the end-users to determine requirements keeping in view all the aspects like data, \\nreports, analyses, metadata, performance, etc.\\n • Work with architects to transform requirements into technical specifications.\\n • Document requirements.\\n • Help identify and assess potential data sources.\\n • Recommend appropriate scope of requirements and priorities.\\n • Validate that BI meets requirements and service-level agreements.\\n • Coordinate prototype reviews.\\n • Gather prototype feedback.\\nDecision Support Analyst\\nA decision support (DS) analyst is an individual who helps encounter issues and supports DSS. The DS \\nanalyst is an expert on issues surrounding business objectives, questions, and problems, and in obtain-\\ning and presenting the required data to address the same issues.\\nThe DS analyst creates data results using several techniques and tools from firing basic queries to \\nmultidimensional analyses and data mining, making new relations and/or derivations as may seem fit. \\nHe/she also makes an attempt at extracting the maximum amount of valid information. It is the DS \\nanalyst’s responsibility to\\n • Educate users on warehousing capabilities.\\n • Analyze business information requirements.\\n • Design training infrastructure.\\n • Discover business transformation rules.\\n • Work with production data to validate business requirements.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 163}, page_content=' • Map the requirements to suit the business functional model.\\n • Create state transformation models.\\n • Discover dimension hierarchies.\\n • Validate hierarchies with production data.\\n • Define business rules for state detection.\\n • Classify business users by type.\\n • Define and have an agreement with business users, and base it on service-level agreement.\\n • Develop security rules/standards.\\n • Create data results through several techniques and tools.\\n • Develop necessary reports.\\n • Develop decision support and EIS applications.\\n • Develop Internet and intranet delivery applications.\\n • Convert existing reporting applications to the environment.\\n • Develop new periodic report applications.\\n • Develop training materials.\\n • Write users’ guide.\\n • Plan acceptance test.\\n • Execute acceptance test plan.\\n • T rain BI users.\\n • Implement support plan.\\n • Assist users in finding the right information.\\n • Interface with process teams regarding business process reengineering.\\nBI Designer\\nThe BI designer aims at designing the data structure for optimal access, performance, and integration. \\nDesigning essentially plays a key role while building new data sets as required for supporting the busi-\\nness needs.\\nThe designer must maintain the balance of needs in both design and content, and must always keep \\nboth the current and future demands in mind to judge and foresee. The works of the BI designer and \\nBI data architect are closely knit, which ensures compliance of all standards, consistency of the project \\nand other information architecture deliverables. The responsibilities of the BI designer are\\n • Create a subject area model.\\n • Create or review the business enterprise model.\\n • Interpret requirements.\\n • Create a logical staging area model.\\n • Create a structural staging area model.\\n • Create a physical staging area model.\\n • Create logical distribution model.\\n • Create a structural distribution model.\\n • Create a physical distribution model.\\n • Create a logical relational model.\\n • Create a structural relational model.\\n • Create a physical relational model.\\n • Create a logical dimensional model.\\nBI Definitions and Concepts • 139'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 164}, page_content='140 • Fundamentals of Business Analytics\\n • Create a structural dimensional model.\\n • Create a physical dimensional model.\\n • Validate models with production data.\\n • Develop processes to maintain and capture metadata from all BI components.\\nETL Specialist\\nBefore implementing any extraction, a proper and apt technique has to be finalized for the process. This \\nis where the ETL specialist comes in to determine and implement the best technique for extracting. \\nCollaboration between the ETL specialist and the ETL architect ensures compliance of all standards \\nand deliverables which enhances the consistency and longevity of infrastructure plans. It is the ETL \\nspecialist’s responsibility to\\n • Understand both the source and the target BI systems.\\n • Identify data sources.\\n • Assess data sources.\\n • Create source/target mappings.\\n • Apply business rules as transformations.\\n • Implement navigation methods/applications.\\n • Design and specify the data detection and extraction processes to be used.\\n • Design and develop transformation code/logic/programs for environment.\\n • Design and develop data transport and population processes for environment.\\n • Build and perform unit test data transformation processes for environment.\\n • Build and perform unit test source data transport and population processes for environment.\\n • Work with production data to handle and enhance data conditions and quality.\\n • Design data cleanup processes.\\n • Adapt ETL processes to facilitate changes in source systems and new business user requirements.\\n • Define and capture metadata and rules associated with ETL processes.\\n • Coordinate with the program-level ETL architect.\\nDatabase Administrator\\nThe database administrator (DBA) is like a guardian of the data and data warehouse environment. He/\\nshe keeps check on physical data that is appended to the existing BI environment under current project \\ncycle. The DBA works closely with the metadata manager to measure and speculate on the alterations \\ndone to BI and efficiency of the processes of the BI environment. It is the DBA’s responsibility to\\n • Design, implement, and tune database schemas.\\n • Conduct regular performance testing and tuning.\\n • Manage storage space and memory.\\n • Conduct capacity planning.\\n • Create and optimize physical tables and partitions.\\n • Implement all models, including indexing strategies and aggregation.\\n • Manage user accounts and access privileges.\\n • Implement vendor software patches.\\n • Analyze usage patterns and downtime.\\n • Administer tables, triggers, etc.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 165}, page_content=' • Log technical action reports.\\n • Document configuration and integration with applications and network resources.\\n • Maintain backup and recovery documentation.\\n5.6 Best praCtiCes in Bi/dW\\nFollowing is a list of best practices adapted from an article in TDWI’s FlashPoint e-newsletter of April \\n10, 2003:\\n • Practice “user first” design: We can gain value from BI/DW products only when they are used \\nby the end-users for whom they have been designed. The first thing to cash in on will be an \\nimpeccable “user experience”. There ought to be “no compromises here!” BI solutions should \\nbe designed to fit seamlessly into the scheme of day-to-day business activities. The design has \\nto help the end-users to be more productive. It has to improve the usability of the system and \\nthereby greater acceptance by the users. In other words, the “user first” design has to change the \\ndesign aim from “users should use it” to “users want to use it”.\\n • Create new value: BI projects are costly endeavors. Therefore, a BI project cannot be just left \\nat extracting and storing the data in the enterprises data warehouse. It should lead to business \\nConnect Me (Internet Resources)\\n • http://www.tdwi.org\\n • Beye Network\\nRemind Me \\n•   BI roles can be broadly divided into two cat-\\negories: program roles and project roles.\\n•   The database administrator is like a guardian \\nof the data and data warehouse environment.\\n • The ETL specialist determines and imple-\\nments the best technique for data extraction.\\n • The BI designer aims at designing the data \\nstructure for optimal access, performance, \\nand integration.\\n • The business requirements analyst maintains \\na synchronized handshake between the end-\\nusers and the BI project team and performs \\nrequirements gathering.\\n • The BI data architect owns the accountability \\nfor the organization’s data.\\n • For a BI project to succeed, executive-level \\nsponsorship is necessary.\\n • A BI program manager is responsible for sev-\\neral projects.\\nBI Definitions and Concepts • 141'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 166}, page_content='142 • Fundamentals of Business Analytics\\nvalue addition. The key point here is that businesses should benefit by investing in BI/DW . A \\nBI solution should be able to impact the business in a positive way. It has to have this positive \\nimpact on all strata of the organization. Besides improving the day-to-day business in terms of \\nimproved productivity, reduced operational costs, etc., it should also assist the organization in \\nrealizing their strategic objectives in a timely manner.\\n • Attend to human impacts: BI projects are known to be less technology-centric and more \\n people-centric. BI supports decision making at the strategic, tactical, and operational levels. It \\nstarts with those who define and articulate strategies to those who help in carrying out day-to-\\nday operations. For its successful implementation, it needs a persistent tight handshake between \\nthe two communities: business users and IT personnel. It requires new skills, an adaptive mind-\\nset, etc. It promises a new experience.\\n • Focus on information and analytics: The transformation of raw data to business benefits \\nthrough BI may be depicted as\\nData → Information → Knowledge → Insights → Impact\\nRaw data over time needs to be transformed into meaningful information. The information \\nneeds to be mined to provide adequate knowledge. The knowledge gained will lead to clearer \\ninsights into the running of the business. This will help in making correct and accurate deci-\\nsions that can lead to huge impacts. Success of a BI/DW initiative relies heavily on analytics \\n(obtaining an optimal and realistic decision based on existing data) and reporting (drill down, \\ndrill through, roll-ups, etc.). The basic querying, reporting, OLAP , and alert tools can provide \\nanswers to questions such as “What happened?”, “Where does the problem lie?”, “How many \\nhave been impacted?”, “How often does it happen?”, etc. Business analytics can provide answer \\nto questions such as “Why is this happening?”, “What will happen next (i.e., predicting)?”, \\n“What is the best that can happen (that is, optimizing)?”, etc.\\n • Practice active data stewardship: Information is created out of data. Good data begets good \\nmeaningful information. And what is “good data”. Good data is “data of quality”. Good data \\nis created by implementing sound data management and metadata management techniques. It \\nis a result of a diligent act of data cleansing and purifying. Data governance is a quality regime \\nthat can be religiously implemented to ensure the accuracy, correctness, and consistency of data. \\nPractice of active data stewardship rings in accountability and thereby enhances the trust and \\nconfidence on data.\\n • Manage BI as a long-term investment: BI projects should be looked at as something that yields \\ngood returns in the long term. Although, small wins are possible and often times experienced, \\nit is a sustainable BI program that should be the focus. It is not a roller-coaster ride that one \\nshould be concerned with, but rather consistent supply of useful information, good analytics, \\nand visible measurable impact.\\n • Reach out with BI/DW solutions: Extend the reach of BI/DW as far as possible. Each busi-\\nness function/process that uses BI is a potential candidate to provide business value. BI being a \\npeople-centric program, the same is true in the case of every business user or IT personnel who \\nuses BI. BI should not be confined only to the boardroom. Organizations have benefitted and \\nwill benefit by implementing BI at all levels.\\n • Make BI a business initiative: BI projects are usually expensive. Businesses have to invest in \\nBI. Besides requiring an executive-level sponsorship, BI relies heavily on accountability. There \\nhas to be accountability for data management, metadata management, data stewardship, etc. In '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 167}, page_content='BI space, it is business first and technology second. T echnology supports BI; it cannot create BI. \\nThe IT folks have to be brought around to appreciate the positive impact of BI. Focus should be \\non leveraging technology to support BI.\\n • Measure results: Businesses that have been able to reap benefits from data analytics have reli-\\ngiously employed effective metrics. They have unfailingly been measuring the TCO (total cost \\nof ownership), TVO (total value of ownership), ROI (return on investment), ROA (return on \\nasset), etc. and used the results to further enrich their business gains. Better metrics mean a bet-\\nter handle on the business and better management and control.\\n • Attend to strategic positioning: The need for BI was born out of a few necessities. BI was brought \\nin to endure changing markets, changing workforce, changing technologies, changing regulations, \\netc. These external forces drove businesses to adopt BI. BI/DW programs were devised to provide \\na foundation to align information technology to business strategies. It is very important to under-\\nstand the need for BI in an organization and leverage it for impactful business benefits.\\nConnect Me (Internet Resources)\\n • http://www.tdwi.org/\\n • TDWI’s FlashPoint e-newsletter of April 10, 2003.\\nTest Me Exercises\\nFill me\\n1.  Data → Information → _______ → Insights \\n→ _______.\\n2.  In BI space it is _______ first and _______ \\nnext.\\n3. TCO is _______.\\n4. ROA is _______.\\n5. TVO is _______.\\n6. Success of BI relies on good _______ and \\n_______.\\nBI Definitions and Concepts • 143\\nRemind Me \\n•   BI is for all and not just for the senior manage-\\nment.\\n•   Focus on leveraging technology to support BI  \\ninitiatives.\\n•   BI is for the long run. Make it into a business \\ninitiative.\\n • Good data is created by sound data manage-\\nment and metadata management.\\n • In BI space, it is business first and technology \\nsecond.\\n • Better metrics mean a better handle on the \\nbusiness and better management and control.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 168}, page_content='144 • Fundamentals of Business Analytics\\n5.7 the CompLete Bi proFessionaL\\nLet us look at what skills are required in a BI professional. We present below a list of disciplines associ-\\nated with BI and we recommend that a budding professional should have a broad knowledge of all the \\ndisciplines, i.e. a view at the “big picture”, and should aim for specialization in a few of them. Here’s our \\nlist:\\n • Data modeling.\\n • Metadata management.\\n • Data quality.\\n • Data governance.\\n • Master data management.\\n • Data integration.\\n • Data warehousing.\\n • Content management.\\n • Enterprise information management.\\n • Business intelligence.\\n • Business analytics.\\n • Performance management.\\nFor ease of understanding, we have grouped together disciplines which complement each other in Table 5.4.\\nSolution:\\n1. Knowledge, impacts\\n2. Business, technology\\n3. T otal cost of ownership\\n4. Return on assets\\n5. T otal value of ownership\\n6. Analytics and reporting\\nTable 5.4 Grouping of disciplines that complement each other\\nT o identify, understand, and discern data Data modeling and metadata management: Data modeling entails \\nmetadata management. Metadata, previously called Data Dictionary, \\nis a collection of definitions and relationships that describe the \\ninformation stored. It is “data about data”. The storage and access of \\nmetadata information is as important today as it was earlier.\\nT o govern data quality and information \\ndelivery\\nData quality and data governance: Good decisions are based on \\nquality data. Data governance is a quality regime that includes ensuring \\naccuracy, consistency, completeness, and accountability of data.\\nT o consolidate data from disparate data \\nsources\\nMaster data management, data integration, and data warehousing: \\nConsolidation and integration of data extracted from varied operational \\ndata sources spread across companies and across geographies and \\nmore likely existing in varied formats, transformation of data, and the \\neventual loading into a common repository is called data warehouse.\\n(Continued)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 169}, page_content='T o manage the supply and demand of data Content management and enterprise information management: \\nThey are the means to manage the information that is available \\n(supply), the information that is required (in demand), and the gap \\nthat exists between the demand and supply. \\nT o measure, monitor and manage \\nperformance: “You cannot manage what you \\ncannot measure, and you cannot measure \\nwhat you cannot define.”\\nBusiness intelligence, business analytics, and performance \\nmanagement: Good metrics help in measuring and managing \\nperformance. KPIs (Key Performance Indicators) are metrics or \\nmeasures that help an organization measure its performance and its \\nsubsequent progress towards its strategic objectives. These KPIs can \\neither be quantifiable or non-quantifiable. A few examples of good \\nKPIs are:\\n • Market share\\n • Market growth\\n • Customer satisfaction\\n • Customer churn rate\\n • Customer retention\\n • Customer profitability\\nT o gain insight and foresight Data mining and predictive analytics: Predictive analytics is about \\nanalyzing the present and historical data to make predictions for \\nthe future. It is about unravelling hidden patterns and trends. One \\nof the very famous examples of predictive modeling is Customer \\nCredit Scoring. Here, the scoring models take into consideration the \\ncustomer’s credit history, his loan application(s), other details about \\nthe customer to rank-order individuals by their likelihood of making \\ntheir future credit card payments on time.\\nAnother example is spotting the “cross-sell” opportunities by analysing \\nthe customers buying patterns.\\nTable 5.4 (Continued)\\nRemind Me\\n•   Metadata is “data about data”.\\n•   Data governance is quality control mecha-\\nnisms employed for accessing, modifying, \\nimproving, moni to ring, managing, assessing, \\nprotecting, using, and maintaining corporate \\ndata.\\n • KPIs can be quantifiable or non-quantifiable.\\n • Good metrics assist in measuring the perfor-\\nmance of the organization.\\n • Predictive analytics is about predicting the \\nfuture based on the analysis of current and \\nhistorical data.\\n • Enterprise information management helps \\nmanage the supply and demand of data.\\nBI Definitions and Concepts • 145'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 170}, page_content='146 • Fundamentals of Business Analytics\\n5.8 popULar Bi tooLs\\nSome of the popular vendors for BI tools are mentioned below as well as depicted in Figure 5.9.\\nRDBMS\\n • Netezza 4.6\\n • NCR T eradata 13\\n • Sybase IQ (DWH & BI RDBMS)\\n • Oracle 11g (Oracle 11g Release 2)\\n • Microsoft SQL Server 2008\\n • DB2 Connector 9.7\\nETL Tools\\n • Informatica 9\\n • IBM’s Data Stage 8.5\\n • Ab Initio 3.0.2\\n • Microsoft SQL Server Integration Services SSIS 2008\\nAnalysis Tools\\n • IBM’s SPSS 9\\n • SAS 9.2\\n • Microsoft SQL Server Analysis Services SSAS 2008\\n • Spotfire(tibco) 3.2.x\\n • Oracle’s Hyperion 11.1.3\\n • Oracle’s Essbase\\nConnect Me (Internet Resources)\\n • http://tdwi.org/articles/2011/01/05/complete-bi-professional.aspx\\nTest Me Exercises\\nFill me\\n1.  _______ are measures that help an organiza-\\ntion measure its performance.\\n2.  _______ is a quality regime to ensure the \\naccuracy, consistency, and completeness of \\ndata.\\n3. _______ helps unravel hidden patterns and \\nspot trends in historical data.\\nSolution:\\n1. KPIs\\n2. Data governance\\n3. Data mining'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 171}, page_content='Reporting/Ad Hoc Querying Tools/Visualization\\n • Microstrategy 9\\n • SAP’s Business Objects 5.x\\n • IBMS’s Cognos V10\\n • Microsoft SQL Server Reporting Services SSRS 2008\\n • Siebel Answers (7.5.3) Siebel 8.1(2008)\\nOpen Source Tools\\nRDBMS MySQL, Firebird\\nETL tools Pentaho Data Integration (formerly called Kettle), SpagoBI\\nAnalysis tools Weka, RapidMiner, SpagoBI\\nReporting  /Ad hoc querying tools/ Visualization Pentaho, BIRT , Actuate, Jaspersoft\\nFigure 5.9 Popular BI tools.\\nMICROSOSFT\\nSYBASE IQ BUSINESS\\nOBJECTS 5.x\\nORACLE\\nORACLE 11G R2 HYPERION 11.1.3\\nNETEZZA 4.6, DB2  SPSS 9\\nPENTAHO\\nWEKA\\nDBMS ETL, DATA\\nINTEGRATION\\nOLAP,\\nDATA WAREHOUSING\\nREPORTING,\\nAD HOC QUERYING ANALYSIS\\nANALYTICS,\\nVISUALIZATION,\\nMINING\\nBack EndF ront EndBI Functions\\nIBM\\nDATASTAGE 8.5 COGNOS v10\\nORACLE WAREHOUSE BUILDER\\nSQL SERVER 2008 SSIS 2008 SSRS 2008 SSAS 2008\\nSAP\\nSIEBEL 8.1\\nNCR TERADATA 13\\nINFORMATICA 9\\nMICROSTRTEGY 9\\nSAS 9.2\\nSAP\\nAB IINITIO 3.0.2 SPOTFIRE (TIBCO) 3.2.x\\nBIRT\\nRAPIDMINER\\nMYSQL\\nBI Definitions and Concepts • 147'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 172}, page_content='148 • Fundamentals of Business Analytics\\nUnsoLved exerCises\\n1. Describe the business intelligence framework.\\n2. Assume you are a project manager who has been sent to collect business requirements for a retail \\nchain. Give a few examples of business requirements that you would have collected.\\nRemind Me \\n•   Popular RDBMS: Oracle 11g, Sybase, MS Sql \\nServer 2008, Netezza, MySQL, etc.\\n•   Popular ETL tools: Ab initio, Informatica, \\nSSIS 2008, Data Stage, etc.\\n•   Popular Reporting tools: Cognos, Microstrat-\\negy, Business Objects, SSRS 2008, etc.\\n • Popular Analysis tools: SPSS, Weka, Rapid-\\nMiner, SSAS 2008, SAS, Spotfire, etc.\\nTest Me Exercises\\nFill me\\n1.  _______ and _______ are open source tools \\nfor analysis.\\n2.  _______ is an open source tool for ETL/data \\nintegration.\\n3. _______ is an open source tool for report-\\ning.\\n4. _______ is an open source RDBMS.\\n5. _______ is IBM’s tool for ETL/data integra-\\ntion.\\n6. _______ is IBM’s tool for reporting.\\n7. Netezza is a product of _______ company.\\nSolution:\\n1. Weka and RapidMiner\\n2. Pentaho Data Integration tool formerly \\ncalled “Kettle”\\n3. Pentaho\\n4. MySQL\\n5. DataStage\\n6. Cognos\\n7. IBM\\nConnect Me (Internet Resources)\\n • http://www.squidoo.com/osbi'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 173}, page_content='3. Mention a few BI tools in each of the following categories:\\na. ETL\\nb. Databases that can support data warehouse\\nc. Reporting\\nd. Business data analytics\\n4. What is metadata? Explain giving examples.\\n5. Why is maintaining the quality of data important?\\n6. How can BI be used to enhance customer experience? Explain with an example.\\n7. How can BI lead to performance enhancement. Explain with an example.\\n8. What do you understand by the term “business value”?\\n9. What is “T otal Cost of Ownership (TCO)”?\\n10. Explain your understanding of the data warehouse.\\n11. Explain the various components of BI architecture.\\n12. Give examples to explain the various types of metadata: business metadata, application meta-\\ndata, technical metadata, and process metadata.\\n13. What type of metadata is stored in the structure given in Table 5.5?\\nTable 5.5 Unsolved Exercise 13\\nColumn Name Data Type and Length Description\\nProjectID Integer Primary Key\\nProjectName Varchar(35) Unique\\nNoofPersons Integer\\nProjectManager Varchar(50) Not Null\\nProjectClient Varchar(35)\\nProjectLocation Varchar(35)\\nProjectStartDate Date Not Null\\nProjectEndDate Date Not Null\\nColumn Name Constraints\\n14. Picture this scenario: There is an online application to buy and sell used cars. The website owner \\nwould like to have answers to the following :\\na. How many visitors visit the website in a day?\\nb. What time of the day there is maximum traffic on the website?\\nc. What time of the day minimum hits happen on the website?\\nd. Do the visitors directly come in through the landing page?\\n What type of metadata is presented in the scenario above?\\n15. Picture this scenario: An enterprise has an enterprise-wide data warehouse. The data architect \\nhas the responsibility of maintaining the data warehouse. The data warehouse is periodically \\nupdated asynchronously. The data architect keeps track of the ETL process – When was it done? \\nWas it an incremental update to the data warehouse?, etc. What according to you is the type of \\nmetadata that the data architect is maintaining?\\nBI Definitions and Concepts • 149'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 174}, page_content='150 • Fundamentals of Business Analytics\\n16. What is cross-sell? Explain with an example.\\n17. What is up-sell? Explain with an example.\\n18. Explain the following terms with an example each:\\na. Customer analytics\\nb. Productivity analysis\\nc. Supply chain analysis\\n19. Provide your understanding of master data management.\\n20. Differentiate between casual users and power users.\\n21. State two BI applications.\\n22. Give two key functionalities of the business requirements analyst.\\n23. Explain three best practices to be followed in the BI space.\\n24. Mention one open source tool for each of the following categories:\\na. ETL\\nb. RDBMS\\nc. Reporting\\nd. Analysis\\n25. What skills should a BI professional possess?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 175}, page_content='What’s in store\\nWe assume that you are familiar with the basics of RDBMS concepts and associated terminologies. We \\nhope that the previous chapters have given you the necessary start in BI. This chapter deals with the \\ngeneral concepts of data integration with respect to data warehousing. It will familiarize you with the \\nconcept of ETL (Extract, T ransform, Load) in the context of data warehousing, and the importance of \\ndata profiling and quality.\\nWe have taken up a sample data set as a case study that will help you relate to the concepts being \\ndiscussed in this chapter and gain a better understanding of the subject.\\nWe recommend you to attempt the “T est Me” and “Challenge Me” exercises at the end of this chap-\\nter to re-enforce the concepts learnt in this chapter. A few books and on-line references have also been \\nlisted at the end. They may be referred to for additional reading.\\nBrief Contents\\nWhat’s in Store\\nNeed for Data Warehouse \\nDefinition of Data Warehouse \\nWhat is a Data Mart?\\nWhat is Then an ODS? \\nRalph Kimball’s Approach vs.  \\nW .H. Inmon’s Approach \\nGoals of a Data Warehouse \\nWhat Constitutes a Data Warehouse?\\nExtract, T ransform, Load\\nWhat is Data Integration?\\nData Integration T echnologies \\nData Quality\\nUnsolved Exercises \\nData Profiling\\nSummary\\nA Case Study from the Healthcare Domain\\nSolved Exercises\\nUnsolved Exercises\\nBasics of Data Integration\\n6\\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 176}, page_content='152 • Fundamentals of Business Analytics\\n6.1 Need for data Warehouse\\nPicture this scenario…\\nThe Darbury Institute of Information T echnology (DIIT) is an engineering institution that conducts \\nengineering courses in Information T echnology (IT), Computer Science (CS), System Engineering \\n(SE), Information Science (IS), etc. Each department (IT , CS, SE, IS, etc.) has an automated library \\nthat meticulously handles library transactions and has good learning content in the form of books, CD/\\nDVDs, magazines, journals, several online references, etc. DIIT is also looking at expansion and is likely \\nto have its branches in all major cities.\\nThe only downside of the library data is that it is stored differently by different departments. One \\ndepartment stores it in MS Excel spreadsheets, another stores it in MS Access database, and yet another \\ndepartment maintains a .CSV (Comma Separated Values) file. The DIIT administration is in need of a \\nreport that indicates the annual spending on library purchases. The report should further drill down to \\nthe spending by each department by category (books, CDs/DVDs, magazines, journals, etc.). However, \\npreparing such a report is not easy because of different data formats used by different departments. Prof. \\nFrank (an expert on database technology) was called upon to suggest a possible solution to the problem \\nat hand. He feels it would be better to start archiving the data in a data warehouse/data mart. The argu-\\nments put forth by him in favor of a library data warehouse are\\n • Data from several heterogenous data sources (MS Excel spreadsheets, MS Access database, .CSV \\nfile, etc.) can be extracted and brought together in a data warehouse as depicted in Figure 6.1.\\n • Even when DIIT expands into several branches in multiple cities, it still can have one data ware-\\nhouse to support the information needs of the institution.\\n • Data anomalies can be corrected through an ETL package.\\n • Missing or incomplete records can be detected and duly corrected.\\n • Uniformity can be maintained over each attribute of a table.\\n • Data can be conveniently retrieved for analysis and generating reports (like the report on spend-\\ning requested above).\\n • Fact-based decision making can be easily supported by a data warehouse.\\n • Ad hoc queries can be easily supported.\\nFigure 6.1 Data from several heterogeneous data sources extracted and loaded in a data warehouse.\\nOperational data source\\nData\\nwarehouse\\nE\\n(Extraction)\\nT\\n(Transformation)\\nL\\n(Load)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 177}, page_content='Basics of Data Integration • 153\\nThe need for the data warehouse is now clear. In a general sense, it is a system which can  conveniently \\narchive data. This data can then be analyzed to make business decisions and predict trends. So, data \\nwarehousing is quite important for organizations. However, there still remains one question unan-\\nswered: Should all organizations go for a data warehouse, and what is an opportune time for an organi-\\nzation to go for data warehousing?\\nLet us take the example of a fictitious company by the name “AllFinances”. The 40-year-old company \\nis in the business of banking, finance, and capital markets. It has grown from 15 employees to 1,50,000 \\nemployees. The company has seen a stupendous rise in their use of enterprise applications − from 1 \\nenterprise application two decades back to 250 plus such applications today. All applications are not on \\nthe same technology. Few applications are on Mainframe, a few on Dot Net, a few on AS/400, and yet \\na few on Java platform. Most of the applications have their independent databases which are also varied. \\nA few have Oracle as the backend, and a few others have SQL Server 2008 or DB2 as the backend. We \\nhave a few others on MySQL. The organization has felt the need for homogeneity. It realizes the impor-\\ntance of integrating data from various enterprise applications existing in silos. The organization appreci-\\nates “single version of truth”. So, “AllFinances” very wisely has chosen to go in for data warehousing.\\nWe list below a few issues/concerns of data usage, which often prompt organizations to go for data \\nwarehousing. If your organization has also faced one or more of these issues, then it is ready for a data \\nwarehouse:\\n • Lack of information sharing: Information though available is not being shared between the \\nvarious divisions or departments. In our example of DIIT , assume there is a subject, “Funda-\\nmentals of software engineering” which is being offered by IT and IS departments. The students \\nof IT and IS departments should be able to access the learning contents on this subject from the \\nlibraries of both the departments. This is possible only if their libraries share the information. \\nIn yet another example from the retail industry, assume there are two departments (one selling \\nleather jackets and the other selling leather accessories) which have the same customers. Also \\nassume that these departments don’t disclose their information to each other. Both the depart-\\nments virtually elicit the same information from the customers. What could it mean for the \\nbusiness? Cross-selling opportunities in favor of the customers cannot be realized. And the quite \\nobvious result: the frustrated customer and loss of improved customer comprehensibility.\\nOn the flip side, let us look at a couple of benefits that can accrue from information shar-\\ning. One, it can provide cross-selling opportunities which in turn can lead to better customer \\nrelationship management. Example: You have just booked yourself on a flight from Delhi to \\nAmsterdam. Within a matter of hours, you receive a call from a cab service, “CabHelp”, of \\nAmsterdam, asking you if you would like to avail their services. In about the same time, “Hotel-\\nLuxury” places a call to you offering you to stay with them at discounted rates. A clear example \\nof cross-sell opportunities made possible because of your itinerary details being shared with \\n“CabHelp” and “HotelLuxury”.\\n • Lack of information credibility: Picture a board meeting of “AllFinances” company…. Alfred, \\na senior executive, presents a business metric X. Richard, another senior executive, is also sup-\\nposedly presenting the same business metric X. But the information provided by Alfred and \\nRichard does not seem to agree. This is because there is no single place where the data is housed. \\nEach (Alfred and Richard) is pulling the data from his own respective spreadsheets and each be-\\nlieves that his data is the most recent and accurate. The only entity confused is the BOARD!!!'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 178}, page_content='154 • Fundamentals of Business Analytics\\n • Reports take a longer time to be prepared: The general practice with the OLTP systems is to purge \\nolder data from transaction processing systems. This is done with the intention of controlling the \\nexpected response time. This purged data along with the current data make it to the data warehouse \\nwhere there is presumably less requirement to control expected response time. The warehouse data is \\nthen used to meet the query and reporting needs. Therefore it becomes difficult, if not impossible, to \\nfurnish a report based on some characteristic at a previous point in time. For example, it is difficult, if \\nnot impossible, to get a report that presents the salaries of employees at grade Level 6 as of the begin-\\nning of each quarter in 2003 because the transaction processing system has the data for the current \\nfiscal year. This type of reporting problem can be easily resolved if the enterprise implements data \\nwarehouse that can handle what is called the “slowly changing dimension” issue. The “slowly chang-\\ning dimension” is discussed in greater detail in Chapter 7, “Multidimensional Data Modeling”.\\n • Little or no scope for ad hoc querying or queries that require historical data: The operational \\nsystems of records do not archive historical data. The queries demanding the usage and analysis \\nof historical data either cannot be satisfied or take a long time. There are some pre-defined/pre-\\nexisting reports that work well but the transaction processing system has little or no support for \\nad hoc querying, particularly those requiring historical data. Picture this… A meeting of senior \\nmanagers is in progress. Decision has to be made on the launch of a new product in an exist-\\ning market in the next quarter, i.e. quarter IV of the fiscal year. The senior executives are going \\nthrough reports. The reports provide them with information on the sales figures of the existing \\nmarket in the quarter gone by, i.e. quarter III. One senior manager requests data for the last five \\nyears to compare the sales trends in quarter III. This has come as an ad hoc requirement and \\nthere is no report to support this. A report to satisfy the above query can be generated but it is \\nsure to take time in the absence of a data warehouse.\\n6.2 Definition of Data Warehouse\\nAccording to William H. Inmon, “A data warehouse is a subject-oriented, integrated, time variant and \\nnon-volatile collection of data in support of management’s decision making process.” Let us look at each of \\nthe terms used in the above definition more closely:\\n • Subject-oriented: A data warehouse collects data of subjects such as “customers”, “suppliers”, \\n“partners”, “sales”, “products”, etc. spread across the enterprise or organization. A data mart on \\nthe other hand deals with the analysis of a particular subject such as “sales”.\\n • Integrated: A typical enterprise will have a multitude of enterprise applications. It is not un-\\nlikely that these applications are on heterogeneous technology platforms. It is also not unlikely \\nthat these applications use varied databases to house their data. Few of the applications may exist \\nin silos. Few others may be sharing a little information between them. A data warehouse will \\nserve to bring together the data from these multiple disparate (meaning differing in the format \\nand content of data) sources after careful cleansing and transformation into a unified format to \\nserve the information needs of the enterprise.\\n • Time-variant: A data warehouse keeps historical data while an OLTP (On-Line T ransaction \\nProcessing) system will usually have the most up-to-date data. From a data warehouse, one can \\nretrieve data that is 3 months, 6 months, 12 months, or even older. For example, a transaction \\nsystem may hold the most recent address of a customer, whereas a data warehouse can hold all \\naddresses associated with a customer recorded, say, over the last five years.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 179}, page_content=' • Non-volatile: We have learnt earlier that transaction processing, recovery, and concurrency con-\\ntrol mechanisms are usually associated with OLTP systems. A data warehouse is a separate physi-\\ncal store of data transformed from the application data found in the operational environment.\\n6.3 What is a Data Mart?\\nPicture this…\\nThe “GoodsForAll” enterprise has successfully implemented an enterprise-wide data warehouse. This data \\nwarehouse has data collected for all the customers and sales transactions from every unit/division and subsid-\\niary in the business. The data warehouse true to its nature provides a homogenized, unified, and integrated \\nview of information. It has proved very useful to the “GoodsForAll” enterprise. The market research wing of \\nthe “GoodsForAll” enterprise wishes to access the data in the data warehouse. They have plans to execute a \\npredictive analytics application on the data stored in the data warehouse and look at how the analysis can \\nhelp provide better business gains. The data architect of the “GoodsForAll” enterprise has decided to create \\na data mart for the market research unit. A data mart is meant to provide single domain data aggregation that \\ncan then be used for analysis, reporting, and/or decision support. Data marts can be sourced from the \\nenterprise-wide data warehouse or can also be sourced directly from the operational/transactional systems. \\nThese data marts can also perform transformations and calculations on the data housed within. When com-\\npared to the data warehouse, data marts are restricted in their scope and business purpose.\\nIs it a good idea to go for a data mart for virtually every business process/event? The answer is “No”. \\nThis could result in several disparate and independent data marts. Chances are that it will become a \\nchallenge to ensure the single version of truth.\\n6.4 What is then an ODs?\\nAn “operational data store” (ODS) is similar to a data warehouse in that several systems around the enterprise \\nfeed operational information to it. The ODS processes this operational data to provide a homogeneous, \\n unified view which can then be utilized by analysts and report-writers alike for analysis and reporting.\\nAn ODS differs from an enterprise data warehouse in that it is not meant to store and maintain vast \\namounts of historical information. An ODS is meant to hold current or very recent operational data. \\nWhy is this required? Sometimes it is required to perform an instant analysis on the more recent data to \\nallow one to respond immediately to a given situation.\\nThere are cases where some enterprises use the ODS as a staging area for the data warehouse. This \\nwould mean that the integration logic and processes are built into the ODS. On a regular basis, the data \\nwarehouse takes the current processed data from the ODS and adds it to its own historical data.\\n6.5 ralPh KiMball ’s aPPrOach vs. W.h. inMOn’s aPPrOach\\nThere are two schools of thought when it comes to building a data warehouse.\\nAccording to Ralph Kimball, “A data warehouse is made up of all the data marts in an enterprise.” This \\nis a bottom–up approach which essentially means that an enterprise-wide data warehouse is a conflu-\\nence of all the data marts of the organization (Figure 6.2). Quite opposite to Kimball’s approach is the  \\ntop–down approach prescribed by W .H. (Bill) Inmon. According to Inmon, “A data warehouse is \\nBasics of Data Integration • 155'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 180}, page_content='156 • Fundamentals of Business Analytics\\na  subject-oriented, integrated, non-volatile, time-variant collection of data in support of management’s  \\n decisions.” Figure 6.3 depicts Inmon’s top–down approach.\\nNow, the question is: What decides whether an organization should follow Ralph Kimball’s approach \\nor should it go the Inmon’s way when it comes to building the enterprise data warehouse? Does the size \\nof the organization play a role in this decision? It has been found that small organizations will benefit \\nby building the data warehouse following the Kimball approach, whereas large organizations will find \\nInmon’s approach extremely lucrative. Let us dwell into the reason.\\nKimball’s approach is faster, cheaper, and less complex. Contrary to this, Inmon’s approach is more \\nexpensive and is a time-consuming slower process involving several complexities. However, it is able to \\nachieve the “single version of truth” for large organizations. Therefore, it is worth investment of time \\nand efforts. The single version of truth might be compromised in Kimball’s approach, and the reason is \\nvery obvious. If you have a large organization, you will have several independent data marts, with each \\ndata mart proclaiming to have the genuine corporate data. The confused entity here is the end-user!!! \\nHe has absolutely no idea which data mart to turn to.\\nLet us explain this with an example. Assume you are running a small business from your home. You \\ncan make do with the help of a single personal computer. Yes, you do realize the importance of keeping \\ndata organized and also the need to maintain historical data. There is, however, no question of the single \\nFigure 6.2 Ralph Kimball’s approach to building a data warehouse.\\n Data mart 1 Data mart 2 Data mart n\\nEnterprise data warehouse\\nFigure 6.3 Bill Inmon’s approach to building a data warehouse.\\nEnterprise data warehouse\\nData mart 1 Data mart 2 Data mart n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 181}, page_content='version of truth when a single person is running the show. Integration is also hardly the requirement. \\nPicture another scenario wherein we have a large corporate house, almost 2,00,000 employees, several \\nbusiness divisions within the enterprise, multifarious requirements, multiple perspectives, and multiple \\ndecisions to make. There is a clear need for integration of data. Large organizations rely heavily on the \\nsingle version of truth for effective decision making. Therefore, Inmon’s architecture looks more allur-\\ning to large organizations.\\n6.6 Goals of a Data Warehouse\\nThe prime goal of a data warehouse is to enable users’ appropriate access to a homogenized and compre-\\nhensive view of the organization. This in turn will support the forecasting and decision-making processes \\nat the enterprise level. Described below are the main goals of a data warehouse.\\n • Information accessibility: Data in a data warehouse must be easy to comprehend, both by the \\nbusiness users and developers alike. It should be properly labelled to facilitate easy access. The \\nbusiness users should be allowed to slice and dice the data in every possible way (slicing and dic-\\ning refers to the separation and combination of data in infinite combinations).\\n • Information credibility: The data in the data warehouse should be credible, complete, and of \\ndesired quality. Let us go back to the board meeting of “AllFinances” mentioned earlier. Suppose \\nin this meeting Alfred presents a business metric X. If Richard also presents the same business \\nmetric X, then the information provided by both Alfred and Richard should be consistent.\\n • Flexible to change: Business situations change, users’ requirements change, technology changes, \\nand tools to access data may also change. The data warehouse must be adaptable to change. Ad-\\ndition of new data from disparate sources or new queries against the data warehouse should not \\ninvalidate the existing information in the data warehouse.\\n • Support for more fact-based decision making: “Manage by fact” seems to be the buzzword \\nthese days. The data warehouse should have enough pertinent data to support more precise \\ndecision making. What is also required is that the business users should be able to access the \\ndata easily.\\n • Support for the data security: The data warehouse maintains the company’s confidential infor-\\nmation. This information falling into wrong hands will do more damage than not having a data \\nwarehouse at all. There should be mechanisms in place to enable the provision of information in \\nthe required format to only those who are supposed to receive it.\\n • Information consistency: Information consistency is about a single/consistent version of truth. \\nA data warehouse brings data from disparate data sources into a centralized repository. Users \\nfrom across the organization make use of the data warehouse to view a single and consistent \\nversion of truth.\\n6.7 What Constitutes a Data Warehouse?\\nData from the operational systems flow into the staging area where it undergoes transformation and  \\nis then placed in the presentation area from where it can be accessed using data access tools. Refer to  \\nFigure 6.4.\\nBasics of Data Integration • 157'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 182}, page_content='158 • Fundamentals of Business Analytics\\n \\nOperationalS ource SystemsD ata Staging DExtractL oad/uni23AF/uni2192/uni23AF/uni23AF/uni23AF/uni2192/uni23AF/uni23AFaata Presentation Data Access \\nArea Area Tools\\n/uni2190/uni23AF/uni23AF\\n • Operational source systems: These systems maintain transactional or operational data. They \\nare outside the data warehouse. There could be any number of such systems (similar or dispa-\\nrate) feeding data to the data warehouse. They may maintain little historical data. The queries \\nagainst such systems generally return an answer set (also called record set or result set) of one or \\nfew records.\\n • Data staging area: The data staging area comprises storage space for the data that has been \\n extracted from various disparate operational sources. It also consists of a set of processes related to \\ndata quality. There are three major processes popularly referred to as extraction, transformation, \\nand loading. The data staging area is off-limits from the business users and is not designed to \\nanswer queries however simple they may be, or to offer presentation services.\\n • Data presentation area: Data staging area is off-limits to the business users. But data presenta-\\ntion area is the interface or the front face of the data warehouse with which the business commu-\\nnity interacts via the data access tools. It is just a collection of integrated data marts. What does \\nthe term “integrated” imply? Consider an example of a bank system consisting of deposit and \\nwithdraw subsystems. It is likely that customer A (a person by the name Connors) of the deposit \\nsystem and Customer B of the loan system are one and the same person. Without integration \\nthere is no way to know this. What are data marts? They are just a subset of the data maintained \\nin the data warehouse, which is of value to a specific group of users. Furthermore, data marts \\ncan be either independent or dependent. Independent data marts are sourced directly from one \\nor more operational systems, or can be sourced from external information providers, or can be \\nsourced from data generated locally from within a department or unit or function. Dependent \\ndata marts, on the other hand, are sourced from enterprise data warehouses.\\nFigure 6.4 Operational Data Sources → Data Warehouse → Data Marts.\\nSales\\ndatabase\\nDW\\nstaging\\narea\\nProducts\\ndatabase\\nCustomer\\ndatabase ETL\\nETL ETL Data\\nwarehouse\\nETL\\nETL\\nOperational\\nApplications\\nData Marts'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 183}, page_content=' • Data access tools: Data access tools can be ad hoc query tools used to query the data presenta-\\ntion area. A data access tool can also be a reporting tool or a data modelling/mining application \\n(for trend analysis or prediction, etc.).\\n6.7.1 Data Sources\\n • Data sources (transaction or operational or external information providers) are the sources from \\nwhich we extract data.\\n • In data warehousing, we extract data from different disparate sources (heterogeneous sources \\nsuch as text files, .CSV files, .XLS files, .MDB files, etc.), transform this data into a certain for-\\nmat (unified/data warehouse format), and then load the data in data warehouse.\\n • The raw material for any data integration is provided by data sources.\\n • Data sources refer to any of the following types of source:\\n \\x83 Data storage Media (flat file, DBMS, etc.).\\n \\x83 Data organization (linked data in COBOL mainframes, normalized forms in RDBMS).\\n • The data in these data sources can be present in any format.\\n6.8 Extract, tranSform, LoaD\\nETL (Extract, T ransform, and Load) is a three-stage process in database usage, especially in data ware-\\nhousing. It allows integration and analysis of data stored in different sources. After collecting the data \\nfrom multiple varied sources (extraction), the data is reformatted (from host format to warehouse \\nformat) and cleansed (to detect and rectify errors) to meet the information needs (transformation) and \\nthen sorted, summarized, consolidated, and loaded into desired end target (loading). Put simply, ETL \\nallows creation of efficient and consistent databases. So we can say, ETL is\\n • Extracting data from different data sources.\\n • T ransforming the extracted data into a relevant format to fit information needs.\\n • Loading data into the final target database, usually a data warehouse.\\nFigure 6.5 shows the intermediate stages of ETL.\\n6.8.1 Data mapping\\n • It is a process of generating data element mapping between two distinct data models.\\n • It is the first process that is performed for a variety of data integration tasks which include\\n \\x83 Data transformation between data source and data destination.\\n \\x83 Identification of data relationships.\\n \\x83 Discovery of hidden sensitive data.\\n \\x83 Consolidation of multiple databases into a single database.\\n6.8.2 Data Staging\\n • A data staging area can be defined as an intermediate storage area that falls between the opera-\\ntional/transactional sources of data and the data warehouse (DW) or data mart (DM).\\nBasics of Data Integration • 159'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 184}, page_content='160 • Fundamentals of Business Analytics\\n • A staging area can be used, among others, for the following purposes:\\n \\x83 T o gather data from different sources ready to be processed at different times.\\n \\x83 T o quickly load information from the operational database.\\n \\x83 T o find changes against current DW/DM values.\\n \\x83 T o cleanse data.\\n \\x83 T o pre-calculate aggregates.\\nData Extraction\\nIt is a process of collecting data from different data sources. In other words, it is the consolidation of \\ndata from different sources having different formats. Flat files and relational databases are most common \\ndata sources. Depending upon the type of source data, the complexity of extraction may vary. The stor-\\nage of intermediate version of data is very necessary. This data is required to be backed up and archived. \\nThe area where the extracted data is stored is called staging area.\\nFigure 6.5 Intermediate stages of ETL.\\nBUILD REFERENCE DATA\\nEXTRACT (ACTUAL DATA)\\nVALIDATE\\nTRANSFORM (CLEAR, APPLY BUSINESS RULES)\\nSTAGE (LOAD INTO STAGING TABLES)\\nCYCLE INITIATION\\nAUDIT REPORTS (SUCCESS/FAILURE LOG)\\nPUBLISH (LOAD INTO TARGET TABLES)\\nARCHIVE\\nCLEANUP\\nDATA MAPPING\\nDATA\\nSTAGING'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 185}, page_content='Data Transformation\\n • A series of rules or functions is applied to the data extracted from the source to obtain derived \\ndata that is loaded into the end target.\\n • Depending upon the data source, manipulation of data may be required. If the data source is \\ngood, its data may require very less transformation and validation. But data from some sources \\nmight require one or more transformation types to meet the operational needs and make data \\nfit in the end target.\\n • Some transformation types are\\n\\uf0a7 Selecting only certain columns to load.\\n\\uf0a7 T ranslating a few coded values.\\n\\uf0a7 Encoding some free-form values.\\n\\uf0a7 Deriving a new calculated value.\\n\\uf0a7 Joining together data derived from multiple sources.\\n\\uf0a7 Summarizing multiple rows of data.\\n\\uf0a7 Splitting a column into multiple columns.\\n • Data transformation is the most complex and, in terms of production, the most costly part of \\nthe ETL process. Let us explain this point with an example: The government has announced a \\n“Student Exchange Program”. The organizing committee of the “Student Exchange Program” \\nhas requested reputed universities of the country to furnish data on their top 10 students in \\nthe final semester of their graduation degree. There are some universities that maintain the \\nstudents score on a grade scale of 0–10. There are other universities that maintain the stu-\\ndents score on a grade scale of “A” to “E”. T o add to the complications, there are universities \\nthat maintain the students score on a grade scale of 0% to 100% and some others that follow \\nthe percentile system. Clearly, once the data is received from the various universities, it will \\nneed to be transformed for some homogeneity to set in before being loaded into the data \\nwarehouse.\\nData Loading\\n • The last stage of the ETL process is loading which loads the extracted and transformed data into \\nthe end target, usually the data warehouse.\\n • Data can also be loaded by using SQL queries.\\nWe will understand the concept of data loading using the case study of DIIT library that we mentioned \\nearlier. Assume for the sake of simplicity that each department (IT , CS, IS, and SE) stores data in sepa-\\nrate sheets in an Excel workbook, except the Issue_Return table which is in an Access database. Each \\nsheet contains a table. There are five tables in all:\\n1. Book (Excel)\\n2. Magazine (Excel)\\n3. CD (Excel)\\n4. Student (Excel)\\n5. Issue_Return (Access)\\nPreviews of each of these tables are given in Figures 6.6–6.10.\\nBasics of Data Integration • 161'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 186}, page_content='162 • Fundamentals of Business Analytics\\nFigure 6.6 A part of the Book Excel sheet.\\nA\\n1\\n2\\n3\\n4\\n5\\n6\\nNo of Copies\\n2\\n10\\n10\\n10\\n10\\nBook_ID\\nBLRB2001\\nBLRB2002\\nBLRB2003\\nBLRB2004\\nBLRB2005\\nPublisher\\nWILLEY PUBLICATION\\nSAMS PUBLICATION\\nTMH PUBLICATION\\nTHM PUBLICATION\\nPEARSON EDUCATION\\nTechnology\\n.NET\\n.NET\\nJEE\\nGENERAL\\nSAP\\nAuthor\\nSAMS WILLEY\\nJACK WILCH\\nMARILDA WHITE\\nVIKRAM PANDEY\\nJIMY ARNOLD\\nBook_Name\\nWPF PROGRAMING\\nC# PROGRAMING\\nADOBE FLEX 2\\nTHE FINANCE\\nHANDBOOK\\nSAP R/3 HANDBOOK\\nBC DE F\\nFigure 6.7 A part of the Magazine Excel sheet.\\nA\\n1 Magazine_ID TitleT echnologyN o of CopiesP eriod\\nREADERS DIGEST GENERAL2 MON\\nMON\\nMON\\nMON\\nYRL\\n2\\n2\\n1\\n3\\n.NET\\n.NET\\n.NET\\nJEE\\nVISUAL STUDIO\\nJAVA FOR ME\\nSQL SERVER\\nMSDN\\n2\\n3\\n4\\n5\\n6\\nBLRM2001\\nBLRM2002\\nBLRM2003\\nBLRM2004\\nBLRM2005\\nBC DE\\nFigure 6.8 A part of the CD Excel sheet.\\nA\\n1 CD_id TitleT echnologyN o of Copies\\nWPF PROGRAMMING .NET 2\\n5\\n10\\n10\\n10\\nJEE\\n.NET\\nDB\\nSAP\\nC# PROGRAMMING\\nSAP CRM CONFIGURATION\\nSTEP BY STEP SERVLET\\nORACLE 10G\\n2\\n3\\n4\\n5\\n6\\nBLRC2001\\nBLRC2002\\nBLRC2003\\nBLRC2004\\nBLRC2005\\nBC D'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 187}, page_content='Of all these tables, the Issue_Return table is the table that keeps records of all transactions (issue and \\nreturn) made in the library by registered users (students). Registered users’ data is stored in the Student \\ntable. The rest of the three tables contain data about the items (books, CDs, and magazines) that can \\nbe issued from the library.\\nLet us again look at the requirements of DIIT administration. “The DIIT administration is in need \\nof a report that indicates the annual spending on library purchases. The report should further drill down \\nto the spending by each department by category (books, CDs/DVDs, magazines, journals, etc.).” Prof. \\nFrank had suggested the building of a data warehouse. In order to implement Prof. Frank’s solution, the \\nfollowing requirements should be satisfied:\\n • Data in all tables should be in proper format and must be consistent.\\n • The three tables − Book, Magazine, and CD − should be combined into a single table that \\ncontains details of all these three categories of items.\\n • The student table should have a single column containing the full name of each student.\\n • Phone numbers must be stored in a numeric (integer) column.\\n • Date columns should be in a uniform format, preferably as a datetime data type.\\n • String columns (Fullname, Address) should be in uniform case (preferably uppercase).\\nFigure 6.9 A part of the Student Excel sheet.\\nC DE FG HBA\\n1 Stud_id Stud_First_name Stud_Middle_name Stud_Last_name Email Address Phone Number Birth Date\\n2 20001\\n20002\\n20003\\n20004\\n20005\\n20006\\n20007\\n20008\\n20009\\n20010\\n20011\\n20012\\n20013\\n20014\\n20015\\nBhanu\\nParul\\nSushma\\ngirish\\nFakir\\nLovepreet\\nJaishankara\\nSathyanarayan\\nGaganmeet\\nBhavya\\nAbhinav\\nABHUIT\\nMukulika\\nJAYARAM\\nRanCHHORDAS\\nPRASAD\\nBillo\\nChandra\\nSingh\\npaRIMAL\\nSamay\\nKumar\\nShyamaldas\\nGalgotla\\nDalakoti\\nSharma\\nRAWAT\\nDas\\nChadha\\nChakshu\\nsINgh\\nHansra\\ndhingra\\npatnala\\nRamcharandas\\nsenroy\\nSAINI\\nChhanchhad\\nSaharanpur\\nChudiala\\nIQBALPUR\\nBaliya\\nSunehtl Khadkhadi\\nPatiala\\nKhatauli\\nModinagar\\nVaranasi\\nBAREILLY\\nMysore\\nPune\\nCHEnnai\\nNew JaIpaiguri\\nAhmedabad\\n9952392126\\n9555533325\\n9554477886\\n9325489654\\n9654238552\\n(8345)225689\\n78562 31848\\n9565622261\\n98789-54655\\n99988-84569\\n7700598648\\n9982485698\\n9900665898\\n9874652365\\n9879879876\\n21-08-1978\\n03-03-1987\\n1-1-1971\\n18/03/1984\\n17/04/1982\\n11.10.1975\\n22/10/1988\\n20/06/1979\\n1.1.1987\\n15-08-1984\\n15/10/1985\\nB_galgotia@yahoo.com\\nparul_rocks@gmail.com\\nsush_sweets@hotmail.com\\ngiri_calls@rocketmail.com\\ndas_faklr@yahoo.co.in\\nsensation_star@gmail.com\\nJai.chakshu@gmail.com\\nSathya_rules@gmail.com\\ngaggu_pranks@gmail.com\\nDhingra.bhavya@gmail.com\\nTeddy_patnala@yahoo.co.in\\ncharan_me_aapke@gmail.com\\nSweet.muku@gmail.com\\nJayaram_s@hotmail.com\\nwise_brains@gmail.com\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\nFigure 6.10 A part of the Issue_Return MS Access database table.\\nStud_ID Item_ID Issue_Date Due_Date Return_Date Damage_fineTransaction_ID\\n15-May-08\\n15-May-08\\n18-May-08\\n22-May-08\\n22-Jul-08\\n29-Jul-08\\n29-Jul-08\\n4-Aug-08\\n7-Aug-08\\n10-Aug-08\\n15-Jun-08\\n15-Jun-08\\n18-Jun-08\\n22-Jun-08\\n22-Aug-08\\n29-Aug-08\\n29-Aug-08\\n4-Sep-08\\n7-Sep-08\\n10-Sep-08\\n110\\n400\\n14-Jun-08\\n18-Jun-08\\n18-Jun-08\\n22-Jun-08\\n23-Aug-08\\n27-Aug-08\\n31-Aug-08\\n4-Sep-08\\n7-Sep-08\\n3-Sep-08\\nBLRB2002\\nBLRB2001\\nBLRM2002\\nBLRB2004\\nBLRC2005\\nBLRB2001\\nBLRB2004\\nBLRM2003\\nBLRC2003\\nBLRC2001\\n20004\\n20007\\n20014\\n20015\\n20001\\n20015\\n20010\\n20007\\n20014\\n20015\\n101001\\n101002\\n101003\\n101004\\n101005\\n101006\\n101007\\n101008\\n101009\\n101010\\nIssue_Return\\nBasics of Data Integration • 163'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 188}, page_content='164 • Fundamentals of Business Analytics\\nT o achieve the stated requirements, and to clean the library data of other minor (but significant) \\ninconsistencies, Prof. Frank decided to first profile the data (manually and/or using a profiling tool) to \\ncheck for quality issues, and then perform ETL to migrate it to the data staging area, and finally to the \\ndata warehouse. This process involves some very important processes, namely data profiling and data \\nintegration (through ETL).\\n6.9 What is Data integration?\\n •   It is the integration of data present in different sources for providing a unified view of the data. \\nRefer to Figure 6.11.\\n •   It is the ability to consolidate data from several different sources while maintaining the integrity \\nand reliability of the data.\\n •  For example, in the library scenario:\\n \\x83 The item (Book, CD, Magazine) and student (Student) data is maintained in Excel files, \\nwhereas the transactional data (Issue_Return) is stored in the Access database.\\n \\x83 The library application would need to integrate all this data and present it in a unified manner \\nto the end-user while maintaining the integrity and reliability of data.\\n \\x83 Data integration would play a vital role in this scenario.\\n6.9.1 t wo Main approaches to Data integration\\nThe two main approaches to data integration are − schema integration and instance integration.\\nSchema Integration\\nMultiple data sources may provide data on the same entity type. The main goal is to allow applications \\nto transparently view and query the data as though it is one uniform data source. This is done using \\nvarious mapping rules to handle structural differences.\\n“Schema integration is developing a unified representation of semantically similar information, \\nstructured and stored differently in the individual databases.”\\nFigure 6.11 Data integration.\\nData source A\\nETLData source B\\nData source C\\nData\\nwarehouse'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 189}, page_content='“Collingwood branch”\\nTransactionID ProductID UnitQuantity\\nC101 T1001 P1010 10\\nCustID\\n_______\\nThe data analyst is looking at merging the data from both the branches, “Collingwood branch” and \\n“T rembly Park branch”. How can the data analyst make sure that the data from the database of one of \\nthe branches under the column “CustID” and the data from the database of another branch under the \\ncolumn “CustomerNumber” are mapped to the same column in the target database? The answer is by \\nlooking up the metadata information. The metadata is data about data. It defines each column, its data \\ntype, the length, the possible constraints, the range of values permitted for the attribute, the rules of \\ndealing with NULL, Zero and blank values, etc.\\nLet us assume that adequate metadata was available and schema integration was successful. The result \\nwill be the following target schema.\\nPicture this…\\nA retail outlet has branches spread across the country. There are some 20 different schemas that need to be \\nintegrated. One of the branches, “Collingwood branch”, stores the transaction details such as “CustID”, \\n“T ransactionID”, “ProductID”, “UnitQuantity”, etc. Another branch, “T rembly Park branch”, stores the \\ntransaction details such as “CustomerNumber”, “T ransactionID”, “ProductID”, “UnitQuantity”, etc.\\n“Trembly Park branch”\\nTransactionID ProductID UnitQuantity\\nC201 T1007 P1111 22\\nCustomerNumber\\n_______\\nTarget Schema:\\nTranID ProductID UnitQuantity\\nC101 T1001 P1010 10 _______\\nC201 T1007 P1111 22 _______\\nCustID\\n_______\\nInstance Integration\\nData integration from multiple heterogeneous data sources has become a high-priority task in many \\nlarge enterprises. Hence to obtain the accurate semantic information on the data content, the informa-\\ntion is being retrieved directly from the data. It identifies and integrates all the instance of the data \\nitems that represent the real-world entity, distinct from the schema integration. \\nPicture this… \\nA corporate house has almost 10,000 employees working for it. This corporate house does not have an \\nERP system. It has few enterprise applications, all existing in silos. There is a “ProjectAllocate” applica-\\ntion that stores the project allocation details of the employees. There is “EmployeeLeave” application \\nthat stores the details about the leaves availed by the employees. There is yet another “EmployeeAttendance” \\nBasics of Data Integration • 165'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 190}, page_content='166 • Fundamentals of Business Analytics\\napplication that has the attendance data of the employees. And, of course, there is an “EmployeePayroll” \\napplication that stores the salary details of the employees. The management has decided to consolidate \\nall the details of every employee in a data warehouse.\\nLet us look at the challenges. Assume there is an employee by the name, “Fred Aleck”. His name is \\nstored as “Fred Aleck” by the “ProjectAllocate” application, as “Aleck Fred” by the “EmployeeLeave” \\napplication, as “A Fred” by the “EmployeeAttendance” application, and to add to the challenge as  \\n“F Aleck” by the “EmployeePayroll” application.\\nYou see it now… The same person and his name has been stored in four different ways.\\n“ProjectAllocate”\\nEmployeeName SocialSecurityNo\\n10014 Fred Aleck ADWPP10017 _______\\nEmployeeNo\\n_______\\nLet us look at how instance integration can solve this problem. One possible solution is presented \\nhere. Look up all the records of the employee using the “EmployeeNo” or the “SocialSecurityNo”. And \\nthen, replace the value in the “EmployeeName” column with one consistent value such as “Fred Aleck” \\nin the example above.\\n“EmployeeLeave”\\nEmployeeName SocialSecurityNo\\n10014 Aleck Fred ADWPP10017 _______\\nEmployeeNo\\n_______\\n“EmployeeAttendance”\\nEmployeeName SocialSecurityNo\\n10014 A. Fred ADWPP10017 _______\\nEmployeeNo\\n_______\\n“EmployeePayroll”\\nEmployeeName SocialSecurityNo\\n10014 F . Aleck ADWPP10017 _______\\nEmployeeNo\\n_______\\n“ProjectAllocate”\\nEmployeeName SocialSecurityNo\\n10014 Fred Aleck ADWPP10017 _______\\nEmployeeNo\\n_______\\n“EmployeeLeave”\\nEmployeeName SocialSecurityNo\\n10014 Fred Aleck ADWPP10017 _______\\nEmployeeNo\\n_______'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 191}, page_content='6.9.2 Need and Advantages for Data Integration\\nData integration is the need of the hour.\\n • It is of benefit to decision makers who will be able to quickly access information based on a key \\nvariable along with the query against existing data from past studies in order to gain meaningful \\ninsights.\\n • It helps reduce costs, overlaps, and redundancies, and business will be less exposed to risks and \\nlosses.\\n • It helps in better monitoring of key variables such as trending patterns and consumer behavior \\nacross geographies, which would alleviate the need to conduct more studies and surveys, bring-\\ning about reduced spending on R&D and minimization of redundancy.\\n6.9.3 Common Approaches of Data Integration\\nFederated Databases\\nSeveral database systems are combined/integrated into one single FDBS. Figure 6.12 shows the FDBS. \\nDescribed below are some features of the FDBS.\\n • A federated database system (FDBS) can be stated as a category of database management \\nsystem (DBMS) that integrates multiple disparate and autonomous database systems into one \\nsingle federated database. Constituent databases may be geographically decentralized and inter-\\nconnected via computer network. Since the constituent databases remain more or less autono-\\nmous, having an FDBS is a contrastable, but feasible, alternative to the task of merging several \\ndisparate databases. A federated database can also be called as virtual database. It is a fully \\nintegrated, logical composite result of all of its constituent databases.\\n • The federated database system was first defined by McLeod and Heimbigner. According to \\nthem, the FDBS is the one which defines the architecture and interconnects the databases sup-\\nporting partial sharing and coordination among database systems.\\n • A Uniform User Interface can be provided through data abstraction which will enable users and \\nclients to retrieve data from multiple non-contiguous databases (that are combined into a feder-\\nated database) using a single query (even if the constituent databases are heterogeneous).\\n • An FDBS should have the ability to decompose a larger/complex query into smaller sub-queries \\nbefore submitting them to the relevant constituent DBMSs, after which the system combines \\nthe individual result sets of each sub-query. Since various DBMSs work on different query \\nlanguages, the FDBS can apply wrappers to sub-queries, so that they can be translated to the \\ncorresponding query languages.\\n“EmployeeAttendance”\\nEmployeeName SocialSecurityNo\\n10014 Fred Aleck ADWPP10017 _______\\nEmployeeNo\\n_______\\n“EmployeePayroll”\\nEmployeeName SocialSecurityNo\\n10014 Fred Aleck ADWPP10017 _______\\nEmployeeNo\\n_______\\nBasics of Data Integration • 167'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 192}, page_content='168 • Fundamentals of Business Analytics\\n • A federated database may consist of a collection of heterogeneous databases. In such a case, it allows \\napplications to look at data in a relatively more unified way without the need to duplicate it across \\nindividual databases or make several smaller, multiple queries and combine the results manually.\\nData Warehousing\\nData integration is an important, fundamental part of data warehousing. It is a process vital to the cre-\\nation of a robust, yet manageable and highly informative data resource whose purpose is to deliver busi-\\nness intelligence (BI) solutions. Data integration includes the necessary activities:\\n • Acquire data from sources (extract).\\n • T ransform and cleanse the data (transform).\\n • Load the transformed data into the data store, which may be a data warehouse or a data mart \\n(load).\\nThe body of knowledge required for data integration includes\\n • Concepts and skills required to analyze and qualify source data.\\n • Data profiling.\\n • Source-to-target mapping.\\n • Data cleansing and transformation.\\n • ETL development.\\nUsing data warehousing method, data is first pulled (extracted) from various data sources. Next, the \\nextracted data is converted into a common format, so that data sets are compatible with one another (trans-\\nformed). Lastly, this new data is loaded into its own database (loaded). When a user runs a query on the \\ndata warehouse, the required data is located, retrieved, and presented to the user in an integrated view.\\nFor example, a data warehouse may contain updated information on drive-in restaurants and road \\nmaps of a certain town in its tables. Once you submit a query on the warehouse, it would integrate the \\ntwo (restaurant locations/timings and road maps) together and send the result set view back to you. The \\nvarious primary concepts used in data warehousing are\\n • ETL (extract, transform, load).\\n • Component-based (data mart).\\nFigure 6.12 A federated database system.\\nInformix\\nInformix DB2 DB2\\nFederated\\nDatabase\\nDB2 DB2\\nDB2 UDB UNIX,\\nWindows, Linux/390\\nDB2 for OS/390, DB2 for iSeries\\nDB2 for VSE/VM\\nDB2 Connect server\\n(Windows, UNIX)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 193}, page_content=' • Dimensional models and schemas.\\n • Metadata-driven.\\nAs shown in Figure 6.13, data from several different/disparate sources is extracted, transformed, and \\nloaded into a single database, which can then be queried as a single schema. Let us understand this with \\nthe help of an example depicted in Figure 6.14.\\nFrom Figure 6.14, it is clear that the sales information, product information, and customer informa-\\ntion have been extracted from different sources. The extracted information then undergoes the ETL \\nprocess where the data is stored in data staging area. Finally, the data from the staging database is loaded \\nin the data warehouse.\\nFigure 6.13 Operational data sources (heterogeneous) to a unified data warehouse.\\nRelational\\ndata sources\\nData\\nwarehouse\\nOther kind\\nof data sources,\\ne.g. Mainframes\\nFlat files\\nData sources Emp\\nId\\nEmp\\nId\\nEmp\\nId\\nName\\nName\\nName\\nmohan\\nMohan\\ndeepika\\ncinDY\\nAMIT\\nAMIT\\nCindy\\n123\\n123\\n23412-08-79\\n12-08-79 29\\n25\\n25\\n26\\n02/14/82\\nDeepika234\\n04/01/8402-10-83\\n02-10-83\\n14-02-82\\n01-04-84\\n456\\n456\\n567\\n567\\nD.O.B\\nD.O.BA GE\\nD.O.BExtraction\\nTransformation\\nFigure 6.14 Operational data sources (heterogeneous) to a unified data warehouse.\\nMetadata Layer\\nSales Information Customer Information Product Information\\nPresentation\\nApplication\\nSales App Customer App Inventory App Proprietary App\\nProduct DB\\nHyd Cust DB\\nSales data Sales data\\nPresentation\\nApplication\\nPresentation\\nApplication\\nData Warehouse\\nData Staging Layer – ETL\\nBLR Cust DB\\nBasics of Data Integration • 169'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 194}, page_content='170 • Fundamentals of Business Analytics\\nMemory-Mapped Data Structure\\n•\\t It is useful when one needs to do in-memory data manipulation, and the data structure is large. \\nIt’s mainly used in the dot net platform and is always performed with C# or using VB.NET\\n•\\t It is a much faster way of accessing the data than using memory stream.\\n6.10 Data IntegratIon technologIes\\nThe following are the technologies used for data integration:\\n1. Data Interchange\\n a.  It is the structured transmission of organizational data between two or more organizations \\nthrough electronic means; used for the transfer of electronic documents from one computer to \\nanother (i.e., from one corporate trading partner to another).\\n b.  Data interchange must not be seen merely as email. For instance, organizations might want to do \\naway with bills of lading (or even checks), and use appropriate EDI messages instead.\\n2. Object Brokering\\n a.  An ORB (Object Request Broker) is a certain variety of middleware software. It gives program-\\nmers the freedom to make calls from one computer to another over a computer network.\\n b. It handles the transformation of in-process data structure to and from the byte sequence.\\n3. Modeling Techniques: There are two logical design techniques:\\n a.  ER Modeling: Entity Relationship (ER) Modeling is a logical design technique whose main fo-\\ncus is to reduce data redundancy. It is basically used for transaction capture and can contribute in \\nthe initial stages of constructing a data warehouse. The reduction in the data redundancy solves \\nthe problems of inserting, deleting, and updating data but it leads to yet another problem. In our \\nbid to keep redundancy to the minimum extent possible, we end up creating a whole lot of tables. \\nThese huge numbers of tables imply dozens of joins between them. The result is a massive spider \\nweb of joins between tables.\\nTable 6.1 Difference between a federated database and a data warehouse\\nPreferred when the databases are present across \\nvarious locations over a large area (geographically \\ndecentralized).\\nPreferred when the source information can be taken from \\none location.\\nData would be present in various servers. The entire data warehouse would be present in one server.\\nRequires high speed network connection. Requires no network connection.\\nIt is easier to create as compared to data \\nwarehouse.\\nIts creation is not as easy as that of the federated database.\\nRequires no creation of new database. Data warehouse must be created from scratch.\\nRequires network experts to set up the network \\nconnection.\\nRequires database experts such as data Steward.\\nFederated\\nData Warehouse'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 195}, page_content='What could be the problems posed by ER Modeling?\\n • End-users find it difficult to comprehend and traverse through the ER model.\\n • Not too many software exist which can query a general ER model.\\n • ER Modeling cannot be used for data warehousing where the focus is on performance access \\nand satisfying ad hoc, unanticipated queries.\\nExample: Consider a library transaction system of a department of DIIT . Every transaction (issue \\nof book to a student or return of book by a student) are recorded. Let us draw an ER model to \\nrepresent the above-stated scenario.\\nSteps to drawing an ER model:\\n • Identify entities.\\n • Identify relationships between various entities.\\n • Identify the key attribute.\\n • Identify the other relevant attributes for the entities.\\n • Draw the ER diagram.\\n • Review the ER diagram with business users and get their sign-off.\\nFigure 6.15 considers 2 entities: Book and Issue_Return.\\n Book entity has the attributes: Book_ID (key attribute), T echnology, Book_Name, Author, \\nPublisher, NoOfCopies.\\n Issue_Return entity has the attributes: Stud_ID, Item_ID, T ransaction_ID (key attribute), \\nIssue_Date, Due_Date, Return_Date, Damage_Fine, etc.\\nThe relationship between the two entities (Book, Issue_Return) is 1:1.\\n b.  Dimensional Modeling: It is a logical design technique, the main focus of which is to present \\ndata in a standard format for end-user consumption. It is used for data warehouses having either \\na Star schema or a Snowflake schema. Every dimensional model is composed of one large table \\ncalled the fact table and a number of relatively smaller tables called the dimensional tables. The \\nfact table has a multipart primary key. Each table has a single-part primary key. The dimension \\nFigure 6.15 ER diagram between Book and Issue_Return entities.\\nBook Issue_ReturnBook Issued\\nto \\nBook_ID\\nBook_Name\\nAuthor\\nPublisher\\nTechnology\\nNo. of Copies\\nTransaction_ID\\nStud_ID\\nItem_ID\\nIssue_Date\\nDue_Date\\nReturn_Date\\nDamage_Fine\\n11\\nBasics of Data Integration • 171'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 196}, page_content='172 • Fundamentals of Business Analytics\\nprimary key corresponds to precisely one component of the multipart key of the fact table. In \\n addition to the multipart primary key, the fact table also contains a few facts which are numeric \\nand additive. The dimension table generally contains textual data. The fact table maintains many-\\nto-many relationships.\\nWhat are the perceived benefits of the dimensional modeling?\\n• End-users find it easy to comprehend and traverse/navigate through the model.\\n• If designed appropriately, it can give quick responses to ad hoc query for information.\\n•  A lot of tools such as ad hoc querying tools, report generation tools, data mining applications, \\netc. are available which can be used on the data warehouse to satisfy the decision support  \\nrequirements of business users.\\nConsider the DIIT library case study. Prof. Frank designed a dimensional schema structure \\nfor the data warehouse as shown in Figure 6.16. The DIIT library was given permission to access \\nthe central college server machine that housed Microsoft SQL Server. Hence, the above relational \\nschema could be implemented as an SQL Server database. Now, the major steps that were taken \\nto transfer data from the Excel spreadsheets and Access database to SQL Server database were as \\nfollows:\\n1.  Profiling the source data (identifying natural key columns, identify data anomalies, corrections \\nto be made, etc.)\\n2. Results of profiling were:\\n a. Identification of natural keys (that would naturally be unique and not null):\\nFigure 6.16 Dimensional data structure for the data warehouse of DIIT .\\nPK\\nPK\\nStud_ID\\nItem_ID\\nItem_Type\\nTitle\\nTechnology\\nNoOfCopies\\nAuthor\\nPublisher\\nPeriod\\nItem_ID\\nIssue_Date\\nDue_Date\\nReturn_Date\\nDamage_Fine\\nLate_Fine\\nPK\\nStud_FullName\\nEmail\\nTransaction ID\\nAddress\\nPhoneNumber\\nBirthDate\\nStud ID\\nDimStudent\\nDimItem\\nFactIssueReturn'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 197}, page_content=' • Book: Book_ID\\n • Magazine: Magazine_ID\\n • CD: CD_ID\\n • Issue_Return: T ransaction_ID\\n • Student: Stud_ID\\n b. Removal of leading and trailing blanks wherever they occur.\\n c. Removal of special characters from “PhoneNumber” column.\\n d. T ransforming the “Birthdate” column to a standard date format.\\n e. Capitalization in “Address” column is not appropriate, hence convert all letters to capitals.\\n3.  Choosing an appropriate ETL tool (SSIS, Kettle, Informatica, etc.) and creating ETL packages \\nto transform and transport the data from the source database to the destination database.\\n4.  Some major rules, transformations, and data-cleaning activities that were identified and imple-\\nmented were:\\n a. Merging together the tables Book, Magazine, and CD into a single table “DimItem”.\\n b. Data-type conversion.\\n c.  Combining Stud_First_name, Stud_Middle_name and Stud_Last_name and creating a \\nnew column “FullName” (fully capitalized) in DimStudent, and “Late_Fine” in FactIssueR-\\neturn (Late_Fine) would be calculated as\\n(Return_Date – Due_Date) ë 10 (in Rs.)\\n d. Removing leading and trailing blanks wherever they occur.\\n e.  Removing special characters from “PhoneNumber” column and its subsequent conversion \\nto numerical format.\\n f. Standardizing the “BirthDate” column format and conversion to “DateTime” datatype.\\n g. T ransforming all entries in the “Address” column to capitals.\\n h.  In the fine columns (Damage_Fine and Late_Fine), each NULL entry be recorded as \\nzero (0).\\n5.  As per general practice, the Dimension tables (DimItem and DimStudent) are populated with \\ndata first, followed by the Fact table(s) (FactIssueReturn). This is because of referential con-\\nstraints of fact on the dimensions.\\nAfter performing ETL, the tables in the database looked like those shown in Figures 6.17–6.19.\\nFigure 6.17 A part of the FactIssueReturn table.\\nStud_ID Item_ID Issue_Date Due_Date Return_Date Damage_fine Late_fineTransaction_ID\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n101001\\n101002\\n101003\\n101004\\n101005\\n101006\\n101007\\n101008\\n101009\\n101010\\n20004\\n20007\\n20014\\n20015\\n20001\\n20015\\n20010\\n20007\\n20014\\n20015\\nBLRB2002\\nBLRB2001\\nBLRM2002\\nBLRB2004\\nBLRC2005\\nBLRB2001\\nBLRB2004\\nBLRM2003\\nBLRC2003\\nBLRC2001\\n2008-05-15 00:00:00.000\\n2008-05-15 00:00:00.000\\n2008-05-18 00:00:00.000\\n2008-05-22 00:00:00.000\\n2008-07-22 00:00:00.000\\n2008-07-29 00:00:00.000\\n2008-07-29 00:00:00.000\\n2008-08-04 00:00:00.000\\n2008-08-07 00:00:00.000\\n2008-08-10 00:00:00.000\\n2008-06-15 00:00:00.000\\n2008-06-15 00:00:00.000\\n2008-06-18 00:00:00.000\\n2008-06-22 00:00:00.000\\n2008-08-22 00:00:00.000\\n2008-08-29 00:00:00.000\\n2008-08-29 00:00:00.000\\n2008-09-04 00:00:00.000\\n2008-09-07 00:00:00.000\\n2008-09-10 00:00:00.000\\n2008-06-14 00:00:00.000\\n2008-06-18 00:00:00.000\\n2008-06-18 00:00:00.000\\n2008-06-22 00:00:00.000\\n2008-08-23 00:00:00.000\\n2008-08-27 00:00:00.000\\n2008-08-31 00:00:00.000\\n2008-09-04 00:00:00.000\\n2008-09-07 00:00:00.000\\n2008-09-03 00:00:00.000\\n0\\n0\\n0\\n0\\n110\\n0\\n0\\n400\\n0\\n0\\n0\\n30\\n0\\n0\\n10\\n0\\n20\\n0\\n0\\n0\\nBasics of Data Integration • 173'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 198}, page_content='174 • Fundamentals of Business Analytics\\nFigure 6.18 A part of the DimStudent table.\\nStud_id\\nBHANU PRASAD GALGOTIA\\nPARUL DALAKOTI\\nSUSHMA BILLO SHARMA\\nGIRISH CHANDRA RAWAT\\nFAKIR DAS\\nGAGANMEET HANSRA\\nBHAVYA DHINGRA\\nABHINAV KUMAR PATNALA\\nABHIJIT RAMCHARANDAS\\nMUKULIKA SENROY\\nJAYARAM SAINI\\nRANCHHORDAS SHYAMALDAS CHHANCHHAD\\nSATHYANARAYAN SAMAY SINGH\\nLOVEPREET SINGH CHADHA\\nJAISHANKARA PARIMAL CHAKSHU\\nStud_FullName EmailA ddress\\nSAHARANPUR\\nCHUDIALA\\nVARANASI\\nPUNE\\n7856231848\\n9654238552\\n9325489654\\n9555533325\\n9952392126\\nPhoneNumberB irthDate\\n1978-08-21 00:00:00.000\\n1978-03-03 00:00:00.000\\n1984-03-18 00:00:00.000\\n1982-04-17 00:00:00.000\\n1988-10-22 00:00:00.000\\n1987-01-01 00:00:00.000\\n1984-08-15 00:00:00.000\\n1979-06-20 00:00:00.000\\n1975-11-10 00:00:00.000\\n1985-10-15 00:00:00.000\\n1971-01-01 00:00:00.000\\n9554477886\\n8545225689\\n9565622261\\n9878954655\\n9998884569\\n7700598648\\n9982485698\\n9900665898\\n9874652365\\n9879879876AHMEDABAD\\nNEW JALPAIGURI\\nCHENNAI\\nMYSORE\\nBAREILLY\\nMODINAGAR\\nKHATAULI\\nPATIALA\\nSUNEHTI KHADKHADI\\nBALIYA\\nIQBALPUR\\nB_galgotia@yahoo.com\\nparul_rocks@gmail.com\\nsush_sweets@hotmail.com\\ngiri_calls@rocketmail.com\\ndas_fakir@yahoo.co.in\\nsensation_star@gmail.com\\nJai.chakshu@gmail.com\\nSathya_rules@gmail.com\\ngaggu_pranks@gmail.com\\nDhingra.bhavya@gmail.com\\nTeddy_patnala@yahoo.co.in\\nSweet.muku@gmail.com\\nJayaram_s@hotmail.com\\nwise_brains@gmail.com\\ncharan_me_aapke@gmail.com\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n20002\\n20003\\n20004\\n20005\\n20006\\n20007\\n20008\\n20009\\n20010\\n20011\\n20012\\n20013\\n20014\\n20015\\n20001\\nNULL\\nNULL\\nNULL\\nNULL\\nFigure 6.19 A part of the DimItem table.\\nItem_ID\\nWILLEY PUBLICATION\\nSAMS PUBLICATION\\nTMH PUBLICATION\\nTHM PUBLICATION\\nPEARSON EDUCATIKON\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\nMON\\nMON\\nMON\\nYRL\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\nMON\\nMON\\nMON\\nMON\\nYRL\\nSAMS WILLEY\\nJACK WILCH\\nMARILDA WHITE\\nVIKRAM PANDEY\\nJIMY ARNOLD\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\n2\\n10\\n10\\n10\\n10\\n2\\n10\\n5\\n10\\n10\\n2\\n3\\n2\\n2\\n1\\n.NET\\n.NET\\nJEE\\nGENERAL\\nSAP\\n.NET\\n.NET\\nSAP\\nJEE\\nDB\\nGENERAL\\n.NET\\nJEE\\n.NET\\n.NET\\nWPF PROGRAMING\\nC# PROGRAMING\\nWPF PROGRAMMING\\nC# PROGRAMMING\\nSAP CRM CONFIGURATIN\\nSTEP BY STEP SERVLET\\nORACLE 10G\\nREADERS DIGEST\\nVISUAL STUDIO\\nJAVA FOR ME\\nSQL SERVER\\nMSDN\\nADOBE FLEX 2\\nTHE FINANCE HANDBOOK\\nSAP R/3 HANDBOOK\\nBook\\nBook\\nBook\\nBook\\nBook\\nCD\\nCD\\nCD\\nCD\\nCD\\nMagazine\\nMagazine\\nMagazine\\nMagazine\\nMagazine\\nBLRB2001\\nBLRB2002\\nBLRB2003\\nBLRB2004\\nBLRB2005\\nBLRC2001\\nBLRC2002\\nBLRC2003\\nBLRC2004\\nBLRC2005\\nBLRM2001\\nBLRM2002\\nBLRM2003\\nBLRM2004\\nBLRM2005\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\nItem_Type TitleT echnology No Of Copies Author Publisher Period\\nTable 6.2 Difference between ER modeling and dimensional modeling\\nOptimized for transactional data. Optimized for query ability and performance.\\nEliminates redundant data. Does not eliminate redundant data, where appropriate.\\nHighly normalized (even at a logical level). It aggregates most of the attributes and hierarchies of a \\ndimension into a single entity.\\nIt is a complex maze of hundreds of entities linked \\nwith each other.\\nIt has logical grouped set of Star schemas.\\nUseful for transactional systems. Useful for analytical systems.\\nIt is split as per the entities. It is split as per the dimensions and facts.\\nER Modeling\\nDimensional Modeling'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 199}, page_content='Relationship Between Dimensional Modeling and Entity Relationship Modeling\\nA single entity relationship diagram will be broken down into several fact table diagrams. The following \\nare the steps to convert an entity relationship diagram into a set of dimensional models:\\n1.  An ER diagram of an enterprise represents almost every business process of the enterprise on a \\nsingle diagram. The first step is to separate out the various business processes and represent each \\nas a separate dimensional model.\\n2.  The second step is to constitute the fact tables. T o do this, identify all many-to-many relation-\\nships in the ER diagram, containing numeric and additive non-key attributes, and construct \\nthem into fact tables.\\n3.  The third step is to constitute the dimension tables. T o do this, de-normalize all the remaining \\ntables into single-part key tables. These single-part key tables connect to the fact table which \\nessentially is multipart. The fact table generally has two or more foreign keys that refer to the \\nsingle-part key of the respective dimension tables. In the cases where the same dimension table \\nconnects to more than one fact table, the dimension table is represented in each schema, and \\nthe dimension tables are referred to as “conformed” between the two-dimensional models.\\n6.11 Data Quality\\nT oday is a world of heterogeneity. We have different technologies from databases (relational to multidi-\\nmensional), RFID tags to GPS units, etc. We operate on different platforms − from personal computers \\nto server machines to cell phones, etc. We have several vendors such as Informatica, IBM, Microsoft, etc. \\nto name a few. We have hordes of data being generated every day i n all sorts of organizations and enter-\\nprises. And we do have problems with data. Data is often duplicated, inconsistent, ambiguous, and \\nincomplete. We do realize that all of this data needs to be collected in one place and cleaned up. Why? \\nWell, the obvious reason is bad data leads to bad decisions and bad decisions lead to bad business.\\n6.11.1 Why Data Quality Matters?\\nLet us look at few instances where bad data quality can/has cost a fortune…\\n • A CD company announced an introductory offer of free CDs. A man defrauded the company \\nby availing of this introductory offer almost 1600 times over. How? Each time he managed to \\nregister a different account with a different address by clever use of punctuation marks, slightly \\ndifferent spellings, fictitious apartment numbers, fictitious street numbers, etc.\\n • Cited here is an instance where a cell phone company has lost out on cross-sell opportunities \\nand has also lost out on potential prospective customers. How? A customer lives with his family \\n(spouse and children) in a separate house, his parents stay in another house at a different address, \\nand his brother is in yet another house at a different physical address. The cell phone company \\nhad no way of pooling this information together to relate those individuals. If they had one, \\nthey could probably look at cashing in on the power of the customer to influence the buying \\nand holding decisions of someone in one of those other, related households. This brings us to a \\nkey question, “How does one define good customer data, and how do you think companies can \\nachieve it?”\\n • Here is another case, where a cable company lost $500,000 because a mislabelled shipment \\nresulted in a cable being laid at a wrong location.\\nBasics of Data Integration • 175'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 200}, page_content='176 • Fundamentals of Business Analytics\\n • Referring back to the DIIT library System case study, it was seen that the “PhoneNumber” \\ncolumn had certain inconsistencies in the data. Consider a situation, where an application was \\ndeveloped that could fetch a phone number from the database and make an IP phone call to \\nthe number from the desktop computer itself. If the “PhoneNumber” column had alphabets \\nor special characters (as was the case in the Excel sheets the library maintained), the applica-\\ntion would definitely throw an error. Hence, it became absolutely essential to clean the dirty \\ndata of such inconsistencies and populate the fields in the database accordingly, as per practical \\nrequirements.\\nAnother field that had a wide difference in the format of date used is the “BirthDate” field. Here, the \\ndate of birth of the students had been entered in three different date formats (such as dd-mm-yyyy, dd/\\nmm/yyyy, dd.mm.yyyy). Also, most records had the birth date entered as a string data type, while some \\nentries were in a date format. Now, in this situation, performing ETL on the source data would result \\nin some records being excluded from the data flow, which would not appear in the database. Hence, it \\nbecame essential to convert the different formats into a single standard date format and store it in the \\ndatabase as a date data type.\\n6.11.2 What is Data Quality?\\nOne of the issues that hinder progress in addressing polluted data is the narrow definition that is \\napplied to the concept of data quality. It has been seen that most attention is paid to data integrity, \\nwhich has a narrower scope than data quality. Hence, we now need to take a look at the following two \\ndefinitions:\\n • Definition of Data Integrity.\\n • Definition of Data Quality.\\nDefinition of Data Integrity\\nData integrity reflects the degree to which the attributes of data associated with a certain entity accu-\\nrately describe the occurrence of that entity. Examples of data integrity:\\n • Primary Key: A column or a collection of columns designated as primary key imposes the \\n“Unique” and “Not Null” constraint.\\n • Foreign Key: A column designated as the foreign key column means it can only have values that \\nare present in the primary key column of the same or different table that it refers to. A foreign \\nkey column can have a null or duplicate value.\\n • Not Null: A Not Null constraint on the column means that the column must be given a value. \\nIt cannot have a Null value (a missing or unknown value). A space or zero or carriage return or \\nline feed is not a Null value).\\n • Check Constraint: A check constraint allows imposing a business rule on a column or a collec-\\ntion of column.\\nLet us explain data integrity with an example. We consider here a table, “Employee” having \\nfour columns: EmpNo (Primary key), DeptNo (Foreign Key), EmpName (Not Null), and the Age \\ncolumn (with a check constraint imposed on it). The table definition of “Employee” table is as \\nfollows:'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 201}, page_content='A column (DeptNo) of the Employee table refers to a column (DeptNo) of the Department table. \\nThis is a case of referential integrity constraint. Employee table is the referencing table and Department \\ntable is the referenced table. Assume the Department table has the following records in it.\\nMetric Attribute Data Type and Length Example\\nEmpNo Numeric Primary Key (Entity Integrity Constraint)\\nDeptNo Varchar(5) Foreign Key (Referential Integrity Constraint)\\nDeptNo column of Employee table refers to \\nDeptNo column of Department table\\nEmpName Varchar(50) Not Null (Not Null Constraint)\\nAge Numeric Age cannot be > 18 or < 65 (Check Constraint)\\nColumn Name\\nConstraint\\nEmployee\\nDepartment\\nD01 Finance\\nD02 Purchase\\nD03 Human Resources\\nD04 Sales\\nDeptNo\\nDeptName\\nLet us take a quick look at the records in the Employee table, particularly the values in the DeptNo \\ncolumn. All the values in the DeptNo column (D01, D02) are present in the DeptNo column of the \\nDepartment table. Here, the referential integrity constraint is being followed.\\nRecord Set (Records in the Table, Employee)\\nColumnName DeptNo EmpName Description\\n1001 D01 John Mathews 25\\n1010 D02 Elan Hayden 27\\n1011 D01 Jennifer Augustine 23\\nEmpNo\\nAge\\nDefinition of Data Quality\\nData quality is measured with reference to appropriateness for purpose as defined by the business users \\nof data and conformance to enterprise data quality standards as formulated by systems architects and \\nadministrators. Therefore, it is evident that the concept of data integrity is local to the domain of data-\\nbase technology. However, the concept of data quality has a wider scope and is rooted in the business. \\nIt is the latter definition that conveys real efforts in the context of data warehousing.\\nBasics of Data Integration • 177'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 202}, page_content='178 • Fundamentals of Business Analytics\\nData quality is not linear. It is described by several dimensions such as accuracy/correctness, complete-\\nness, consistency, and timeliness.\\n • Correctness/Accuracy: Accuracy of data is the degree to which the captured data correctly re-\\nflects/describes the real world entity/object or an event. Examples of data accuracy:\\n \\x83 The address of customer as maintained in the customer database is the real address.\\n \\x83 The temperature recorded in the thermometer is the real temperature.\\n \\x83 The air pressure as recorded by the barometer is the real air pressure.\\n \\x83 The bank balance in the customer’s account is the real value customer deserves from the \\nBank.\\n \\x83 The age of the patient as maintained in the hospital’s database is the real age.\\n • Consistency: This is about the single version of truth. Consistency means data throughout the \\nenterprise should be in sync with each other. Let us look at a few examples of inconsistent data:\\n \\x83 A customer has cancelled and surrendered his credit card. Yet the card billing status reads as \\n“due”.\\n \\x83 An employee has left the organization. Yet his email address is still active.\\nLet us look at yet another example. Consider a financial organization, “EasyFinance”. This \\norganization has several departments. There are departments that work in silos and there are \\ndepartments that work in tandem. A customer comes over to deposit a cheque to his account. \\nThe cheque is collected by the “cheque collection department”. The status of the cheque is des-\\nignated as “cleared”. However, the money is yet to be credited to the account. The reason being, \\nonly after the transactions are closed for the day, the processing will begin. For this brief time \\nperiod, the data is inconsistent.\\n • Completeness: The completeness of data is the extent to which the expected attributes of data \\nare provided. Examples of data completeness are as follows:\\n \\x83 Data of all students of a University are available.\\n \\x83 Data of all patients of a hospital are available.\\n \\x83 All the data of all the clients of an IT organization is available.\\nLet us look at a case where all the data is not available yet it is considered complete. Example: \\nIn the feedback form of a restaurant, a customer provides his postal address (mandatory require-\\nment) but does not mention his email address or his telephone number (optional requirement). \\nCan this data still be taken as complete? The answer is “yes” subjected to the fact if it still meets \\nthe expectations of the user (in our example, the restaurant manager). The next question is \\n“Can the data be complete but inaccurate?” The answer is “Yes”. In our example, the customer \\ndid provide a postal address, so the data is complete because it meets the expectations of the \\nrestaurant staff; but the customer could have provided an incorrect address − a typical case of \\ncomplete yet inaccurate data.\\n • Timeliness: The timeliness of data is extremely crucial. Right data to the right person at the \\nright time is important for business. Delayed supply of data could prove detrimental to the \\nbusiness. No matter how important the data is, if it is not supplied at the right time, it becomes \\ninconsequential and useless. Few examples are as follows:\\n \\x83 The airlines are required to provide the most recent information to their passengers.\\n \\x83 There can be no delay in the publishing of the quarterly results of an enterprise. The results \\ncannot be announced the next year.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 203}, page_content='An example where data is not timely:\\n \\x83 The population census results are published two years after the census survey is completed.\\n • Metadata: We have discussed few of the dimensions of data quality such as completeness, \\n accuracy, consistency, and timeliness. What we have not touched upon is yet another dimen-\\nsion of data quality and that is “metadata”. We all know metadata is data about data. T o quote \\na few examples: if we consider relational databases, table definitions along with column defini-\\ntions (data type and length), constraint descriptions, business rules, etc. constitute metadata. \\nOther detailed examples include the conceptual and logical models as discussed in Chapter 7,  \\n“Multidimensional Data Modeling”. One key role of metadata that is often overlooked is its role \\nin determining data usage.\\nA famous quote goes as: A man with one watch knows what time it is. A man with two watches \\nis never sure.\\nAnd have we witnessed “the two many watches” phenomenon? The answer is yes.\\nPicture this…\\nA manufacturing company has made it mandatory for its employees to attend 5 days of training pro-\\ngram every quarter. The count of the number of training days attended by the employees is tracked by \\nthe team leader, the training coordinator, and by the individual (employee) who undergoes the training \\nprogram. Let us take the case of William Welsh, an employee with the finance department. William has \\njust finished his 5 days of training from March 29, 2011 to April 2, 2011. Here is a sample of data that \\nis maintained by the team leader, the training coordinator and by William Welsh.\\n • T eam Leader: 3 days for quarter IV (Jan−March) and 2 days for quarter I (Apr−June).\\n • Training Coordinator: 5 days for quarter IV (Jan−March) and zero days for quarter I (Apr−June). \\nThe reason given by him is the training commenced on 29 March and therefore counted in the \\nsame quarter.\\n • William Welsh: Zero days for quarter IV (Jan−March) and 5 days for quarter I (Apr−June). \\nThe reason given by him is the training ended on 2 April and therefore counted in the next \\nquarter.\\nAll the three data are correct but from different perspectives. Clearly, it is a case of “too many watches”. \\nHow could this problem be solved? This problem could be resolved by having the metadata clearly state \\nso. Let us look at some typical business questions such as “How many customers do we have?”, “How \\nmany alliance partnerships do we have?”, “How many vendor partnerships do we have?”, “How many \\nproducts do we have?”, “How much expenditure did we incur?”, etc. In the context of these questions, \\nanother example of metadata is providing clear definitions of what the terms “customers”, “vendors”, \\n“alliance partners”, “products”, “expenditure”, etc. actually mean.\\nLet us consider from the business domain perspective. Here, the metadata changes to what they \\nexpect in high level reports. Let us look at it in the light of an example. In a transactional system, data \\nis usually maintained to an accuracy of say a precision value of 6 (6 places after decimal) and that makes \\nsense. However, the same data when pulled in a report might be rounded off, first to 2 places after \\ndecimal and then completely rounded off to the nearest integer in a still higher level report. However, \\nif there are millions of records, there could be a huge discrepancy in the amount quoted because of this \\nrounding off and data is labelled “poor quality”.\\nBasics of Data Integration • 179'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 204}, page_content='180 • Fundamentals of Business Analytics\\n6.11.3 How Do We Maintain Data Quality?\\nFrom a technical standpoint, data quality results from the process of going through the data and scrub-\\nbing it, standardizing it, and de-duplicating records, as well as doing some of the data enrichment.\\n • Clean up your data by standardizing it using rules.\\n • Use fancy algorithms to detect duplicates which are obvious by just looking at the strings. For \\nexample, “ICS” and “Informatics Computer System” do not look similar. But if they have the \\nsame address, same number of employees, etc., then you can say they are the same.\\n • Let us look at another instance of de-duplication. A retail outlet has several branches in the city. \\nThe same customer might happen to visit a few of these. It is very likely that his name is spelled \\ndifferently while invoicing at the varied branches. Assuming the name of the customer is “Aleck \\nStevenson”. In one of the invoices, his name appears as “Mr. A. Stevenson”, in another it is spelled \\nas “Mr. Stevenson Aleck”, in another case it is “Mr. S. Aleck”, and so on. Different formats of the \\nname but the same customer. We require an algorithm that could look up another detail of the \\ncustomer such as the social security number which will be common in all transactions made by \\nthe customer and replace the name of the customer with just one consistent format.\\nInconsistent data concerning Mr. Aleck Stevenson before cleaning up\\nInvoice 1:\\nCustomerName SocialSecurityNo\\n101 Mr. Aleck Stevenson ADWPS10017 _______\\nBillNo\\n_______\\nInvoice 2:\\nCustomerName SocialSecurityNo\\n205 Mr. S. Aleck ADWPS10017 _______\\nBillNo\\n_______\\nInvoice 3:\\nCustomerName SocialSecurityNo\\n314 Mr. Stevenson Aleck ADWPS10017 _______\\nBillNo\\n_______\\nInvoice 4:\\nCustomerName SocialSecurityNo\\n316 Mr. Alec Stevenson ADWPS10017 _______\\nBillNo\\n_______'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 205}, page_content='Consistent data after cleaning up\\nInvoice 1:\\nCustomerName SocialSecurityNo\\n101 Mr. Aleck Stevenson ADWPS10017 _______\\nBillNo\\n_______\\nInvoice 2:\\nCustomerName SocialSecurityNo\\n205 Mr. Aleck Stevenson ADWPS10017 _______\\nBillNo\\n_______\\nInvoice 3:\\nCustomerName SocialSecurityNo\\n314 Mr. Aleck Stevenson ADWPS10017 _______\\nBillNo\\n_______\\nInvoice 4:\\nCustomerName SocialSecurityNo\\n316 Mr. Aleck Stevenson ADWPS10017 _______\\nBillNo\\n_______\\n • We can also look at using external data to clean up the data for de-duplication. For example, US Post-\\nal Service publishes a CD of every valid address in the US. One easy step to major de-duplication is \\nfor businesses to buy that CD and use that to convert all their address data to this standard format.\\n6.11.4 Key Areas of Study\\nLet us look at a few key areas of study in this area:\\n • Data governance: Good decisions are based on quality data. Data governance is a quality regime \\nthat includes ensuring accuracy, consistency, completeness, and accountability of data. There \\nare policies that govern the use of data in an organization. This is done primarily to secure data \\nfrom hackers and data from inadvertently leaking out. Data governance also ensures compliance \\nwith regulations.\\n • Metadata management: Metadata, previously called Data Dictionary, is a collection of defini-\\ntions and relationships that describe the information stored. It is data about data. The storage \\nand access of metadata information is as important today as it was earlier.\\n • Data architecture and design: Overall architecture − data storage, ETL process design, BI \\narchitecture, etc.\\n • Database management: This includes optimizing the performance of the database, backup, \\nrecovery, integrity management, etc.\\n • Data security: Who should have access? Which data needs to be kept private?\\nBasics of Data Integration • 181'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 206}, page_content='182 • Fundamentals of Business Analytics\\n • Data quality: Lots of work is needed to ensure that there is a single version of truth in the data \\nwarehouse. Especially difficult for non-transactional data (i.e., data that is not there in a data-\\nbase). For example, Ashwin Shrivastava is the same as A. Shrivastava. Need fancy software that \\nwill do these transformations on the data.\\n • Data warehousing and business intelligence: T o measure, monitor, and manage performance: \\n“you cannot manage what you cannot measure and you cannot measure what you cannot define”.\\nUnsolved exercises\\n 1. What is data quality?\\n 2. Why is data quality important?\\n 3.  How do we maintain data quality? Explain \\ngiving examples.\\n 4.  How is data integrity different from data \\nquality? Explain.\\n 5.  Data quality is defined by several dimen-\\nsions like accuracy/correctness, timeliness, \\nconsistency, and completeness. Explain \\ngiving examples.\\n 6.  Data can be accurate yet inconsistent. \\n Explain with an example.\\n 7.  Data is complete yet inaccurate. Explain \\nwith an example.\\n 8.  Why is the timeliness of data so important? \\nComment.\\n 9.  Is metadata a dimension of data quality? \\nComment.\\n10.  Explain entity integrity and referential in-\\ntegrity constraint using an example.\\n11.  Write about a situation from your life \\nwhere you feel that data quality has been \\ncompromised.\\n6.12  dATA ProFilinG\\n6.12.1 The context\\nA few questions…\\nIf you have ever been a part of the process of data warehouse design, has this happened to you?\\n • You were in a great hurry to start your project and create your database, and populate it with \\ndata; however, you later realized that there were several data inconsistencies in the source, like \\nmissing records or NULL values.\\n • Or, the column you chose to be the primary key column is not unique throughout the table.\\n • Or, you realized that the schema design was not coherent to the end user-requirements.\\n • Or, any other concern with the data or the database/data warehouse that made you wish you had \\nfixed that concern right at the beginning.\\nWell, you are not alone! Every day, many database professionals (novices and experienced people \\nalike) face such situations. Every single day, these people encounter many problems and issues with the \\nquality of the data they are populating in the database/data warehouse.\\nT o fix such data quality issues would mean making changes in your ETL data flow packages, cleaning \\nthe identified inconsistencies, etc. This in turn will lead to a lot of re-work to be done. Re-work will \\nmean added costs to the company, both in terms of time and effort. What would you do in such a case? \\nWell, analyze the data source more closely, of course! Also, you would want to understand the business \\nrules and user requirements better, or know the final purpose for which the database will be used for.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 207}, page_content='6.12.2 The Problem\\nIn case the quality of the data at the source is not good, the inconsistencies and errors tend to amplify \\nthemselves over the entire process of creating ETL packages, creating the data warehouse, and finally \\nusing that data warehouse for analysis or reporting purposes.\\nFrom the business point of view, one cannot expect the final data warehouse to deliver the right infor-\\nmation in this case. As we are all aware, right information delivery is extremely important for making \\nwise, informed decisions and hence meeting expected goals and achieving quality results.\\nFrom the developer’s point of view, incorrect information resulting from poor quality data will mean \\nregressively analysing the source data for drawbacks and inconsistencies. This means a huge amount of \\nre-work to be done. Re-work would mean more time consumed and more effort required to be put into \\nanalysing what went wrong, then editing or re-creating ETL packages, and making suitable changes in \\nthe data warehouse. Certainly, all this is something we can do without!\\nConsider the case of the library system of DIIT . The source data that was main-\\ntained in Excel sheets and Access database had a lot of inconsistencies that were \\npointed out by Prof. Frank. One of these inconsistencies was the “PhoneNumber” \\ncolumn in the “Student” table.\\nThis column has certain entries that have special characters, like circular brackets \\n(). Suppose, all these entries were to pass on as they are, into the database, without \\ncleaning them of the special characters and spaces, etc. and imagine if an applica-\\ntion used this database to refer to the phone number of a particular student and \\nattempted to dial directly to that number. Since any of these numbers could be a \\nstring value with special characters, the application will fail to do the required job. \\nIn this case, it is of utmost importance that this column be maintained as a purely \\nnumerical (integer) column, cleansed of all non-integral characters.\\nNow, it is required of an ETL developer to keep a suspiciously vigilant eye for \\nsuch errors. There may be thousands and lakhs of records in a table, and there may \\nbe very small, unnoticeable errors like these in the table. So, one cannot just proceed \\nwith performing ETL without looking out for such errors or inconsistencies and \\nfiguring how to deal with them.\\n6.12.3 The Solution\\nInstead of a solution to the problem, would it not be better to catch it right at the start before it \\nbecomes a problem? After all, we are all too familiar with the age-old saying: “Prevention is better \\nthan cure!”\\nIn fact, this has been the tone of database designers, developers and administrators since the time \\ndatabases came into being. However, with the exponential rise in the volume of data being stored, \\nstudying and analyzing data in the source manually, became a tedious task. Hence data profiling soft-\\nware came to the rescue!\\nAs per Kimball, data profiling software is now used not only for initial analysis of the data source, \\nbut throughout the life-cycle of data warehouse development. They have proved to be of great help in \\nidentifying data quality issues with the source as well as in looking out for errors that crept in during \\nthe data integration phase.\\nPhone Number\\n9952392126\\n9555533325\\n9554477886\\n9325489654\\n9654238552\\n(8545)225689\\n78562 31848\\n9565622261\\n98789-54655\\n99988-84569\\n7700598648\\n9982485698\\n9900665898\\n9874652365\\n9879879876\\nBasics of Data Integration • 183'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 208}, page_content='184 • Fundamentals of Business Analytics\\n6.12.4 What is Data Profiling?\\nData profiling is the process of statistically examining and analysing the content in a data source, and \\nhence collecting information about that data. It consists of techniques used to analyze the data we have \\nfor accuracy and completeness.\\n • Data profiling helps us make a thorough assessment of data quality.\\n•\\t It assists the discovery of anomalies in data.\\n • It also helps us understand content, structure, relationships, etc. about the data in the data \\nsource we are analyzing.\\n•\\t It helps us know whether the existing data can be applied to other areas or purposes too.\\n • It helps us understand the various issues/challenges we may face in a database project much \\n before the actual work begins. This enables us to make early decisions and act accordingly.\\n • It helps add quality to data by converting from the format in which it is stored (i.e., assigning \\nmore meaning to it), or categorizing it.\\n•\\t It helps assess the risks associated with integrating data with other applications.\\n • Data profiling is also used to assess and validate metadata. This helps determine if the source is \\nsuitable enough for the intended purpose; and if so, then it is used to identify initial problems \\nso that an appropriate solution may be designed for them.\\nAccording to Brian Marshall, data profiling can be either data quality profiling or database profiling.\\n • Data quality profiling: It refers to analyzing the data from a data source or database against \\ncertain specified business rules or requirements. This enables us identify and thus assess the ma-\\njor problems/issues associated with the quality of the data being analyzed. The analysis can be \\nrepresented as summaries or details.\\n� Summaries: Counts and percentages that give information on the completeness of data sets, \\nthe problem distribution in a data set, the uniqueness of a column, etc.\\n� Details: Involves lists that contain information about missing data records or data problems \\nin individual records, etc.\\n • Database profiling: It refers to the procedure of analysis of a database, with respect to its schema \\nstructure, relationships between tables, columns used, data-type of columns, keys of the tables, etc.\\nGenerally, database profiling is the initial step that defines the data quality rules and lays the basic \\ngroundwork for the task of data quality profiling.\\n6.12.5 When and How to Conduct Data Profiling?\\nIt is a good practice to schedule profiling tasks right before going into the details of designing the \\nsystem/warehouse (though profiling is also conducted throughout the data warehousing process). \\nGenerally, data profiling is conducted in two ways:\\n • Writing SQL queries on sample data extracts put into a database.\\n • Using data profiling tools.\\nWhen to Conduct Data Profiling?\\n • At the discovery/requirements gathering phase: As soon as source data systems have been \\nidentified and business requirements have been laid out, an initial data profiling exercise must \\ntake place to examine the source data for anomalies, or any other such drawbacks that do not '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 209}, page_content='concur with the given business requirements, or are detrimental to the designing of the data \\nwarehouse. This phase involves more of data quality profiling. It helps identify most potential \\nissues at an early stage, and hence avoid corrections and re-work.\\n • Just before the dimensional modeling process: This is the stage where intensive data profiling \\nis done. This stage involves more of database profiling, and also some of data quality profiling. In \\nthis phase, we analyze the most appropriate schema design for the dimensional data warehouse, \\nand decide on the best method we can employ for conversion of the source data system to the \\ndimensional model.\\n • During ETL package design: Certain data profiling analyses can be done during the ETL process \\ntoo. The advantage is: it will help us identify possible errors and problems that may creep into the \\ndata due to ETL transformations applied on it. Data profiling during ETL also enables us identify \\nwhat data to extract and what filters to apply, besides giving information on whether transforma-\\ntions have been applied correctly or not. This phase hence involves more of data quality profiling.\\nHow to Conduct Data Profiling?\\nAs mentioned before, data profiling involves statistical analysis of the data at source and the data being \\nloaded, as well as analysis of metadata. These statistics may be used for various analysis purposes. The \\nmost common examples of analyses to be done are as under:\\n • Data quality: Analyze the quality of data at the data source. A column containing telephone num-\\nbers may be alpha-numeric in nature. Hence, the non-numeric characters need to be removed.\\n • NULL values: Look out for the number of NULL values in an attribute.\\n • Candidate keys: Analysis of the extent to which certain columns are distinct (percentage-wise) \\nwill give the developer useful information with respect to selection of candidate keys.\\n • Primary key selection: T o check whether the candidate key column does not violate the basic \\nrequirements of not having NULL values or duplicate values.\\n • Empty string values: A string column may contain NULL or even empty string values. During cube \\nanalysis, these empty string or NULL values may create problems later. For example, if a cube is cre-\\nated in Microsoft SSAS, columns containing empty string values cause the cube to fail deployment.\\n • String length: An analysis of the largest and shortest possible length as well as the average string \\nlength of a string-type column can help us decide what data type would be most suitable for the \\nsaid column.\\n • Numeric length and type: Similarly, assessing the maximum and minimum possible values of \\na numeric column can help us decide what numeric data type would be best suited for that col-\\numn. Also, if it does not have decimal values, one should consider declaring it as an integer-type \\ncolumn instead of float-type.\\n • Identification of cardinality: The cardinality relationships (like one-to-one, one-to-many, and \\nmany-to-many) are important for inner and outer join considerations with regard to several \\nBI tools. They are also important for the design of the fact-dimension relationships in the data \\nwarehouse.\\n • Data format: Sometimes, the format in which certain data is written in some columns may not \\nbe user-friendly. For example, if there is a string column that stores the marital status of a person \\nin the form of “M” for “Married” and “U” for “Unmarried”, we might consider changing the \\nshort forms to the full lengthened forms (i.e., change to “Married” and “Unmarried”, respec-\\ntively) in the data warehouse, since they are easier to comprehend.\\n... and many more cases like these.\\nBasics of Data Integration • 185'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 210}, page_content='186 • Fundamentals of Business Analytics\\nCommon Data Profiling Software\\nMost of the data-integration/analysis softwares have data profiling functions built into them. \\nAlternatively, various independent data profiling tools are also available. Some popular ones (as shown \\non www.topbits.com) have been listed below:\\n • Trillium Enterprise Data Quality: Powerful, yet very user-friendly software.\\n� It scans all the data systems you require it to manage.\\n� Automatically runs continual scans periodically to check whether all the data is consistently \\nupdated.\\n� Removes duplicate records.\\n� Provides for the separation of data into categories to allow easier data management.\\n� Generates statistical reports about the data systems regularly.\\n • Datiris Profiler: This tool is very flexible and can manage your data without inputs from the \\nuser. Certain defaults can be set, and the tool manages your data automatically. It has many \\npowerful features (listed below) that set it at a level higher than other profiling tools:\\n� A powerful metric system.\\n� Very good compatibility with other applications.\\n� Domain validation.\\n� Command-line interface.\\n� Pattern analysis.\\n� Real time data viewing.\\n� Batch profiling.\\n� Conditional profiling.\\n� Profile templates and spreadsheets.\\n� Data definitions.\\n • Talend Data Profiler: It is a free, open-source software solution to data profiling, which is now \\nslowly becoming popular. It may not be as powerful as Datiris or other paid profilers, but it is \\ngood enough for small businesses and non-profit organizations.\\n • IBM Infosphere Information Analyzer: A powerful profiling tool developed by IBM, it does \\na deep-scan of the system in a very short time-period. Various other software features integrated \\nwith this tool are\\n� IBM Infosphere security framework.\\n� Scanning scheduler.\\n� Reports.\\n� Source system profiling and analysis.\\n� Rules analysis.\\n� User annotations.\\n� Consistent common metadata across all other IBM Infosphere products.\\n • SSIS Data Profiling Task: This data profiling tool is not an independent software tool. It is \\nintegrated into the ETL software called SQL Server Integration Services (SSIS) provided by \\nMicrosoft. It can provide useful statistics about the source data as well as the transformed data \\nthat is being loaded into the destination system.\\n • Oracle Warehouse Builder: Oracle warehouse builder is not strictly a data-profiling software \\ntool. It has the necessary functionality to let a person with zero programming knowledge build '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 211}, page_content='a data warehouse from scratch. One of its features is the data profiling functionality which helps  \\nanalyze source systems and hence provide “clean” data.\\nsUMMArY\\nWe have come to the end of this chapter, and by now we can appreciate (to a certain extent) the basic \\nconcepts of data integration, the ETL process, issues and concerns about data quality, and the enormous \\nbenefits of profiling data intensively at every stage of the data warehousing life-cycle.\\nGiven below is the list of major steps that are undertaken during the data warehousing process:\\n • Identify data sources.\\n•\\t Design schema for data warehouse.\\n•\\t Profile the source data.\\n•\\t Formulate business rules and strategy for data integration.\\n•\\t Perform ETL and populate the data into the data warehouse.\\n • Perform tests and checks (validation) on the transported data and the related metadata.\\nThe major advantages of data profiling are listed below:\\n • Potential threats, errors, or inconsistencies can be detected quite early at the start of the project \\nlife-cycle.\\n•\\t It saves time and effort.\\n•\\t It increases the quality of data, hence the information derived is of the highest quality too.\\n • Scheduling data profiling tasks periodically will help detect and eliminate erroneous missing or \\nduplicate data immediately, thus maintaining a high level of accuracy and consistency.\\n • Helps add deeper meaning to data.\\nEven though data profiling may seem to be a tedious activity, it has benefits that far outweigh the \\nefforts put into profiling. It adds value to the database and creates great value for the business as well.\\nA cAse sTUdY FroM The heAlThcAre doMAin\\n“HealthyYou” is a home healthcare products and services company of the “GoodLife HealthCare \\nGroup” that provides various easy-to-use at home, medical products for patients suffering from various \\nBasics of Data Integration • 187'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 212}, page_content='188 • Fundamentals of Business Analytics\\nailments, delivered at their doorstep. This company provides three types of medical products catego-\\nrized as Disposable-Items (cotton pack, syringe, saline bottle, hand gloves, bandage, etc.), Reusable-\\nItems (wheelchair, walker, donut cushion, thermometer, blood glucose meter, adjustable beds, etc.), and \\nMedicines (Avayatin, Aquasure, Acerint, Instadril, Antidrome, Mutacine, etc.). There is a department \\nfor each category such as DisposableItem (DI), ReusableItem (RI), and Medicines (Med) department. \\n“HealthyYou” has expansion plans and is likely to have branches in different locations nationwide.\\nRita (receptionist) sits at the reception desk and attends to calls and makes note of the products \\nrequired/requested/ordered by the patients. The customer can either place an order on call or can even \\ncome down to the company’s center and purchase the products. If an order is made on call then payment \\nhas to be made online. However, cash/debit card payment is accepted when one directly purchases at the \\ncenter. Data is stored and maintained by each department in MS Excel spreadsheet. Rita, the reception-\\nist, maintains the details of callers/patients in an MS Access Database. However, the orders placed by the \\ncaller/patient are maintained by her in an MS Excel spreadsheet. The management of the company is in \\nneed of a report that will indicate the products that are in demand and are sold off-the-shelf very quickly. \\nThis is because the company would like to optimize their manufacturing processes to produce products \\nthat are in demand in larger volumes. Likewise they would want to discontinue the manufacturing of \\nproducts which are no longer in demand. A report is also required that will show the annual revenue \\ngenerated by the sale of products of all categories. This report should further drill down to the earnings \\non each item/product. The data is stored in different formats and to get a unified view of the data, a lot of \\nwork will be required. Robert (Manager) was called upon to suggest a possible solution to the problem. \\nIn Robert’s opinion, it would be better if the company starts to archive the data in a data warehouse/data \\nmart. The arguments put forth by him in favour of the company’s data warehouse were:\\n • Data from several heterogeneous data sources (MS Excel spreadsheets, MS Access database, \\n.CSV file, etc.) can be extracted and brought together in a data warehouse.\\n • Even when the company expands into several branches in multiple cities nationwide, it still can \\nhave one data warehouse to support the information needs of the company.\\n•\\t Data anomalies can be corrected through an ETL package.\\n•\\t Missing or incomplete records can be detected and duly corrected.\\n•\\t T ransformations can be made to convert the data into an appropriate format.\\n•\\t Duplicate data can be removed.\\n•\\t Uniformity can be maintained over each attribute of a table.\\n•\\t Retrieval of data for analysis and reports can be done conveniently (like the report requested \\nabove).\\n•\\t Fact-based decision making can be easily supported by a data warehouse.\\n • Ad hoc queries can be easily supported.\\nLet us assume that all the categories [DisposableItem, ReusableItem, Medicines, Purchase (showing the \\nproducts purchased by the patients)] store the data in separate sheets in an Excel workbook, except the \\nPatient table which is in an Access database. Each sheet contains a table. There are five tables in all:\\n • Patient (Access)\\n•\\t Disposable (Excel)\\n•\\t Reusable (Excel)\\n•\\t Medicines (Excel)\\n • Purchase (Excel)\\nPreviews of each of these tables are as follows:'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 213}, page_content='Patient\\nDisposable\\nCBA\\n1\\n2\\n3\\n4\\n5\\n6\\nDisposable Item Id\\nD001\\nD002\\nD003\\nD004\\nD005\\nDisposable Item Name\\nCotton Pack\\nSyringe\\nSaline bottle\\nHand gloves\\nBandage\\nUnit Price (INR)\\nRs.45\\nRs.101.25\\nRs.330.75\\nRs.67.5\\nRs.134.10\\nReusable\\nCBA\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\nReusable Item Id\\nR001\\nR002\\nR003\\nR004\\nR005\\nR006\\nReusable Item Name\\nWheel Chair\\n    Walker\\n             Adjustable Bed\\n      Donut Cushion\\n    Thermometer\\n   Blood Glucose Meter\\nUnit Price (INR)\\nRs.6727.5\\nRs.2250\\nRs.100400\\nRs.855\\nRs.506.25\\nRs.1125\\nC\\nDisease\\nD\\nDate of Birth\\nE\\nGender\\nF\\nPhone Number\\nB\\nPatient Name\\nA\\nPatient ID1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\n20\\n21\\n22\\n10001\\n10002\\n10003\\n10004\\n10005\\n10006\\n10007\\n10008\\n10009\\n10010\\n10011\\n10012\\n10013\\n10014\\n10015\\n10016\\n10017\\n10018\\n10019\\n10020\\n10021\\nA.V.Rao\\nRaman Chandrashekar\\nSinghania M K\\nTarannum Naaz\\nAlbert Goldberg\\nYogeshwar Bachupally\\nNikhil Shirish Agate\\nCharles Winslet\\nCharlotte Beckinsale\\nNiharika Tyagi\\nAnkita Dhananjay Karandikar\\nBhuvan Vishwanath Deshpande\\nAllison Williams\\nN. Sirisha Naidu Peddinti\\nSandeep Maroli Kini\\nManjunath Nagappa Krishna Murthty\\nSophie Brown\\nHima Bindu Venkata Neelamraju\\nPhunsuk Wangdu\\nPriyanka Badjatiya\\nHo-Shi Zong\\nAnemia\\nDiabetes\\nArthritis\\nCough\\nFever\\nPolio\\nArthritis\\nFever\\nDiabetes\\nBody Ache\\nCough\\nBody Ache\\nDiabetes\\nFracture\\nDiabetes\\nCough\\nArthritis\\nCold\\nPolio\\nArthritis\\nFracture\\n030-0074321\\n(5) 555-4729\\n(5) 555-3932\\n(171) 555-7788\\n0921-12 34 65\\n0621-08460\\n88.60.15.31\\n(91) 555 22 82\\n91.24.45.40\\n(604) 555-4729\\n(171) 555-1212\\n(1) 135-5555\\n(5) 555-3392\\n0452-076545\\n(11) 555-7647\\n(171) 555-2282\\n0241-039123\\n40.67.88.88\\n(171) 555-0297\\n7675-3425\\n(11)555-9857\\n8/21/1971\\n3/3/1966\\n4.4.1956\\n6/11/1989\\n1/1/1989\\n3/18/2001\\n4/4/1962\\n4.12.1994\\n11/10/1968\\n10/10/1988\\n9/6/1963\\n11.1.1982\\n7/8/1964\\n5/8/1988\\n11.10.1953\\n1/4/1952\\n4/12/1954\\n11/10/1977\\n2/10/1999\\n12/6/1945\\n1/1/1976\\nM\\nM\\nM\\nF\\nM\\nM\\nM\\nM\\nM\\nF\\nF\\nM\\nM\\nM\\nM\\nM\\nF\\nF\\nM\\nF\\nM\\nBasics of Data Integration • 189'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 214}, page_content='190 • Fundamentals of Business Analytics\\nMedicines\\nMedicineId\\nM001\\nAcerint\\nInstadril\\nAntidrome\\nNitacine\\nMutacine\\nBendrigin\\nAquasure\\nAvayatin\\nArthritis\\nPolio\\nBody Ache\\nFracture\\nFever\\nCough\\nDiabetes\\nAnemia\\nRs.90\\nRs.94.5\\nRs.54\\nRs.81\\nRs.63\\nRs.126\\nRs.49.5\\nRs.123.75\\nM002\\nM003\\nM004\\nM005\\nM006\\nM007\\nM008\\nMedicineName Disease ExpiryDate\\n10/20/2014\\n2/4/2016\\n9/5/2014\\n8/6/2012\\n4/5/2016\\n8/3/2015\\n7/2/2013\\n9/25/2012\\nUnitPrice(INR)1\\nAB CD E\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\nPurchase\\nCD EFBA\\nBillId ItemId PatientId QuantityOrdered PurchaseDate Payment Mode1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\n20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n30\\n31\\n32\\n33\\nB001\\nB002\\nB003\\nB004\\nB005\\nB006\\nB007\\nB008\\nB009\\nB010\\nB011\\nB012\\nB013\\nB014\\nB015\\nB016\\nB017\\nB018\\nB019\\nB020\\nB021\\nB022\\nB023\\nB024\\nB025\\nB026\\nB027\\nB028\\nB029\\nB030\\nB031\\nB032\\nD001\\nD002\\nD002\\nD002\\nD002\\nD002\\nD002\\nD002\\nD002\\nD003\\nD003\\nD004\\nD005\\nM001\\nM001\\nM002\\nM003\\nM006\\nM008\\nR001\\nR002\\nR003\\nR004\\nR005\\nM005\\nM004\\nM007\\nM004\\nM004\\nD001\\nM004\\nD001\\n10021\\n10009\\n10002\\n10015\\n10019\\n10007\\n10001\\n10009\\n10017\\n10001\\n10001\\n10021\\n10014\\n10001\\n10001\\n10002\\n10003\\n10006\\n10014\\n10014\\n10017\\n10001\\n10021\\n10008\\n10005\\n10016\\n10012\\n10014\\n10011\\n10014\\n10011\\n10014\\n8\\n3\\n4\\n2\\n7\\n5\\n6\\n5\\n4\\n5\\n5\\n2\\n3\\n12\\n12\\n10\\n10\\n14\\n12\\n1\\n1\\n1\\n2\\n1\\n16\\n12\\n11\\n15\\n16\\n12\\n16\\n12\\n29/09/2010\\n20/10/2010\\n29/10/2010\\n30/10/2010\\n30/10/2010\\n23/11/2010\\n24/11/2010\\n22/11/2010\\n30/11/2010\\n20/12/2010\\n13/12/2010\\n14/12/2010\\n19/12/2010\\n31/12/2010\\n15/1/2011\\n21/1/2011\\n16/1/2011\\n18/1/2011\\n18/1/2011\\n19/1/2011\\n17/01/2011\\n20/01/2011\\n21/01/2011\\n25/01/2011\\n31/01/2011\\n13/2/2011\\n15/2/2011\\n19/2/2011\\n18/2/2011\\n16/2/2011\\n18/2/2011\\n16/2/2011\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCard\\nCard\\nCard\\nCash\\nOnline\\nCash\\nOnline\\nCash\\n(Continued)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 215}, page_content='The Purchase table keeps records of all transactions (purchases) made from the company by customers \\n(patients). “Patients” data is stored in the Patient table. The rest of the three tables contain data about \\nthe products (DisposableItem, ReusableItem, Medicines) that can be purchased from the company. The \\nrequirements, as stated by Robert, are as follows:\\n • Data in all tables should be in proper format and must be consistent.\\n • UnitPrice column should be in a uniform format, preferably as a numeric data type.\\n • Date of birth should be in a uniform format (dd-mm-yyyy).\\n • Date columns should be in a uniform format, preferably as a datetime data type.\\n • The three tables − DisposableItem, ReusableItem, and Medicines − shall be combined into a \\nsingle table that contains details of all these three categories of products.\\n • Extra white spaces should be removed from the product names.\\nLet us look at the ER model for the above-stated scenario. Here, we consider two entities: DisposableItem \\nand Purchase.\\nEntity Relationship Model\\nCD EFBA\\nBillId ItemId PatientId QuantityOrdered PurchaseDate Payment Mode1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\n20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n30\\n31\\n32\\n33\\nB001\\nB002\\nB003\\nB004\\nB005\\nB006\\nB007\\nB008\\nB009\\nB010\\nB011\\nB012\\nB013\\nB014\\nB015\\nB016\\nB017\\nB018\\nB019\\nB020\\nB021\\nB022\\nB023\\nB024\\nB025\\nB026\\nB027\\nB028\\nB029\\nB030\\nB031\\nB032\\nD001\\nD002\\nD002\\nD002\\nD002\\nD002\\nD002\\nD002\\nD002\\nD003\\nD003\\nD004\\nD005\\nM001\\nM001\\nM002\\nM003\\nM006\\nM008\\nR001\\nR002\\nR003\\nR004\\nR005\\nM005\\nM004\\nM007\\nM004\\nM004\\nD001\\nM004\\nD001\\n10021\\n10009\\n10002\\n10015\\n10019\\n10007\\n10001\\n10009\\n10017\\n10001\\n10001\\n10021\\n10014\\n10001\\n10001\\n10002\\n10003\\n10006\\n10014\\n10014\\n10017\\n10001\\n10021\\n10008\\n10005\\n10016\\n10012\\n10014\\n10011\\n10014\\n10011\\n10014\\n8\\n3\\n4\\n2\\n7\\n5\\n6\\n5\\n4\\n5\\n5\\n2\\n3\\n12\\n12\\n10\\n10\\n14\\n12\\n1\\n1\\n1\\n2\\n1\\n16\\n12\\n11\\n15\\n16\\n12\\n16\\n12\\n29/09/2010\\n20/10/2010\\n29/10/2010\\n30/10/2010\\n30/10/2010\\n23/11/2010\\n24/11/2010\\n22/11/2010\\n30/11/2010\\n20/12/2010\\n13/12/2010\\n14/12/2010\\n19/12/2010\\n31/12/2010\\n15/1/2011\\n21/1/2011\\n16/1/2011\\n18/1/2011\\n18/1/2011\\n19/1/2011\\n17/01/2011\\n20/01/2011\\n21/01/2011\\n25/01/2011\\n31/01/2011\\n13/2/2011\\n15/2/2011\\n19/2/2011\\n18/2/2011\\n16/2/2011\\n18/2/2011\\n16/2/2011\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCard\\nCard\\nCard\\nCash\\nOnline\\nCash\\nOnline\\nCash\\nDisposableItem PurchasePurchasedDisposableItemName\\nUnitPrice\\nDisposableItemId\\nPatientId\\nQuantityOrdered\\nItemId\\nBillIdId\\nPurchasedate\\nPaymentMode\\n(Continued)\\nBasics of Data Integration • 191'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 216}, page_content='192 • Fundamentals of Business Analytics\\nLet us draw the dimensional model for this scenario.\\nDimensional Model\\nDimItem\\nPK ItemId\\nItemName\\nUnitPrice(In $)\\nDisease\\nExpiryDate\\nDimPatient\\nPK PatientId\\nPatientName\\nGender\\nDisease\\nDateOfBirth\\nPhoneNumber\\nFactPurchase\\nPK BillId\\nItemId\\nPatientId\\nQuantityOrdered\\nTotalAmount (INR)\\nPurchaseDate\\nPaymentMode\\nThe above relational schema could be implemented as an SQL Server database. Now, the major steps \\nthat were taken to transfer data from the Excel spreadsheets and Access database to SQL Server database \\nwere as follows (as done in the last example):\\n1.  Profiling the source data (identifying natural key columns, identifying data anomalies, correc-\\ntions to be made, etc.)\\n2. Results of profiling were:\\na. Identification of natural keys (that would naturally be unique and not null):\\n� Patient: PatientId\\n� DisposableItem: DisposableItemId\\n� ReusableItem: ReusableItemId\\n� Medicines: MedicineId\\n� Purchase: BillId\\nb. Removal of leading and trailing blanks wherever they occur.\\nc. Removal of special character(Rs.) from the “UnitPrice” column.\\nd. Removal of special character(-,.,(,)) from the “PhoneNumber” column.\\ne. T ransforming the “DateOfBirth” column to a standard date format (dd-mm-yyyy).\\nf. Deriving a column “BillAmount” in for the Purchase table which is the multiplication of \\nUnitPrice and QuantityOrdered.\\ng. The Gender column should contain “Male” and “Female” instead of “M” and “F ,” respectively.\\nh. Removal of duplicate rows from the Purchase table.\\n3.  Choose an appropriate ETL tool (SSIS, Kettle, Informatica, etc.) and create ETL packages to \\ntransform and transport the data from the source database to the destination database.\\n4.  Some of the major rules, transformations and data-cleaning activities that were identified and \\nimplemented were:\\na. Merging together the tables DisposableItem, ReusableItem, and Medicines into a single \\ntable “DimItem”.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 217}, page_content='b. Data-type conversion.\\nc. Removal of special character (Rs.) from the “UnitPrice” column.\\nd. Creating a new column “T otalAmount” in FactPurchase. T otalAmount would be calculated as\\n(QuantityOrdered) ë UnitPrice (INR )\\ne. Removing leading and trailing blanks wherever they occur.\\nf. Removal of special characters from the “PhoneNumber” (-,(,),.) column and its subsequent \\nconversion to numerical format.\\ng. Removal of special characters from the “UnitPrice” (Rs.) column and its subsequent conver-\\nsion to numerical format.\\nh. Standardizing the “BirthDate” column format (dd-mm-yyyy) and conversion to “Date-\\nTime” datatype.\\ni. Removal of duplicate rows from the Purchase table.\\nj. Changing the values of the Gender column from “M” and “F” to “Male” and “Female,” \\nrespectively.\\n5.  As per general practice, the Dimension tables (DimItem and DimPatient) are populated with \\ndata first, followed by the Fact table(s) (FactPurchase). This is because of referential constraints \\nof fact on the dimensions.\\nAfter performing ETL, the tables in the database looked like the diagrams below:\\nDimItem\\nItemId\\n1 Cotton Pack\\nSyringe\\nBandage\\nAquasure\\nAcerint\\nInstadril\\nAntidrome\\nBendrigiin\\nNitacine\\nWalker\\nBlood Glucose Meter\\nThermometer\\nDonut Cushion\\nAdjustable Bed\\nMutacine\\nWheel Chair\\nAvayatin\\nHand Gloves\\nSaline bottle\\nD002\\nD003\\nD004\\nD005\\nM001\\nM002\\nM003\\nM004\\nM005\\nM006\\nM007\\nM008\\nR001\\nR002\\nR003\\nR004\\nR005\\nR006\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\nItemName Disease\\n45.00 NA\\n2016-02-04 00:00:00.000\\n2012-08-06 00:00:00.000\\n2016-04-05 00:00:00.000\\n2015-08-03 00:00:00.000\\n2013-07-02 00:00:00.000\\n2014-09-05 00:00:00.000\\n2012-09-25 00:00:00.000\\n2014-10-20 00:00:00.000\\nNA\\nNA\\nNA\\nNA\\nAnemia\\nArthritis\\nCough\\nFever\\nPolio\\nBody Ache\\nFracture\\nDiabetes\\nNA\\nNA\\nNA\\nNA\\nNA\\nNA\\n101.25\\n330.75\\n67.50\\n134.10\\n123.75\\n90.00\\n49.50\\n54.00\\n81.00\\n63.00\\n6727.50\\n855.00\\n1125.00\\n506.25\\n100440.00\\n2250.00\\n126.00\\n94.50\\nExpiryDateUnitPrice(INR)\\nD001\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\nNULL\\nBasics of Data Integration • 193'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 218}, page_content='194 • Fundamentals of Business Analytics\\nDimPatient\\nPatientId\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\n20\\n21\\n10001\\n10002\\n10003\\n10004\\n10005\\n10006\\n10007\\n10008\\n10009\\n10010\\n10011\\n10012\\n10013\\n10014\\n10015\\n10016\\n10017\\n10018\\n10019\\n10020\\n10021\\nA.V. Rao\\nRaman Chandrashekar\\nSinghania M K\\nTarannum Naaz\\nAlbert Goldberg\\nYogeshwar Bachupally\\nNikhil Shirish Agate\\nCharles Winslet\\nCharlotte Beckinsale\\nNiharika Tyagi\\nAnkita Dhananjay Ka...\\nBhuvan Vishwanath...\\nAllison Williams\\nN. Sirisha Naidu Ped...\\nSandeep Maroli Kini\\nManjunath Nagappa...\\nSophie Brown\\nHima Bindu Venkata...\\nPhunsuk Wangdu\\nPriyanka Badjatiya\\nHo-Shi-Zong\\nMale\\nMale\\nMale\\nFemale\\nMale\\nMale\\nMale\\nMale\\nMale\\nFemale\\nFemale\\nMale\\nMale\\nMale\\nMale\\nMale\\nFemale\\nFemale\\nMale\\nFemale\\nMale\\nPatientName Gender Disease DateOfBirth PhoneNumber\\nAnemia\\nDiabetes\\nArthritis\\nCough\\nFever\\nPolio\\nArthritis\\nFever\\nDiabetes\\nBody A...\\nCough\\nBody A...\\nDiabetes\\nFracture\\nDiabetes\\nCough\\nArthritis\\nCold\\nPolio\\nArthritis\\nFracture\\n0300074321\\n55554729\\n55553932\\n1715557788\\n0921123465\\n062108460\\n88601531\\n915552282\\n91244540\\n6045554729\\n1715551212\\n11355555\\n55553392\\n0452076545\\n115557647\\n1715552282\\n0241039123\\n40678888\\n1715550297\\n76753425\\n115559857\\n1971-08-21 00:00:00.000\\n1966-03-03 00:00:00.000\\n1956-04-04 00:00:00.000\\n1989-06-11 00:00:00.000\\n1989-01-01 00:00:00.000\\n2001-03-18 00:00:00.000\\n1962-04-04 00:00:00.000\\n1994-04-12 00:00:00.000\\n1968-11-10 00:00:00.000\\n1988-10-10 00:00:00.000\\n1963-09-06 00:00:00.000\\n1982-11-01 00:00:00.000\\n1964-07-08 00:00:00.000\\n1988-05-08 00:00:00.000\\n1953-11-10 00:00:00.000\\n1952-01-04 00:00:00.000\\n1954-04-12 00:00:00.000\\n1977-11-10 00:00:00.000\\n1999-02-10 00:00:00.000\\n1945-12-06 00:00:00.000\\n1976-01-01 00:00:00.000\\nFactPurchase\\nBillId ItemId PatientId QuantityOrdered PurchaseDateTotalAmont(INR)P ayment Mode \\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\n20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n30\\nB001\\nB002\\nB003\\nB004\\nB005\\nB006\\nB007\\nB008\\nB009\\nB010\\nB011\\nB012\\nB013\\nB014\\nB015\\nB016\\nB017\\nB018\\nB019\\nB020\\nB021\\nB022\\nB023\\nB024\\nB025\\nB026\\nB027\\nB028\\nB029\\nB030\\nD001\\nD002\\nD002\\nD002\\nD002\\nD002\\nD002\\nD002\\nD002\\nD003\\nD003\\nD004\\nD005\\nM001\\nM001\\nM002\\nM003\\nM006\\nM008\\nR001\\nR002\\nR003\\nR004\\nR005\\nM005\\nM004\\nM007\\nM004\\nM004\\nD001\\n10021\\n10009\\n10002\\n10015\\n10019\\n10007\\n10001\\n10009\\n10017\\n10001\\n10001\\n10021\\n10014\\n10001\\n10001\\n10002\\n10003\\n10006\\n10014\\n10014\\n10017\\n10001\\n10021\\n10008\\n10005\\n10016\\n10012\\n10014\\n10011\\n10014\\n2010-09-29 00:00:00.000\\n2010-10-20 00:00:00.000\\n2010-10-29 00:00:00.000\\n2010-10-30 00:00:00.000\\n2010-10-30 00:00:00.000\\n2010-11-23 00:00:00.000\\n2010-11-24 00:00:00.000\\n2010-11-22 00:00:00.000\\n2010-11-30 00:00:00.000\\n2010-12-20 00:00:00.000\\n2010-12-13 00:00:00.000\\n2010-12-14 00:00:00.000\\n2010-12-19 00:00:00.000\\n2010-12-31 00:00:00.000\\n2011-01-15 00:00:00.000\\n2011-01-21 00:00:00.000\\n2011-01-16 00:00:00.000\\n2011-01-18 00:00:00.000\\n2011-01-18 00:00:00.000\\n2011-01-19 00:00:00.000\\n2011-01-17 00:00:00.000\\n2011-01-20 00:00:00.000\\n2011-01-21 00:00:00.000\\n2011-01-25 00:00:00.000\\n2011-01-31 00:00:00.000\\n2011-02-13 00:00:00.000\\n2011-02-15 00:00:00.000\\n2011-02-19 00:00:00.000\\n2011-02-18 00:00:00.000\\n2011-02-16 00:00:00.000\\n8\\n3\\n4\\n2\\n7\\n5\\n6\\n5\\n4\\n5\\n5\\n2\\n3\\n12\\n12\\n10\\n10\\n14\\n12\\n1\\n1\\n1\\n2\\n1\\n16\\n12\\n11\\n15\\n16\\n12\\n360.00\\n315.00\\n405.00\\n225.00\\n720.00\\n495.00\\n630.00\\n495.00\\n405.00\\n1665.00\\n1665.00\\n135.00\\n405.00\\n1485.00\\n1485.00\\n900.00\\n945.00\\n1125.00\\n1530.00\\n6750.00\\n2250.00\\n100440.00\\n1710.00\\n495.00\\n855.00\\n585.00\\n675.00\\n765.00\\n810.00\\n540.00\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCard\\nCard\\nCard\\nCash\\nOnline\\nCash\\n(Continued)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 219}, page_content='Now the data is in a unified view and analysis can be done on the data as required. T o know the sales of \\neach product, we can write a query in SQL Server as:\\nCREATE TABLE ProductSales (\\n ItemName varchar (50) PRIMARY KEY,\\n T otalQuantityOrdered int);\\nINSERT INTO ProductSales (ItemName, T otalQuantityOrdered)\\nSelect B.ItemName, ISNULL (T otalQuantityOrdered, 0) AS T otalQuantityOrdered FROM\\n((SELECT DimItem.ItemName, SUM (FactPurchase.QuantityOrdered) AS T otalQuantityOrdered\\nFROM FactPurchase INNER JOIN\\nDimItem ON FactPurchase.ItemId = DimItem.ItemId\\nGROUP BY DimItem.ItemName) AS A\\nRIGHT OUTER JOIN\\n(Select ItemName from DimItem)AS B\\nON A.ItemName=B.ItemName);\\nThe analyzed data can be shown as follows:\\nBillId ItemId PatientId QuantityOrdered PurchaseDateTotalAmont(INR)P ayment Mode \\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\n20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n30\\nB001\\nB002\\nB003\\nB004\\nB005\\nB006\\nB007\\nB008\\nB009\\nB010\\nB011\\nB012\\nB013\\nB014\\nB015\\nB016\\nB017\\nB018\\nB019\\nB020\\nB021\\nB022\\nB023\\nB024\\nB025\\nB026\\nB027\\nB028\\nB029\\nB030\\nD001\\nD002\\nD002\\nD002\\nD002\\nD002\\nD002\\nD002\\nD002\\nD003\\nD003\\nD004\\nD005\\nM001\\nM001\\nM002\\nM003\\nM006\\nM008\\nR001\\nR002\\nR003\\nR004\\nR005\\nM005\\nM004\\nM007\\nM004\\nM004\\nD001\\n10021\\n10009\\n10002\\n10015\\n10019\\n10007\\n10001\\n10009\\n10017\\n10001\\n10001\\n10021\\n10014\\n10001\\n10001\\n10002\\n10003\\n10006\\n10014\\n10014\\n10017\\n10001\\n10021\\n10008\\n10005\\n10016\\n10012\\n10014\\n10011\\n10014\\n2010-09-29 00:00:00.000\\n2010-10-20 00:00:00.000\\n2010-10-29 00:00:00.000\\n2010-10-30 00:00:00.000\\n2010-10-30 00:00:00.000\\n2010-11-23 00:00:00.000\\n2010-11-24 00:00:00.000\\n2010-11-22 00:00:00.000\\n2010-11-30 00:00:00.000\\n2010-12-20 00:00:00.000\\n2010-12-13 00:00:00.000\\n2010-12-14 00:00:00.000\\n2010-12-19 00:00:00.000\\n2010-12-31 00:00:00.000\\n2011-01-15 00:00:00.000\\n2011-01-21 00:00:00.000\\n2011-01-16 00:00:00.000\\n2011-01-18 00:00:00.000\\n2011-01-18 00:00:00.000\\n2011-01-19 00:00:00.000\\n2011-01-17 00:00:00.000\\n2011-01-20 00:00:00.000\\n2011-01-21 00:00:00.000\\n2011-01-25 00:00:00.000\\n2011-01-31 00:00:00.000\\n2011-02-13 00:00:00.000\\n2011-02-15 00:00:00.000\\n2011-02-19 00:00:00.000\\n2011-02-18 00:00:00.000\\n2011-02-16 00:00:00.000\\n8\\n3\\n4\\n2\\n7\\n5\\n6\\n5\\n4\\n5\\n5\\n2\\n3\\n12\\n12\\n10\\n10\\n14\\n12\\n1\\n1\\n1\\n2\\n1\\n16\\n12\\n11\\n15\\n16\\n12\\n360.00\\n315.00\\n405.00\\n225.00\\n720.00\\n495.00\\n630.00\\n495.00\\n405.00\\n1665.00\\n1665.00\\n135.00\\n405.00\\n1485.00\\n1485.00\\n900.00\\n945.00\\n1125.00\\n1530.00\\n6750.00\\n2250.00\\n100440.00\\n1710.00\\n495.00\\n855.00\\n585.00\\n675.00\\n765.00\\n810.00\\n540.00\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCash\\nCard\\nOnline\\nCard\\nCard\\nCard\\nCash\\nOnline\\nCash\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\nItemNameT otalQuantityOrdered\\n43\\n36\\n24\\n20\\n16\\n14\\n12\\n11\\n10\\n10\\n10\\n3\\n2\\n2\\n1\\n1\\n1\\n1\\n0\\nInstadril\\nSyringe\\nAvayatin\\nCotton Pack\\nAntidrome\\nBendrigin\\nMutacine\\nNitacine\\nAcerint\\nAquasure\\nSaline bottle\\nBandage\\nDonut Cushion\\nHand Gloves\\nAdjustable Bed\\nThermometer\\nWalker\\nWheel Chair\\nBlood Glucose Meter\\n(Continued)\\n(Continued)\\nBasics of Data Integration • 195'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 220}, page_content='196 • Fundamentals of Business Analytics\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\nItemNameT otalQuantityOrdered\\n43\\n36\\n24\\n20\\n16\\n14\\n12\\n11\\n10\\n10\\n10\\n3\\n2\\n2\\n1\\n1\\n1\\n1\\n0\\nInstadril\\nSyringe\\nAvayatin\\nCotton Pack\\nAntidrome\\nBendrigin\\nMutacine\\nNitacine\\nAcerint\\nAquasure\\nSaline bottle\\nBandage\\nDonut Cushion\\nHand Gloves\\nAdjustable Bed\\nThermometer\\nWalker\\nWheel Chair\\nBlood Glucose Meter\\nPoint Me (Books)\\n • The Data Warehouse ETL T oolkit by Ralph \\nKimball.\\n•\\t The Data Warehouse Lifecycle T oolkit by Ralph \\nKimball.\\nRemind Me \\n• \\t Data warehouse is a  system which can conve-\\nniently archive data.\\n• Data warehouse consists of four distinct \\ncomponents:\\n� Operational source systems.\\n� Data staging area.\\n� Data presentation area.\\n� Data access tools.\\n•\\t\\t ETL stands for Extract, T ransform, Load.\\n•\\t\\t ETL is\\n� Extracting data from different data \\nsources.\\n� T ransforming the data into relevant for-\\nmat to fit operational needs.\\n� Loading data into the final target data-\\nbase, usually a data warehouse.\\n • Data integration is the integration of data \\npresent in different sources and providing a \\nunified view of the data.\\n • Common approaches of data integration:\\n� Federated databases\\n� Data warehousing\\n� Memory-mapped data structure\\n • Data integration technologies:\\n�\\n Data interchange\\n� Object brokering\\n� Modeling techniques:\\n a. Entity Relationship (ER) Modeling\\n b. Dimensional Modeling\\n • Data profiling is the process of statistically \\nexamining and analyzing the content in a \\ndata source, and hence collecting information \\nabout that data.\\n(Continued)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 221}, page_content='Connect Me (Internet Resources)\\n•\\t http://en.wikipedia.org/wiki/Federated_database_system\\n•\\t http://en.wikipedia.org/wiki/Data_integration\\n•\\t http://www.telusplanet.net/public/bmarshal/dataqual.htm#DOC_TOP\\n•\\t http://www.tech-faq.com/data-profiling.html\\n•\\t http://it.toolbox.com/wiki/index.php/Data_profiling\\n•\\t http://en.wikipedia.org/wiki/Data_profiling\\n•\\t www.rkimball.com/html/designtipsPDF/KimballDT59SurprisingValue.pdf\\n•\\t http://tdwi.org/Articles/2010/02/03/Data-Profiling-Value.aspx?Page=1\\nTest Me Exercises\\nMatch me\\nData staging area Reduce data \\nredundancy\\nData warehouse Object brokering\\nER Modeling Data mapping\\nData Integration \\nT echnology\\nIntermediate storage\\nData Integration Approach Data profiling \\nsoftware\\nCycle initiation, build \\nreference data\\nArchive data\\nDatiris, Talend Instance Integration\\nColumn A Column B\\nBasics of Data Integration • 197'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 222}, page_content='198 • Fundamentals of Business Analytics\\nData staging area Intermediate storage\\nData warehouse Archive data\\nER Modeling Reduce data \\nredundancy\\nData Integration \\nT echnology\\nObject brokering\\nData Integration Approach Instance integration\\nCycle initiation, build \\nreference data\\nData mapping\\nDatiris, Talend Data profiling \\nsoftware\\nColumn A Column B\\nSolution:'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 223}, page_content='BI Crossword\\n1\\n7.\\n3.\\n5.\\n2\\n8.\\n3 2.\\n4 6.\\n1.\\n5 4. 6\\nBasics of Data Integration • 199'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 224}, page_content='200 • Fundamentals of Business Analytics\\nAcROSS\\n1  Statistical analysis of data content to \\n assess quality of data (9)\\n2  A system that stores and organizes large \\namounts of data in digital form for easy \\nmanagement and retrieval of data (8)\\n3  The process of combining data from dif-\\nferent sources to present it in a unified \\nform, while maintaining the integrity of \\nthe data (15)\\n4  A virtual database that is the integrated \\nview of multiple heterogeneous, auton-\\nomous and disparate databases (9)\\n5  The stage of data integration where con-\\nditions and rules are applied to make \\nfunctional changes to data extracted \\nfrom source (9)\\n6  The accuracy with which the attributes \\nassociated with data of an entity accu-\\nrately describe the occurrence of that \\nentity (13)\\nDOwn\\n1.  Intermediate storage area, that falls in \\nbetween data source and data mart (7)\\n2.  Data profiling tool developed by IBM: \\n________ Information Analyzer (10)\\n3.  After transformation of source data, it \\ngoes into target database. This final pro-\\ncess is called ____ (4)\\n4.  The process by which data elements \\nare matched between two distinct data \\nmodels for the purpose of identifying \\nrelationships, discovering hidden data, \\nidentifying required transformations \\netc. (7)\\n5.  Process by which data is pulled out from \\nsource for further transformation (7)\\n6.  The reliability, efficiency and overall in-\\ntegrity of data, and its appropriateness \\nfor the purpose of the business is called \\n_____ (11)\\n7.  Process of correcting/removing incon-\\nsistencies, inaccuracy, irregularities \\netc. in the data from records in a data-\\nbase (9)\\n8.  Property of the data in a database sys-\\ntem which measures the amount of data \\nactually available as compared to the \\namount of data that is expected to be \\navailable (12)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 225}, page_content='Solution:\\nC\\nPR OF IL IN G\\nLE\\nOE A\\nAX N\\nDA TA BA SE\\nRI C\\nDA TA IN TE GR AT IO NO\\nNC GM\\nFE DE RA TE DP\\nSO AL\\nTR AN SF OR MD AT AI NT EG RI TY\\nAP AA T\\nGH PQ E\\nIE PU N\\nNR IA E\\nGE NL S\\nGI S\\nT\\nY\\nsolved exercises\\n1. State the differences between data warehouse and data marts.\\nSolution:\\nFocuses on one subject area. Focuses on all subject areas across the \\nenterprise.\\nThere can be more than one data mart for an organization. \\nThere can be one data mart for every function such as a data \\nmart for finance, a data mart for marketing, a data mart for \\nhuman resources, etc.\\nThere can be only one enterprise-wide data \\nwarehouse.\\nContains relatively less information. Contains relatively more information.\\nIs easy to understand and navigate. Is relatively tougher to understand and \\nnavigate.\\nData Warehouse Data Mart\\nBasics of Data Integration • 201'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 226}, page_content='202 • Fundamentals of Business Analytics\\n2.  What are the differences between the top–down approach and the bottom–up approach to  building \\na data warehouse?\\nSolution:\\nThe focus is on data warehouse. The focus is on data marts.\\nWe start with designing the model for a data warehouse. We start with designing the model for a data \\nmart.\\nData warehouse is enterprise-oriented while data marts are \\nsubject-specific.\\nData marts provide both enterprise and \\nsubject specific views.\\nData warehouse is known to contain data at the atomic level \\nwhereas the data marts contain summarized data.\\nData marts contain both atomic and \\nsummary data.\\nBoth the data warehouse and data marts can be queried. Usually the data marts are queried.\\nThe top–down approach uses a multi-tier architecture \\ncomprising of staging area, data warehouse and dependent data \\nmarts.\\nThe bottom–up approach uses a flat \\narchitecture comprising staging area and \\ndata marts.\\nT op–Down Approach Bottom–Up Approach\\n3. What are the various ETL tools available in the market?\\nSolution:\\nInformatica Informatica Corporation\\nSQL Server Integration Services Microsoft\\nAb initio Ab initio Corporation\\nOracle Warehouse Builder Oracle Corporation\\nData Stage IBM Corporation\\nETL T ool Vendor\\n4. What do you understand by data cleansing?\\nSolution: Data cleansing is also called data scrubbing. It is a process that involves the detection and \\nremoval/of corrections from the database, which are caused by incomplete, inaccurate, redundant, \\nobsolete, or improperly formatted data.\\n5. What is real time data warehousing?\\nSolution: In general, a data warehouse is an archive of historical data. Such a data warehouse is \\na window on the past. If such a data warehouse is queried, it will reflect the state of the business \\nsometime in the past. Real time data warehouse is known to house real time business data. If \\nsuch a data warehouse is queried, it will reflect the state of the business at the time the query was \\nrun.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 227}, page_content='Unsolved exercises\\n1. Why is there a need for a data warehouse? Explain.\\n2. What is a data warehouse? Explain.\\n3. Explain these terms in William H. Inmon’s definition of a data warehouse: subject-oriented, \\nintegrated, non-volatile, and time-variant.\\n4. How is the Ralph Kimball’s approach to building a data warehouse different from the William \\nH. Inmon’s approach to building a data warehouse? Explain.\\n5. When should an organization go for a data warehouse? Comment.\\n6. Should larger organizations adopt the William H. Inmon’s approach to building a data ware-\\nhouse? Explain with reasons.\\n7. What are the goals that a data warehouse is meant to achieve?\\n8. What is your understanding of data sources? Explain.\\n9. What is data integration? Why should data be integrated in a data warehouse? Explain.\\n10. What are the advantages of building a data warehouse? Explain.\\n11. What are the various approaches to data integration?\\n12. What constitutes a data warehouse? Explain.\\n13. Assume you are a teacher and you are required to collect the “Date of Birth” of your students. T o \\nyour surprise, students provide “Date of Birth” in various formats such as “DD.MM.YY”, “DD/\\nMM/YYYY”, “DD-MMM-YY”, “MM/DD/YY”, “YY.MM.DD”. What will you do when faced \\nwith such a situation?\\n14. Explain schema integration and instance integration with an example.\\n15. What is your understanding of “data transformation”? Why is it required to transform data?\\n16. Explain the ETL process.\\n17. Explain the difference between “entity relationship modeling” and “dimensional modeling”.\\n18. Explain the steps to convert an ER model to a dimensional model.\\n19. How is an “Operational Data Store” different from a Data Warehouse? Explain.\\n20. What is your understanding of the staging area? Explain.\\n21. What is the meaning of data profiling? Explain.\\n22. When and how is data profiling conducted? Explain.\\n23. Mention a few data profiling tools available in the market.\\n24. Mention a few ETL tools available in the market.\\n25. How is a data warehouse different from a data mart? Explain.\\n26. Can reports be pulled from an OLTP source or from an operation data store (ODS)? Explain.\\n27. What is “single version of truth”? Explain with an example.\\n28. How is a federated database different from a data warehouse? Explain.\\n29. What is your understanding of the “presentation area”? Explain.\\n30. Is it a good idea for enterprises to maintain independent data marts? Explain your answer with \\nreasons.\\nBasics of Data Integration • 203'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 228}, page_content=''),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 229}, page_content='What’s in store\\nYou are already familiar with the concepts relating to basics of RDBMS, OLTP , and OLAP applica-\\ntions, role of ERP in the enterprise as well as “enterprise production environment” for IT deployment. \\nWe hope you have got a firm grasp on the concepts covered in the chapters “Types of Digital Data” \\n(Chapter 2), “Introduction to OLTP and OLAP” (Chapter 3), “Getting Started with Business \\nIntelligence” (Chapter 4), and “Basics of Data Integration (Chapter 6)”. With this background it’s time \\nto think about “how data is modeled”.\\nJust like a circuit diagram is to an electrical engineer, an assembly diagram is to a mechanical engi-\\nneer, and a blueprint of a building is to a civil engineer so is the data models/data diagrams to a data \\narchitect. But is “data modeling” only the responsibility of a data architect? The answer is “No”. A \\nBusiness Intelligence (BI) application developer today is involved in designing, developing, deploying, \\nsupporting, and optimizing storage in the form of data warehouse/data marts. T o be able to play his/her \\nrole efficiently, the BI application developer relies heavily on data models/data diagrams to understand \\nBrief Contents\\nWhat’s in Store\\nIntroduction\\nData Modeling Basics\\nTypes of Data Model\\nData Modeling T echniques\\nFact Table\\nDimension Table\\nTypical Dimensional Models\\nDimensional Modeling Life Cycle\\nDesigning The Dimensional Model\\nSolved Exercises\\nUnsolved Exercises\\nMultidimensional Data \\nModeling\\n7'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 230}, page_content='206 • Fundamentals of Business Analytics\\nthe schema structure, the data, the relationships between data, etc. In this chapter we will familiarize \\nyou with the basics of data modeling – How to go about designing a data model at the conceptual and \\nlogical levels? We will also discuss the pros and cons of the popular modeling techniques such as ER \\nmodeling and dimensional modeling.\\nWe suggest you refer to some of the learning resources suggested at the end of this chapter and also \\ncomplete the “T est Me” exercises. You will get deeper knowledge by interacting with people who have \\nshared their project experiences in blogs. We suggest you make your own notes/bookmarks while read-\\ning through the chapter.\\n7.1 introduction\\nrefer to the case study Brief of “tentoten retail stores”\\nA new range of cosmetic products has been introduced by a leading brand, which T enT oT en wants to \\nsell through its various outlets. In this regard T enT oT en wants to study the market and the consumer’s \\nchoice of cosmetic products. As a promotional strategy the group also wants to offer attractive introduc-\\ntory offers like discounts, buy one get one free, etc.\\nT o have a sound knowledge of the cosmetics market, T enT oT en Stores has to carry out a detailed \\nstudy of the buying pattern of consumers’ by geography, the sales of cosmetic products by outlet, most \\npreferred brand, etc. and then decide on a strategy to promote the product.\\nT o take right decisions on various aspects of business expansion, product promotion, consumer \\npreferences, etc., T enT oT en Stores has decided to go in for an intelligent decision support system. They \\napproached “AllSolutions” to provide them with an automated solution. AllSolutions is one of the \\nleading consulting firms of the world. They have been into business for about 15 years. Over the years \\nthey have become known for providing optimal IT solutions to the business problems of big and small \\nenterprises alike.\\nAfter studying the requirements of T enT oT en Stores, AllSolutions decided on building a data \\nwarehouse application. T o construct a data model that would meet the business requirements \\nput forth by T enT oT en Stores, AllSolutions identified the following concerns that need to be \\naddressed:\\n1.  What are the entities involved in this business process and how are they related to each \\nother?\\n2. What tables associated with those entities must be included in the data warehouse?\\n3. What columns have to be included into each table?\\n4. What are the primary keys for the tables that have been identified?\\n5.  What are the relations that the tables have with each other and which is the column on which \\nthe relationship has to be made?\\n6. What should be the column definitions for the columns that have been identified?\\n7. What are the other constraints to be added into the tables?\\nHaving zeroed down on the requirements for T enT oT en Stores, we now proceed to build its data model. \\nBut, let us first understand “What is a data model?” and “What are the steps involved in designing a data \\nmodel?”'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 231}, page_content='Multidimensional Data Modeling • 207\\n7.2 data ModeLinG Basics\\nBefore getting down to the basics of data modeling, let us do a quick recap on a few database terms such \\nas entity, attribute, cardinality of a relationship, etc.\\n7.2.1 entity\\nEntity is a common word for anything real or abstract about which we want to store data. Entity types \\ngenerally fall into five categories: roles (such as employee, executives, etc.), events (such as hockey \\nmatch, cricket match, etc.), locations (such as office campus, auditorium, multiplex theatre, etc.),  \\ntangible things (such as book, laptop, etc.), or concepts (such as a project idea). For example, Harry, \\nLuther, Connors, Jennifer, etc. could be instances of the “employee” entity.\\n7.2.2 attribute\\nAn attribute is a characteristic property of an entity. An entity could have multiple attributes. For \\nexample, for the “car” entity, attributes would be color, model number, number of doors, right or left \\nhand drive, engine number, diesel or petrol, etc.\\n7.2.3 cardinality of relationship\\nThis relationship defines the type of relationship between two participating entities. For example, one \\nemployee can work on only one project at any given point in time. One project, however, can have \\nseveral employees working on it. So, the cardinality of relationship between employee and project is \\n“many to one”. Here is an example of a “one to one” cardinality. One person can sit on only one chair \\nat any point of time. One chair can accommodate only one person in a given point of time. So, this \\nrelationship has “one to one” cardinality.\\nT o read more on entity, attribute, cardinality, etc. please refer:\\n • An Introduction to Database Systems (8th Edition), C.J. Date, Addison Wesley.\\n • Database System Concepts by Abraham Silberschatz, Henry Korth and S. Sudarshan, McGraw \\nHill.\\n • Fundamentals of Database Systems (6th Edition) by Ramez Elmasri and Shamkant Navathe, \\n Addison Wesley.\\nWith this understanding of a few database terms, let us proceed to understand data model.\\n7.3 types of data ModeL\\nA data model is a diagrammatic representation of the data and the relationship between its different \\nentities. Although time consuming, the process of creating a data model is extremely important. It \\nassists in identifying how the entities are related through a visual representation of their relationships \\nand thus helps reduce possible errors in the database design. It helps in building a robust database/data \\nwarehouse. There are three types of data models:\\n • Conceptual Data Model.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 232}, page_content='208 • Fundamentals of Business Analytics\\n • Logical Data Model.\\n • Physical Data Model.\\n7.3.1 conceptual data Model\\nThe conceptual data model is designed by identifying the various entities and the highest-level relationships \\nbetween them as per the given requirements. Let us look at some features of a conceptual data model:\\n• It identifies the most important entities.\\n • It identifies relationships between different entities.\\n • It does not support the specification of attributes.\\n • It does not support the specification of the primary key.\\nGoing back to the requirement specification of T enT oT en Stores, let us design the conceptual data \\nmodel (Figure 7.1). In this case, the entities can be identified as \\n• Category (to store the category details of products).\\n• SubCategory (to store the details of sub-categories that belong to different categories).\\n• Product (to store product details).\\n• PromotionOffer (to store various promotion offers introduced by the company to sell products).\\n• ProductOffer (to map the promotion offer to a product).\\n• Date (to keep track of the sale date and also to analyze sales in different time periods).\\n• Territory (to store various territories where the stores are located).\\n•  MarketType (to store details of various market setups, viz. “Hypermarkets & Supermarkets”, \\n“T raditional Supermarket”, “Dollar Store”, and “Super Warehouse”).\\n• OperatorType (to store the details of types of operator, viz. company-operated or franchise).\\n• Outlet (to store the details of various stores distributed over various locations).\\n• Sales (to store all the daily transactions made at various stores).\\nThere can be several other entities, but for the current scenario we restrict ourselves to the entities listed \\nabove. Let us now define the relationships that exist between the various entities listed above.\\n • Outlet has a MarketType.\\n • Outlet has an OperatorType.\\n • Outlet belongs to a Territory.\\n • SubCategory belongs to a Category.\\n • Product belongs to a SubCategory.\\n • ProductOffer is an instance of PromotionOffer for a Product.\\n • Sales of a Product.\\n • Sales in a specific Date duration.\\n • Sales from an Outlet.\\n7.3.2 Logical data Model\\nThe logical data model is used to describe data in as much detail as possible. While describing the data, \\npractically no consideration is given to the physical implementation aspect. Let us look at some features \\nof a logical data model:\\n • It identifies all entities and the relationships among them.\\n • It identifies all the attributes for each entity.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 233}, page_content=' • It specifies the primary key for each entity.\\n • It specifies the foreign keys (keys identifying the relationship between different entities).\\n • Normalization of entities is performed at this stage.\\nHere is a quick recap of various normalization levels:\\nT est  \\n1NF Relation should have atomic attributes. The \\ndomain of an attribute must include only atomic \\n(simple, indivisible) values.\\nForm new relations for each non-atomic \\nattribute.\\n2NF For relations where the primary key contains \\nmultiple attributes (composite primary key), \\nnon-key attributes should not be functionally \\ndependent on a part of the primary key.\\nDecompose and form a new relation \\nfor each partial key with its dependent \\nattribute(s). Retain the relation with the \\noriginal primary key and any attributes that \\nare fully functionally dependent on it.\\n3NF Relation should not have a non-key attribute \\nfunctionally determined by another non-key \\nattribute (or by a set of non-key attributes). In other \\nwords, there should be no transitive dependency of \\na non-key attribute on the primary key.\\nDecompose and form a relation that \\nincludes the non-key attribute(s) that \\nfunctionally determine(s) other non-key \\nattribute(s).\\nNormal Form Remedy (Normalization)\\nFigure 7.1 The conceptual data model for T enT oT en Stores.\\nDate Market\\nType\\nOutletSales\\nSub-\\nCategory\\nCategory\\nProduct\\nProduct\\nOffer\\nPromotion\\nOffers\\nTerritory\\nOperator\\nType\\nMultidimensional Data Modeling • 209'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 234}, page_content='210 • Fundamentals of Business Analytics\\nFor more on normalization, we recommend the following books:\\n • An Introduction to Database Systems (8th Edition), Addison Wesley.\\n • Database System Concepts by Abraham Silberschatz, Henry Korth and S. Sudarshan, McGraw Hill.\\nBefore introducing you to the physical data model, we get back to our case study. Having identified the \\nentities, now we shall identify the various attributes for the entities and thus design the logical model \\nfor T enT oT en Stores database.\\nDescription  \\nProductSubCategoryID The Product SubCategory ID uniquely identifies \\nthe sub-categories that belong to each product.\\nPrimary Key\\nSubCategoryName The name of the corresponding sub-category.\\nProductCategoryID The Product Category ID to which the sub- \\ncategory belongs.\\nRefers to the Category \\n(ProductCategoryID)\\nColumns Constraint\\nSubCategory\\nDescription  \\nProductID The product code for the respective product, and \\nwill be the primary key for the Product Table.\\nPrimary Key\\nProductName The name of the product.\\nProductDescription Gives a brief description about the product.\\nSubCategoryID Describes the sub-category the product belongs to.\\nDateOfProduction Date when the corresponding product was \\nmanufactured.\\n“dd/mm/yyyy” format\\nLastDate \\nOfPurchase\\nThe last date the shipping was made to the \\nwarehouse.\\nCurrentInventoryLevel The number of products that are currently present \\nin the inventory of the product.\\nStandardCost The standard price for the product.\\nListPrice The listed price for the product.\\nColumns Constraint\\nProduct\\nDescription  \\nProductCategoryID The ProductCategory ID is used to uniquely \\nidentify different types of categories.\\nPrimary Key\\nCategoryName The name of the corresponding category.\\nColumns Constraint\\nCategory\\n(Continued)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 235}, page_content='Description  \\nPromotionOfferID It is used to uniquely identify the various \\npromotion offers.\\nPrimary Key\\nPromotionType The type of offers given. (Discounts, Buy One \\nGet One Free, etc.)\\nDiscountPercentage The percentage of discount given on the List Price \\nof the product.\\nComplimentaryProduct Complimentary products that might be offered \\nwith a product.\\nDateOfOfferExpiry The date when the offer will expire. “dd/mm/yyyy” format\\nColumns Constraint\\nPromotionOffers\\nDescription  \\nProductID Refers to a product from the product table to \\nwhich the offer is to be made.\\nPrimary Key,\\nRefers to Product (ProductID)\\nPromotionOfferID Refers to the promotion offer that is to be \\ngiven with a product.\\nPrimary Key,\\nRefers to PromotionOffers \\n(PromotionOfferID)\\nColumns Constraint\\nProductOffer\\nDescription  Columns Constraint\\n(Continued)\\nDiscontinued Used to find whether the manufacturing of a \\nparticular product has been discontinued.\\n“Y” or ”N”\\nDiscontinuedDate The date when the product manufacture was \\ndiscontinued.\\n“dd/mm/yyyy” format\\nDateID The Date ID for each date for uniquely identifying \\neach date. Primary Key\\nDate The corresponding date. “dd/mm/yyyy” format\\nDayOfWeek The name of the day of the week. (Monday, T uesday, Wednesday, \\nThursday, Friday, Sunday)\\nWeekOfMonth The week number w.r.t. the month. (1, 2, 3, 4)\\nDescription  Columns Constraint\\nDate\\n(Continued)\\nMultidimensional Data Modeling • 211'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 236}, page_content='212 • Fundamentals of Business Analytics\\nWeekOfYear Describes the category the product belongs to. (1, 2, 3, …, 52)\\nMonthName Contains the month name of the year. (January, February, …, \\nDecember)\\nMonthOfYear The month number in the year. (1, 2, 3, …, 12)\\nQuarter The quarter period of the corresponding year. (1, 2, 3, 4)\\nYear Contains the corresponding year. “yyyy” format\\nDescription  Columns Constraint\\n(Continued)\\nDescription  \\nMarketID Uniquely identifies the store setup. Primary Key\\nMarket_Name The store setup based on which the store \\noperates.\\n(Hypermarkets & \\nSupermarkets, T raditional \\nSupermarket, Dollar Store, \\nSuper Warehouse)\\nColumns Constraint\\nMarketType\\nDescription  \\nOperator_ID Identifies the type of operation. Primary Key\\nOperator The type of working of the outlet/store. (Company Operated, \\nFranchises, etc.)\\nColumns Constraint\\nOperator_Type\\nStore ID Each store has a respective Store ID. It will be  \\nused to uniquely identify various stores. Primary Key\\nMarketID The market type of the store. Refers to the Market \\n(MarketID)\\nOperatorID The working type of the store. Refers to the Operator_Type \\n(Operator_ID)\\nT erritoryID It contains the territory that the store belongs to. Refers to the T erritory Table\\nOpening Time The time when the corresponding store opens. 24 hours format\\nDescription  Columns Constraint\\nOutlets\\n(Continued)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 237}, page_content='T o conclude the logical data modeling:\\n • We have identified the various entities from the requirements specification.\\n • We have identified the various attributes for each entity.\\n •  We have also identified the relationship that the entities share with each other (Primary key – \\nForeign Key).\\nThe logical data model for T enT oT en Stores, based on the above-identified entities, is depicted in Figure 7.2.\\nMultidimensional Data Modeling • 213\\n(Continued)\\nClosing Time The time when the corresponding store closes. 24 hours format\\nStoreOpenDate Contains the date when the store was opened. “dd/mm/yyyy” format.\\nDescription  Columns Constraint\\nT erritoryCode Identifies each territory uniquely in the T erritory \\nTable. Primary Key\\nT erritory The name of the territory corresponding to the \\nterritory code.\\nCity The city in which the territory is present.\\nState The state to which the city belongs to.\\nTerritory\\nDescription  Columns Constraint\\nT ransactionID Identifies every sale that was made. Primary Key\\nT ransactionDate Contains the date the sales were made. Refers to the Time Table\\nStoreID Contains the ID of the store from where the sale \\nwas made. Refers to the Stores Table\\nProductID Contains the ID of the product that was sold. Refers to the Product Table\\nQuantityOrdered Contains the quantity of the product sold.\\nT otalAmount Contains the total amount of the sale made for the \\ncorresponding product.\\nSalesAmount = ItemSold * \\nUnitPrice\\nSalesTransaction\\nDescription  Columns Constraint'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 238}, page_content='214 • Fundamentals of Business Analytics\\nFigure 7.2 Logical data model for T enT oT en Stores.\\nTerritory\\nOperator_Type\\nOutlets\\nDate\\nSales Transaction\\nPromotionOffers\\nDiscountAmount\\nDiscontinued\\nDiscontinuedDate\\nComplimentaryProduct\\nProductOffers\\nProduct SubCategory\\nCategory\\nMarket Type\\nPK\\nPK\\nPK\\nPK\\nPK PK\\nPK\\nPK\\nFK1\\nFK2\\nFK3\\nFK1\\nFK1\\nFK1\\nPK,FK1\\nPK,FK2\\nTransactionDate\\nStoreID\\nProductID\\nQuantityOrdered\\nTotalAmount\\nProduct Descripton\\nSubCategoryID\\nDateOfProduction\\nLastDateOfPurchase\\nCurrentInventoryLevel\\nStandardCost\\nListPrice\\nFK2\\nFK3\\nPK\\nPK\\nTerritory ID\\nOperator ID\\nOutletID\\nDateID\\nTransactionID\\nPromotionOfferID\\nProductID ProductSubCategoryID\\nProductCategoryID\\nCategoryName\\nProductID\\nPromotionOfferID\\nPromotionType\\nDateOfOfferExpiry\\nMarket ID\\nMarket_Name\\nMarketID\\nDate\\nDayOfWeeK\\nWeekOfMonth\\nWeekOfYear\\nMonthName\\nMonthOfYear\\nQuarter\\nYear\\nOperatorID\\nTerritoryID\\nOpeningTime\\nClosingTime\\nStoreOpenDate\\nOperator\\nTerritory\\nCity\\nState\\nProductName SubCategoryName\\nProductCategoryID'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 239}, page_content='Now that we understand conceptual and logical data model, let us perform a quick comparison between \\nthe two:\\n • All attributes for each entity are specified in a logical data model, whereas no attributes are speci-\\nfied in a conceptual data model.\\n • Primary keys are present in a logical data model, whereas no primary key is present in a concep-\\ntual data model.\\n • In a logical data model, the relationships between entities are specified using primary keys and \\nforeign keys, whereas in a conceptual data model, the relationships are simply stated without \\nspecifying attributes. It means in a conceptual data model, we only know that two entities are \\nrelated; we don’t know which attributes are used for establishing the relationship between these \\ntwo entities.\\n7.3.3 physical Model\\nA physical data model is a representation of how the model will be built in the database. A physical \\ndatabase model will exhibit all the table structures, including column names, columns data types, \\ncolumn constraints, primary key, foreign key, and the relationships between tables. Let us look at some \\nfeatures of a physical data model:\\n • Specification of all tables and columns.\\n • Foreign keys are used to identify relationships between tables.\\n • While logical data model is about normalization, physical data model may support de-normal-\\nization based on user requirements.\\n • Physical considerations (implementation concerns) may cause the physical data model to be \\nquite different from the logical data model.\\n • Physical data model will be different for different RDBMS. For example, data type for a column \\nmay be different for MySQL, DB2, Oracle, SQL Server, etc.\\nThe steps for designing a physical data model are as follows:\\n • Convert entities into tables/relation.\\n • Convert relationships into foreign keys.\\n • Convert attributes into columns/fields.\\nLet us look at the physical data model in the light of our T enT oT en Stores case study. Having created \\nthe logical data model, now the physical model shall be created for the respective entities by adding the \\ncolumn definition for the attributes. The detailed descriptions of the table are as shown below (we use \\nMS SQL Server 2008 Database here):\\niProductCategoryID INT IDENTITY(1,1) PRIMARY KEY\\nvCategoryName VARCHAR(50) NOT NULL\\nCategory\\nMultidimensional Data Modeling • 215'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 240}, page_content='216 • Fundamentals of Business Analytics\\niProductSubCategoryID INT IDENTITY(1,1) PRIMARY KEY\\nvSubCategoryName VARCHAR(50) NOT NULL\\niProductCategoryID INT Category(iProductCategoryID)\\nSubCategory\\niProductID INT PRIMARY KEY Product (iProductID)\\niPromotionOfferID INT PRIMARY KEY PromotionOffers \\n(PromotionOfferID)\\nProductOffer\\nProduct\\niProductID INT IDENTITY(1,1) PRIMARY KEY\\n vProductName VARCHAR(50) NOT NULL\\n vProductDescription VARCHAR(250) NOT NULL\\niSubCategoryID INT SubCategory(iProductSubCategoryID)\\ndDateOfProduction DATE NOT NULL\\ndLastDateOfPurchase DATE NOT NULL\\niCurrentInventoryLevel INT NOT NULL\\nmStandardCost MONEY NOT NULL\\nmListPrice MONEY NOT NULL\\ncDiscontinued CHAR(1) CHECK “Y” or ”N”\\ndDiscontinuedDate DATE NULL \\nPromotionOffers\\niPromotionOfferID INT IDENTITY(1,1) PRIMARY KEY\\nvPromotionType VARCHAR(30) NOT NULL\\ntiDiscountPercent TINYINT NULL\\nvComplimentaryProduct VARCHAR(50) NULL\\ndDateOfOfferExpiry DATE NOT NULL\\nDate\\niDateID INT IDENTITY(1,1) PRIMARY KEY \\ndDate DATE NOT NULL \\nvDayOfWeek VARCHAR(10) NOT NULL \\niWeekOfMonth INT NOT NULL\\n(Continued)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 241}, page_content='iMarketID INT IDENTITY(1,1) PRIMARY KEY\\nvMarket_Name VARCHAR(30) NOT NULL\\nMarketType\\niOperator_ID INT IDENTITY(1,1) PRIMARY KEY\\nvOperator VARCHAR(50) NOT NULL\\nOperator_Type\\n(Continued)\\niT erritoryCode INT IDENTITY(1,1) PRIMARY KEY \\nvT erritory VARCHAR(30) NOT NULL \\nvCity VARCHAR(6) NOT NULL \\nvState VARCHAR(6) NOT NULL \\nTerritory\\niStoreID INT IDENTITY(1,1) PRIMARY KEY\\niMarketID INT Market(iMarketID)\\niOperatorID INT Operator_Type(iOperator_ID)\\niT erritoryID INT T erritory(iT erritory_ID)\\nvOpeningTime VARCHAR(5) NOT NULL,\\n[0-2][0-9][:][0-9][0-9]\\nvClosingTime VARCHAR(5) NOT NULL,\\n[0-2][0-9][:][0-9][0-9]\\ndStoreOpenDate DATE NOT NULL\\nOutlets\\niWeekOfYear INT NOT NULL\\nvMonthName VARCHAR(10) NOT NULL \\niMonthOfYear INT NOT NULL \\niQuarter INT NOT NULL \\niYear INT NOT NULL \\niT ransactionID INT IDENTITY(1,1) PRIMARY KEY\\niT ransactionDate INT Date(iDateID)\\nSalesTransaction\\n(Continued)\\nMultidimensional Data Modeling • 217'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 242}, page_content='218 • Fundamentals of Business Analytics\\nColumn Name\\nDate\\nSalesTransaction\\nProduct\\nSubCategory\\nMarketType\\nOutlets Territory\\niDateID\\ndDate\\nint\\nint\\nint\\nint\\nint\\nint\\ndate\\nvarchar(10)\\nvarchar(10)\\nvDayOfWeek\\niWeekOfMonth\\niWeekOfYear\\nvMonthName\\niMonthOfYear\\niQuarter\\niYear\\nData Type Allow Nulls\\nColumn Name\\niTransactionID\\niProductID\\nvProductName\\nvProductDescription\\niSubCategoryID\\ndDateOfProduction\\ndLastDateOfPurchase\\niCurrentInventoryLevel\\nmStandardCost\\nmListPrice\\ncDiscontinued\\ndDiscontinuedDate\\nColumn Name\\niProductSubCategoryID int\\nint\\nvarchar(50)vSubCategoryName\\niProductCategoryID\\niTransactionDate\\niStoresID\\niProductID\\ntiQuantityOrdered\\nmTotalAmount\\nData Type\\nint\\nint\\nint\\nint\\nint\\nint\\nmoney\\nmoney\\nchar(1)\\ndate\\ndate\\ndate\\nvarchar(50)\\nvarchar(255)\\ntinyint\\nmoney\\nint\\nAllow Nulls\\nColumn Name Data Type Allow Nulls\\nData Type Allow Nulls\\nData TypeColumn Name\\niMarketID int\\niOutletID int int\\nvarchar(50)\\nvarchar(20)\\nvarchar(20)\\nint\\nint\\nint\\nchar(5)\\nchar(5)\\ndate\\niMarketID\\niOperatorID\\niTerritory_ID\\niTerritory_ID\\nvTerritory\\nvCity\\nvState\\ncOpeningTime\\ncClosingTime\\ndStoreOpenDate\\nvarchar(30)vMarket_Name\\nAllow Nulls\\nOperator_Type\\nData TypeColumn Name\\niOperator_ID int\\nvarchar(30)vOperator\\nAllow Nulls\\nProductOffer\\nPromotionOffers\\nData TypeColumn Name\\niProductID int\\nint\\nvarchar(30)\\nvarchar(50)\\ntinyint\\ndate\\nintiPromotionOfferID\\niPromotionOfferID\\nvPromotionType\\ntiDiscountPercentage\\nvComplimentaryProduct\\ndDateOfferExpiry\\nAllow Nulls\\nCategory\\nData TypeColumn Name\\nint\\nvarchar(50)\\niProductCategoryID\\nvCategoryName\\nAllow Nulls\\nData TypeColumn Name Allow Nulls\\nData TypeColumn Name Allow Nulls Data TypeColumn Name Allow Nulls\\nFigure 7.3 Physical data model for T enT oT en Stores.\\niStoreID INT Outlets (iOutletID)\\niProductID INT Product(iProductID)\\niQuantityOrdered INT NOT NULL\\nmT otalAmount MONEY NOT NULL\\n(Continued)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 243}, page_content='Figure 7.3 depicts the physical model for T enT oT en Stores. Let us look at a few points of difference \\nbetween the logical data model and the physical data model:\\n • The entity names of the logical data model are table names in the physical data model.\\n • The attributes of the logical data model are column names in the physical data model.\\n • In the physical data model, the data type for each column is specified. However, data types can \\ndiffer depending on the actual database (MySQL, DB2, SQL Server 2008, Oracle, etc.) being \\nused. In a logical data model, only the attributes are identified without going into details about \\nthe data type specifications.\\n7.4 data ModeLinG techniQues\\n7.4.1 normalization (entity relationship) Modeling\\nAs learnt earlier, a table/relation in Third Normal Form (3NF) has no transitive dependency of a non-\\nkey attribute on the primary key. This is achieved by decomposing and forming a relation that includes \\nthe non-key attribute(s) that functionally determine(s) other non-key attribute(s). The Entity \\nRelationship (ER) Model makes use of the third normal form (3NF) design technique. This form of \\nnormalization is very useful as it takes care of the insert, delete, and update anomalies. Here is an \\nexample of ER modeling:\\nAn industry service provider, “InfoMechanists”, has several Business Units (BUs) such as Financial \\nServices (FS), Insurance Services (IS), Life Science Services (LSS), Communication Services (CS), T est-\\ning Services (TS), etc. Each BU has a BU Head, who is most certainly an employee of the company. A \\nBU head can head at the most one BU. A BU Head, as a manager, has many employees reporting to \\nhim. Each employee has a current residential address. There are also cases where a couple (both husband \\nand wife) are employed either in the same BU or a different one. In such a case, they (the couple) have \\nthe same address. An employee can be on a project, but at any given point in time, he or she can be \\nworking on a single project only. Each project belongs to a client. There could be chances where a client \\nhas awarded more than one project to the company (either to the same BU or different BUs). A project \\ncan also be split into modules which can be distributed to BUs according to their field of specialization. \\nFor example, in an insurance project, the development and maintenance work is with Insurance Ser-\\nvices (IS) and the testing task is with T esting Services (TS). Each BU usually works on several projects \\nat a time.\\nGiven the above specifications, let us see how we will proceed to design an ER model. Enumerated \\nbelow is a list of steps to help you arrive at the ER diagram:\\n1. Identify all the entities.\\n2.  Identify the relationships among the entities along with cardinality and participation type  \\n(total/partial participation).\\n3. Identify the key attribute or attributes.\\n4. Identify all other relevant attributes.\\n5. Plot the ER diagram with all attributes including key attribute(s).\\n6. The ER diagram is then reviewed with the business users.\\nStep 1: Identify all the entities\\n • Business Units\\nMultidimensional Data Modeling • 219'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 244}, page_content='220 • Fundamentals of Business Analytics\\n • BU Head\\n • Employee\\n • Address\\n • Project\\n • Client\\nStep 2: Identify the relationships among the entities\\n • One BU will have only one head. Hence the cardinality is “one to one”.\\n1Business\\nUnit Headed by BU Head1\\n • A BU Head is also an employee. Hence the cardinality is “one to one”. The following diagram \\nillustrates a case of partial and total participation. Each BU Head is an employee, but every em-\\nployee is not a BU Head. The participation of the entity BU Head in the relationship “Is an” is \\n“T otal”, but the participation of the entity Employee in the relationship “Is an” is “Partial”.\\n1 1BU Head Is an Employee\\n • An employee in the role of a manager may have several employees reporting into him/her. Hence, \\nthe cardinality is “one to many” (self-referential).\\nEmployee Manages 1\\nM\\n • One employee resides at a single address but many employees (in the case of spouses) can have \\nthe same address. Hence the cardinality is “many to one”.\\n1MEmployee Resides at Address\\n • One employee can work on one project only at any point in time but one project can have sev-\\neral employees assigned to it. Hence the cardinality is “many to one”.\\n1MEmployee Assigned to Project'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 245}, page_content=' • Each BU can have many projects allocated to it, but there are chances that different modules of \\nthe same project may be allocated to different units. Hence the cardinality is “many to one”.\\n • One client could have awarded several projects to the company. Hence the cardinality is “one \\nto many”.\\n1 MClient Belongs to Project\\nProject Allocated to Business\\nUnits\\nMN\\nStep 3: Identify the key attribute or attributes\\n • BU Name is the key attribute for the entity “Business Units”, as it identifies the business units \\nuniquely.\\n • EmployeeID is the key attribute for the entity “Employee” which is a foreign key for the “BU \\nHead” entity.\\n • ProjectID is the key attribute for the “Project” entity.\\n • ClientID is the key attribute for the “Client” entity.\\n • HouseNumber is the key attribute for the “Address” entity.\\nStep 4: Identify all other relevant attributes\\n • Business Units(Domain).\\n • Employee(EmployeeName, EmailID, PhoneNumber).\\n • Project(ProjectName, StartDate, EndDate).\\n • Client(ClientName).\\n • Address(Street, City, State, Country).\\nStep 5: Draw the ER diagram. Figure 7.4 shows the diagram of the ER model for “InfoMechanists”.\\nLet us take a quick look at the pros and cons of ER modeling.\\nPros:\\n • The ER diagram is easy to understand and is represented in a language that the business users \\ncan understand.\\n • It can also be easily understood by a non-technical domain expert.\\n • It is intuitive and helps in the implementation on the chosen database platform.\\n • It helps in understanding the system at a higher level.\\nCons:\\n • The physical designs derived using ER model may have some amount of redundancy.\\n • There is scope for misinterpretations because of the limited information available in the \\n diagram.\\nMultidimensional Data Modeling • 221'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 246}, page_content='222 • Fundamentals of Business Analytics\\n7.4.2 dimensional Modeling\\nLet us understand why dimensional modeling is required.\\npicture this…\\nYou have just reached the Bangalore International Airport. You are an Indian national due to fly to \\nLondon, Heathrow International Airport. You have collected your boarding pass. You have two bags \\nthat you would like checked in. The person at the counter asks for your boarding pass, weighs the bags, \\npastes the label with details about your flight number, your name, your travel date, source airport code, \\nand destination airport code, etc. He then pastes a similar label at the back of your boarding pass. This \\ndone, you proceed to the Immigration counter, passport, and boarding pass in hand. The person at the \\nimmigration counter verifies your identity, visa, boarding pass, etc. and then stamps the immigration \\nseal with the current date on your passport. Your next stop is the security counter. The security person-\\nnel scrutinize your boarding pass, passport, etc. And you find yourself in the queue to board the aircraft. \\nAgain quick, careful rounds of verification by the aircraft crew before you find yourself ensconced in \\nFigure 7.4 ER model for “InfoMechanists”.\\nBusiness Units Headed by1 BU Head1\\nEmployee\\nAddress\\nProject\\nClient\\n1\\n1\\nM\\nIs an\\nManages\\nResides at\\nAssigned\\nBelongs to\\nM\\n1\\n1 M\\nM\\n1\\nAllocated\\nN\\nM\\nEmployeeName\\nEmployeeID\\nPhoneNumber\\nEmailID\\nStreet\\nCity\\nState\\nHouseNumber Country\\nBUName\\nProjectID\\nEndDate\\nClientNameClientID\\n1\\nDomain\\nStartDate\\nProjectName'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 247}, page_content='your seat. You must be wondering what has all this got to do with multidimensional modeling. Well, \\nwe are trying to understand multidimensional perspectives of the same data. The data here is our \\n“boarding pass”. Your boarding pass is looked at by different personnel for different reasons:\\n • The person at the check-in counter needs your boarding pass to book your check-in bags.\\n • The immigration personnel looked at your boarding pass to ascertain the source and destination \\nof your itinerary.\\n • The security personnel scrutinized your boarding pass for security reasons to verify that you are \\nan eligible traveller.\\n • The aircraft crew looked at your boarding pass to onboard you and guide you to your seat.\\nThis is nothing but multidimensional perspectives of the same data. T o put it simply, “Same Data, \\nMultiple Perspectives”. T o help with this multidimensional view of the data, we rely on dimensional \\nmodeling.\\nconsider another scenario...\\nAn electronic gadget distributor company “ElectronicsForAll” is based out of Delhi, India. The company \\nsells its products in north, north-west, and western regions of India. They have sales units at Mumbai, \\nPune, Ahmedabad, Delhi, and Punjab. The president of the company wants the latest sales information \\nto measure the sales performance and to take corrective actions if required. He has requested this infor-\\nmation from his business analysts. He is presented with the report as below:\\nsales report of “electronicsforall”:\\nThe number of units sold: 113\\nEven though the data in the above sales report is correct, it is not able to convey any useful information \\nto the president as he cannot view the data from any perspective.\\nNow to enhance the understanding of the data, the same data is presented by adding a perspective \\nof time as shown below:\\nSales Report of “ElectronicsForAll”:\\nThe number of units sold over time:\\nFebruary March\\n14 41 33 25\\nJanuary April\\nThe above data conveys the information to a certain extent, but still it does not give a complete picture \\nof the scenario. Now let us add yet another perspective, i.e. product, to the data, and the meaning of the \\ndata gets further enhanced.\\nsales report of “electronicsforall”:\\nThe number of items sold for each product over time:\\nMultidimensional Data Modeling • 223'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 248}, page_content='224 • Fundamentals of Business Analytics\\nJan Feb Mar Apr\\nDigital Camera 6 17\\nMobile Phones 6 16 6 8\\nPen Drives 8 25 21\\nProduct\\nSimilar to the previous two cases, the meaning of the data can be further enriched by adding the \\nregion as another perspective as shown in the following table:\\nSales Report of “ElectronicsForAll”:\\nThe number of items sold in each region for each product over time:\\nJan Feb Mar Apr\\n(Units) (Units) (Units) (Units)\\nMumbai Digital Camera 3 10\\nMobile Phones 3 16 6\\nPen Drives 4 16 6\\nPune Digital Camera 3 7\\nMobile Phones 3 8\\nPen Drives 4 9 15\\nThis method of analyzing a performance measure (in this case the number of units sold) by looking \\nat it through various perspectives, or in other words the contextualized representation of a business \\nperformance measure, is known as dimensional modeling.\\nDimensional modeling is a logical design technique for structuring data so that it is intuitive to busi-\\nness users and delivers fast query performance. Dimensional modeling is the first step towards building \\na dimensional database, i.e. a data warehouse. It allows the database to become more understandable \\nand simpler. In fact, the dimensional database can be viewed as a cube having three or more dimen-\\nsional/perspectives for analyzing the given data.\\nDimensional modeling divides the database into two parts: (a) Measurement and (b) Context. Mea-\\nsurements are captured by the various business processes and other source systems. These measure-\\nments are usually numeric values called facts. Facts are enclosed by various contexts that are true at the \\nmoment the facts are recorded. These contexts are intuitively divided into independent logical clumps \\ncalled dimensions. Dimensions describe the “who, what, when, where, why, and how ” context of the \\nmeasurements.\\nT o better understand the fact (measurement)–dimension (context) link, let us take the example of \\nbooking an airlines ticket. In this case, the facts and dimensions are as given below:\\nFacts − Number of tickets booked, amount paid, etc.\\nDimensions − Customer details, airlines, time of booking, time of travel, origin city, destination city, \\nmode of payment, etc.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 249}, page_content='Benefits of Dimensional Modeling\\n • Comprehensibility:\\n\\uf0a7 Data presented is more subjective as compared to objective nature in a relational model.\\n\\uf0a7 Data is arranged in a coherent category or dimensions to enable better comprehension.\\n• Improved query performance.\\n•\\t T rended for data analysis scenarios.\\n7.5 fact taBLe\\nA fact table consists of various measurements. It stores the measures of business processes and points to \\nthe lowest detail level of each dimension table. The measures are factual or quantitative in representation \\nand are generally numeric in nature. They represent the how much or how many aspect of a question. For \\nexample, price, product sales, product inventory, etc.\\n7.5.1 t ypes of fact\\nAdditive Facts\\nThese are the facts that can be summed up/aggregated across all dimensions in a fact table. For example, \\ndiscrete numerical measures of activity – quantity sold, dollars sold, etc.\\nConsider a scenario where a retail store “Northwind T raders” wants to analyze the revenue generated. \\nThe revenue generated can be in terms of product; it can be over a period of time; it can be across differ-\\nent regions; it can be by the employee who is selling the products; or it can be in terms of any combina-\\ntion of multiple dimensions. (Product, time, region, and employee are the dimensions in this case.) The \\nrevenue, which is a fact, can be aggregated along any of the above dimensions to give the total revenue \\nalong that dimension. Such scenarios where the fact can be aggregated along all the dimensions make the \\nfact a fully additive or just an additive fact. Here revenue is the additive fact.\\nFigure 7.5 depicts the “SalesFact” fact table along with its corresponding dimension tables. This fact \\ntable has one measure, “SalesAmount”, and three dimension keys, “DateID”, “ProductID”, and “StoreID”. \\nThe purpose of the “SalesFact” table is to record the sales amount for each product in each store on a daily \\nbasis. In this table, “SalesAmount” is an additive fact because we can sum up this fact along any of the three \\nFigure 7.5 An example of additive fact table.\\nDateID\\nProductID\\nStoreID\\nSalesAmount\\nSalesFact\\nDateID\\nDay\\nMonth\\nQuarter\\nYear\\nDimDate\\nProductID\\nProductName\\nProductCategoryID\\nDimProduct\\nProductCategoryID\\nName\\nDescription\\nUnitPrice\\nDimProductCategory\\nStoreID\\nStoreName\\nStoreLocation\\nDimStore\\nMultidimensional Data Modeling • 225'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 250}, page_content='226 • Fundamentals of Business Analytics\\ndimensions present in the fact table, i.e. “DimDate”, “DimStore”, and “DimProduct”. For example, the \\nsum of “SalesAmount” for all 7 days in a week represents the total sales amount for that week.\\nSemi-Additive Facts\\nThese are the facts that can be summed up for some dimensions in the fact table, but not all (e.g., \\naccount balances, inventory level, distinct counts, etc.).\\nConsider a scenario where the “Northwind T raders” warehouse manager needs to find the total number \\nof products in the inventory. One inherent characteristic of any inventory is that there will be incoming \\nproducts to the inventory from the manufacturing plants and outgoing products from the inventory to the \\ndistribution centers or retail outlets. So if the total products in the inventory need to be found out, say, at \\nthe end of a month, it cannot be a simple sum of the products in the inventory of individual days of that \\nmonth. Actually, it is a combination of addition of incoming products and subtraction of outgoing ones. \\nThis means the inventory level cannot be aggregated along the “time” dimension. But if a company has \\nwarehouses in multiple regions and would like to find the total products in inventory across those ware-\\nhouses, a meaningful number can be arrived at by aggregating inventory levels across those warehouses. \\nThis simply means inventory levels can be aggregated along the “region” dimension. Such scenarios where \\na fact can be aggregated along some dimensions but not along all dimensions give rise to semi-additive \\nfacts. In this case, the number of products in inventory or the inventory level is the semi-additive fact.\\nLet us discuss another example of semi-additive facts. Figure 7.6 depicts the “AccountsFact” fact \\ntable along with its corresponding dimension tables. The “AccountsFact” fact table has two measures: \\n“CurrentBalance” and “ProfitMargin”. It has two dimension keys: “DateID” and “AccountID”. “Cur-\\nrentBalance” is a semi-additive fact. It makes sense to add up current balances for all accounts to get \\nthe information on “what’s the total current balance for all accounts in the bank?” However, it does not \\nmake sense to add up current balances through time. It does not make sense to add up all current bal-\\nances for a given account for each day of the month. Similarly, “ProfitMargin” is another non-additive \\nfact, as it does not make sense to add profit margins at the account level or at the day level.\\nNon-Additive Facts\\nThese are the facts that cannot be summed up for any of the dimensions present in the fact table (e.g. \\nmeasurement of room temperature, percentages, ratios, factless facts, etc.). Non-additive facts cannot be \\nFigure 7.6 An example of semi-additive fact.\\nDateID\\nAccountID\\nCurrentBalance\\nProfitMargin\\nAccountsFact\\nDateID\\nDay\\nMonth\\nQuarter\\nYear\\nDimDate\\nAccountID\\nAccountType\\nCustomerID\\nDimAccount\\nCustomerID\\nCustomerName\\nCustomerLocation\\nCustomerType\\nDimCustomer'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 251}, page_content='added meaningfully across any dimensions. In other words, non-additive facts are facts where the SUM \\noperator cannot be used to produce any meaningful results. The following illustration will help you \\nunderstand why room temperature is a non-additive fact.\\nExamples of non-additive facts are:\\n • Textual facts: Adding textual facts does not result in any number. However, counting textual \\nfacts may result in a sensible number.\\n • Per-unit prices: Adding unit prices does not produce any meaningful number. For example, the \\nunit sales price or unit cost is strictly non-additive. But these prices can be multiplied with the num-\\nber products sold and can be depicted as total sales amount or total product cost in the fact table.\\n • Percentages and ratios: A ratio, such as gross margin, is non-additive. Non-additive facts are \\nusually the result of ratio or other calculations, such as percentages.\\n • Measures of intensity: Measures of intensity such as the room temperature are non-additive \\nacross all dimensions. Summing the room temperature across different times of the day produces \\na totally non-meaningful number.\\n • Averages: Facts based on averages are non-additive. For example, average sales price is non-\\nadditive. Adding all the average unit prices produces a meaningless number.\\n • Factless facts (event-based fact tables): Event fact tables are tables that record events. For \\nexample, event fact tables are used to record events such as Web page clicks and employee or \\nstudent attendance. In an attendance recording scenario, attendance can be recorded in terms of \\n“yes” or “no” OR with pseudo facts like “1” or “0”. In such scenarios, we can count the values \\nbut adding them will give invalid values. Factless facts are generally used to model the many-to-\\nmany relationships or to track events that did or did not happen.\\nFigure 7.7 depicts an example of a “factless fact table” – “EventFact”. This factless fact table has \\nfour dimension keys: “EventID”, “SpeakerID”, “ParticipantID”, and “DateID”. It does not have any \\nmeasures or facts. This table can be queried to get details on the events that are the most popular. It \\ncan further be used to track events that did not happen. We can also use this table to elicit information \\nabout events that were the least popular or that were not attended.\\nAn Example of Multidimensional Modeling\\nAlex is excited. He will be travelling to the USA for business-related work. He has carefully planned his \\nitinerary. Before embarking on the journey, he wants to check the weather in various US cities. He has \\nMultidimensional Data Modeling • 227\\n5th May (7 AM) 27°C\\n5th May (12 PM) 33°C\\n5th May (5 PM) 10°C\\nSum 70°C (Non-meaningful \\nresult)\\nAverage 23.3°C (Meaningful \\nresult)\\nDATE (Time) T emperature'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 252}, page_content='228 • Fundamentals of Business Analytics\\nFigure 7.7 An example of factless fact table.\\nEventID\\nSpeakerID\\nParticipantID\\nDateID\\nEventFact EventID\\nEventName\\nEventType\\nEventLocation\\nDimEvent\\nDateID\\nDay\\nMonth\\nQuarter\\nYear\\nDimDate\\nSpeakerID\\nSpeakerName\\nSpeakerAddress\\nSpeakerOrg\\nDimSpeaker\\nParticipantID\\nParticipantName\\nParticipantAddress\\nParticipantType\\nDimParticipant\\nIn the above table, we have two dimensions, say, the “Geography” dimension and the “Time” \\ndimension. “NameofCity” and “DateDetails” are attributes of the geography and time dimension, \\nrespectively. There are also two facts, “MinT emp” and “MaxT emp”. Using this table, it is possible to \\nfind out information about the maximum daily temperatures and the minimum daily temperatures \\nfor any group of cities or group of days. Now let us assume that we wish to view the maximum and \\nminimum temperatures for states. A city belongs to a state. Let us add an attribute “State” to the \\n“Geography” dimension. The relationship between the state and the city is as depicted in the fol-\\nlowing figure:\\nState\\nCity\\nA state can have multiple cities. The relationship is one-to-many from the state to cities. Now assume \\nthat we wish to have a look at the minimum and maximum temperatures by counties. This can be \\nsearched the Internet to get the required information for the coming week. He has a table of data before \\nhim which looks like as shown below:\\nDateDetails MinT emp\\nLos Angeles 22 May 2011 86 105\\nSan Francisco 22 May 2011 78 107\\nPhoenix 22 May 2011 88 98\\nLos Angeles 23 May 2011 82 106\\nSan Francisco 23 May 2011 76 104\\nPhoenix 23 May 2011 86 96\\nName of City MaxT emp'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 253}, page_content='achieved by adding yet another attribute “County” to the geography dimension. The relationship \\nbetween the state and county is as depicted in the following figure. The relationship is again one-to-\\nmany from the state to counties.\\nCounty\\nCity\\nState\\nYou already know that temperature is a non-additive fact. However, one can look at the average of \\ntemperatures for cities or states or for different time periods or for a combination of geography and \\ntime.\\n7.6 diMension taBLe\\nDimension tables consist of dimension attributes which describe the dimension elements to enhance \\ncomprehension. Dimension attributes (descriptive) are typically static values containing textual data or \\ndiscrete numbers which behave as text values. Their main functionalities are: query filtering/constrain-\\ning and query result set labeling. The dimension attribute must be\\n • Verbose: Labels must consist of full words.\\n • Descriptive: The dimension attribute names must be able to convey the purpose of the dimen-\\nsion element in as few and simple words as possible.\\n • Complete: Dimension attributes must not contain missing values.\\n • Discrete values: Dimension attributes must contain only one value per row in dimension table.\\n • Quality assured: Dimension attributes must not contain misspelt values or impossible values.\\n7.6.1 dimension hierarchies\\nA dimension hierarchy is a cascaded series of many-to-one relationships and consists of different levels. \\nEach level in a hierarchy corresponds to a dimension attribute. Hierarchies document the relationships \\nbetween different levels in a dimension.\\nA dimension hierarchy may also be described as a set of parent–child relationships between attri-\\nbutes present within a dimension. These hierarchy attributes, also known as levels, roll up from a child \\nto parent. For example, Customer totals can roll up to Sub-region totals which can further roll up to \\nRegion totals. A better example would be − daily sales could roll up to weekly sales, which further roll \\nup to month to quarter to yearly sales.\\nLet us understand the concept of hierarchy through the example depicted in Figure 7.8 In this \\nexample, the Product hierarchy is like this\\nDepartment → Category → Brand → Product Name\\nMultidimensional Data Modeling • 229'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 254}, page_content='230 • Fundamentals of Business Analytics\\nSimilarly, the Date hierarchy is depicted as\\nYear → Quarter → Month\\nExample: 2011 → Q1 → April\\nFor a better idea of dimension hierarchy, let us assume a product store, “ProductsForAll”. The store has \\nseveral departments such as “Confectionary”, “Electronics”, “T ravel Goods”, “Home Appliances”, \\n“Dairy Products”, etc. Each department is further divided into categories. Example “Dairy Products” is \\nfurther classified into “Milk”, “Butter”, “Cottage Cheese”, “Yogurt”, etc. Each product class offers sev-\\neral brands such as “Amul”, “Nestle”, etc. And, finally each brand has specific product names. For \\nexample, “Amul cheese” has names such as “Amul Slim Cheese”, “Amul EasySpread”, etc.\\n7.6.2 t ypes of dimension tables\\n • Degenerate Dimension\\n • Slowly Changing Dimension\\n • Rapidly Changing Dimension\\n • Role-playing Dimension\\n • Junk Dimension\\nDegenerate Dimension\\nA degenerate dimension is a data that is dimension in temperament but is present in a fact table. It is a \\ndimension without any attributes. Usually, a degenerate dimension is a transaction-based number. \\nThere can be more than one degenerate dimension in a fact table.\\nDegenerate dimensions often cause confusion as they don’t feel or look like normal dimensions. They \\nact as dimension keys in fact tables; however, they are not joined to corresponding dimensions in other \\ndimension tables as all their attributes are already present in other dimension tables.\\nFigure 7.8 An example for dimension hierarchies.\\nDepartment\\nProduct Date Location\\nLevel 1\\nLevel 2\\nLevel 3\\nLevel 4\\nCategory\\nBrand Month\\nQuarter\\nYear Country\\nState\\nRegion\\nProduct\\nName'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 255}, page_content='Degenerate dimensions can also be called textual facts, but they are not facts as the primary key for the \\nfact table is often a combination of dimensional foreign keys and degenerate dimensions. As already stated, \\na fact table can have more than one degenerate dimension. For example, an insurance claim line fact table \\ntypically includes both claim and policy numbers as degenerate dimensions. A manufacturer can include \\ndegenerate dimensions for the quote, order, and bill of lading numbers in the shipments fact table.\\nLet us look at an example of degenerate dimension. Figure 7.9 depicts a PointOfSaleFact table along \\nwith other dimension tables. The “PointOfSaleFact” has two measures: AmountT ransacted and Quan-\\ntitySold. It has the following dimension keys: DateKey that links the “PointOfSaleFact” to “DimDate”, \\nProductID that links the “PointOfSaleFact” to “DimProduct”, and StoreID that links the “PointOf-\\nSaleFact” to “DimStore”. Here, T ransactionNo is a degenerate dimension as it is a dimension key \\nwithout a corresponding dimension table. All information/details pertaining to the transaction are \\nextracted and stored in the “PointOfSaleFact” table itself; therefore, there is no need to have a separate \\ndimension table to store the attributes of the transaction.\\nSlowly Changing Dimension (SCD)\\nIn a dimension model, dimension attributes are not fixed as their values can change slowly over a period \\nof time. Here comes the role of a slowly changing dimension. A slowly changing dimension is a dimen-\\nsion whose attribute/attributes for a record (row) change slowly over time, rather than change on a \\nregular timely basis.\\nLet us assume a company sells car-related accessories. The company decides to assign a new sales ter-\\nritory, Los Angeles, to its sales representative, Bret Watson, who earlier operated from Chicago. How \\ncan you record the change without making it appear that Watson earlier held Chicago? Let us take a \\nlook at the original record of Bret Watson:\\nFigure 7.9 An example of degenerate dimension.\\nDateKey\\nProductID\\nStoreID\\nTransactionNo\\nAmountTransacted\\nQuantitySold\\nPointOfSaleFact\\nProductID\\nProductName\\nProductCategory\\nUnitPrice\\nDateKey\\nDay\\nMonth\\nQuarter\\nYear\\nStoreID\\nStoreName\\nCityLocation\\nState\\nCountry\\nZipCode\\nDimDate\\nDimProduct\\nDimStore\\nMultidimensional Data Modeling • 231\\nSalesRepName  \\n1001 Bret Watson Chicago\\nSalesRepID SalesT erritory'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 256}, page_content='232 • Fundamentals of Business Analytics\\nNow the original record has to be changed as Bret Watson has been assigned “Los Angeles” as his \\nsales territory, effective May 1, 2011. This would be done through a slowly changing dimension. Given \\nbelow are the approaches for handling a slowly changing dimension:\\ntype–i (overwriting the history)\\nIn this approach, the existing dimension attribute is overwritten with new data, and hence no history is \\npreserved. This approach is used when correcting data errors present in a field, such as a word spelled \\nincorrectly.\\nAs per our example, the new record for Bret Watson after the change of his territory would look \\nlike:\\nSalesRepName  \\n1001 Bret Watson Los Angeles\\nSalesRepID SalesT erritory\\nA disadvantage of managing SCDs by this method is that no historical records are kept in the data \\nwarehouse.\\nAdvantages\\n • It is the easiest and simplest approach to implement.\\n • It is very effective in those situations requiring the correction of bad data.\\n • No change is needed to the structure of the dimension table.\\nDisadvantages\\n • All history may be lost in this approach if used inappropriately. It is typically not possible to \\ntrace history.\\n • All previously made aggregated tables need to be rebuilt.\\ntype–ii (preserving the history)\\nA new row is added into the dimension table with a new primary key every time a change occurs to any of \\nthe attributes in the dimension table. Therefore, both the original values as well as the newly updated values \\nare captured. In this method, the record for Bret Watson after the change of his territory would look like: \\nSalesRepName  \\n1001 Bret Watson Chicago\\n1006 Bret Watson Los Angeles\\nSalesRepID SalesT erritory\\nType-II SCDs enable tracking of all the historical information accurately, hence these can have infi-\\nnite number of entries due to the various types of changes.\\nAdvantages\\nThis approach enables us to accurately keep track of all historical information.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 257}, page_content='Disadvantages\\n • This appproach will cause the size of the table to grow fast.\\n • Storage and performance can become a serious concern, especially in cases where the number of \\nrows for the table is very high to start with.\\n • It complicates the ETL process too.\\ntype–iii (preserving one or More Versions of history)\\nThis approach is used when it is compulsory for the data warehouse to track historical changes, and \\nwhen these changes will happen only for a finite number of times. Type-III SCDs do not increase the \\nsize of the table as compared to the Type-II SCDs since old information is updated by adding new \\ninformation. In this method, the record for Bret Watson after the change of his territory would look \\nlike:\\nSalesRepName OriginalSalesT erritory CurrentSalesT erritory\\n1001 Bret Watson Chicago Los Angeles 01-May-2011\\nSalesRepID EffectiveFrom\\nAdvantages\\n • Since only old information is updated with new information, this does not increase the size of \\nthe table.\\n • It allows us to keep some part of history.\\nDisadvantages\\nType-III SCDs will not be able to keep all history where an attribute is changed more than once. For \\nexample, if Bret Watson is later assigned “Washington” on December 1, 2012, the Los Angeles informa-\\ntion will be lost.\\nTable 7.1 presents a comparison of the three types of handling of slowly changing dimensions.\\nRapidly Changing Dimension\\nWe have seen how to handle very slow changes in the dimension, but what would happen if the changes \\noccur more frequently? A dimension is considered to be a fast changing dimension, also called a rapidly \\nchanging dimension, if its one or more attributes change frequently and also in several rows.\\nFor example, consider a customer table having around 1,00,000 rows. Assuming that on an aver-\\nage 10 changes occur in a dimension every year, then in one year the number of rows will increase to \\n1,00,000 × 10 = 10,00,000.\\nT o identify a fast changing dimension, look for attributes having continuously variable values. Some \\nof the fast changing dimension attributes have been identified as\\n • Age\\n • Income\\n • T est score\\n • Rating\\n • Credit history score\\nMultidimensional Data Modeling • 233'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 258}, page_content='234 • Fundamentals of Business Analytics\\nType-I Type-II\\nWhen to use\\n•  When the attribute \\nchange is simple.\\n•  T racking of history not \\nrequired.\\n•  T o keep a track of all the \\nhistorical changes.\\n•  T o keep a track of a finite \\nnumber of historical changes.\\nAdvantage\\n•  Easiest and simplest to \\nimplement.\\n•  Effective in performing \\ndata correction.\\n•  No change in data  \\nstructure.\\n•  Enables tracking of \\nhistorical changes ac-\\ncurately.\\n•  Can track infinite num-\\nber of changes.\\n•  Does not increase the size as \\nType-II, as old information is \\nupdated.\\n•  Keeps a part of the history, \\nequivalent to the number of \\nchanges predictable.\\nDisadvantage\\n•  All history is lost if used \\ninappropriately.\\n•  Previous aggregated tables \\nhave to be remade.\\n•  Dimension table grows \\nfast.\\n•  Complicated ETL pro-\\ncess to load the dimen-\\nsion model.\\n•  No complete history, especially \\nwhen change occurs very often.\\n•  Risk of losing history or \\nchanging design if more his-\\ntory has to be traced.\\nImpact on \\nexisting \\ndimension tables\\n•  No impact. No change in \\ntable structure.\\n•  No impact. No change \\nin table structure.\\n•  Dimension table is modified \\nto accommodate additional \\ncolumns.\\n•  Number of columns based on \\nnumber of changes to track.\\nImpact on pre-\\naggregation\\n•  All pre-existing aggrega-\\ntions have to be re-built.\\n•  No impact. Aggregate ta-\\nbles need not be re-built.\\n•  All pre-existing aggregations \\nhave to be re-built.\\nImpact on \\ndatabase size\\n•  No impact on the size of \\nthe database. \\n•  Accelerated growth as a \\nnew row is added every \\ntime a change occurs.\\n•  No impact as the data is only \\nupdated.\\nType-III\\n • Customer account status\\n • Weight\\nOne method of handling fast changing dimensions is to break off a fast changing dimension into one \\nor more separate dimensions known as mini-dimensions. The fact table would then have two separate \\nforeign keys – one for the primary dimension table and another for the fast changing attributes.\\nRole-Playing Dimension\\nA single dimension that is expressed differently in a fact table with the usage of views is called a role-\\nplaying dimension. Consider an on-line transaction involving the purchase of a laptop. The moment an \\norder is placed, an order date and a delivery date will be generated. It should be observed that both the \\ndates are the attributes of the same time dimension. Whenever two separate analyses of the sales perfor-\\nmance – one in terms of the order date and the other in terms of the delivery date – are required, two views \\nof the same time dimension will be created to perform the analyses. In this scenario, the time dimension \\nis called the role-playing dimension as it is playing the role of both the order and delivery dates.\\nTable 7.1  Comparison of the three types of handling of slowly changing dimensions'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 259}, page_content='Another example of the role-playing dimension is the broker dimension. The broker can play the role \\nof both sell broker and buy broker in a share trading scenario. Figure 7.10 will help you have a better \\nunderstanding of the role-playing dimension.\\nIn Figure 7.10, “Shipping” is a fact table with three measures – “T otal”, “Quantity”, and “Discount”. \\nIt has five dimension keys – “ProductID” that links the fact table “Shipping” with the “DimProduct” \\ndimension table; “DateID” that links “Shipping” with the “DimTime” dimension table; “ShipperID” \\nthat links “Shipping” with the “DimShipper” dimension table; and the remaining two dimension keys, \\n“T oCityID” and “FromCityID”, link the “Shipping” fact table with the same dimension table, i.e. \\n“DimCity”. The two cities, as identified by the respective CityIDs, would have the same structure \\n(DimCity) but would mean two completely different cities when used to signify FromCity and T oCity. \\nThis is a case of role-playing dimension.\\nJunk Garbage Dimension\\nThe garbage dimension is a dimension that contains low-cardinality columns/attributes such as indica-\\ntors, codes, and status flags. The garbage dimension is also known as junk dimension. The attributes in \\na garbage dimension are not associated with any hierarchy.Figure 7.10 An example of role-playing dimension shown in represented the “Shipping” fact table.\\nProductID\\nProductName\\nProductCategoryIDDateID\\nDay\\nMonth\\nQuarter\\nYear\\nDimProduct\\nCityID\\nCityName\\nZipcode\\nState\\nCountry\\nDimCity\\nProductCategoryID\\nName\\nDescription\\nUnitPrice\\nDimProductCategory\\nProductID\\nDateID\\nFromCityID\\nToCityID\\nShipperID\\nTotal\\nQuantity\\nDiscount\\nShipping\\nShipperID\\nShipperName\\nCityID\\nShipperType\\nDimShipper\\nDimTime\\nMultidimensional Data Modeling • 235'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 260}, page_content='236 • Fundamentals of Business Analytics\\nWe recommend going for junk/garbage dimension only if the cardinality of each attribute is relatively \\nlow, there are only a few attributes, and the cross-join of the source tables is too big. The option here \\nwill be to create a junk dimension based on the actual attribute combinations found in the source data \\nfor the fact table. This resulting junk dimension will include only combinations that actually occur, \\nthereby keeping the size significantly smaller.\\nLet us look at an example from the healthcare domain. Shown below are two source tables and a fact \\ntable.\\n \\n1 ICU\\n2 Pediatrics\\n3 Orthopedic\\n4 Ophthalmology\\n5 Oncology\\n6 Physiotherapy\\nTreatmentTypeID TreatmentTypeDescription\\nTreatmentLevel (Source Table)\\nCaseTreatmentFact (Fact Table)\\nTreatmentTypeID  \\n4 1 2\\n1 3 3\\n3 4 5\\nCaseTypeID CountofPatients\\nA junk dimension will combine several low cardinality flags and attributes into a single table rather \\nthan modeling them as separate dimensions. This will help reduce the size of the fact table and make \\ndimensional modeling easier to work with. In our example, each of the source tables [CaseType (Case-\\nTypeID, CaseTypeDescription) and T reatmentLevel (T reatmentTypeID, T reatmentTypeDescription)] \\nhas only two attributes each. The cardinality of each attribute is also low.\\nOne way to build the junk dimension will be to perform a cross-join of the source tables. This will \\ncreate all possible combinations of attributes, even if they do not or might never exist in the real world.\\n \\n1 Referred by another hospital\\n2 Walkin\\n3 Consultation\\n4 T ransferred by a branch of the \\nsame hospital\\nCaseTypeID CaseTypeDescription\\nCaseType (Source Table)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 261}, page_content='The other way is to build the junk dimension based on the actual attribute combinations found in \\nthe source tables for the fact table. This will most definitely keep the junk dimension table significantly \\nsmaller since it will include only those combinations that actually occur. Based on this explanation, we \\nredesign the fact table along with the junk dimension table as shown below:\\n \\n1 2\\n2 3\\n3 5\\nSurrogateKeyID CountofPatients\\nCaseTreatmentFact\\nCaseTreatmentJunk\\nSurrogateKeyID TreatmentTypeDescriptionCaseTypeID CaseTypeDescription TreatmentTypeID\\n1 4 T ransferred by a branch \\nof the same hospital\\n1 ICU\\n2 1 Referred by another \\nhospital\\n3 Orthopedic\\n3 3 Consultation 4 Ophthalmology\\n7.7 typicaL diMensionaL ModeLs\\nAs stated earlier, the Entity Relationship (ER) data model is a commonly used data model for relational \\ndatabases. Here, the database schema is represented by a set of entities and the relationship between \\nthem. It is an ideal data model for On-Line T ransaction Processing (OLTP).\\nLet us look at a data model that is considered apt for On-Line Data Analysis. Multidimensional data \\nmodeling is the most popular data model when it comes to designing a data warehouse. Dimensional \\nmodeling is generally represented by either of the following schemas:\\n • Star Schema.\\n • Snowflake Schema.\\n • Fact Constellation Schema.\\n7.7.1 star schema\\nIt is the simplest of data warehousing schema. It consists of a large central table (called the fact table) \\nwith no redundancy. The central table is being referred by a number of dimension tables. The schema \\ngraph looks like a starburst (Figure 7.11). The dimension tables form a radial pattern around the large \\ncentral fact table. The star schema is always very effective for handling queries.\\nIn the star schema, the fact table is usually in 3NF or higher form of normalization. All the dimen-\\nsion tables are usually in a de-normalized manner, and the highest form of normalization they are usu-\\nally present in is 2NF . The dimension tables are also known as look up or reference tables.\\nMultidimensional Data Modeling • 237'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 262}, page_content='238 • Fundamentals of Business Analytics\\nFigure 7.12 shows the Star schema for “T enT oT en” Stores. A few tables from the logical model of \\n“T enT oT en” Stores depicted in Figure 7.12 are selected in the construction of the star model for T enT oT en \\nStores. The tables, “Product”, “SubCategory”, and “Category” are consolidated into the “DimProduct” \\ntable. The tables “ProductOffer” and “PromotionOffers” are consolidated into the “DimPromotions” \\ntable. Table “Date” is mapped as the “DimDate” dimension. The tables “Outlets”, “MarketType”, \\n“Operation_Type”, and “T erritory” are modeled into the “DimOutlets” table. Finally, as payment can be \\nmade via several currencies, a new dimension “DimCurrency” is modeled to enable standardization.\\nFigure 7.13 shows the Star schema for “ElectronicsForAll”. Here, the sales are considered along four \\ndimensions, i.e. Time, Product, Employee, and Customer. The schema diagram shows a central fact \\ntable for “Sales”. The “Sales”central fact table has the keys to each of the four dimensions along with \\nthree measures – T otal, Quantity, and Discount. Each dimension is represented by only one table. Each \\nFigure 7.11 The data model for star schema.\\nDimension Dimension\\nFact\\nTransaction\\nDimension Dimension\\nFigure 7.12 The data model for “T enT oT en” Stores in Star Schema.\\nFactInternetSales\\nDimCurrencyDimTime\\nDimOutlets\\nDimProduct\\nDimPromotions'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 263}, page_content='table further has a set of attributes. For example, the Product dimension table has these attributes – \\n ProductID, ProductName, ProductCategory, and UnitPrice. Similarly, the Customer dimension table \\nhas the attributes – CustomerID, CustomerName, Address, City, and ZipCode.\\n7.7.2 snowflake schema\\nThe Snowflake schema is a variant of the Star schema. Here, the centralized fact table is connected to \\nmultiple dimensions. In the Snowflake schema, dimensions are present in a normalized form in multi-\\nple related tables (Figure 7.14). A snowflake structure materializes when the dimensions of a star schema \\nare detailed and highly structured, having several levels of relationship, and the child tables have mul-\\ntiple parent tables. This “snowflaking” effect affects only the dimension tables and does not affect the \\nfact table. \\nFigure 7.15 shows the data model for “T enT oT en” Stores in Snowflake schema. Figure 7.16 depicts \\nthe snowflake schema for “ElectronicsForAll”. If you look carefully at Figures 7.13 and 7.16, there is \\nno change in the “Sales” fact table. The difference lies in the definition of dimension tables. The single \\ndimension table for “Employee” in the Star schema is normalized in the Snowflake schema, resulting in a \\nnew “Department” table. The “Employee” dimension table now contains the attributes – EmployeeID, \\nEmployeeName, Title, DepartmentID, Region, T erritory. The “DepartmentID” attribute links the \\n“Employee” dimension table with the “Department” dimension table. The “Department” dimension \\nFigure 7.13 Star schema for sales of “ElectronicsForAll”.\\nOrderID\\nOrderDate\\nYear\\nQuarter\\nMonth\\nProductID\\nOrderID\\nCustomerID\\nEmployeeID\\nTotal\\nQuantity\\nDiscount\\nCustomerID\\nCustomerName\\nAddress\\nCity\\nZipCode\\nProductID\\nProductName\\nProductCategory\\nUnitPrice\\nEmployeeID\\nEmployeeName\\nTitle\\nDepartment\\nRegion\\nTerritory\\nTime Dimension Product Dimension\\nEmployee Dimension\\nSales\\nCustomer Dimension\\nMultidimensional Data Modeling • 239'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 264}, page_content='240 • Fundamentals of Business Analytics\\nFigure 7.14 The data model for Snowflake schema.\\nDimension\\nDimension\\nNormalized\\nDimension\\nFact\\nTransaction\\nNormalized\\nDimension\\nNormalized\\nDimension\\nDimension Dimension\\nDimension\\nDimension\\nFigure 7.15 The data model for “T enT oT en” Stores in Snowflake schema.\\nDimTime\\nFactInternet\\nSales\\nDimEmployee\\nDimPromotions\\nDimCurrency\\nDimProduct\\nDimCategory\\nDimSubCategory\\nDimSalesTerritory\\ntable has details about each department, such as “Name” and “Location” of the department. Similarly, \\nthe single dimension table for “Customer” in the Star schema is normalized in the Snowflake schema, \\nresulting in a new “City” table. The “Customer” dimension table now contains the attributes: Custo-\\nmerID, CustomerName, Address, CityID. The “CityID” attribute links the “Customer” dimension '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 265}, page_content='table with the “City” dimension table. The “City” dimension table has details about each city such as \\n“CityName”, “Zipcode”, “State”, and “Country”.\\nAs we have in the example of “ElectronicsForAll”, the main difference between the Star and Snow-\\nflake schema is that the dimension tables of the Snowflake schema are maintained in normalized form \\nto reduce redundancy. The advantage here is that such tables (normalized) are easy to maintain and \\nsave storage space. However, it also means that more joins will be needed to execute a query. This will \\nadversely impact system performance.\\nIdentifying Dimensions to be Snowflaked\\nIn this section, we will observe the practical implementation of the dimensional design.\\nWhat is snowflaking?\\nThe snowflake design is the result of further expansion and normalization of the dimension table. In \\nother words, a dimension table is said to be snowflaked if the low-cardinality attributes of the dimen-\\nsions have been divided into separate normalized tables. These tables are then joined to the original \\ndimension table with referential constraints (foreign key constraints).\\nGenerally, snowflaking is not recommended in the dimension table, as it hampers the understand-\\nability and performance of the dimensional model as more tables would be required to be joined to \\nsatisfy the queries.\\nWhen do we snowflake?\\nThe dimensional model is snowflaked under the following two conditions:\\n • The dimension table consists of two or more sets of attributes which define information at dif-\\nferent grains.\\n • The sets of attributes of the same dimension table are being populated by different source \\nsystems.\\nFor understanding why and when we snowflake, consider the “Product” dimension table shown in \\nFigure 7.17. \\nFigure 7.16 Snowflake schema for sales of “ElectronicsForAll”.\\nOrderID\\nOrder Date\\nYear\\nQuarter\\nMonth\\nProductID\\nOrderID\\nCustomerID\\nEmployeeID\\nTotal\\nQuantity\\nDiscountl\\nCustomerID\\nCustomerName\\nAddress\\nCityID\\nProductID\\nProductName\\nProductCategoryID\\nEmployeeID\\nEmployeeName\\nTitle\\nDepartmentID\\nRegion\\nTerritory\\nTime Dimension\\nProduct Dimension\\nEmployee Dimension\\nSales\\nCustomer Dimension\\nCityID\\nCityName\\nZipcode\\nState\\nCountry\\nCity Dimension\\nDepartmentID\\nName\\nLocation\\nDepartment\\nDimension \\nProductCategoryID\\nName\\nDescription\\nUnitPrice\\nProductCategory\\nDimension \\nMultidimensional Data Modeling • 241'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 266}, page_content='242 • Fundamentals of Business Analytics\\nThe “Product” table (Figure 7.17) has three sets of attributes related to the “Product”, “Category”, and \\n“Suppliers”. These sets of attributes have different levels of grains (detail level) and are also populated by \\ndifferent source systems. The “Product” dimension table is a perfect example for snowflaking for the \\nfollowing two reasons:\\n • The product table represents three different sets of attributes. One set shows “Product” attri-\\nbutes, the second set contains the “Category” attributes, and the third set shows the “Suppliers” \\nattributes. The level of detail (granularity) for the three sets is very different from each other.\\n • On a detailed analysis, we observe that the “Products” attributes are populated by the OLTP \\n(On-Line T ransaction Processing) database while the other two attributes are populated from \\nFigure 7.17 The “Product” dimension table.\\nFactOrderDetails * DimProducts*\\nFactOrderDetails Product_SK\\nProductID\\nProductName\\nSupplierID\\nCompanyName\\nContactName\\nContactTitle\\nAddress\\nCity\\nRegion\\nPostalCode\\nCountry\\nPhone\\nFax\\nHomePage\\nCategoryID\\nCategoryName\\nDescription\\nPicture\\nQuantityPerUnit\\nUnitPrice\\nUnitsInStock\\nUnitsOnOrder\\nRecorderLevel\\nDiscontinued\\nProduct_SK\\n[(Other Columns...)]'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 267}, page_content='the external consultancy firms. It may be possible that another source system in the enterprise is \\nresponsible for supplying some of the other attributes.\\nThe “Product” table after it has been snowflaked is shown in Figure 7.18. Due to Snowflaking, \\ndimension table low-cardinality attributes have been divided into separate normalized tables called \\n“DimCategory” and “DimSupplier”.\\nWhen NOT to snowflake?\\nNormally, you should avoid snowflaking or normalization of a dimension table, unless required and \\nappropriate. Snowflaking reduces space consumed by dimension tables, but compared with the entire \\ndata warehouse the saving is usually insignificant.\\nDo not snowflake hierarchies of one dimension table into separate tables. Hierarchies should belong \\nto the dimension table only and should never be snowflaked. Multiple hierarchies can belong to the \\nsame dimension if the dimension has been designed at the lowest possible detail.\\n7.7.3 fact constellation schema\\nThe constellation schema is shaped like a constellation of stars (i.e. Star schemas). This is more complex \\nthan Star or Snowflake schema variations, as it contains multiple fact tables. This allows the dimension \\ntables to be shared among the various fact tables. It is also called “Galaxy schema”. The main disadvan-\\ntage of the fact constellation is more complicated design because multiple aggregations must be taken \\ninto consideration (Figure 7.19).\\nFigure 7.18 The data model for the “Product” table in Snowflaked schema.\\nFactOrderDetails \\nDimProducts\\nDimSupplier\\nDimCategory\\nDescription\\nPicture\\nCategoryName\\nCategoryID\\nCategory_SK\\nProduct_SK\\nCategory_SK\\nSupplier_SK\\nProductID\\nUnitsOnOrder\\nReorderLevel\\nUnitsInStock\\nUnitPrice\\nDiscontinued\\nQuantityPerUnit\\nProductName\\nFactOrderDetails\\nProduct_SK\\n[(Other Columns....)]\\nSupplier_SK\\nSupplierID\\nContactTitle\\nAddress\\nCity\\nRegion\\nPostalCode\\nCountry\\nPhone\\nFax\\nHomePage\\nContactName\\nCompanyName\\nMultidimensional Data Modeling • 243'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 268}, page_content='244 • Fundamentals of Business Analytics\\nFigure 7.19 The data model for Fact Constellation schema.\\nDimension Dimension\\nDimension\\nNormalized\\nDimension\\nFACT\\nFACT\\nFACT\\nDimension\\nDimension Dimension\\nDimension\\nDimension\\nDimension\\nDimension Dimension\\nFigure 7.20 Fact constellation schema of a data warehouse for “Sales” and “Shipping”.\\nOrderID\\nOrder Date\\nYear\\nQuarter\\nMonth\\nProductID\\nOrderID\\nCustomerID\\nEmployeeID\\nTotal\\nQuantity\\nDiscount\\nCustomerID\\nCustomerName\\nAddress\\nCityID\\nProductID\\nProductName\\nProductCategoryID\\nEmployeeID\\nEmployeeName\\nTitle\\nDepartmentID\\nRegion\\nTerritory\\nTime Dimension\\nProduct Dimension\\nEmployee Dimension\\nSales\\nCustomer Dimension\\nCityID\\nCityName\\nZipcode\\nState\\nCountry\\nCity Dimension\\nDepartmentID\\nName\\nLocation\\nDepartment\\nDimension \\nProductCategoryID\\nName\\nDescription\\nUnitPrice\\nProductCategory\\nDimension \\nProductID\\nOrderID\\nFromCityID\\nToCityID\\nShipperID\\nTotal\\nQuantity\\nDiscount\\nShipping\\nShipperID\\nShipperName\\nCityID\\nShipperType\\nShipper Dimension'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 269}, page_content='Figure 7.21 The data model for Fact Constellation schema of “T enT oT en” Stores.\\nDimEmployee\\nDimProduct\\nFactInternetSales\\nDimCustomer\\nFactResellerSales\\nDimPromotion\\nDimCurrency\\nDimGeography\\nDimReseller\\nProductKey\\nCustomerKey\\nGeographyKey\\nCustomerAlternateKey\\nTitle\\nMiddleName\\nNameStyle\\nBirthDate\\nMaritalStatus\\nSuffix\\nGender\\nEmailAddress\\nTotalChildren\\nYearlyIncome\\nEnglishEducation\\nSpanishEducation\\nFrenchEducation\\nEnglishOccupation\\nSpanishOccupation\\nFrenchOccupation\\nHouseOwnerFlag\\nNumberCarsOwned\\nAddressLine2\\nPhone\\nCommuteDistance\\nDateFirstPurchase\\nAddressLine1\\nNumberChildrenAtHome\\nLastName\\nFirstName\\nOrderDateKey\\nPromotionKey\\nCurrencyKey\\nSalesOrderNumber\\nOrderQuantity\\nUnitPrice\\nExtendedAmount\\nUnitPriceDiscountPct\\nDiscountAmount\\nTotalProductCost\\nSalesAmount\\nTaxAmt\\nFreight\\nCustomerPONumber\\nCarrierTrackingNumber\\nProductStandardCost\\nRevisionNumber\\nSalesOrderLineNumber\\nSalesTerritoryKey\\nCustomerKey\\nShipDateKey\\nDueDateKey\\nProductKey\\nPromotionKey\\nCurrencyKey\\nCurrencyName\\nCurrencyAlternateKey\\nPromotionAlternateKey\\nEnglishPromotionName\\nDiscountPct\\nMinQty\\nResellerKey\\nGeographyKey\\nGeographyKey\\nCity\\nPostalCode\\nSalesTerritoryKey\\nStateProvinceCode\\nStateProvinceName\\nCountryRegionCode\\nEnglishCountryRegionName\\nSpanishCountryRegionName\\nFrenchCountryRegionName\\nPhoto\\nBusinessType\\nResellerName\\nOrderFrequency\\nOrderMonth\\nProductLine\\nAddressLine1\\nAddressLine2\\nAnnualSales\\nBankName\\nMinPaymentType\\nMinPaymentAmount\\nAnnualRevenue\\nYearOpened\\nLastOrderYear\\nFirstOrderYear\\nNumberEmployees\\nResellerAlternateKey\\nMaxQty\\nEndDate\\nStartDate\\nSpanishPromotionCategory\\nEnglishPromotionCategory\\nFrenchPromotionCategory\\nFrenchPromotionType\\nSpanishPromotionType\\nEnglishPromotionType\\nFrenchPromotionName\\nSpanishPromotionName\\nOrderDateKey\\nDueDateKey\\nShipDateKey\\nResellerKey\\nEmployeeKey\\nCurrencyKey\\nSalesTerritoryKey\\nRevisionNumber\\nOrderQuantity\\nUnitPrice\\nExtendedAmount\\nProductStandardCost\\nFreight\\nCarrierTrackingNumber\\nCustomerPONumber\\nTaxAmt\\nSalesAmount\\nTotalProductCost\\nDiscountAmount\\nUnitPriceDiscountPct\\nSaleOrderLineNumber\\nSalesOrderNumber\\nPromotionKey\\nEmployeeKey\\nHireDate\\nBirthDate\\nLoginID\\nMaritalStatus\\nSalariedFlag\\nGender\\nPayFrequency\\nSickLeaveHours\\nStartDate\\nEndDate\\nDepartmentName\\nSalesPersonFlag\\nCurrentFlag\\nVacationHours\\nBaseRate\\nEmergencyContactPhone\\nEmergencyContactName\\nEmailAddress\\nNameStyle\\nMiddleName\\nLastName\\nFirstName\\nSalesTerritoryKey\\nEmployeeNationalIDAlternate...\\nParentEmployeeNationalIDAlt...\\nParentEmployeeKey\\nPhone\\nTitle\\nStatus\\nProductKey\\nProductAlternateKey\\nProductSubcategoryKey\\nWeightUnitMeasureCode\\nSizeUnitMeasureCode\\nEnglishProductName\\nSpanishProductName\\nFrenchProductName\\nStandardCost\\nColor\\nSafetyStockLevel\\nReorderPoint\\nListPrice\\nSize\\nSizeRange\\nWeight\\nProductLine\\nDealerPrice\\nClass\\nStyle\\nModelName\\nLargePhoto\\nArabicDescription\\nHebrewDescription\\nStartDate\\nEndDate\\nStatus\\nThaiDescription\\nChineseDescription\\nFrenchDescription\\nEnglishDescription\\nDaysToManufacture\\nFinishedGoodsFlag\\nMultidimensional Data Modeling • 245'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 270}, page_content='246 • Fundamentals of Business Analytics\\nFigure 7.20 depicts the Fact Constellation schema for two fact tables “Sales” and “Shipping” of a data \\nwarehouse. The “Sales” table is identical to the “Sales” table shown in Figures 7.13 and 7.16. Let us take \\na look at the “Shipping” fact table. The “Shipping” table has five dimensions or keys – “ProductID”, \\n“OrderID”, “FromCityID”, “T oCityID”, and “ShipperID”. Further, it has three measures – “T otal”, \\n“Quantity”, and “Discount”. The dimension tables “Time”, “Product”, and “City” are shared between \\nthe two fact tables “Sales” and “Shipping”. As stated earlier, the fact constellation allows the dimension \\ntables to be shared between fact tables.\\nOne question we still have to answer is which model (Star, Snowflake, or Fact Constellation) is pref-\\nerable for an enterprise-wide data warehouse and for data marts. And the answer is…\\nAn enterprise-wide data warehouse collects information about subjects that span the entire \\norganization. Therefore, the Fact Constellation schema is the preferred schema for enterprise-wide \\ndata warehouse. The Fact Constellation schema can model multiple, inter-related subjects.\\nData marts, on the other hand, focus on selected subjects, and therefore their scope is department-\\nwide. Both the Star and Snowflake schemas are commonly used as data models for data marts. Figure \\n7.21 depicts the data model for Fact Constellation schema of “T enT oT en” Stores. \\nNow that we are familiar with dimensions, facts and dimensional models, let us see the evolution of \\ndimensional model right from identifying the requirements to analyzing the performance of a business \\nprocess to designing the model to actually analyzing the performance.\\n7.8 diMensionaL ModeLinG Life cycLe\\nIn this section, we will discuss the process followed while designing a dimensional model. Designing a \\nsuitable dimensional model can be a difficult task as requirements are typically difficult to define. Many \\na time only after seeing the result of a data model we are able to decide whether it satisfies our require-\\nment or not. Also, the organizational requirements may change over time.\\nBut, where should we start designing the model? What should be the first step? T o help in this deci-\\nsion process, we have a dimensional modeling life cycle which consists of the following phases which \\nare also depicted in Figure 7.22:\\n • Requirements Gathering.\\n • Identifying the Grain.\\nFigure 7.22 Dimensional modeling life cycle.\\nRequirements Gathering\\nIdentify the Grain\\nIdentify the Dimensions\\nIdentify the Facts\\nDesign the Dimensional Model'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 271}, page_content=' • Identifying Dimensions.\\n • Identifying Facts.\\n • Designing the Dimensional Model.\\n7.8.1 requirements Gathering\\nRequirements gathering is a process of selecting the business processes for which the dimensional model \\nwill be designed. Based on this selection, the requirements for the business process are gathered and \\ndocumented. Hence it can be said that requirements gathering focuses on the study of business pro-\\ncesses and information analysis actions in which users are involved.\\nWhile doing requirements gathering, it is important to focus on two key elements of analysis:\\n • What is to be analyzed?\\n • The evaluation criteria.\\nA requirements gathering process, thus, is extremely oriented toward understanding the domain for \\nwhich the modeling is to be done. Typically, requirements at this stage are documented rather infor-\\nmally or, at least, they are not represented in detailed schemas. There are two methods for deriving \\nbusiness requirements:\\n • Source-driven requirements gathering.\\n • User-driven requirements gathering.\\nSource-Driven Requirements Gathering\\nSource-driven requirements gathering is a method in which requirements are determined by using the \\nsource data in production operational systems. This is done by analyzing the ER model of source data \\nif it is available or the physical record layouts, and selecting data elements that seem to be of interest.\\nAdvantages: The major advantages of this approach are:\\n • From the beginning you know what data you can supply because you limit yourself to what is \\navailable.\\n • The time spent on gathering requirements from the users in the early stages of the project is \\nsaved. However, there is no alternative to the importance and value you get when you involve \\nthe users in the requirements gathering phase.\\nDisadvantages: Listed below are a few disadvantages of this approach.\\n • Minimal user involvement increases the risk of producing an incorrect set of requirements.\\n • Depending on the volume of source data you have, and the availability of ER models for it, this \\ncan also be a very time-consuming approach.\\n • Perhaps some of the user’s key requirements may need the data that is currently unavailable. \\nWithout identifying these requirements, there is no chance to investigate what external data is \\nrequired. (External data is data that exists outside the enterprise. External data can be of signifi-\\ncant value to the business users.)\\nSimply put, the source-driven approach provides only what you have. This approach can be appropriate \\nin two cases. First, relative to dimensional modeling, it can be used to develop a fairly comprehensive list \\nof the major dimensions that are of interest to the enterprise. So if you plan to have an enterprise-wide \\nMultidimensional Data Modeling • 247'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 272}, page_content='248 • Fundamentals of Business Analytics\\ndata warehouse, this approach could minimize duplicate dimensions across separately developed data \\nmarts. Second, analyzing relationships in the source data helps you identify areas on which your data \\nwarehouse development efforts should be focused.\\nUser-Driven Requirements Gathering\\nThe user-driven requirements gathering method is based on identifying the requirements by analyzing \\nthe functions that the users perform. This is generally done by conducting a series of meetings and/or \\ninterviews with users.\\nAdvantages: The main benefits of this approach are:\\n • It focuses on providing what is really needed rather than what is available.\\n • This approach has a smaller scope than the source-driven approach; therefore, it generally pro-\\nduces a useful data in a shorter span of time.\\nDisadvantages:\\n • On the negative side, the users might have unrealistic expectations. They must clearly under-\\nstand that some of the data they need might not be available due to various reasons.\\n • It is a time-consuming process as the user requirements may change over time.\\n • If a user is too focused, it is possible to miss useful data that is available in the production \\nsystems.\\nWhile using user-driven requirement gathering approach, we must try not to limit ourselves to the \\nthings asked by the user. Out-of-the-box thinking should be promoted while defining the requirements \\nfor a data warehouse. We believe that a user-driven requirement gathering is the approach of choice, \\nespecially while developing dependent data marts or populating data marts from a business-wide enter-\\nprise warehouse.\\nFigure 7.23 Source-driven vs. user-driven approach.\\nUser requirements\\nSource data\\nWhat is useful and\\ndeliverable \\nUser driven\\nSource driven\\nUser requirements\\nOperational data'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 273}, page_content='Refer to Figure 7.23. The ideal approach is to design the data warehouse keeping in mind both \\nthe user requirements and the source data available such that the solution developed is deliverable as \\nwell as useful. While gathering the requirements, the questions should be asked so as to gather “who”, \\n“when”, “where”, “what”, and “how” of the business model. The questions for this purpose could be \\nas follows:\\n • Who are the organizations, groups, and people of interest?\\n • What functions are required to be analyzed?\\n • Why do we require data?\\n•\\t When should the data be recorded?\\n•\\t Where do relevant processes occur, geographically as well as organizationally?\\n•\\t How is the performance of the processes being analyzed?\\n • How is the performance of the various business modules measured?\\n•\\t What factors decide the success or failure?\\n•\\t What is the method used for distribution of information? Is it SMS or email (examples)?\\n•\\t What steps are presently taken to fulfil the information?\\n•\\t What level of detailing would enable data analysis?\\n7.8.2 identify the Grain\\nThe second phase of the dimensional modeling life cycle is to identify the grain. T o understand how to \\nidentify a grain first we need to understand what is meant by the term “grain”?\\nWhat is a Grain?\\nThe “grain” refers to the level of detail or fineness to which the data can be analyzed. The grain in \\na dimensional model is the finest level of detail implied by the joining of the fact and dimension \\ntables. T o have a better idea of grain, let us consider the following tables with their attributes:\\n • Date (year, quarter, month, and day)\\n • Store (region, district, and store)\\n • Product (category name, price, and product)\\nFor this group of tables, the grain is the product sold in a store in a day. Some other examples of \\ngrain are:\\n•\\t A daily snapshot of the inventory levels for each product in a warehouse.\\n•\\t A monthly snapshot for balance of each bank account.\\n•\\t A bus ticket purchased on a day.\\n•\\t A single item on an invoice.\\n•\\t A single item on a restaurant bill.\\nGranularity: Granularity is defined as the detailed level of information stored in a table.\\n • The more the detail, the lower is the level of granularity.\\n • The lesser the detail, the higher is the level of granularity.\\nChoosing the right granularity is a very important step while designing a dimensional model for a data \\nwarehouse. Let us understand this through the following examples:\\nMultidimensional Data Modeling • 249'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 274}, page_content='250 • Fundamentals of Business Analytics\\n • If we consider a table LocationA (Country, State), it will have a granularity at the state level, \\ni.e. it will have information at state level but will not contain information at the city level. \\nBut if we modify the same table and change it to LocationB (Country, State, City), it will \\nnow have a granularity at the city level, i.e. we can retrieve information at the city level using \\nthis table.\\n • Consider a table dateA (year, quarter). It has a granularity at the quarter level, i.e. it will contain \\ninformation at the quarter level but will not have information for a particular day or month. \\nNow, if we modify the table to dateB (year, quarter, month), it now has a granularity at the \\nmonth level, but does not contain information at the day level.\\nSo while designing a dimensional model, we should make sure that the granularity of all the tables (i.e. \\nfact and dimension tables) should be same.\\n7.8.3 identify the dimensions\\nOnce the grain has been identified, we shall proceed towards determining the dimensions for the data \\nmodel. The key features of a dimension table are\\n • Dimension tables contain attributes that describe facts in the fact table.\\n • Each dimension table has only one lowest level of detail called the dimension grain, also referred \\nto as the granularity of the dimension.\\n • Each non-key element (other than the surrogate key) should appear in a single dimension \\ntable.\\n7.8.4 identify the facts\\nAfter identifying the dimensions in the model, our next step is to identify the fact table and the rele-\\nvant facts/measures in that table. Before identifying the relevant facts/measures we should identify the \\nfact tables in the database design. The following features of fact table will help you identify the fact \\ntables:\\n • The fact table will mostly contain numeric and additive values.\\n • It contains at least two foreign keys.\\n • It usually comprises vast number of records.\\n • Tables having many-to-many relationship in an ER model can be used as fact tables in a dimen-\\nsional model.\\nHaving identified the fact table, our next step is to identify the facts/measures for the same. While \\nidentifying the facts the following points should be kept in mind:\\n • A fact should generally be numeric in nature.\\n • It should be of importance to the business analysis.\\n • It should confirm the grain level identified in the step “Identify the grain”.\\nThe essence of multidimensional data modeling is to prepare the tables and hence the associated data in \\na format suitable for analysis. Once the database is modeled multidimensionally, we can start analyzing \\nthe data from various perspectives.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 275}, page_content='desiGninG the diMensionaL ModeL\\nDraw a Star/Snowflake/Fact Constellation model.\\n•  http://www.stanford.edu/dept/itss/docs/oracle/10g/olap.101/b10333/multimodel.htm\\n•   http://office.microsoft.com/en-us/excel-help/overview-of-pivottable-and-pivotchart-reports-\\nHP010342752.aspx?CTT=1\\nConnect Me\\nPoint Me\\n•   Dimensional Modeling: In a Business Intelli-\\ngence Environment, IBM.\\n•   Excel 2010: Data Analysis and Business Mod-\\neling, Wayne L. Winston.\\nRemind Me\\nNormalization (Entity Relationship) Model:\\n•   Logical model that seeks to eliminate data re-\\ndundancy.\\n•  It depicts data relationships.\\n•  Difficult to master and understand.\\n•   Oriented towards storing and saving data \\nrather than business user understanding.\\nDimensional Model:\\n•   Logical design that is used in data warehousing.\\n•   Composed of a set of fact and dimension \\ntables.\\n•  Models data as a hypercube.\\n•   Oriented towards faster retrieval of data,  \\ntogether with better understanding of data by \\nbusiness users.\\nMultidimensional Data Modeling • 251'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 276}, page_content='252 • Fundamentals of Business Analytics\\nChallenge Me\\nIn the T enT oT en Stores scenario, try to discover \\nall the possible entities that can be identified \\ntowards helping the group in taking a good deci-\\nsion which would help the group in deciding on \\nvarious aspects of business expansion, product \\npromotion, and consumer preferences.\\nExplore the “What-If” analyses features in Excel \\n2010 and check if the future of business in the \\nNorthwind T raders scenario can be predicted with \\nthe help of the entities present in their business.\\nLet Me\\nTest Me Exercises\\nBelow are a set of data modeling terminologies which are jumbled. The activity is to find the hidden \\nterms.\\nResume as : ______________________________________\\nThe sarcasm : ______________________________________\\nOn and it moralize : ______________________________________\\nSelf facts cast : ______________________________________\\nGrainy ultra : ______________________________________\\nT ube artist : ______________________________________\\nT o concealed lump : ______________________________________\\nIs candid, clinging : ______________________________________\\nCompile dashingly : ______________________________________\\nNeediest or demeaning : ______________________________________\\nAnswers for anagrams\\n 1. Measures\\n 2. Star Schema\\n 3. Normalization\\n 4. Factless fact\\n 5. Granularity\\n 6. Attributes\\n 7. Conceptual Model\\n 8. Slicing and dicing\\n 9. Physical modeling\\n10. Degenerate dimension'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 277}, page_content='soLVed exercises\\n1. Is the OLTP database design optimal for a data warehouse?\\nSolution: No. The tables in an OLTP database are in a normalized state and therefore will incur addi-\\ntional time to execute queries and finally to return with results. Additionally, an OLTP database is \\nsmaller in size and does not contain historical/longer period (yesteryears) data, which needs to be ana-\\nlyzed. An OLTP system basically is based on the ER model and not on Dimensional Model. If a com-\\nplex query is executed on an OLTP system, it may cause a heavy overhead on the OLTP server that \\nmight affect normal business processes.\\n2. If de-normalization improves data warehouse processes, why is the fact table in normal form?\\nSolution: Foreign keys of fact tables are primary keys of dimension tables. It is clear that a fact table \\ncontains columns which are primary keys to other tables that decide the normal form for the fact table.\\n3. What is real time data warehousing?\\nSolution: Data warehousing can also capture business activity data. Real time data warehousing \\ncaptures business activity data as it occurs. As soon as the business activity is complete and there is \\ndata about it, the completed activity data flows into the data warehouse and becomes available \\ninstantly.\\n4. What is ODS?\\nSolution: The expansion of ODS reads Operational Data Store. An ODS has a database structure that \\nserves it well as a repository for near real time operational data rather than long-term trend data. The \\nODS has the potential to become the enterprise-shared operational database, allowing operational \\nsystems that are being re-engineered to use the ODS as their operation databases.\\n5. What is “factless fact table”?\\nSolution: A fact table which does not contain numeric fact columns is called “factless fact table”.\\n6. What is a level of granularity of a fact table?\\nSolution: The level of granularity means the level of detail that you place into the fact table in a data \\nwarehouse. In other words, it implies the level of detail that one is willing to put for each transac-\\ntional fact.\\n7. What are the different methods of loading dimension tables?\\nSolution: There are two ways to load data into the dimension tables. They are:\\n •  Conventional (slow) method: All the constraints and keys are validated against the data before \\nit is loaded. This way data integrity is maintained.\\n •  Direct (Fast) Method: All the constraints and keys are disabled before data is loaded. Once data \\nis loaded, it is validated against all the constraints and keys. If data is found invalid or dirty, it is \\nnot included in index and all future processes are skipped on this data.\\n8. What is surrogate key?\\nSolution: Surrogate key is a substitution for the natural primary key. It is simply a unique identifier \\nor number for each row that can be used for the primary key to the table. The only requirement for \\na surrogate primary key is that it is unique for each row in the table. Surrogate keys are always inte-\\nger or numeric.\\nMultidimensional Data Modeling • 253'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 278}, page_content='254 • Fundamentals of Business Analytics\\nPurpose is operational monitoring. Purpose is strategic decision support.\\nContains current data only. Contains both current as well historical data.\\nVolatile data Static data\\nContains only detailed low-level or atomic or \\nindivisible data. Contains both detailed and summary data.\\nSatisfies the organization’s need for up-to-the-\\nsecond data.\\nSatisfies the organization’s need for archived, \\nhistorical data.\\nOperational Data Store (ODS) Enterprise Data Warehouse\\nComputer Associates Erwin\\nIBM Corporation Rational Rose\\nMicrosoft Visio\\nOracle Corporation Oracle Designer\\nVendor Product\\nRequires relatively more space on the database. Requires relatively less space on the database.\\nHas relatively lesser number of dimension tables \\nand therefore lesser number of joins.\\nHas relatively more number of dimension tables and \\ntherefore more number of joins.\\nIncreases query performance Reduces query performance.\\nSuitable for heavy end-user query workloads. Not suitable for heavy end-user query workloads.\\nStar Schema Snowflake Schema\\n11. Why data marts are required?\\nSolution: Data marts facilitate querying and maintenance because the data mart usually contains \\ndata pertaining to a business process or a group of related business processes.\\n12. What are conformed dimensions?\\nSolution: A dimension that is shared between more than one fact table is called as conformed \\ndimension.\\n13. What are the various data modeling tools available in the market?\\nSolution: \\nSolution: \\n14. What are the differences between Star schema and Snowflake schema?\\n 9. What is data mining?\\nSolution: Data mining is the process of\\n • Analyzing data from different perspectives and summarizing it into useful information.\\n • Identifying patterns and trends and being able to predict the future.\\n10. How is an ODS different from an enterprise data warehouse?\\nSolution: '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 279}, page_content='TimeKey\\nProductKey\\nBranchKey\\nLocationKey\\nUnitsSold\\nDollarsTransacted\\nAverage_Sales\\nProductKey\\nProductName\\nProductBrand\\nProductType\\nSupplierType\\nLocationKey\\nStreet\\nCity\\nState\\nCountry\\nBranchKey\\nBranchName\\nBranchType\\nTimeKey\\nDay\\nDayOfWeek\\nMonth\\nQuarter\\nYear\\nSalesFactTable\\nLocationDimension\\nBranchDimension\\nProductDimensionTimeDimension\\nMeasures\\nunsoLVed exercises\\n1. What is a data model? Why is there a need for a data model?\\n2. What are the salient features of the Conceptual Model? Explain.\\n3. How is the Conceptual Model different from a Logical Model? Explain.\\n4. How is the Logical Model different from a Physical Model? Explain.\\n5. Why should you normalize your database? Explain giving example.\\n6. Assume you are working on an on-line inventory application. Would you like to go with nor-\\nmalizing your database or de-normalizing your database?\\n7. Assume you are the owner of a reporting application. Your application pulls data from an under-\\nlying database and generates a report. Would you recommend going with de-normalization to \\nyour database team?\\n8. Which situation will demand to go with dimensional modeling? Explain your answer with an \\nexample.\\nMultidimensional Data Modeling • 255\\n15.  Draw the star model for “HealthyYou”, a home healthcare product and services branch of “Good-\\nLife HealthCare Group”.\\nSolution: '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 280}, page_content='256 • Fundamentals of Business Analytics\\n9. What constitutes a fact table? What are the various types of facts? Explain using examples.\\n10. What constitutes a dimension table? Explain.\\n11. What is your understanding of slowly changing dimension? Explain.\\n12. What is your understanding of the rapidly changing dimension? Explain.\\n13. Explain the role-changing dimension with examples.\\n14. Explain the junk/garbage dimension with examples.\\n15. Explain the various types of dimensional models: star, snowflake and fact constellation.\\n16. Explain the term “grain” with an example.\\n17. Explain the term “hierarchy” with an example.\\n18. What scenario will prompt you to use Star schema? Explain.\\n19. What scenario will prompt you to use Snowflake schema? Explain.\\n20. What scenario will prompt you to use Fact Constellation schema? Explain.\\n21. What is a “factless fact”? Explain with an example.\\n22. Consider this scenario. An employee of an enterprise has completed work on the project that \\nhe was working on. He has been assigned to a new project. Each project is identified using a \\nunique project code and project name. At the completion of this new project, he will move \\ninto a new project. What we are trying to say here is that an employee does not always remain \\non the same project code and project name. How will you maintain his data? (Hint: Rapidly \\nchanging dimension.)\\n23. How does maintaining the data in a multidimensional format help with data analysis? \\nComment.\\n24. Compare and contrast the various types of slow changing dimensions. Use an example to better \\nexplain your answer.\\n25. What is the difference between data warehousing and business intelligence? Explain.\\n26. Draw the star model for GoodFood Restaurants Inc.\\n27. Draw the snowflake model for “HealthyYou”.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 281}, page_content='What’s in store\\nYou are already familiar about the core purpose of Business Analytics, viz. supporting decision making \\nwith facts. These facts primarily are numeric data, measured and made available at the right time, in the \\nright format to facilitate decision making. In this chapter you will learn all about these “numeric facts” \\nthat are like the “seed” which could grow into a big “tree”. We would like to reaffirm that the informa-\\ntion presented here is very basic in nature and forms the foundation for deeper understanding of the \\nsubject.\\nIn this chapter we will familiarize you with the terminology associated with measurement, need for a \\nsystem of measurement, characteristics of measures, process used for defining good measures, relation-\\nship of these measures with individuals/teams/departments and the entire company. We will share several \\nexamples in the industry we have chosen, i.e. retail, hotel, and domains that are very familiar to all of us.\\nWe suggest you refer to some of the learning resources suggested at the end of this chapter and also \\ncomplete the “T est Me” exercises. We suggest you conduct self-research in your area of interest leverag-\\ning the information available on the Internet.\\nBrief Contents\\nWhat’s in Store\\nUnderstanding Measures and Performance \\nMeasurement System T erminology \\nNavigating a Business Enterprise,  \\nRole of Metrics, and Metrics Supply Chain \\n“Fact-Based Decision Making” and KPIs \\nKPI Usage in Companies \\nWhere do Business Metrics and KPIs Come \\nFrom? \\nConnecting the Dots: Measures to Business \\nDecisions and Beyond\\nSummary\\nUnsolved Exercises\\nMeasures, Metrics, KPIs, and \\nPerformance Management\\n8'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 282}, page_content='258 • Fundamentals of Business Analytics\\n8.1 Understanding MeasUres and PerforMance\\nPicture this familiar scenario…\\nWhen you joined your high school, you were familiarized about the subjects you are required to \\nstudy, lab experiments you need to conduct, tests you must write, assignments/projects you need to \\nsubmit, how your final marks will be computed, how rank students will be rewarded, minimum \\nscore needed to move to next class, and so on. Why all these? Would you join a high school where \\nthere was no duration of the high school programs, no definition of the course curriculum, no idea \\nof subjects to study, no pass criteria, or no clarity about when and how you would move to the col-\\nlege level?\\nVirtually everything around us has a system of measurement. You have already studied about basic \\nmeasures such as length, mass, and time.  You know how speed, velocity, and acceleration are measured. \\nYou know when you are running a high temperature (fever) or have gained weight; you know the pur-\\npose of the speedometer in a scooter/car. So, now we will attempt to help you understand “measures” \\nrelating to businesses.\\nIn the example of your high school system, think about the following questions:\\n • How your report card is defined – Subjects, Minimum marks, Maximum marks, Your score in \\neach subject?\\n • How top 10 students are declared in every grade?\\n • How your school compares last year’s results with current year to show progress to your parents? \\nHow does your school fare in comparison to other high schools in the neighborhood?\\n • How the high school “revises the curriculum” or introduces a new subject to improve the rel-\\nevance of the curriculum with changing times?\\n • How does your high school plan for increasing the intake capacity by adding more sections and \\nnew teachers?\\nYou will find a common thread running in the answers of the above questions. And, that is, “perfor-\\nmance” which is all about achieving goals/results. T o analyze performance and to declare achievements \\nwe need “measures” and systematic data/facts collection. This is the heart of this chapter.\\n8.2 MeasUreMent systeM terMinology\\nThere are some terms associated with the system of measurement that need to be defined before we look \\nat how businesses use the system of measurement for analyzing business performance.\\n • Data: It is a collection of facts which have similar attributes or characteristics.\\n“Phone number” is a named collection of, say, mobile phone numbers of your friends.\\n“Email IDs” is an example of collection of email IDs of your classmates.\\nNotice that all mobile phone numbers are of numeric type (10-digit long) and all email IDs will \\nhave the format of friend@mycollege.com.\\n • Measure: Data with associated unit of measure (UOM) is typically termed as measure. \\n“Lab hours per month” has a numeric data associated with “time duration”.\\n“Average wait time for bill payment” is a measure derived out of multiple data points.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 283}, page_content='Measures, Metrics, KPIs, and Performance Management • 259\\n • Metric: It is a system of measures based on standard UOM with a business context. The term \\nbusiness metric also refers to the same.\\n“Product defect rate” by city is an example of measuring “what percentage of goods was returned \\nby customers in different cities”.\\n“Employee attrition rate” by quarter measures the percentage of employees leaving the company \\nwithin each three-month period.\\n • Indicator: It is a business metric used to track business results or success/performance.\\n“Call drop frequency” for mobile phone users is an indicator of user dissatisfaction.\\n“Earnings per share” may indicate increased investor interest.\\n“Cost per unit shipped” may indicate the rising cost of delivery of products.\\n • Index: It consists of a composite set of indicators used to address the overall health of business \\noperations.\\n“Customer satisfaction index” measured on a scale of 1 to 5.\\n“Market performance index” measured using standard stock market scale.\\nA metric data when properly defined includes four components. T wo of these are descriptive in nature, \\nthat is, they are qualitative. These components are: Subject and Stratum. The other two are quantitative \\ncomponents: Quantum and Application. Let’s know more about these four components.\\n • Subject: This measure is about a customer, a product, a supplier, an employee, etc.\\n • Quantum: It is the value of the measure, such as cost, frequency, duration, amount, etc.\\n • Stratum: It is the grouping consideration expressed like By Location, By Quarter, By Customer, \\netc.\\n • Application: Value compared with similar measurements like previous month, forecast, target, etc. \\nLet us identify the above components in the following piece of information.\\n“Cell phone” Cost in “Asia Pacific Region” is USD 100 against Target of USD 75.\\nIn the above information, Subject is product (cell phone), Quantum is actual cost (USD 100), Stratum \\nis region (in our case Asia Pacific), and Application is comparison with target (USD 75). Notice that \\ncost and target must have the same unit of measure and scale (not hundreds or thousands of USD) for \\ncomparison. You will come across several examples throughout this chapter that will help you under-\\nstand these terms.\\n8.3  navigating a BUsiness enterPrise, role of Metrics, \\nand Metrics sUPPly chain\\nPicture this familiar scenario…\\nYou are a passenger on a flight from Mumbai to New York. The flight is about to depart and the in-\\nflight announcements have just been completed. Think about the role of the flight captain and his team. \\nYour thoughts may include:\\n • The goal of the flight captain is to reach the destination safely, on-time.\\n • He has carefully planned the route for the day, altitude, average speed, and traffic based on the \\nweather, system maps, recommended critical changes, if any, etc.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 284}, page_content='260 • Fundamentals of Business Analytics\\n • He has checked fuel sufficiency, technical report, food and beverages status, flight attendants, \\netc. to ensure that the aircraft is fully ready for the flight.\\n • He is aware of the cockpit instrumentation readings,  target values, allowed deviation range, and \\nemergency procedures if the need arises.\\n • He is aware of the impact of the decisions he might make during flight. He has alternative strate-\\ngies in mind.\\n • He knows his team members’ competencies, knows resources available to make every customer \\nhappy and uphold the values of the airline he represents.\\n • Many more…\\nT oday, running a large business enterprise is like navigating an airliner or a ship safely to the pre-deter-\\nmined destination. Just like the captain relies on critical flight measurements like altitude, speed, cabin \\npressure, aircraft functions, etc. similarly businesses depend on measurements that help business leaders \\nnavigate the enterprise. You will recognize that all the work is not carried out just by the flight captain; \\nit’s the responsibility of a large team and the systems starting with ground staff to a series of control \\ntowers that guide each aircraft to its destination. Drawing a parallel with the business, business leaders \\ntoo depend on key functions such as human resource, finance, sales, marketing, research, production, \\nprocurement, facilities, distribution teams, etc. to reach business goals. Each business function will need \\nits own goals and measurements to ensure that the entire company achieves business success together. \\nEvery team within each function needs to achieve its goals, and finally every individual also needs to \\ncontribute his/her best for the business to reach its goals. This in business performance terms is called \\nalignment.\\nLet us see what happens in a retail store in the following scenario. The marketing department has \\nits independent goal to maximize sales volume. They launch a new “Discount sales campaign”. At the \\nsame time the store operations department sets a goal to reduce sales support staff in each store. The \\npurchase department has its own independent goal to reduce inventory cost, and hence reduces stock. \\nWhat happens if the above-stated goal remains independent department-level goals? You are right! The \\noutcome would be – When more customers come to store they don’t find items that were on “Discount \\nsale”. There is no one to help on the shop floor! There is no stock in the store to service the customer \\ndemand! This happened because there was no alignment of goals of different departments.\\nA good measurement system, together with the system to plan and collaborate will make the scene \\nvery different. Purchase and  operations are aware of the marketing campaign and projected sales and \\nthey have prepared for the “Discount sales campaign”. Operations defer the staff reduction move. \\nRather, it increases the help available on the floor. Purchase ensures processes to fulfil customer orders \\nsmoothly. This is what is termed as being on-the-same-page.\\nThe measurement system has a huge role in guiding the execution of business strategy. Exactly as \\nthe flight captain slightly alters the flight path to take care of local turbulence and yet he is aware of the \\ndestination/goal, business decision makers too test new approaches and reach business goals leveraging \\nbusiness metrics.\\nLet’s now focus our attention to the question – What are the attributes of a good metric? The descrip-\\ntion given in Table 8.1 will enable you to answer this question.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 285}, page_content='Metric Attribute Remarks Example\\nName Metric should be assigned a simple, \\neasy-to-remember name. Do not include \\ncodes, long words, and unit of measure.\\n1. eLearning T raining Days \\n2. Average Lines of Code\\nAbbreviation Short form used inside the organization. eTD/ ALOC in above cases.\\nDescription Provide explanation to help users \\nunderstand more contexts and \\ncomprehend the metric unambiguously.\\neLearning Days – T otal number of full-\\ntime days equivalent spent in training \\nusing online course delivery system. Users \\nmay log-in any number of times and \\nduration of each session is captured in \\nminutes. \\nUnit of Measure (for \\ndata capture)\\nThe commonly measured base unit needs \\nto be included.\\nIn the eLearning example, the unit is \\n“Minutes”.\\nScale Commonly reported granularity of unit \\nof measure. We need to capture the \\nconversion formula.  Simple multiples \\nlike 1000 (K) or M (Million) are \\ncommonly used. \\nIn the eLearning example, as the data \\nstorage granularity is “Days”, the scale is \\n“minutes/(60 * 8)” assuming 8 hours is a \\nstandard training day.\\nMetric Owner Position/department responsible and \\naccountable for the metric. \\nThe training support manager in the \\ntraining department could be an owner.\\nFrequency Indicates how often this metric will be \\nmeasured.\\nIn the eLearning example, it could be \\n“Month”, i.e. every month the metric is \\nconsolidated. It’s useful to indicate when \\nthe metric will be available for use, e.g. \\navailable after 2 working days in each \\nmonth.\\nPriority Department/organization priority in \\nterms of value of this metric in the \\ncurrent organizational context.\\nHigh/medium/low could be used.\\nData Values\\nTarget\\nActual\\n(Computed will \\ninclude Minimum, \\nMaximum, and \\nAverage, Valid range)\\nThese are some very important attributes \\nto be defined. Actual represents current \\nperiod/cycle captured value. T arget \\nrepresents the intended/planned value. \\nThe lowest and highest possible values \\nindicate the range. \\nIn the eLearning example, it may be the \\nmandate of the organization to ensure \\n2 days equivalent for each employee as \\ntarget. Actual is the value captured for each \\nemployee.\\nTarget Description What is the definition of normal \\nachievement? What constitutes high \\nperformance? What is the escalation \\nthreshold? What is the overall rationale for \\narriving at average/normal performance?\\nIn our example, it’s good to encourage \\nemployees to keep themselves current and \\nhence continuous learning is critical.  2 \\ndays out of 22 working days (10%) could \\nbe a good average.\\n(Continued)\\nMetric Attribute Example\\nTable 8.1 Salient attributes of a good metric\\nMeasures, Metrics, KPIs, and Performance Management • 261'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 286}, page_content='262 • Fundamentals of Business Analytics\\nFinally, let’s look at how can we say that the defined metric is a good metric?  This is really a complex \\nquestion.  While we can suggest test for structural correctness, it may not turn out to be a metric of \\nbusiness importance or vice versa. \\nExperts suggest the following SMART test for ensuring metric relevance to business. Refer to Table \\n8.2. Some of the readers may be familiar with this SMART test that is as applied for goals/objectives \\nas well. \\nRefer to Table 8.3. We are now ready to understand the “supply chain” associated with the metric, \\ni.e. where does measurement start, how the measures get transformed into metric, how do they get \\ndistributed, how users leverage them, how users achieve business results? This entire process could be \\ncompared to how a product (say, smartphone) you purchased creates personal productivity value start-\\ning with raw materials used to manufacture phone, its assemblies, product, delivery channels, use of \\nphone features to enhance personal productivity and measuring the product gain (value).\\nTable 8.1 (Continued)\\nMetric Attribute Remarks Example\\nFormula How to compute the metric and \\nexceptions?\\nThis again makes the definition \\nunambiguous for ALL stakeholders.\\nIn this example, organization may indicate \\nterms like:\\n • For permanent staff\\n • Month = 22 working day\\n • Deduct leave days\\n • Include holidays\\nWeight When we define a group of 6–8 strategic \\nmetrics, sometimes it may be u seful to \\ndeclare the relative importance of metrics \\nin that group.  Weight of the metrics need \\nto add up to 100.\\nConsider training weight:\\nInstructor-led T raining – 30, eLearning – \\n40, T eam project – 30\\nTotal Learning weight 100\\nMeasurement \\nPerspective\\nIt may be useful to indicate the \\norganization’s strategic perspective that is \\nimpacted by this metric.\\nIn this case,  customer and  finance \\nperspectives of the balanced scorecard are \\nimpacted by talent development.\\nBalanced scorecard has been discussed in \\ndetail in Chapter 9.\\nTrusted Data Source The IT application that has the trusted \\nactual values.\\nIn our case it could be LMS (Learning \\nManagement System).\\nRevision History List of all changes made to metric definition with date/person ID stamps from the data \\nof approval for implementation.\\nDate of Approval First implementation roll-out date.\\nOrganization-specific \\nindicators\\nOrganizations attempt to record metric type (lead or lag) data quality indicator, \\ninternal metrics classification category, typical applications that use the metric, \\ninitiatives that currently depend on this metric, expected direction of trend, etc.\\nMetric Attribute Example'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 287}, page_content='Table 8.2 SMART test for ensuring metric relevance to business\\nSpecific Metric is clearly defined, articulated, and understood by all stakeholders, and is \\ntriggering action.\\nMeasurable Someone in the organization must have the ability/instrumentation to \\naccurately, easily, and regularly measure the actual value at reasonable cost and  \\ntechnology. Think if a clinical thermometer would cost USD 1000!!\\nAttainable There will be no metric without target. This target may be stretched but must \\nbe attainable with the current level of people efforts and  processes. Speed by \\ncycle can’t be enhanced to 300 kmph no matter whatever be the technology \\nused!\\nResult-oriented The metric must motivate team members performing the work. In businesses, \\nresults are crucial.\\nTime-bound All actual values of metrics should be traceable to the date/time when the actual \\nvalue measurement was taken. The instrument used for measurement also has \\na key role in sampling, accuracy, speed, and correctness that can be verified in \\nother ways.\\nT est T est Focus\\nTable 8.3 Supply chain associated with the metric\\nEntities to be measured Includes employee, vendor, product, customer, asset, expense category, sales \\npromotion, service feedback, …\\nInstrumentation Measurement data, data capture, and  storage in raw form\\nRaw material Reference data, definitions, benchmarks, limits, …\\nSub-assemblies Measures with unit, format, storage structure, archives, …\\nProduct Business metrics approved, communicated and measured, verified and analyzed \\nwith rigor\\nMetrics Delivery Reports, dashboards, scoreboards, alerts, Flash updates\\nBusiness Activity Areas\\n(Decisions/Actions)\\nPlan review, tracking project progress, sales campaign analysis, profit forecast\\nBusiness Application Budget control, quality improvement, innovation projects\\nBusiness Value Business results meeting and exceeding plan\\nComponent of Measurement Supply Chain Contribution\\nMeasures, Metrics, KPIs, and Performance Management • 263'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 288}, page_content='264 • Fundamentals of Business Analytics\\nAs an example to illustrate the above supply chain concept, think of the electrical energy meter or \\nwater meter installed in your home. The entity to be measured is energy consumption or water con-\\nsumption and the associated instrument is energy/water meter. In this system of measurement, the \\nutility company keeps record of meter reading and takes meter reading every month. The sub-assembly \\nis the amount of energy consumed, added tax, adjustments of advances, calculation of late fee if any, \\nand arriving at the net bill amount. The delivery to consumer is total energy/water consumed and net \\npayable utility bill amount. The same data for energy/water consumption analysis will reveal different \\npatterns of energy/water consumption in locations/state/country. They will further look at energy/water \\nrequirements by household, industry, agriculture, and environment. The same data when goes to mar-\\nketing function helps identify consumers for new projects like solar water heater/rain water harvesting \\nto support energy/water conservation. These are applications of metrics. They help business managers \\nmake decisions about target conservation they must achieve to escape increased taxation for industries \\nconsuming very large amounts of resources or promote green innovations. The utility company achieves \\ngoals of meeting energy/water requirements, promote conservation of resources, and serve consumers \\nwith accurate/timely billing and  collection channels. That is the real power of each metric!\\nNow that you have some idea about the “big picture” of business enterprise operations, we will fur-\\nther explore how metrics helps managers make business decisions.\\n8.4 “fact-Based decision Making” and kPis\\nWe all decide all the time about the actions we want to take. Some of our actions are very intuitive, \\nand we don’t analyze thoroughly before acting. Some decisions raise questions in our minds – Think \\nabout the new vehicle you want to buy or a new house you are considering to buy! This is the place \\nwhere measures and quantitative values will help us compare alternatives. When we use “facts” we are \\nnot driven by emotions or gut feel. The true picture emerges when we start comparing similar quanti-\\nties or qualitative ratings. It’s now very evident that metrics help us evaluate alternatives more objec-\\ntively and help us in decision making. Just think of the analogy of the flight captain looking at the \\ncockpit dials and weighing options in real time to choose the best alternative procedure to address a \\nparticular challenge. Similarly, team members engaged in business activities use the “facts” to objectively \\ncompare and choose the “best option” for a given business situation. This is the heart of decision \\nmaking at individual levels and is termed as “fact-based decision making”.\\nNow let’s understand the need for “fact-based systems” for decision making in businesses. All busi-\\nnesses develop a high-level vision, objectives for each function/initiative, key performance areas/goals, \\nkey performance indicators, targets, and allowed variance for targets to steer the business towards its \\ngoals. This is the performance management process of enterprises.\\nEssentially, performance measurement is about analyzing the success of a project team, department, \\nor country-wide business or global business’s efforts by comparing data on what actually happened \\nto what was planned or intended. Performance measurement is about asking: Is progress being made \\ntowards the desired goals? Are appropriate decisions and actions being undertaken to ensure achieving \\nthose goals? Are there any challenges that need attention? \\nPerformance measurement is the selection and use of quantitative measures specific to team initia-\\ntives, department, group, or entire company to develop information about critical aspects of business \\nactivities, including their results/outcomes. Performance measurement involves regular collection, track-\\ning, and reporting of data relating to effort invested as well as work produced and results achieved.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 289}, page_content='If the measures have such a huge impact on the business results, it’s needless to say that the measures \\nare required to be chosen very carefully. Let’s look at some characteristics of good business metrics. We \\nwill identify those metrics that are important at the entire company level and call them as Key Perfor-\\nmance Indicators (KPIs). Remember that “not everything that can be counted counts and not everything \\nthat counts can be counted”.\\n • Relevance and  functionality: The KPIs chosen should be directly related to business results \\nthat the company is trying to produce in the specific business function. Like, your body temper-\\nature measurement can only indicate whether you have fever or not, but can say nothing about \\nyour blood pressure! You may even remember popular Murphy’s Law – “You cannot determine \\nthe direction in which the train went by looking at the tracks”.\\n • Understandable: Chosen KPIs must be defined unambiguously. A KPI needs to be understood \\nin one and only one way by all stakeholders. It must be documented, and its definition must be \\neasily accessible to all users. \\n • Reliability and Credibility: The value of KPIs needs to be authentic and should be validated \\nas “trusted” or “dependable”. Someone is going to base an important decision on the chosen \\nmetric. Adequate checks are needed to declare data as trustworthy. This also means that the data \\nmust represent the “single version of truth”.\\n • Abuse-proof: An abuse-proof measure is unlikely to be used against intended purpose or \\nindividual(s) involved in the measurement process.\\nPerformance management could be defined as the use of performance measurement facts to help set agreed-\\nupon business performance goals, define objectives for growth and innovation, or excel, allocate, and pri-\\noritize resources, inform managers of their targets, and report on the success in meeting those goals.\\nIn other words,  we may say that KPIs are objective, measurable attributes of business performance, \\nwhich assist in informed decision making. They are a means of assessing the business functions’ health and \\na means of assisting in the prediction of business success and potential failure. They can also be a means of \\ncapturing best practices and lessons learned at individual, team, department, and company levels.\\nKey performance indicators are quantitative or qualitative measures which reflect the business per-\\nformance of a company in achieving its goals and strategies. KPIs reflect strategic value drivers rather \\nthan just measuring non-critical business activities and processes. They align all levels of an organization \\nclearly defined and cascaded down to individual level targets to create accountability and track business \\nprogress. KPIs are designed specifically for each organization and may use industry standard values for \\nbenchmarking (comparing with world-class standards). \\nLet us look at a few sample KPIs used by the Human Capital and T raining Management division of \\n“GoodFood Restaurants Inc.”: \\n • Average time to recruit.\\n • Average open time of job positions.\\n • # of responses to open job positions.\\n • # of interviews to fill up open job positions.\\n • # of offers that were made. \\n • # of responses to the offers made.\\n • % of vacancies that were filled within x time.\\n • % of new employees that remained after x time.\\n • % of new employee satisfaction rate.\\nMeasures, Metrics, KPIs, and Performance Management • 265'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 290}, page_content='266 • Fundamentals of Business Analytics\\nFew sample KPIs employed by the Employee T raining Management Division of “GoodFood Restaurant” \\nare as follows:\\n • % of employees who underwent training.\\n • Average training cost per employee.\\n • % of employees satisfied with training.\\n • Average training hours per employee.\\n • Ratio of internal vs. external training.\\n • % of budget spent on employees training.\\n • ROI of training.\\nLikewise, let us look at a few sample KPIs likely in use by the Help Desk of “GoodFood Restaurant”:\\n • Average no. of calls by customers in a day.\\n • Average time spent by a help desk employee in attending to calls.\\n • % of complaints serviced in a day.\\n • % of customers satisfied by the services offered.\\n • % of complaints serviced well before the SLA (service-level agreement) time.\\nKPIs help change the way business team members do their jobs, approach their daily planning/schedule, \\nand deal with daily urgencies/escalations. KPIs help people focus on the “big picture”. They help people \\ndistinguish the important from the trivial, the “must be done” from the “could be done”, and allow \\nemployees to set their own priorities. KPIs are best employed at the lowest level for an individual.\\nKPIs differ from industry to industry as indicated below:\\n • For the retail industry, the average dollars per sale is a good KPI.\\n • For project managers, employee attrition is an important KPI.\\n • Inventory accuracy is an important KPI for distribution companies.\\n • Inventory turns is a very important KPI for manufacturing and distribution companies.\\n • For telemarketers, the number of phones calls made is an important KPI.\\n • For accounts payable departments, the number of AP Days outstanding is important.\\n8.5 kPi Usage in coMP anies\\nKPIs could be used in the company at strategic, tactical, and operational levels. We will not be detailing \\nthe techniques used for defining KPIs as this is clearly an advanced topic. At this stage it is sufficient to \\nknow that there are techniques like Cause and  Effect Modeling, Goal Question Metric and  Measure \\n(GQMM), Balanced Scorecard (BSC), Six Sigma, MBNQA, TQM, Economic Value Add (EVA) \\nManagement Frameworks to represent KPIs to define, align, track, and communicate strategy. The fol-\\nlowing points highlight how KPIs are used by companies. \\n • KPIs often times are built as KPI tree. A lower order metric aggregates actual value into a higher \\nlevel and the structure looks like a tree structure. \\n • KPIs are typically classified into lag indicators that reflect the result achieved (net profit) or lead \\nindicators that project the possibility of achieving the target (large projects using patented ideas). \\nWhile companies look at both the effort and results picture, the result/outcome KPIs are tracked \\nwith rigor. '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 291}, page_content=' • KPIs reflect the value drivers or the control levers that directly and significantly influence the \\noutcome that is being tracked. \\n • KPIs are cascaded down from corporate level to regional, functional, team, and individual levels. \\nThis helps in aligning the efforts of the company towards achievement of strategic goals.\\n • KPIs are also targeted for specific roles. This technique avoids information overload and helps \\nteam members focus on what they need to achieve to meet the overall goals of the company.\\n • KPIs are employed to track several non-financial goals of large global companies in areas in-\\ncluding strategy quality of the company, execution capability, research and  thought leadership, \\ntalent management ability, innovation, quality of processes, top management effectiveness, and \\nso on.\\n • Standard KPIs may be purchased from third-party consulting firms, and it’s even possible to buy \\nindustry benchmarks that help business leaders compare their competitive position in the global \\nmarketplace.\\n8.6 Where do BUsiness Metrics and kPis coMe froM?\\nIt’s important to know how companies evolve business metrics and KPIs and the IT technology that is \\ncritical to deliver the agreed metrics to the right user, at the right time, and in the right format on the \\npreferred device of the user.\\nThere are several sources of inputs that companies use to evolve KPIs at corporate, regional, func-\\ntional/department, strategic, team, and individual levels. Some of  the inputs for metrics are as depicted \\nin Table 8.4.\\nTable 8.4 Potential sources for metrics\\nCorporate Vision, Mission, Values External stakeholder KPIs, metrics that are tracked by \\nbusiness analysts/market research firms, etc.\\nBusiness Performance Projections/ Forecasts/ \\nGuidance \\nTypically financial performance, profit, industry-specific \\nbenchmark metrics, and so on.\\nBusiness Plan (Sales) Revenue – Customer, product, service line revenues\\nCompetitive position and  advantages\\nTalent and  partner plans\\nRegional and  channel plans\\nStrategic investments, innovations, research\\nProduction/Manufacturing Inventory, purchase, strategic sourcing projects\\nT echnology adoption, mass production, quality \\nimprovement-based cost savings\\nOperations & Service Customer satisfaction, field service expenses\\nService quality inputs/benchmarks\\nSupport costs, replacements\\nSociety and CSR Care for environment\\nSource Inputs for Metrics\\n(Continued)\\nMeasures, Metrics, KPIs, and Performance Management • 267'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 292}, page_content='268 • Fundamentals of Business Analytics\\nFunction-specific such as Human capital & \\ntraining, Finance, Procurement, Technology \\nInfrastructure, Facilities & Maintenance, \\nMarketing, Quality, R & D\\nFunction-specific\\nTalent Performance Management Strategic talent development metrics\\nTable 8.4 (Continued)\\nSource Inputs for Metrics\\nCompanies look at past performance, new requirements, and competitive data to track KPIs in a \\nscorecard just like the student report card. When it comes to senior leadership levels, the number of \\nKPIs will be just around 20. It cascades down to various functions, business lines, and support organiza-\\ntions. At individual levels, the KPIs will be a combination of applicable corporate KPIs, function-level \\nKPIs, strategic innovation KPIs, and individual contribution KPIs.\\n8.7  connecting the dots: MeasUres to BUsiness decisions \\nand Beyond\\nYou are now ready to get an integrated picture of different concepts we have outlined about metrics. \\nMeasure is a part of our life. It has a powerful influence on the decisions we make, if used properly.  \\nThere exist scientific methods and frameworks that have been researched for years for harnessing the \\npower of measures. There is a need to transform simple facts into key performance indicators by adding \\nmore “contexts” to basic facts. Look at Figure 8.1 to understand the relationship that exists between the \\nbusiness world and the technical world centered on facts.\\nFigure 8.1 Mapping metrics to business phases.\\nBusiness\\nenvironment\\nBusiness\\nstrategies\\nBusiness\\nresults\\nBusiness\\ngoals/t argets\\nBusiness\\ntactics/ operations\\nKnowledge of\\nprocesses\\nTrustworthy\\nfacts /systems\\nMetrics/ KPIs\\nfor decisions\\nOutcomes of\\ninitiatives\\nInsights for execution\\nexcellence\\nBusiness\\nleadership'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 293}, page_content='Global businesses rely on technology-enabled initiatives to achieve market leadership position. Such \\nstrategic initiatives may be focused on innovation, targeted customer marketing, process optimiza-\\ntion, risk management, global resource planning, global procurement, productivity enhancement, new \\nopportunities identification, corporate performance management, and so on. These strategies need to \\nbe executed flawlessly or with “zero defect”. This only means that every decision has to be accurate and \\nmust contribute to reaching/exceeding the pre-set goals/targets. There is no room for mistakes. Such \\naccurate decisions only need to be objective, i.e. without emotions, and collaboratively supported by \\nleadership team. Only process metrics/KPIs can provide the reality status on the ground accurately in a \\nconsistent and repeatable fashion. This data will be used to alter/re-align or fine tune processes. Hence, \\ndecision makers need trustworthy KPIs/metrics. This can only come from carefully thought-out, pre-\\ndesigned, and technology-enabled systems of facts. This is the true power of metrics. \\nsUMMary\\n • Businesses depend on metrics for objective decision making.\\n • Business metrics are goal/result oriented.\\n • Metrics are not isolated but typically connect as KPI tree.\\n • Metrics motivate performance at individual, team, function, and company levels.\\n • There exists a scientific process to define, transform, communicate, and apply metrics for busi-\\nness value.\\n • Metrics have four distinct components, viz., Subject, Stratum, Quantum, and Application.\\n • Decision quality depends on the quality of actual metric values. Hence IT is leveraged to support \\nconsistent, accurate, speedy collection, tracking, consolidation, and reporting of metrics.\\n • Not everything that can be counted counts, and not everything that counts can be counted.\\n • Organization culture, standardization, education, and leadership are needed to implement effec-\\ntive fact-based decision culture.\\nRemind Me\\n \\n•   There is nothing special about business \\n metrics. They are just as natural as any other \\nentity we measure.\\n•   Navigating business is similar to navigating \\nairplane. Both the aircraft captain and the \\nbusiness leader need accurate data at the right \\ntime in the right form.\\n•  Every metric needs to be designed carefully \\nstarting with instruments to value it can pro-\\nvide. (Energy meter to discount plan for solar \\nwater heater users.)\\n•  Many times a single metric will not tell the com-\\nplete story. The airplane cockpit doesn’t have just \\none meter but several for different measurements. \\nIn business, this takes the form of KPI tree.\\n•  KPIs reflect the entire performance of the \\ncompany and will be cascaded down to the \\nlevel of individuals. This is called alignment.\\n•  In an ideal situation every individual needs to \\nknow only the KPIs that he/she is responsible \\nfor and some KPIs that represent collabora-\\ntive outcomes.\\nMeasures, Metrics, KPIs, and Performance Management • 269'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 294}, page_content='270 • Fundamentals of Business Analytics\\nUnsolved exercises\\n1. Define KPI. Comment on the need for KPIs.\\n2. How is KPI different from Critical Success Factors? Explain.\\n3. A company is looking for recruiting graduates for their new business unit. They have asked the \\nHR (Human Resource) team to go ahead with recruitment. What KPIs will be most relevant for \\nmeasuring the effectiveness of the recruiting process?\\n4. Define KPIs to measure the effectiveness of a learning program.\\n5. “You cannot manage what you cannot measure, and you cannot measure what you cannot \\n define”. Comment giving an example.\\n6. Search and prepare KPIs for measuring the effectiveness of a TV channel.\\n7. Determine 10 KPIs that will help decide the candidate for “Best Driver” award in the state trans-\\nport company.\\n8. What KPIs are used in a cricket academy to select batsmen, bowlers, and fielders?\\n9. How would you aggregate KPIs for selecting sports teams for tournaments at college, state, \\n regional, national, and international levels?\\n10. What KPIs will need to cascade from the national level to the individual outlet level for a \\ncountry-wide retail chain such as Cafe Coffee Day to ensure same consumer experience?\\nPoint Me (Books)\\n•   Corporate Performance Management, Wade & \\nRecardo, Butterworth-Heinemann.\\n•   Six Sigma Business Scorecard, Gupta, McGraw-\\nHill.\\n•  Measuring Business Performance, Neely, The \\nEconomist Books.\\n•  Decision Making, Rowe, Harvard Business \\nSchool Press.\\n•  Measure Up! How to Measure Corporate Perfor-\\nmance, Lynch & Cross Blackwell Business.\\n•  The Balanced Scorecard, Kaplan & Norton, \\nHarvard Business School Press.\\n (Please note that the content in the books are for \\nadvanced learning.)\\nConnect Me (Internet Resources)\\n • www.bettermanagement.com\\n • Google for “Performance measures” Retail/Manufacturing/Supply Chain.\\n • Download Microsoft Dynamics KPI Guide.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 295}, page_content='11. What is “fact-based decision making”? Explain your answer with an example.\\n12. Explain the four components of metric data: Subject, Stratum, Quantum, and Application. Use \\nan example to explain your answer.\\n13. Explain few attributes of a good metric.\\n14. Explain GQMM with the help of an example.\\n15. How does “measures” help with good decision making? Explain.\\n16. You are the owner of a retail chain. You wish to enhance the productivity of your store’s employ-\\nees. What metrics will you define to achieve this objective?\\n17. You are the owner of a private airline. Your business has been incurring losses. T o combat the \\nsame, you have decided to cut cost. What metrics will you define to achieve this objective?\\n18. A supply chain is “Manufacturer → Whole seller → Retailers → Consumers”. What metrics can \\nbe defined for this supply chain?\\n19. “You cannot determine the direction in which the train went by looking at the tracks”. Com-\\nment giving an example.\\n20. “KPIs reflect the entire performance of the company and will be cascaded down to the level of \\nindividuals”. Explain giving an example.\\nMeasures, Metrics, KPIs, and Performance Management • 271'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 296}, page_content=''),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 297}, page_content='What’s in store\\nYou are now familiar with the key concepts relating to business metrics and KPIs, multidimensional \\nmodeling, and the big picture of a business enterprise. With this background, it’s time to think \\nabout the basics of enterprise reporting and gain hands-on experience in using a simple reporting \\ntool. \\nReporting is an integral part of OLTP applications. We will summarize some of the best practices \\nfrom the OLTP world that have influenced the evolution of standard reporting practices. Our focus is \\non OLAP-centric reporting. This class of enterprise reporting will objectively communicate facts relat-\\ning to strategy, corporate/department performance against plan, status of critical initiatives, and metrics \\nthat matter to the stakeholders. These reports help leaders align their business activities to the vision \\nand strategies of their enterprise and to monitor their performance against the organization’s goals. We \\nwill introduce you to some analysis types, and we have a special section on the  “Balanced Scorecard” \\nas well.\\nBrief Contents\\nWhat’s in Store\\nReporting Perspectives Common to All Levels \\nof Enterprise\\nReport Standardization and Presentation \\nPractices\\nEnterprise Reporting Characteristics in OLAP \\nWorld\\nBalanced Scorecard\\nDashboards\\nHow Do You Create Dashboards?\\nScorecards vs. Dashboards\\nThe Buzz Behind Analysis…\\nUnsolved Exercises\\nBasics of Enterprise  \\nReporting\\n9'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 298}, page_content='274 • Fundamentals of Business Analytics\\nThis chapter is a “Must Read” for first-time learners interested to learn about the basics of corporate \\nperformance management, the key performance indicators, the balanced scorecard, and the enterprise \\ndashboard. In this chapter we will also familiarize you with the difference between the balanced score-\\ncard and the enterprise dashboard.\\nWe suggest you refer to some of the learning resources suggested at the end of this chapter and also \\ncomplete the “T est Me” exercises. You will get deeper knowledge by interacting with people who have \\nshared their project experiences in blogs. We suggest you make your own notes/bookmarks while read-\\ning through the chapter.\\n9.1  reporting perspectives common to all levels  \\nof enterprise\\nWe have already introduced you to the organization of a large enterprise in Chapter 1, “Business View \\nof Information T echnology Applications”. Typically enterprises have headquarters and several regional \\ncenters. Several geographic location-focused operations may aggregate to the nearest regional center. \\nEach geographic location may have “revenue generating – customer facing units” and “support units”. \\nThere could be regional or corporate level support functions as well. IT could be leveraged at the local \\noperations level or the regional level or the entire corporate level. Hence, it is natural to expect IT-enabled \\nreporting to occur at local, regional, or corporate levels. Let’s understand some common perspectives of \\nreporting that apply at all levels of the enterprise.\\n • Function level: Reports being generated at the function level may be consumed by users within \\na department or geographic location or region or by decision makers at the corporate level. One \\nneeds to keep in mind the target audience for the reports. The requirements will vary based on \\nthe target audience. Departments such as HR, marketing, production, purchase, accounting, \\netc. will need specific standard reports to handle operational, tactical, and strategic challenges. \\nReports could be produced in many languages to meet global user needs.\\n • Internal/external: Sometimes the consumers of reports may be external to the enterprise. We \\nare very familiar with the annual reports of organizations. Correctness as well as attractive pre-\\nsentation of the report is of paramount importance.\\n • Role-based: T oday we are witnessing massive information overload. The trend is to provide \\nstandard format of report to similar roles across the enterprise, as they are likely to make simi-\\nlar decisions. For example, a sales executive responsible for strategic accounts will need similar \\n information/facts for decision making irrespective of the country/products he/she handles.\\n • Strategic/operational: Reports could also be classified based on the nature of the purpose they \\nserve. Strategic reports inform the alignment with the goals, whereas operational reports pres-\\nent transaction facts. The quarterly revenue report indicates variance with regard to meeting \\ntargets, whereas the daily cash flow summary indicates summary of day’s business transactions. \\nWhen consolidated across several locations, regions, products/services, even this report will be \\nof strategic importance.\\n • Summary/detail: As the name suggests, summary reports do not provide transaction-level in-\\nformation, whereas detailed reports list atomic facts. Even here several summaries could be ag-\\ngregated to track enterprise-level performance.\\n • Standard/ad hoc: Departments tend to generate periodic reports, say, weekly, monthly, or quar-\\nterly reports in standard formats. Executives many times need ad hoc or on-demand reports for \\ncritical business decision making.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 299}, page_content='Basics of Enterprise Reporting • 275\\n • Purpose: Enterprises classify reports as statutory that focus on business transparency and need to \\nbe shared with regulatory bodies. For example, a bank reporting to the Reserve Bank stipulated \\nparameters of its operations. You might have even heard of audit reports that are produced to \\ncheck the correctness and consistent application of business policies across global transactions. \\nAnalytical reports look into a particular area of operation like sales, production, and procure-\\nment, and they find patterns in historical data. These reports typically represent large data inter-\\npretations in the form of graphs. Scorecards are used in modern enterprises to objectively capture \\nthe key performances against set targets and deviation with reasons. These scorecards help kick \\noff many initiatives that bring back business parameters under control.\\n • Technology platform-centric: Reporting in today’s context need not use paper at all. Dash-\\nboards could be delivered on smartphones and tablets. Reports could be published in un-ed-\\nitable (secure) form with watermarks. Reports could be protected to be used by a specific per-\\nson, during specific hours from specific device! Reports could be delivered to the target user in \\nuser-preferred formats such as worksheet, word document, PowerPoint Presentation, text file \\nor HTML document, and so on. Reports could be just generated once and shared with many \\nusers through an email link as well. Security of data is a constant concern in large enterprises as \\nreports represent the secret recipe of the business. Several tools have emerged in the marketplace \\nto meet the reporting requirements of the enterprise. It is not at all uncommon for enterprises \\nto use several tools and technologies to meet the reporting requirements of the enterprise. Some \\nhave even set up Reporting Centers of Excellence to handle this crucial function.\\n9.2 report standardization and presentation practices\\nNow let’s turn our attention to some of the common best practices that most enterprises employ while \\nconsidering reporting requirements. Enterprises tend to standardize reporting from several perspectives. \\nSome report standardization perspectives are as follows:\\n • Data standardization: This standardization perspective enables enterprise users performing \\nsame role to receive common, pre-determined data sets that relate directly to their role. The \\ndata provided will also include facts needed for active collaboration with other functions within/\\noutside the enterprise.\\n • Content standardization: Enterprises focus on content standardization. This is tightly tied to \\nthe name of the report. For example, the shipping report from despatch will have information \\nthat helps users connected with shipping to make informed decisions.\\n • Presentation standardization: The third perspective of standardization is about report \\npresentation. Here enterprises set standards on naming conventions, date formats, color/\\nblack–white usability standards, use of logos, fonts, page formats, security classifications, \\ncover pages, and so on. \\n • Metrics standardization: The next major focus of standardization will be typically on metrics. \\nEnterprises’ functions strive to find the metrics that best reflect the status of performance to help \\nteams control the progress towards their goals. External benchmarking and purchasing threshold \\nvalues for industry key metrics are common.\\n • Reporting tools’ standardization: Another key perspective is about reporting tools. Enterpris-\\nes  deploy specific class of reporting tools for different requirements of departments/locations/\\naudience. '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 300}, page_content='276 • Fundamentals of Business Analytics\\nReport title It is important to provide a crisp name for the report such that it reflects its purpose. \\nSome teams may even add the target audience. Example:\\nCash flow report for SOUTH Region\\nProduct Shipping Report for Plant 2 \\nReporting period As the reports use data collected over a specific period, it is critical to state the same. \\nThe period format could be:\\nFor week beginning March DD, YYYY\\nFrom DD/MM/YYYY to DD/MM/YYYY\\nHeader/footer It is good to include report headers and footers that repeat on every page. The \\ncontent could have elements like logo, function name, page number, confidentiality \\nlevel, etc.\\nColumn headings The numeric data presented will need to be read based on the column names. Again \\nkeeping crisp but meaningful names is critical. These are different from RDBMS \\ncolumn names and need to be user-friendly.\\nColumn selection and \\nsequence\\nAlthough reports are meant to be used by users in the same role, but across different \\nlocations, users have their own preferences when they want to see the information \\nbeing presented. There needs to be flexibility for users to select the columns that \\nthey would like to see as well as the order or sequence from left to right. Example − \\nMicrosoft Explorer and Microsoft Outlook allow one to select from a list of available \\ncolumns and also display it in a preferred sequence.\\nFilters Users may not be interested to see all the lines simultaneously. They need to have \\nflexibility to use standard filters/custom filters (user-defined) to view lines that meet \\nspecific criteria. Example:\\nCash Flow for Department = “XXX”\\nCash Flow for Amount > 100000.00\\nSort sequence Users would like to view reports lines arranged in increasing or decreasing order for \\nconvenience of decision making.  Example:\\nNames to be arranged in alphabetical order\\nRevenue Report to be in decreasing order of amount\\nIt may be needed to sort lines in cascading fashion as well.\\nBY Department + BY Employee Name\\nBY Customer + BY Date + BY Invoice number\\nT otals/group totals When data lines are sorted, they may need to be grouped or bunched together in \\nchunks that make business sense. In these situations, users expect totals and cross-\\ntotals as well as overall totals to be computed/provided.\\nData field formatting Users also expect the stored data to be represented with formatting to enhance \\nreading convenience.\\nUsing currency symbols like $, etc.\\nDate formatting like June 3, 2011\\nComputed or \\ncalculated fields\\nUsers may want to introduce new columns that are derived from existing columns \\nand compute some value for decision making.\\nFeature Description\\nTable 9.1 Features of good reporting\\n(Continued)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 301}, page_content='Report content and presentation related approaches and styles have evolved in synchronization with \\nadvancements in technologies relating to display and printing. Some features of the good reporting \\ndrawn from the OLTP world of reporting are given in Table 9.1.\\nLet us now look at a few common report layout types.\\n9.2.1 common report layout t ypes\\n • Tabular reports: Tabular reports have a finite number of columns, typically representing the \\nfields in a database. A tabular report has header and footer, and repeating detail rows. Data can \\nbe grouped on various fields. Each group can have its own header, footer, breaks, and subtotal. \\nTable reports are typically used for logging detailed transactions. The tabular report depicted in \\nFigure 9.1 is grouped on “Category” and “SubCategory”. It displays details of all products under \\neach “SubCategory” and “Category”.\\n • Matrix reports: As discussed earlier, business reporting is about summarizing information for \\nanalysis. A matrix, cross-tab, or pivot report aggregates data along the x-axis and y-axis of a grid \\nto form a summarized table. Unlike tabular report columns, matrix report columns are not \\nstatic but are based on group values. Figure 9.2 depicts a matrix report that displays the total \\nsales of products under each SubCategory and Category. The row grouping is on Category and \\nSubCategory and the column grouping is on Month (Jan, Feb, Mar).Figure 9.1 A tabular report.\\nCategory\\nAccessories\\nProduct\\n81 $1, 622.35\\n659.6700\\n223761.5198\\n367932.3286\\n476252.2608\\n441260.5848\\n303304.0350\\n163518.0337\\n87291.5819\\n750.0000\\n3923.6094\\n3015.2169\\n 1622.3484\\n435.2727\\n283.8735\\n234.3750\\n206.1455\\n8779.0719\\n7666.2318\\n7999.7376\\n2676.1644\\n7374.7581\\n6499.7868\\n6058.7961\\n 498.2142 30.71 %\\n31.25 %\\n31.25 %\\n31.25 %\\n10.06 %\\n10.06 %\\n10.06 %\\n10.06 %\\n10.06 %\\n10.06 %\\n7.65 %\\n31.25 %$908.39\\n$750.00\\n$659.67\\n$1, 392.87\\n$87,291.58\\n$73,328.26\\n$34,991.68\\n$64,628.29\\n$79,542.52\\n$60,243.49\\n$76,226.45\\n69\\n45\\n50\\n55\\n71\\n64\\n52\\n59\\n54\\n49\\n62\\nSport-100 Helmet, Red\\nSport-100 Helmet, Blue\\nSport-100 Helmet, Black\\nSales Account Margin Margin %Cumulative TotalOrder Quantity\\nHelmets\\nLocks\\nMinipump\\nMountain-200 Black, 38\\nMountain-300 Black, 38\\nMountain-200 Silver, 38\\nMountain-200 Silver, 42\\nMountain-200 Silver, 46\\nMountain-200 Black, 42\\nMountain-200 Black, 46\\nCable Lock\\nPumps\\nBikes\\nMountain Bikes\\nSubCategory\\nHighlighting \\nbreaches\\nReports may highlight using color or font size/style to make the field seize the \\nattention of the user.\\nNotes Sometimes it may be essential to notify users of last-minute update messages that \\ncould answer typical questions raised by users.\\nFeature Description\\nTable 9.1 (Continued)\\nBasics of Enterprise Reporting • 277'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 302}, page_content='278 • Fundamentals of Business Analytics\\n • List reports: A list report has a single, rectangular detail area that repeats for every record or group \\nvalue in the underlying data set. Its main purpose is to contain other related data regions and re-\\nport items and to repeat them for a group of values. The list report, depicted in Figure 9.3, repeats \\nFigure 9.2 A matrix report.\\nCategory\\nAccessories\\nSubCategory\\nHelmets\\nPumps\\nLocks\\nSubCategory Total\\n3371.1455\\n635.6820\\n720.0000\\n4726.8275\\n4360.2840\\n467.7660\\n735.0000\\n5563.0500\\n3923.6094\\n659.6700\\n750.0000\\n5333.2794\\n11655.0389\\n1763.1180\\n2205.0000\\n15623.1569\\nJanF eb Mar Total\\nFigure 9.3 A list report.\\nClothing\\nCategory\\nCategory Total 29971.9329 41683.7603  34013.9171  105669.9103\\nClothing Jerseys\\nBib-Shorts\\nShorts\\nTights\\nGloves\\nCaps\\nSubCategory Total\\n4787.5064\\n6533.274\\n3563.406\\n7828.956\\n6817.938\\n440.8525\\n29971.9329\\n7498.504\\n8477.058\\n3923.346\\n9853.686\\n11230.9888\\n700.1775\\n41683.7603\\n5906.1858\\n6533.274\\n3743.376\\n9859.0628\\n7332.1706\\n639.8479\\n34013.9171\\n18192.1962\\n21543.606\\n11230.128\\n27541.7048\\n25381.0974\\n1780.8779\\n105669.6103\\nSubCategoryJ an Feb Mar Total\\nBikes\\nBikes\\nCategory Total\\nRoad Bikes\\nMountain Bikes\\nSubCategory Total\\n672148.884\\n499562.0668\\n1171710.951\\n1171710.951\\n1345479.743\\n808888.6166\\n2154368.36\\n2154368.36\\n778022.7529\\n581875.2828\\n1359898.036\\n1359898.036\\n2795651.38\\n1890325.966\\n4685977.346\\n4685977.346\\nCategory SubCategoryJ an Feb Mar Total\\nComponents\\nCategory Total\\nHeadsets\\nMountain frames\\nForks\\nRoad Frames\\nWheels\\nHandlebars\\nSubCategory Total\\n1784.682\\n44023.2746\\n2065.41\\n44494.5131\\n17155.503\\n1608.7395\\n111132.1222\\n111132.1222\\n4040.022\\n108360.7628\\n3717.738\\n41904.0135\\n22941.237\\n2267.6475\\n183231.4208\\n183231.4208\\n5111.88\\n83686.3161\\n4130.82\\n46293.1435\\n23089.089\\n2398.6\\n164709.8486\\n164709.8486\\n10936.584\\n236070.3535\\n9913.968\\n132691.6701\\n63185.829\\n6274.987\\n459073.3916\\n459073.3916\\nComponents\\nCategory SubCategoryJ an Feb Mar Total'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 303}, page_content='for each Category group. The records in the data set are grouped on Category and SubCategory. \\nThere are three Category Groups (Clothing, Bikes, and Components) in this list report.\\n • Chart reports: Chart reports provide a visual context for a lot of different kinds of data. There \\nare several chart forms that can be used in the chart report such as bar chart, line graph, column \\nchart, scatter plot, pie chart, etc. Figure 9.4 depicts a chart report of the total sales amount for \\neach product in each Category and SubCategory. Figure 9.5 shows a chart report with trend \\nlines for each category.\\nFigure 9.5 A chart report with trend lines for each category.\\nClothing\\nSales Amount\\nMov. Avg (Sales Amount)\\nAxis Title\\nAxis Title\\nJan\\nFeb\\nMar\\nApr\\nMay\\nJun\\n80000\\n60000\\n40000\\n20000\\n0\\nAccessories\\nSales Amount\\nMov. Avg (Sales Amount)\\nAxis Title\\nAxis Title\\nJan\\nFeb\\nMar\\nApr\\nMay\\nJun\\n14000\\n2000\\n4000\\n6000\\n8000\\n10000\\n12000\\n0\\nComponents\\nSales Amount\\nMov. Avg (Sales Amount)\\nAxis Title\\nAxis Title\\nJan\\nFeb\\nMar\\nApr\\nMay\\nJun\\n100000\\n200000\\n300000\\n400000\\n500000\\n0\\nBikes\\nSales Amount\\nMov. Avg (Sales Amount)\\nAxis Title\\nAxis Title\\nJan\\nFeb\\nMar\\nApr\\nMay\\nJun\\n500000\\n1000000\\n2000000\\n2500000\\n1500000\\n0\\nBasics of Enterprise Reporting • 279\\nFigure 9.4 A chart report.\\nChart Title\\nAccessories\\nCategories\\nBikes\\nClothing Components\\nSales amount in $\\nLegend Title\\nCaps\\n800\\n600\\n400\\n200\\n0\\nLocks\\nGloves\\nForks\\nHeadsets\\nMountain Frames\\nWheels\\nHandlebars\\nRoad Frames\\nJerseys\\nBib-Shorts\\nShorts\\nPumps\\nMountain Bikes\\nRoad Bikes\\nHelmets\\nTights\\nNote: The colored figure is provided in the accompanying CD.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 304}, page_content='280 • Fundamentals of Business Analytics\\n • Gauge reports: These are the reports with gauge controls. If gauge controls are appropriately \\ndesigned, one look at the gauge and you can say whether the enterprise is doing well, requires \\nattention (not immediate though), or is in a bad state. Gauge reports depict values against a \\ncertain threshold. Figure 9.6 depicts a gauge report of student’s performance. There are three \\ncolor zones indicated on the gauge: red, amber, and green. Red depicts “immediate attention \\nrequired”, amber depicts “cause for concern but not urgent”, and green depicts “things are going \\ngood”. In our report on student’s performance, students with total marks > 79% are awarded \\n“A” grade and are therefore in the green zone. Students with total marks >=65 but <80% are \\nawarded “B” grade and are therefore in the amber zone. Students with total score less than 65% \\n(not qualified) are awarded “C” grade and are in the red zone. In this example, the threshold \\nvalue for each gauge is 65% with an upper limit of 100%.\\n9.2.2 report delivery formats\\nIn an attempt to ensure on-time delivery of information to the right decision makers, several technolo-\\ngies could be used for delivering reports in the enterprise. Here are some common formats of report \\ndelivery:\\n • Printed reports: Used only when really essential.\\n • Secure soft copy: You are already familiar with formats like un-editable PDF files, ZIP files, \\npassword-protected documents, documents with watermark, etc.\\nFigure 9.6 A gauge report.\\nStudent No.\\nA101 55\\n59\\n70\\n66\\n60\\n80\\n77\\n77\\n90\\n198\\n196\\n240\\n66.00%\\n65.333%\\n80.00%\\nB\\nB\\nA\\nA102\\nA103\\nMarks in SQL Marks in SSRS Marks in SSIS Total Percent Grade\\nIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\\n 0           10               20                  30               40     50\\nIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\\n 0           10               20                  30               40     50\\nIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\\n 0           10               20                  30               40     50'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 305}, page_content=' • Email attachments: Reports could be attached to emails.\\n • Embedded emails: Reports could be embedded into email and protected to ensure that they \\ncannot be printed, saved, or forwarded.\\n • FTP: Reports could also be transferred to local systems by file transfers with security controls.\\n • Link to reports: The enterprise may choose to save reports to a central server and only provide \\na link through email.\\n • Worksheet, PowerPoint Presentation, text: Some users may need data for their own analysis \\nand hence may need reports in Excel, PowerPoint, MS Word, or HTML/XML formats.\\n • eBOOK: Reports can now be grouped and formed into an eBOOK for publication to users. \\nSome authorized users may be allowed to download the same onto their mobile devices.\\nBefore we jump to the core of reporting in the OLAP world, let’s quickly recall the process relating to \\nproduction of reports and the role of reporting tools. Report development, like ETL or program devel-\\nopment, has essential phases of requirements analysis, design, development, testing, production, and \\ndistribution. Typically, tools are used in design, development, and distribution phases. Design area \\nincludes several aspects like choosing data sources, columns from RDBMS, layout development, sample \\ndata generation, SQL query processing, and report preview. Typically, report specifications could be \\nsaved for future use. Every time the report needs to be generated, the user/admin user could either enter \\nthe variable parameters such as date, notes, filters, etc. at run time or provide these parameters in a file \\nand include the file in the command for report generation. Enterprises use several reporting tools to \\nmeet the growing needs of different types of users and also for distribution/archiving of generated \\nreports. Reporting tools also have the ability to generate only summary or detailed reports. Report \\ndevelopers may catalog common filters, sort sequences, columns for selection, and computed fields to \\nenhance flexibility of reporting.\\n9.3 enterprise reporting characteristics in olap World\\nEnterprises invest money and efforts to help decision makers gain access to the right information at the \\nright time on the right device. Some of the critical focus areas of enterprise reporting are as follows:\\n • Single version of truth: The value of providing the same “fact value” irrespective of the path the \\nuser has taken to reach for the data is of paramount importance in reporting.\\n • Role-based delivery: This feature is critical to avoid information overload.\\n • Anywhere/anytime/any-device access: Users have their own preferences and therefore flexibil-\\nity needs to be built to ensure that users come to the same source of information again and again \\nand don’t find alternative ways to decision making.\\n • Personalization: Users’ choices of delivery method, format like PDF/worksheet/CSV , book \\nmarking, customizing (in terms of language), etc. will need to be addressed.\\n • Security: Enterprises have huge concern over the unauthorized access to business-critical infor-\\nmation, hacking by malicious sources, inadvertent leakage of business data, etc. The security \\nframework needs to be thoroughly examined before implementing reporting.\\n • Alerts: Decision makers need immediate notification of threshold breaches of critical business \\nKPIs.  These alerts need to be delivered to various devices such as laptop, mobile devices in \\ndifferent forms like email, sound, voice message, SMS text, pop-up, etc. depending on user \\npreferences.\\nBasics of Enterprise Reporting • 281'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 306}, page_content='282 • Fundamentals of Business Analytics\\n • Reports repository: Many enterprises are attempting to create secure report repositories that \\nservice a wide range of users and have flexible delivery/viewing options. Managing the content \\nof the repository itself is a task that needs specialized competencies and tools.\\nEnterprises have witnessed and reported huge gains arising out of business analytics reporting. Enterprise \\nreporting is not about buying tools and  converting existing reports to new platforms, but is all about \\nbuilding a culture of “fact-based decision making”. This is essentially change management. Some of the \\nlong-term benefits of these investments include:\\n • Enhanced collaboration: T eams around the globe will use facts to be on the same page and look \\nat the same facts for designing powerful alternatives, collaboratively.\\n • Objective communication: Managers are no longer required to exercise “gut feel” to make \\n“seat-of-the-pant” decisions. They can look at facts.\\n • Reduced cost of audits/reviews: As all members of the team are on the same page, there is no \\nneed to waste meeting time to bring them to the same level of understanding by briefings. They \\nare already aware.\\n • Reduced decision cycle time: Enterprises adopting structure business analytics-based reporting \\nwill make consistent decisions and that too faster.\\n • Better predictability and ability to influence goals: Facts can be used to innovate and gain \\ntruly sustainable market leadership and competitive advantage.\\n9.4 Balanced scorecard\\nWe realize that “Measurement, Analysis, and Knowledge Management” (Malcolm Baldrige criteria) are \\ncritical for effective management of the organization and for a fact-based, knowledge-driven system for \\nimproving performance and competitiveness. It serves as a foundation for the performance manage-\\nment system.\\nHow many business people take the strategy talk, that has an important link with the performance \\nand competitiveness of their organization, seriously? Surprisingly, not many. According to a Fortune \\nMagazine survey, “Only 5% of the workforce understands the strategy, 85%  of executives spend less \\nthan one hour per month discussing strategy, only 25% of managers have incentives linked to strategy.” \\nSo, there is always a need for a strategic planning and management system which could\\n • Align business activities to the organization’s vision and strategies.\\n • Improve internal and external communication.\\n • Monitor the organization’s performance against its strategic goals.\\nThe balanced scorecard is one such strategic planning and management tool used by organizations to \\nalign their business activities with their organization’s vision and strategies.\\nDr. Robert S. Kaplan and David P . Norton gave the world the balanced scorecard in 1992. They have \\nto their credit a book titled The Balanced Scorecard which was published in 1996. This was followed by \\ntheir second book titled The Strategy Focused Organization in 2004. In this book, they have proposed \\nthe “Strategic Linkage Model” or “Strategy Model”.\\nThe balanced scorecard is designed to identify the financial and non-financial measures and attach \\nsome targets to them so that at a later point in time during review it is possible to decide whether the \\norganization’s performance has met the set expectations or not.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 307}, page_content='9.4.1 four perspectives of Balanced scorecard\\nThe balanced scorecard maps the organization’s strategic objectives into the following four perspectives \\nas depicted in Figure 9.7:\\n • Financial perspective: The financial perspective addresses the question of how shareholders \\nview the firm and which financial goals are desired from the shareholder’s perspective.\\nFigure 9.7 The four perspectives of the balanced scorecard.\\nFinancial\\n“To succeed financially,\\nhow should we appear\\nto our shareholders”\\nCustomer\\n“To achieve our vision,\\nhow should we appear\\nto our customers”\\nInternal Business\\nProcesses\\n“To satisfy our \\nshareholders and\\ncustomers, what\\nbusiness processes\\nmust we excel at?”\\nLearning and Growth\\n“To achieve vision,\\nhow will we sustain our\\nability to change\\nand improve”\\nVision and\\nStrategy\\nBasics of Enterprise Reporting • 283'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 308}, page_content='284 • Fundamentals of Business Analytics\\n • Customer perspective: The customer perspective addresses the question of how the firm is \\nviewed by its customers and whether the firm will be able to fulfil customers’ expectations.\\n • Internal business process perspective: The business process perspective identifies the processes \\nin which the organization must excel to satisfy its shareholders’ expectations of good financial \\nreturns and also keep its customers happy and loyal.\\n • Learning and growth perspective: The learning and growth perspective identifies the compe-\\ntencies that the employees of the organization must acquire for long-term improvement, sustain-\\nability, and growth.\\n9.4.2 Balanced scorecard as strategy map\\nThe balanced scorecard was earlier plotted as a four-box model. This model has evolved since then and \\nis now plotted as a strategy map. The strategy map places the four balanced scorecard perspectives into a \\ncausal hierarchy. The causal hierarchy shows that the objectives support each other and that delivering \\nthe right performance in the lower perspectives will help achieve the objectives in the upper perspectives. \\nThe balanced scorecard strategy map depicts how the company intends to create value for its sharehold-\\ners and customers.\\nFigure 9.8 shows the strategy map with the cause and effect relationship among four perspectives of \\nthe balanced scorecard. Each of the four balanced scorecard perspectives can be described in terms of \\nthe following parameters:\\n • Objectives: What is it that you wish to achieve?\\n • Measurement: How do you know if you have been able to achieve the stated objectives?\\n • Target: What is the level of performance expected or the level of improvement expected? \\n • Initiative: What is it that you would do to achieve your targets and thereby your objectives?\\n9.4.3 measurement system\\nThe measurement system interconnects the objectives and the measures in the various perspectives so \\nthat they can be validated and managed. For example, let us consider an airline company XYZ which \\nwishes to reduce its operating costs. It has decided to reduce the number of planes but at the same time \\nincrease the frequency of the flights among different cities to increase its revenue.\\nThe question is: How will the airlines company retain its customers and increase its customer satis-\\nfaction rate?\\nAn analysis of customers’ data reveals that on-time delivery of services makes customer happy and \\nsatisfied. T o ensure on-time departure of flights, the airline company has to ensure that the ground \\nturnaround time is less. (Ground turnaround time is the time that the ground crew takes to clean and \\nmaintain the flight and also allow the passengers to get in and settle down.) But at the same time, the \\nairline company has to ensure that the flights depart at the scheduled time.\\nLet us look how the airline improves the quality of service and reduces the ground turnaround time. \\nThe airlines achieves this by training and improving the skill sets of the ground crew. The cause and \\neffect relationship among the four balanced scorecard perspectives concerning the airlines example is \\ndepicted in Figure 9.9. The tabular representation of the objectives, measures, target, and initiative \\nconcerning the airlines is given in Figure 9.10.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 309}, page_content='9.4.4 Balanced scorecard as a management system\\nThe balanced scorecard translates an organization’s missions and strategies into tangible objectives and \\nmeasures. Figure 9.11 depicts the following four steps for designing the balanced scorecard:\\n • Clarify and translate vision and strategy.\\n • Communicate and link strategic objectives and measures.\\nFigure 9.8 Strategy map depicting four balanced scorecard perspectives in causal hierarchy.\\nFinancial\\nShareholder\\nvalue\\nProductivity Revenue\\nCustomer\\nCustomer retention\\nattributes\\nPrice   Quality   Time Brand\\nInternal Business Processes\\nOperations\\nManagement\\nProcesses\\nCustomer\\nManagement\\nProcesses\\nInnovation\\nProcesses\\nCSR\\nProcesses\\nLearning and Growth  \\nPeople capability\\nInformation systems\\nTechnology and infrastructure\\nCustomer\\nrelationships\\nRelation\\nfunction\\nBasics of Enterprise Reporting • 285'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 310}, page_content='286 • Fundamentals of Business Analytics\\nFigure 9.10  The tabular representation of the objectives, measures, target and initiative concerning the \\nairlines example.\\nObjectives Target Initiative\\nCycle time\\noptimization\\n30 mins\\n90%\\nFast ground turnaround\\ntime\\nOn-ground time\\nOn-time departure\\nMeasurement\\nFigure 9.9  The cause and effect relationship among the four balanced scorecard perspectives in the case \\nof the airlines example.\\nFinancial\\nProfits\\nGrow revenues Fewer planes\\nCustomer Attract and Retain more\\nCustomers\\nOn-time service Lowest prices\\nInternal Business Processes\\nFast ground turnaround time\\nLearning and Growth\\nGround crew alignment'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 311}, page_content=' • Plan, set targets, and align strategic initiatives.\\n • Enhance strategic feedback and learning.\\nThe balanced scorecard not only measures performance but also communicates and aligns the strategies \\nthroughout the organization. Some benefits of the balanced scorecard are as follows:\\n • T ranslating the organization’s strategies into measurable parameters.\\n • Communicating the strategies to all the individuals in the organization.\\n • Alignment of individual goals with the organization’s strategic objectives.\\nAltogether, the balanced scorecard translates the visions and strategies into a set of objectives and mea-\\nsures across a balanced set of perspectives. The scorecard includes measures of desired outcomes as well \\nas processes that will drive the desired outcomes for the future.\\nFigure 9.11 Four steps for creating the balanced scorecard.\\nClarifying and Translating Vision\\nand Strategy\\nClarifying the vision\\nGaining consensus\\nPlanning and Target Setting\\nCommunicating and Linking\\nBalanced\\nScorecard\\nCommunicating and educating\\nSetting goals\\nLinking reward performance\\nmeasures\\nSetting targets\\nStrategic Feedback\\nand Learning\\nArticulating the shared vision\\nSupplying strategic feedback\\nFacilitating strategy review and\\nlearning\\nAligning strategic\\ninitiatives\\nAllocating resources\\nBasics of Enterprise Reporting • 287'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 312}, page_content='288 • Fundamentals of Business Analytics\\n\\u2003 Remind\\u2003Me\\n• The balanced scorecard is a strategic planning \\nand management tool.\\n• The balanced scorecard is designed to empha-\\nsize both financial as well as non-financial \\naspects of the organization.\\n• The four perspectives of the balanced score-\\ncard are: financial, customer, internal business \\nprocess, and learning and growth.\\n• Each perspective can be described in terms of: \\nobjectives, measures, targets, and initiatives.\\n• The four steps required for designing the bal-\\nanced scorecard are:\\n\\uf0a7\\n Clarify and translate vision and strategy.\\n\\uf0a7  Communicate and link strategic objectives \\nand measures.\\n\\uf0a7  Plan, set targets, and align strategic initia-\\ntives.\\n\\uf0a7 Enhance strategic feedback and learning.\\nPoint\\u2003Me\\u2003(Books)\\n • The Balanced Scorecard, Kaplan and Norton, \\n1996.\\n • The Strategy-Focused Organization: How \\n Balanced Scorecard Companies Thrive in the \\nNew Business Environment, Kaplan and Nor-\\nton, 2004.\\n\\u2003 Connect\\u2003Me\\u2003(Internet\\u2003Resources)\\n• The Balanced Scorecard - Measures that Drive \\nPerformance, Harvard Business Review,  \\nFeb. 1992 \\n• The Balanced Scorecard: Translating Strategy \\ninto Action, Harvard Business School Press, \\nBoston (1996) '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 313}, page_content='Scorecard\\u2003Puzzle\\nSolution:\\n1. Strategy Map\\n2. Initiatives\\n3. Scorecard\\n4. Finance\\nACROSS\\n3. It is a strategic planning and\\n    management tool.\\n4. /T_his perspective addresses the question\\n     of how shareholders view the ﬁrm.\\nDOWN\\n1. It places the four perspectives into\\n    causual hierarchy.\\n2. It is what the organizations do to achieve their\\n    targets and thereby their objectives.\\n12\\n3\\n4\\nTest\\u2003Me\\u2003Exercises\\nAnswer me\\n1.  What are the four perspectives of the \\nbalanced scorecard?\\n2.  Why is there a need to translate the bal-\\nanced scorecard into a strategy map?\\n3.  Why does the balanced scorecard take \\ninto consideration the non-financial \\nmeasures as well?\\n4.  What are the four basic steps required in \\nthe design of the balanced scorecard?\\n5.  Can the balanced scorecard be plotted \\nonly for the organization, or can we plot \\nit for a business unit as well?\\nBasics of Enterprise Reporting • 289'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 314}, page_content='290 • Fundamentals of Business Analytics\\n9.5 dashBoards\\nCorporate or enterprise dashboards are changing the way we look at information and the way we ana-\\nlyze our business. A well-constructed corporate dashboard answers four basic questions:\\n • Where?\\n • What?\\n • How?\\n • Why?\\nInstead of wading through pages of disparate operational data, dashboards portray critical operating and \\nstrategic information about an organization using a collection of powerful graphical elements. One \\nquick glance at the dashboard tells users the key performance indicators and metrics used to measure \\nand monitor the company’s performance. Dashboards help in\\n • Better analysis.\\n • Better tracking.\\n • Proactive alerting.\\n9.5.1 What are dashboards?\\nWhat is the first thing that comes to your mind when you hear the word “dashboard”?\\nYes you guessed it right… It is indeed an automobile’s dashboard!\\nDashboard is a control panel in an automobile that provides the driver with all the information \\nregarding the operations and control of the vehicle. The dashboard used in Information T echnology \\nalmost resembles that of an automobile, but is more interactive than an automobile dashboard.\\nSo, what really is a dashboard? A dashboard is a graphical user interface that organizes and presents \\ninformation in a way that is easy to read. It provides at-a-glance insight to what is actually happening in \\nan organization. Dashboards have the following attributes:\\n • They display data relevant to their own objectives.\\n • They throw light on key performance indicators and metrics used to measure and monitor the \\norganization’s performance.\\n • Since dashboards are designed to serve a specific purpose, they inherently contain pre-defined \\nconclusions that help the end-user analyze his or her own performance.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 315}, page_content='9.5.2 Why enterprises need dashboards?\\nFigure 9.12 describes the benefits accruing to enterprises through dashboards.\\nFigure 9.12 Importance of dashboards for enterprises.\\nImproves\\nLeads to\\nimproved\\nBetter\\nCorporate dashboard\\nDecision making Compliance\\nAccountability & transparency\\nacross organisation\\n9.5.3 t ypes of dashboard\\nEnterprise Performance Dashboards\\nThese dashboards provide an overall view of the entire enterprise, rather than of specific business func-\\ntions/process. Typical portlets in an enterprise performance dashboard include:\\n • Corporate financials.\\n • Sales revenue.\\n • Business Unit KPIs (key performance indicators).\\n • Supply chain information.\\n • Compliance or regulatory data.\\n • Balanced scorecard information.\\nFigure  9.13 and 9.14  are samples of enterprise performance dashboards.\\nFigure 9.13 A sample enterprise performance dashboard.\\nBasics of Enterprise Reporting • 291'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 316}, page_content='292 • Fundamentals of Business Analytics\\nCustomer Support Dashboards\\nOrganizations provide this type of dashboard to its customers as a value-add service. A customer sup-\\nport dashboard provides customers their personal account information pertaining to the business rela-\\ntionship, such as\\n • Online trading.\\n • Utility services.\\n • Entertainment.\\n • B2B SLA (business-to-business service-level agreement) monitoring.\\nDivisional Dashboards\\nThese are one of the most popular dashboards used to provide at-a-glance actionable information to \\ndivision heads, operational managers, and department managers. Each division has its own set of KPIs \\nwhich can be visually displayed on the enterprise dashboard. Typical divisional dashboards include:\\n • Purchasing dashboards.\\n • Supply chain dashboards.\\n • Operations dashboards.\\n • Manufacturing dashboards.\\n • Quality control dashboards.\\n • Marketing dashboards.\\nFigure 9.14 Another sample enterprise performance dashboard.\\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 317}, page_content=' • Sales dashboards.\\n • Finance dashboards.\\n • Human resources dashboards.\\n9.6 hoW do You create dashBoards?\\nMost dashboards are created around a set of measures or key performance indicators (KPIs). KPI is an \\nindicator of the performance of a task, and it reveals the performance that is below the normal range so \\nthat corrective action can be taken. It draws attention to problem areas. The measures used in the dash-\\nboard should be relevant and support the initial purpose of the dashboard.\\n9.6.1 steps for creating dashboards\\nFirst Step\\nUnderstand/identify the data that will go into an enterprise dashboard. Enterprise dashboards can con-\\ntain either/both of the following mentioned data:\\n • Quantitative data.\\n • Non-quantitative data.\\nQuantitative data is the data that gives an idea of what is currently going on. Examples of quantitative \\ndata for an Education dashboard:\\n • No. of student batches.\\n • No. of learning programs.\\n • No. of students who have successfully qualified the internal certification.\\n • No. of students being trained on the various learning programs.\\nExamples of non-quantitative data for an Education dashboard:\\n • Salient features of the foundation learning program.\\n • Challenges faced by the instructor in classroom training.\\n • Users comments on the effectiveness of the learning program.\\nSecond Step\\nDecide on the timeframes. The various timeframes could be\\n • This month to date.\\n • This quarter to date.\\n • This year to date.\\n • T oday so far.\\nThird Step\\nDecide on the comparative measures. The comparative measures could be\\n • The same measure at the same point in time in the past.\\n • The same measure at some other point in time in the past.\\nBasics of Enterprise Reporting • 293'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 318}, page_content='294 • Fundamentals of Business Analytics\\n • A distinct yet relative measure.\\n • A competitor’s measure.\\nLast Step\\nDecide on the evaluation mechanisms. The evaluation can be performed as follows:\\n • Using visual objects, e.g. traffic lights.\\n • Using visual attributes, e.g. red color for the measure to alert a serious condition.\\n9.6.2 tips for creating dashboard\\n • Don’t make your dashboard a data repository: Avoid using additional and unwanted data. \\nFocus on the primary goal of dashboard. T oo much data makes the dashboard look cluttered and \\ndilutes the actual information you are trying to present.\\n • Avoid fancy formatting: T o communicate the actual information effectively through your dash-\\nboard, it is very important to present the data as simply as possible. It is important to focus on \\ndata rather than shiny graphics.\\n • Limit each dashboard to one printable page: Dashboards provide at-a-glance views into \\nthe key measures relevant to a particular objective. So, it is important to keep all the data in \\none page. It ensures better comparison between the different sections of the dashboard and \\nprocess the cause and effect relationship more effectively. When the user has to scroll left, \\nright, or down, these benefits are diminished. On the contrary, when dashboards bring all \\nthe information on one page then one glance can give a complete insight into the organiza-\\ntion’s performance. It also helps in identifying the problems where corrective actions are \\nrequired.\\nLet us take one example. All organizations set certain goals that they wish to achieve. They select cer-\\ntain criteria to evaluate their performance. Suppose they want to visually see what their margin percent \\nis and monitor their performance against the defined goals.\\nOne way to visually depict this is by using a gauge where the indicator can clearly indicate if the goal \\nwas achieved or not. If the indicator is green then it must have met the goal, and if it is in red or yellow \\nthen corrective actions have to be taken. Figure 9.15 depicts a sample gauge indicator.\\nFigure 9.15 A sample gauge indicator.\\n44 Units\\n50\\n35\\n0\\nNor mal Warming Critical\\nMargin %\\n60'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 319}, page_content='Dashboards have the following benefits:\\n • They place all critical information in just one screen. One need not flip through different pages \\nto see the desired critical information.\\n • They help in improved decision making.\\n • They help in rapid problem detection.\\n • They help in better analysis of performance.\\n • They identify the trends and corrective actions to improve the organization’s performance.\\nRemind\\u2003Me\\n • Dashboard is a graphical user interface that \\nprovides at-a-glance insight into what is actu-\\nally happening in an organization.\\n • Types of dashboard.\\n\\uf0a7\\t Enterprise dashboard.\\n\\uf0a7\\t Customer support dashboard.\\n\\uf0a7\\t Divisional dashboard.\\n • Steps for creating a dashboard:\\n\\uf0a7\\t Identify the data that will go into an \\n enterprise dashboard.\\n\\uf0a7\\t Decide on the timeframe.\\n\\uf0a7\\t Decide on the comparative measures.\\n\\uf0a7\\t Decide on the evaluation mechanisms.\\n • Benefits of a dashboard:\\n\\uf0a7\\t Better analysis.\\n\\uf0a7\\t Better tracking.\\n\\uf0a7\\t Proactive alerting.\\nPoint\\u2003Me\\u2003(Books)\\n • Information Dashboard Design: The Effective \\nVisual Communication of Data, Stephen Few.\\n • Say It With Charts: The Executive’s Guide to \\n Visual Communication, Gene Zelazny.\\n • en.wikipedia.org/wiki/Dashboard_(business)\\n • www.appsbi.com/what-are-dashboards\\nConnect\\u2003Me\\u2003(Internet\\u2003Resources)\\nBasics of Enterprise Reporting • 295'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 320}, page_content='296 • Fundamentals of Business Analytics\\n9.7 scorecards vs. dashBoards\\nBy now you have a fair understanding of dashboards and scorecards. Can the terms “dashboard” and \\n“scorecard” be used interchangeably? Or is there a difference between the two?\\nBefore we get into the differences, let us look at the commonality between a balanced scorecard and a \\ndashboard. Both are measurement systems, built on integrated data, usually a data warehouse. Both provide \\nBI\\u2003Crossword\\nSolution:\\nDashboard\\n3\\n4\\n12\\nACROSS\\n3. Dashboards eases _____ making.\\n4. One of the chief benefits of\\n    dashboards\\nDOWN\\n1. It helps monitor the performance of an enterprise.\\n2. Dashboard is a collection of powerful _____ elements.\\n1. Scorecard 3. Decision\\n2. Graphical 4. Accountability\\nTest\\u2003Me\\u2003Exercises\\nAnswer me\\n1. What are dashboards?\\n2.  Why do organizations need a dashboard?\\n3.  What are the various attributes of a dash-\\nboard?\\n4.  What is the difference between quantitative \\ndata and non-quantitative data?\\n5. What makes a dashboard good or bad?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 321}, page_content='the organization with an insight/view on business performance.  An ideal scenario is for the organization \\nto measure its performance against its balanced scorecard, then drill down to the data warehouse (has data \\nfrom several operational/transaction processing systems) to detect the possible causes of a problem. T o know \\nthe current operational status of the problem area, you can revert to the dashboard. This was the tracking \\nfrom the balanced scorecard to the dashboard. Let us look at a reverse scenario. We can start with a problem \\nat hand. We view the current operational status of the problem at hand via the dashboard. We then take \\nsome remedial step at the operational level to counter the problem, monitor it through the dashboard, and \\nthen trace it back to the balanced scorecard to view the result of this action at the operational level.\\nA balanced scorecard is a business performance measurement (BPM) used mostly at the senior man-\\nagement level to view the business performance through indicators. It enables senior executives to \\nperform a pulse-check on how the organization is performing in terms of accomplishing its strategic \\nobjectives. In contrast, an enterprise dashboard is equivalent to an automotive dashboard that displays \\nreal time changes in tactical information often displayed as charts, graphs, and gauges. A dashboard is \\na business activity (process) monitoring (BAM) or business process measurement (BPM) used most by \\nthe operational managers to monitor day-to-day operations through visualization.\\n9.7.1 Kpis: on dashboards as well as on scorecards\\nA KPI is a metric that is tied to a target. KPIs usually indicate how far a metric is from its pre-deter-\\nmined target. KPIs are designed to let a business user know at a glance whether results are on target or \\noff target.Balanced scorecards use KPIs almost entirely to measure success in each area of the business \\nas defined in the strategy map. On the other hand, dashboards use KPIs to highlight milestones in \\noperations.\\n9.7.2 indicators: on dashboards as well as on scorecards\\nIndicators, sometimes called icons, are graphical elements that give visual cues about performance. For \\nexample, traffic light symbols can be used as indicators − red to indicate a problem, yellow to indicate \\na potential concern, and green to show that performance is meeting or exceeding its goal.\\nWhat indicators are commonly used in dashboards and scorecards? Dashboards use mostly graphs, \\ngrids, gauges, and a variety of visualization techniques to highlight the operational data. On the other \\nhand, scorecards commonly use symbols and icons.\\nAn example would make it clearer. Let us look at the balanced scorecard of a manager, responsible for \\nthe customer service function of an enterprise. His scorecard might have the following indicators:\\n • Minimum resolution time.\\n • Maximum resolution time.\\n • Percentage of issues resolved at first attempt.\\n • Customer satisfaction survey.\\nAll the above indicators will be considered for a period of time (generally a month or a quarter). \\nThe indicators will also be compared against the pre-defined goals and help analyze the manager’s \\nperformance. The manager’s dashboard might use the following indicators:\\n • Number of inbound calls (the calls customer initiates to the help desk) in queue.\\n • Number of calls in escalation.\\nBasics of Enterprise Reporting • 297'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 322}, page_content='298 • Fundamentals of Business Analytics\\n • Average call resolution time.\\n • Current CSRs (customer service representatives) on-line.\\nBased on the above example, the differences between dashboards and balanced scorecards can be sum-\\nmarized as follows:\\n • Dashboards can provide tactical guidance while scorecards can assess the quality of execution.\\n • Scorecards inherently measure against strategic goals while dashboards present real time \\ninformation.\\nReferring to Wayne Eckerson’s “Performance Dashboards”, the distinction between balanced scorecards \\nand dashboards stated as follows:\\nThe primary difference between the two is that dashboards monitor the performance of operational processes, \\nwhereas scorecards chart the progress of tactical and strategic goals.\\nTable 9.2 points out key differences between dashboards and scorecards. The enterprise dashboard is a \\nuseful weapon in the hands of today’s managers looking to steer their business in the right direction and \\nto always keep it on course. There are operational dashboards designed for operational managers to help \\nthem discharge their day-to-day operational activities with ease. There are strategic dashboards that are \\nused by the C class (CEO, COO, CIO, CFO, etc.) and by business unit heads to assess metrics that \\nrepresent corporate strategy and direction.\\nWhat next after the standard reports and enterprise dashboards. This brings us to the next topic, i.e. \\nanalysis.\\n9.8 the Buzz Behind anal Ysis…\\nWe will discuss three major kinds of analysis here:\\n • Funnel analysis.\\n • Distribution channel analysis.\\n • Performance analysis.\\n9.8.1 funnel analysis\\nLet us look at what is funnel analysis. \\nBusiness use Performance Measure Monitor Operations\\nUsers Senior Executives Operations Manager\\nUsed by Corporate/Unit Corporate/Department\\nData Summary Detail\\nRefresh Monthly/Quarterly/Annual Intra-day\\nFeature Dashboards\\nTable 9.2 Key differences between dashboards and scorecards\\nBalanced Scorecard'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 323}, page_content='picture this…\\nYou are a visitor on a popular website that sells books on-line. You are required to follow a set of steps \\nto buy the book. Let us list down the set of steps…\\n • Visit the website that sells the book.\\n • Search for a particular book.\\n • Add the book to your cart.\\n • Buy the book by making the payment after careful validation, and complete the check-out process.\\n • Input the shipping address so that the book can be successfully shipped.\\nThese are the steps from an end user’s viewpoint, i.e. a visitor to the books’ on-line site. In order to suc-\\ncessfully complete the transaction, you are required to complete each step listed above − from visiting \\nthe website to making the payment and completing the check-out process. This is called the conversion \\nfunnel, shown in Figure 9.16. If you were able to successfully purchase the book, you have been con-\\nverted from a visitor to a customer.\\nNow let us get into the shoes of a website analyst whose job is to analyze and recommend changes to \\nthe site in a way that maximizes the chances of the visitors eventually turning into customers. The web-\\nsite analyst will typically use a funnel mechanism to work out how the website is performing. The funnel \\nanalysis works on a simple philosophy. You work out how much you put in the top, and how much you \\nget out, at the bottom. The more you put in the top, the more you’ll get out, at the bottom.\\nThe website analyst will try to analyze the bottlenecks at each step. He will want to zero down to the \\ncause at every step that may potentially result in a “drop-off”. Once the spots have been identified, next \\nis to fix the same to improve the conversion rate.\\nLet us look at what bottlenecks can possibly occur at each of the steps mentioned above:\\n • The navigation to the home page of the website is difficult. Visitors rarely come in through the \\nhome page although they come in onto different pages of the website in as many different ways.\\n • The visitor doesn’t really have a fascination for the search button on the website and struggles \\nwhile searching for a particular book.\\n • The visitor faces problem in adding the book to the shopping cart.\\nFigure 9.16 The typical funnel of book-selling website.\\nLanding page\\nSearch for the book\\nAdd book to cart\\nPurchase the book by\\nmaking payment\\nFinal checkout\\nDrop-offs can happen\\nat any of the stage\\nBasics of Enterprise Reporting • 299'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 324}, page_content='300 • Fundamentals of Business Analytics\\n • He/she experiences problems while making the payment. Far too many details are asked for and \\nthe payment page times out ever so frequently.\\n • He/she faces difficulty in editing the shipping address once the address has been fed in.\\nSo, what is required to have a good conversion rate?\\n • Easy navigation to pages to allow users to progress through every stage.\\n • The required action should be easy, very obvious, and compelling.\\nThe essence of conversion rate optimization is to get a majority of visitors through the funnel. The focus \\nshould be on fixing the problem at the correct stage. If you are losing more people immediately after the \\nlanding page, it makes little sense to fix the problem somewhere down the line. However, if the drop-off \\nat the landing stage is very small, then the problem is probably on one of the pages down the line.\\nOne question that we must answer is: “Does every website have a conversion funnel, even those that \\ndo not sell anything?” The answer is “Yes”. Assume a services company has a website. The website has a \\nhome page and through the home page, you can navigate to a bunch of other pages. Each page describes \\na particular service offered by the services company. Each page leads to a “contact us” page that details \\nout the steps on “how one can get in touch with the services company”. A successful conversion here \\nwill be when a visitor clicks on a button of the “contact us” form. However, it is not always as easy as \\nit sounds. A vast majority of websites experience a  “drop-off” between each stage in their conversion \\nfunnel. This means that for some reason visitors are failing to progress to the next stage and are not turn-\\ning into customers. Your aim here is to lose as few people at any point in the process as possible.\\nIn conclusion, there are two rules that can be followed:\\nRule 1: Do away with/eliminate unnecessary steps to conversions as they just contribute to increased \\nconversion funnel drop-off rates. The fewer the steps, the more likely a visitor will follow through with \\na conversion.\\nRule 2: Use an effective call-to-action in every step of your path.\\n9.8.2 distribution channel analysis\\nDistribution channels move products and services from businesses to consumers and to other \\n businesses. Distribution channels are also known as marketing channels or channels of distribution. \\nThese consist of a set of interdependent organizations −  such as wholesalers, retailers, and sales \\nagents – involved in making a product or service available for use or consumption.\\npicture this…\\nYou would like to buy a personal computer. You can choose to buy it directly from the manufacturers \\nby placing an order with them either in person or over the telephone (teleshopping) or over email or \\non-line through the Internet (online buying) or through several kinds of retailers including independent \\ncomputer stores, franchised computer stores, and department stores.\\nDistribution channel structures usually range from two to five levels as described below:\\n • A two-level structure is directly from the manufacturer or provider to the consumer, i.e. manu-\\nfacturer → consumer\\n • A three-level structure is: manufacturer → retailer → consumer\\n • A four-level structure is: manufacturer → wholesaler → retailer → consumer\\n • A five-level structure is: manufacturer → manufacturer’s agent → wholesaler →  retailer → \\nconsumer'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 325}, page_content='This brings us to the question, “Is selling directly from the manufacturer to the consumer always the \\nmost efficient?” The answer is “No”. Intermediaries such as wholesalers, retailers, etc. provide several \\nbenefits to both manufacturers and consumers: benefits such as improved efficiency, a better assortment \\nof products, routinization of transactions, and easier searching for goods as well as customers.\\nAnother example from the hospitality domain is as follows: Several customers visit the “GoodFood \\nRestaurant”. Some of these customers have read about the restaurant’s excellent ambience and quality food \\nin newspapers, heard it as advertised over the television, or seen it on hoardings put up at prominent places \\nand therefore have come in. A few others have just walked in to check out the restaurant, all by themselves. \\nA few others came to know of the restaurant through their friends. Yet, a few others have heard it all from \\ntheir colleagues, etc. What we are trying to convey here is that the restaurant attracts all sorts of guests.\\nDistribution channel analysis is the analysis of the various channels to determine which channel is \\nthe most efficient. In the restaurant example, it will be worthwhile to understand whether the word of \\nmouth is fetching them very many customers, or is it their advertisement over television or the hoard-\\nings that is striking gold for them. The investment can then be very intelligently made by the restaurant \\nowners on positioning their brand.\\n9.8.3 performance analysis\\nLet us start off with “why performance analysis?” And, let us try to explain this with an example. Alex \\nwas visiting his cousin, Justin, who had purchased an SUV (super utility vehicle) a couple of months \\nback. Alex was also trying to arrive at a decision on which one should he go for at the end of the quarter \\nwhen his company will award him some bonus. Conversations veered around to the performance of the \\nSUV . Questions such as: “What’s the mileage like?”, “How is it to drive on rough terrains?”, “How \\nmuch of maintenance is required?”, “What is the approximate total cost of ownership?”, etc. were being \\nasked. The answers to these questions helped Alex understand the performance of the vehicle and also \\ndecide on the affordability of the vehicle.\\nPerformance analysis is carried out “to improve a part of the organization/unit/function or to fix a \\nproblem that somebody has put forth”. Performance analysis helps uncover several perspectives of a \\nproblem or opportunity. It helps identify any or all drivers towards (or barriers) successful performance, \\nand propose a solution system based on what is discovered.\\nLet us take another example. In almost every enterprise the world over, an employee is apprised of his/her \\nperformance in the performance review that is usually conducted annually or after every six months. This in \\nturn will help him or her perform better because given the data, the areas of improvement are laid bare. For \\nan organization, the performance analysis could be evaluating the performance indicators such as ROI \\n(Return on Investment), ROA (Return on Assets), Return on Equity, etc. against those of its competi-\\ntors in the domestic or global market.\\nYet another example of performance analysis is an examination of the performance of current employ-\\nees to determine if training can help reduce performance problems such as low output, uneven quality, \\nexcessive waste, etc.\\nLet us further look at the above explained three analyses in the light of a case study here.\\npicture this…\\nA company “Infotech” with a major focus on the retail domain is hiring. The company recruits in large \\nnumbers from the national talent pool of Computer Science (CS) and Non-Computer Science (NCS) \\ngraduate engineers. These recruits have come in through various channels. Some came in through “Walk-in \\ninterviews”, some were “Referrals” (referred to by the employees of the company), some applied “On-line” \\nBasics of Enterprise Reporting • 301'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 326}, page_content='302 • Fundamentals of Business Analytics\\nover the company’s website, some came in through direct “Campus recruitment” (where in the company \\nvisited their college/university), etc. Some of these recruits (CS/NCS) have undergone “Industrial T raining” \\nwith a corporate house while others are raw with no industrial training experience. Offers are made. Of \\nthe selected recruits, some accept the offer and others decline. Those who accept the offer are the prospec-\\ntive candidates and are identified using a “Candidate ID”.  Amongst those who accept the offer, some do \\nnot join the corporate/enterprise. Those who do join are called T rainees/Student T rainees and are on pro-\\nbation, and are put through a customized training program to prepare them for the floor. They are identi-\\nfied using a unique “Employee ID”. No two employees in the organization can have the same “Employee \\nID”. They are also assessed after the training gets over and before their actual life on the shop floor starts. \\nThose who make it through the assessments are released to the shop floor/production/delivery. The \\n“Infotech” company decides to perform some analysis to conclude the following:\\n • How many make it from the recruit stage to the employee stage? (Funnel Analysis)\\n • Which channel of recruitment (“On-line”, “Campus Recruitment”, “Walk-in interviews” or \\n“Referrals”) is the most profitable? (Channel Analysis)\\n • How many CS trainees make it through the training to eventually qualify for the shop floor? \\n(Performance Analysis)\\n • How many NCS trainees make it through the training to eventually qualify for the shop floor? \\n(Performance Analysis)\\n • How many trainees (CS/NCS, irrespective of their background) with an “Industrial T raining” \\nqualification in their kitty eventually qualify for the shop floor? (Performance Analysis)\\n • How many trainees (CS/NCS, irrespective of their background) without an “Industrial T rain-\\ning” qualification in their kitty eventually qualify for the shop floor? (Performance Analysis)\\n • How have the CS graduate engineers fared in their education starting from SSC → HSC/Di-\\nploma →\\tDegree → T raining? (Performance Analysis)\\n • How have the NCS graduate engineers fared in their education starting from SSC → HSC/\\nDiploma →\\tDegree → T raining? (Performance Analysis)\\nWe consider here a data set that is shared in an Excel sheet. The Excel sheet has 3796 rows and 18 col-\\numns of data. You can have a look at the sheet in the accompanying CD. Let us look at what the funnel \\nanalysis reveals:\\nThe funnel analysis as depicted in Figure 9.17 clearly reveals that out of 3796 recruits who have been \\nselected and made the offer, only 2597 accepted the offer and are the prospective candidates. Out of the \\n1. Candidate ID Used to uniquely identify a candidate. A candidate is a recruit \\nwho has accepted the offer made by “Infotech”\\n2. Employee ID Used to uniquely identify an employee. A trainee becomes an \\nemployee upon joining the organization\\n3. First Name First Name of the Employee\\n4. Middle Name Middle Name of the Employee\\n5. Last Name Last Name of the Employee\\n6. DegreePercentage Percentage scored in the Degree Examination\\nS. No. Column Name Column Description\\n(Continued)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 327}, page_content='2597 prospective candidates, only 1811 join the “Infotech” company in the capacity of an employee \\nand undergo a customized training program. Out of the 1811 employee who underwent the training \\nprogram, only 1001 employees qualified and were released to begin life on the shop floor.\\n(Continued)\\n7. 12th/DiplomaPercentage Percentage scored in the 12th Grade or equivalent diploma\\n8. SSCPercentage Percentage scored in SSC\\n9. University Name The name of the university\\n10. Native State The name of his/her native state\\n11. Background(CS/NCS) Computer Science (CS) / Non Computer Science (NCS) \\nbackground\\n12. Industrial T raining Industrial training at the corporate house\\n13. T rainingExam1Percentage Percentage scored in the first training exam\\n14. Exam1Grade Grade secured in the first training exam\\n15. T rainingExam2Percentage Percentage scored in the second training exam\\n16. Exam2Grade Grade secured in the second training exam\\n17. IntoProduction Whether released to production/delivery\\n18. Channel Channels such as ‘Campus Recruitment’, ‘Online’, ‘Referrals’, \\n‘Walk-in Interviews’\\nS. No. Column Name Column Description\\nFigure 9.17 Funnel analysis of employee recruitment by the “Infotech” company.\\nRecruits Candidates Trainees Employees\\n2597\\n1811\\n1001\\n3796\\nBasics of Enterprise Reporting • 303'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 328}, page_content='304 • Fundamentals of Business Analytics\\nLet us now have a quick look at the distribution channel analysis of employee recruitment by the \\n“Infotech” company. The company gets its recruits from four recruitment channels: “Campus recruit-\\nment”, candidates applying “On-line”, “Walk-in interviews”, and “Referrals” (where employees of the \\ncompany refer candidates). In the channel analysis, depicted in Figure 9.18, it is obvious that “Campus \\nRecruitment” fetches the biggest number. There were 1171 recruits through the “Campus Recruit-\\nment” program, 1088 through “Referrals”, 909 applied “On-line”, and only 628 came in through \\n“Walk-in interviews”.\\nNow for the performance analysis:\\nAs indicated by Figure 9.19, out of 515 CS trainees who underwent the training program, 452 were \\nable to successfully qualify for the shop floor, and only 549 out of 1299 NCS trainees qualified the \\ntraining program.\\nFigure 9.18 Channel analysis of employee recruitment by the “Infotech” company.\\nWalk-in Interviews\\nNo. of Participants\\n0 200 600\\n628\\n909\\n1088\\n1171\\n1000 14001200800400\\nOn-line\\nReferral\\nCampus Recruitment\\nChannel of Recruitment\\nFigure 9.19 Performance analysis of “Infotech” recruits (CS/NCS) in the training program.\\nTrainees\\nEmployees\\nNCSCS\\nCS/NCS\\n512452\\n549\\n1299\\n1200\\n1000\\n800\\n600\\n400\\n200\\n0\\n1400No. of Trainees/Employees'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 329}, page_content='As indicated in Figure 9.20, out of 151 trainees with an “Industrial T raining” background, who \\nunderwent the training program, 139 were able to successfully qualify for the shop floor. And, \\nof 1660 trainees without an “Industrial T raining” background, only 862 qualified the training \\nprogram.\\nAs is evident from Figure 9.21, both the CS and NCS groups show a decline from their SSC to HSC/\\nDiploma with the dip being the highest at the Degree level, only to rise during the training once they \\njoin the “Infotech” company.\\nFigure 9.20  Another performance analysis of “Infotech” (Industrial training/not trained) recruits in the \\ntraining program.\\nTrainees\\nEmployees\\nIndustrial\\nTraining\\nTraining\\nNot\\nTrained\\n151 139\\n862\\n1660\\n2000\\n1500\\n1000\\n500\\n0\\nNo. of Trainees/Employees\\nFigure 9.21 Another performance analysis of “Infotech” recruits (CS/NCS).\\nExams\\nSSC\\nAverage Percentage Marks\\n90\\n85\\n80\\n75\\n70\\n65\\n60\\n55\\nHSC/Diploma Degree Training\\nCS NCS\\nBasics of Enterprise Reporting • 305'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 330}, page_content='306 • Fundamentals of Business Analytics\\nRemind\\u2003Me\\n • Scorecards measure performance against stra-\\ntegic goals, whereas dashboards present real \\ntime information using graphical elements.\\n • KPIs are designed to let a business user know \\nat a glance whether results are on target or off \\ntarget.\\n • An indicator gives visual cues about  \\nperformance.\\n • Dashboards mostly use graphs, grids, gauges, \\nand a variety of visualization techniques to high-\\nlight the operational data. On the other hand, \\nscorecards commonly use symbols and icons.\\n • www.klipfolio.com/satellite/dashboards-scorecards\\n • office.microsoft.com/.../what-is-the-difference-between-a-dashboard-and-a-scorecard-\\nHA101772797.aspx - United States\\nConnect\\u2003Me\\u2003(Internet\\u2003Resources)\\nBI\\u2003Crossword\\nScorecard vs. Dashboard\\n3\\n12\\n4\\nACROSS\\n1.  These are graphical elements that give\\n     visual cues about performance.\\n3.  Users of balanced scorecards.\\n4.  _____ is Business Activity\\n     Process Monitoring.\\nDOWN\\n2.  _____ is a Business Performance Measurement.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 331}, page_content='unsolved exercises\\n1. Describe the functions that you think are there in a typical enterprise.\\n2. What is a balanced scorecard? Explain.\\n3. Why do you think companies or business units/functions or individuals should define and \\nmaintain a balanced scorecard?\\n4. Describe the Malcolm Baldrige Performance Excellence Framework.\\n5. “T exas Nameplate Company (TNC)” has won the Malcolm Baldrige award twice. Read more \\nabout the company and describe their focus on quality which led to their winning the award \\ntwice.\\n6. Why is it important for enterprises to go for “enterprise dashboard”? Explain.\\n7. How is a balanced scorecard different from an enterprise dashboard? Explain.\\n8. Is it possible to trace the progress on the operational tasks as depicted by the dashboard to the \\nstrategic objectives as defined by the balanced scorecard? Explain.\\n9. Create a balanced scorecard for a fictitious enterprise. Explain the rationale behind it.\\n10. Who is the balanced scorecard for? Explain your answer.\\n11. Who is the enterprise dashboard for? Explain your answer.\\n12. “The primary difference between the two is that dashboards monitor the performance of operational \\nprocesses whereas scorecards chart the progress of tactical and strategic goals.” Explain giving an example.\\n13. Explain various types of analysis such as “performance analysis”, “channel analysis”, and “funnel \\nanalysis”. Give examples in support of your answer.\\n14. Think of your college/school/university results and cite the different analysis that can be per-\\nformed on your results.\\n15. Why is “measurement, analysis, and knowledge management” so important for an enterprise? \\nGive reasons to support your answer.\\n16. Assume you are the owner of a fast food chain. Give the different ways in which you will pro-\\nmote your fast food outlet. How will you perform the analysis?\\n17. Why is there so much emphasis on “internal processes” for any enterprise? Give reason to justify \\nyour answer.\\n18. Discuss “balanced scorecard as a strategy map”. Giving example in support of your answer.\\n19. Are KPIs plotted on a balanced scorecard? Explain.\\n20. Are KPIs plotted on an enterprise dashboard? Explain.\\n1. Indicators\\n2. Scorecard\\n3. Executives\\n4. Dashboard\\nSolution:\\nBasics of Enterprise Reporting • 307'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 332}, page_content=''),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 333}, page_content='What’s in store?\\nThis chapter focuses on the understanding of Statistics. It will help you understand basic concepts asso-\\nciated with describing data sets and techniques used to visualize data. Further we will look into advanced \\nconcepts like Hypothesis and t-T est along with Correlation Analysis, Regression and ANOVA. \\n10.1 role of statistics in analytics\\nWe have come across several branches of mathematics like arithmetic, algebra, geometry, and so on. \\nStatistics and probability are also the subjects associated with mathematics that come very handy when \\nwe want to understand and analyze “Data”. Let us first study some data-related questions that may or \\nmay not need the concepts associated with statistics to answer and then define these subjects. Look at \\nthe following pairs of questions:\\nBrief Contents\\nRole of Statistics in Analytics\\nData, Data Description and Summarization\\nGetting to Describe Categorical Data\\nGetting to Describe Numerical Data\\nAssociation between Categorical Variables\\nAssociation between Quantitative Variables\\nStatistical T ests\\nPaired and Unpaired Data Sets\\nMatched Pair Groups in Data Sets\\nCommon Statistical T esting Scenarios\\nUnderstanding Hypothesis and t-T est\\nCorrelation Analysis\\nRegression\\nANOVA \\nThe F-T est\\nTime Series Analysis\\nUnderstanding Statistics\\n10'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 334}, page_content='310 • Fundamentals of Business Analytics\\n1. What is your monthly income?\\n2. Do IT programmer get paid more than the accountant?\\n3. How fast can your dog run?\\n4. Do dogs run faster than cats? \\n5. How much rain did Mumbai receive in December 2015?\\n6. Does it rain more in Mumbai than Bangalore?\\n7. What is the probability of rain this Friday?\\n8. What is the probability of train getting delayed over 10 minutes during weekends?\\nSome of these are just one single fact that you can recall/find and answer. But the questions numbered \\n2, 4, 6 have variability; there can be more data points and each of these situations need the application \\nof statistics to answer those questions.\\nThe last two questions need the use of probability concepts to predict the possibility using a large set \\nof data points collected over a period of time.\\nNow let us look at some of the business-related practical scenarios and questions that could be \\nanswered using statistics.\\n1.  You are a doctor trying to develop a cure for Ebola. Currently you are working on a medicine \\nlabeled D-X. You have data from patients to whom medicine D-X was given. You want to de-\\ntermine on the basis of those results whether D-X really cures Ebola. \\n2.  You are the quality manager at a mobile phone factory producing over 10000 pieces each day. \\nYou observe that last T uesday’s assembly batch reported that there were several phone bodies \\nthat were slightly smaller than usual and hence got rejected. You want to find whether anything \\nchanged in the manufacturing line and it is an aberration.\\n3.  You are the social media advertising manager at a product company and you have launched sev-\\neral digital campaigns to promote your product to get over 1000 online customers each week. \\nWhat is the probability of getting such sales?\\n4.  You are the service in-charge of a motorcycle repair shop. Of late, you have seen quite a few \\ncustomers complain about quality of service. You would like to find how many customers are \\nlikely to switch your competitor over the next three months?\\nThe “Numbers” provided by probability will help you make decisions for corrective actions in business. \\nIn the above examples, the drug researcher may need to focus on plan B if the drug D-X is not curing \\nsufficient number of patients. The quality manager may need to schedule repair of machines that are \\ncontributing to the production of defective parts. The service in-charge may want to talk to dissatisfied \\ncustomers immediately to prevent churn. Hence statistics and probability have many applications in \\nanalyzing business data and supporting decision-making.\\nYes, predicting outcome of games, stock movement, etc. are all big time applications of statistics and \\nprobability as well.\\nFor a layman, “statistics” means numerical information expressed in quantitative terms. This infor-\\nmation may relate to objects, processes, business activities, scientific phenomena, or sports. \\nWe can define statistics as science of collecting large number of facts (or real-world observations) and \\nanalyzing with the purpose of summarizing the collection and drawing inferences. \\nWe can define probability as a measure or estimate of the degree of confidence one may have in the \\noccurrence of an event, measured on a scale of impossibility to certainty. It may be defined as the pro-\\nportion of favorable outcomes to the total number of possibilities. '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 335}, page_content='Understanding Statistics • 311\\nThe term statistics sometimes causes confusion and therefore needs explanation. \\nA statistic is just a number. There are two kinds of statistics: (a) summarization or aggregation or \\ndescriptive statistics and (b) probability statistics or inferential statistics. The most important sum-\\nmarization statistics are the total, averages such as the mean and median, the distribution, the range and \\nother measures of variation. Inferential statistics uses descriptive statistics as its input and probability \\ntheory to predict outcomes.\\nDescriptive statistics: It allows one to show, describe or present data in a meaningful way such that \\npatterns might emerge from the data. It can only be used to describe the group that is being studied. \\nIt cannot be generalized to a larger group. In other words, it is just a way to describe our data. \\nExample: \\n1. Measures of central tendency such as mean, median and mode.\\n2. Measures of spread such as range, IQR (inter-quartile range), variance, standard deviation.\\nInferential statistics: Inferential statistics helps to make predictions or inferences about a population \\nbased on the observation or analysis of a sample. However, it will be imperative that the sample be \\nrepresentative.\\nInferential statistics can be used for two purposes: to aid scientific understanding by estimating the \\nprobability that a statement is true or not, and to aid in making sound decisions by estimating which \\nalternative among a range of possibilities is most desirable. \\nIt is important to note that if the raw data sets are of poor quality, probabilistic and statistical \\n manipulation cannot be very useful. Hence decisions based on such erroneous foundations will be \\nflawed. \\nThere are many tools that are used in the field of statistics and probability such as t-test, Z-test, \\nF-test, Histogram, Rank and Percentile calculation, Sampling, Curve fitting, Correlation, Covariance, \\nRegression, Random number generation, ANOVA and so on.\\nNow, let us understand more about data and its variety.\\n10.2 Data, Data Description anD summarization\\nWhen we think about data, we find two fundamental types viz. alphanumeric and numeric. In the fol-\\nlowing sections we will understand concepts relating to these two types of data and possible ways to \\ndescribe them.\\n10.2.1 Getting to Describe “categorical Data”\\nLet us first recall some of the terms associated with data.\\nData – It is a collection of facts that have similar attributes or characteristics. \\n • “Phone number list” is a named collection of, say, mobile phone numbers of your friends.\\n • “Email IDs list” is an example of collection of email IDs of your classmates.\\nMeasure – Data with associated unit of measure (UOM) is typically termed as measure. \\n • “Service hours per month” has a numeric data associated with “time duration”.\\n • “Average product shipment time” is a measure derived out of multiple data points.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 336}, page_content='312 • Fundamentals of Business Analytics\\nMetric – It is a system of measures based on standard UOM with a business context. The term business \\nmetric also refers to the same.\\n • “Product proliferation rate” by region is an example of measuring “what percentage of products \\nwere purchased by customers in different cities belonging to the region”.\\n • “Employee attrition rate” by quarter measures the percentage of employees leaving the company \\nwithin each three-month period.\\nPattern – Pattern in data is a predictable arrangement or feature.\\n • Consumers who receive coupons buy more electronics than consumers without coupons is a \\npattern.\\nA pattern in a statistical model describes variations in data set.\\n • If you were to tabulate the average price of used motorcycles by gathering data about used \\nvehicles like Make-Model, Year of Manufacture, Mileage and Average price and draw a scatter \\nplot, you can determine the suggested market price for any new entry with a different mileage \\n(Figure 10.1).\\nWe have seen data collected being entered in rows and columns, with column indicating a particular \\nfield and row representing each instance of column values. The column entries are called categorical or \\nordinal variables and represent potential groups of occurrences. Numerical variables describe quantita-\\ntive attributes of the data like income, height, age, etc. Numerical variables have unit of measurement. \\nThe data collected for a numerical variable must share a common unit of measurement. \\nOne of the key operations we perform on tables is aggregation or totaling. Aggregation generates \\nfewer rows of summary. For example, if you have a table of monthly OLA cab hiring expenses along \\nwith type of car like Mini, Sedan and Van, you can sum or aggregate the total amount you have spent \\nby the cab type. Here you will have just three rows for each type of cab with the total money you have \\nspent in the month for that category.\\nFigure 10.1  Scatter plot showing the correlation between average price of used motorcycles  \\nand their mileage.\\n0\\n0\\n50 100 150 200\\n2000\\n4000\\n6000\\n8000\\n10000\\n12000\\n14000\\n16000\\n18000Price\\nMiles (000)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 337}, page_content='Understanding Statistics • 313\\nA time series is a sequence of data that records an attribute at different times. The rows of a time series \\ncarry different meaning compared to the examples above. Here we record changing value of the same \\nparameter/variable over a regular time interval called frequency (see Figure 10.2).\\nA bar chart can be used to display the distribution of categorical variables. Here the length of the bar \\nwill be proportional to the count of the category. Figure 10.3 shows a bar graph depicting world leading \\ninvestments in clean energy initiatives. You need to note that the area occupied by each of the bars is \\nproportional to the quantity it is showing. This graph gets cluttered if number of entries are too many. \\nSometimes pie chart is also used for the same purpose. Recent practices do not recommend use of pie \\ncharts. Pie charts should be used when the number of slices can be kept between 3 and 6, otherwise with \\ntoo many slices it can get extremely difficult to read the pie chart. \\nFigure 10.2 Sample time series analysis.\\n7/14/2008 7/14/2009 7/14/2010 7/14/2011 7/14/2012\\nDate\\nReturn\\n–0.2000\\n–0.1500\\n–0.1000\\n–0.0500\\n0.0000\\n0.0500\\n0.1000\\n0.1500\\n0.2000\\nMonthly returns to Microsoft stock—A ugust 2008–July 2015\\nFigure 10.3 Sample bar chart.\\n65.13China\\nGermany\\nJapan\\nItaly\\nUnited Kingdom\\nIndia\\nAustralia\\nSouth Africa\\nBrazil\\nCanada\\nFrance\\nBelgium\\nGreece\\nSpain\\nUnited States\\n20%\\n–37%\\n–27%\\n75%\\n–51%\\n–17%\\n–45%\\n– 40%\\n–32%\\n–23%\\n–34%\\n–11%\\n–179%\\n–68%\\n20563%\\n35.58\\n22.80\\n16.28\\n14.71\\n8.34\\n6.85\\n6.19\\n5.46\\n5.34\\n4.41\\n4.31\\n4.05\\n3.42\\n2.95'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 338}, page_content='314 • Fundamentals of Business Analytics\\nHere are some terms that we need to be familiar with:\\n1.  The Mode of a category is the most common category in the data set or the category with \\nhighest frequency. This will be the longest bar. Sometimes you may have more than one high \\nfrequency category and is termed as multi-model graph.\\n2. Median of the category is the label of the middle data point when the values are sorted.\\n10.2.2 Getting to Describe “numerical Data”\\nWhile handling a large collection of numerical data values, we use three basic methods to describe the \\nnumerical data – percentiles, histograms and box plots. \\nA percentile rank is the percentage of scores that fall below a given score. Median is the 50th \\npercentile, the lower quartile is the 25th percentile and the upper quartile is the 75th percentile. The \\nminimum is the 0th percentile and the maximum is the 100th percentile. The most familiar statistic is \\nthe mean or the average. The average squared deviation from the mean is the variance. \\nT o calculate the percentile rank of n\\n2 in the series n1, n2, n3, n4, n5, n6 use the following formula: \\nPercentile = (Number of data points below the n2 value)/(T otal number of data points) × 100\\nPercentile ranks are not on an equal interval scale.\\nSo far we have seen the different statistics that identify largest, smallest, middle, average and mode \\n(highly repeated values) in a data set. There is another aspect to consider while describing the data set, \\nviz., how far the different data points are spread from the center? Let us examine these concepts.\\nOne measure of spread is the Range. The range is simply the difference between the smallest value \\n(minimum) and the largest value (maximum) in the data. \\n1.  Range is used in manufacturing industries for the statistical quality control of manufactured \\nproducts in large scale like LED bulbs.\\n2.  Range is useful in studying the variations in the prices of mutual funds, shares that are sensitive \\nto price changes that fluctuate from one period to another. \\nThe Inter Quartile Range (IQR) gives information about how the middle 50% of the data are spread. \\nThe interquartile range is the difference between the Q3 and Q1. Hence, IQR = Q3 − Q1. \\nThe difference between a data value and the mean is called the deviation. One way to measure how \\nthe data are spread is to look at how far away each of the values is from the mean. This could be positive \\nor negative value. \\nThe standard deviation is a measure of the average deviation for all of the data points from the \\nmean. As the sum of mean always adds to zero, we will need to use the squared deviations to make \\neach value positive. Standard deviation is a statistic used as a measure of the dispersion or variation in \\na distribution, equal to the square root of the arithmetic mean of the squares of the deviations from \\nthe arithmetic mean. Variance is calculated by taking the differences between each number in the set \\nand the mean, squaring the differences (to make them positive) and dividing the sum of the squares by \\nthe number of values in the set. Hence, the variance is a numerical value used to indicate how widely \\nindividuals in a group vary. If individual observations vary greatly from the group mean, the variance \\nis big; and vice versa.\\nA histogram is a graph that shows the counts in a data set as the heights of the bar that are propor-\\ntional to the areas of the bar distributed on a chosen interval scale. The interval will accommodate all '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 339}, page_content='Understanding Statistics • 315\\n0\\n2\\n4\\n6\\n8\\n10\\n12\\n0-1 1-2 2-3 3-4 4-5 5-6 6-7 7-8 8-9 9-10 10-11\\nNumber of minutes on hold\\nNo. of customers willing to wait\\nCall center hold-time\\nFigure 10.4 Sample histogram.\\nFigure 10.5 Sample Box and Whisker Plot.\\nMedian The other half\\nof the sample\\nOne half\\nof the sample\\nUpper\\nquartile\\nLower\\nquartile\\nMinimum Maximum\\nOne quarter\\nof the sample\\nOne quarter\\nof the sample\\nMiddle half\\nof the sample\\nLargest sample valueSmallest sample value\\n46 81 01 2\\nWhisker\\nBox legth\\ninterquartile\\nWhisker\\npossible values of the numerical variable (Figure 10.4). An outlier is an observation that lies an abnor-\\nmal distance from other values in a random sample from a population.\\nA Boxplot is a way of graphically summarizing groups of numerical data through their quartiles. \\nBoxplots may also have lines extending vertically from the boxes (called whiskers) indicating variability \\noutside the upper and lower quartiles (Figure 10.5). \\nThe extremes at the right and left of the histogram where the bars become short are termed as the \\ntails of the distribution. If one tail stretches out farther than the other, the distribution is Skewed \\n(Figure 10.6).\\nWe may not have the opportunity to analyze the entire set of occurrences all the time. For example, \\ngetting data about all the people in India in the age group of 45−50 years who need vision correction. '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 340}, page_content='316 • Fundamentals of Business Analytics\\nHence we use the following terminology to describe the boundaries of the data set we are using for data \\nanalysis:\\n1.  Population: In every statistical analysis we aim to analyze information about some group of \\nindividuals or things. In statistical language, such a collection is called a population or universe. \\nFor example, we have the population of all cars manufactured by a company in the last 10 years. \\nA population could be finite or infinite, depending on whether the number of elements is finite \\nor infinite. In most situations, the population may be considered infinitely large.  \\n2.  Sample: A finite subset of population is called a sample. The definition of a sample is a small \\npart of a large data set used to represent the whole or to learn something about the whole. An \\nexample of a sample is a small piece of chocolate offered free at a store to get you to buy a box \\nof newly launched chocolate. Another example of a sample is a small quantity of blood that is \\ntaken to test in a lab.  \\n3.  Sampling: Sampling is concerned with the selection of a subset of items from within a statisti-\\ncal population to estimate characteristics of the whole population. \\n10.2.3 association between categorical Variables\\nContingency table provides information about possible relationship between categorical variables. \\nUsed with Chi squared test and concepts of probability (discussed in subsequent sections), contingency \\ntables are applied in various data analysis situations. For example,\\nIn order to discover whether online buyers subscribe to the retailer’s mailing list, a question was posted on \\nthe website and responses collected. The results are shown in the following table:\\nFigure 10.6 Boxplot as a replacement for histogram.\\nHistogram—symmetr ic\\nHistogram—s kewed to the right\\nHistogram—s kewed to the left\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\nMean\\nMedian\\nMedian\\nJoin Mailing List Decline to Join T otal\\nBuy YES  52  12  64\\nNO 343 3720 4063\\nTOTAL 395 3732 4127'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 341}, page_content='Understanding Statistics • 317\\nJoin Mailing List Decline to Join T otal\\nBuy YES 52\\n(81.25%)\\n12\\n(18.75%)\\n64\\n(100%)\\nNO 343\\n(8.44%)\\n3720\\n(91.56%)\\n4063\\n(100%)\\nTOTAL 395\\n(9.57%)\\n3732\\n(90.42%)\\n4127\\nA contingency table is a matrix that displays the frequency distribution of the categorical variables. \\nThey are heavily used in survey research, engineering and scientific research. The term “row percents” \\ndescribes conditional contingency that gives the percentages out of each row total that fall in the vari-\\nous column categories. Similarly, column based contingencies are also computed; this provides a better \\npicture for decision makers.\\nT wo categorical variables are related in the sample if at least two rows noticeably differ in the pattern \\nof row percentages. This is the same as saying that two categorical variables are related in the sample if \\nat least two columns noticeably differ in the pattern of columns percentages.\\n10.2.4 association between Quantitative Variables\\nIn order to study or investigate the possible influence of two numerical variables on each other we use \\nscatter plots. Scatter plots show how much one variable affects another. The relationship between two \\nvariables is called their correlation. For example, we may want to understand if the consumption of \\nFigure 10.7 Sample Scatter plots depicting correlation between variables.\\nCorrelation\\nrelationship\\n No correlationModerate positive\\ncorrelation\\nStrong negative\\nrelationship\\nStrong positive\\ncorrelation\\nModerate negative\\nrelationship'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 342}, page_content='318 • Fundamentals of Business Analytics\\nelectricity in household is related to day temperature? In such situations we use scatter plots. This idea \\nis often times used to explore data for market segmentation. This is also the topic of correlation \\nanalysis.\\nT o describe the association, start with the direction. In this example, colder the winter, the larger \\nwill be the electricity consumption. This pattern has positive direction because the data points tend \\nto concentrate in the lower left and upper right corners. Another property of the association is the \\ncurvature. When the pattern appears like line, it will be linear and if the curve bends the association \\nit will be non-linear. The third property of association is the variation around the pattern. Finally, \\nthe outliers in terms of their numbers and position have an influence on the line that represents the \\ndata pattern.\\nCovariance quantifies the strength of the linear association between two numerical variables. It \\nmeasures the degree to which data points are concentrated along an imaginary diagonal line in the  \\nscatter plot.\\nCorrelation is a more easily interpreted measure of linear association derived from covariance. \\nCorrelation does not have any units and it can reach -1.0 or +1.0 but these extremes are unusual. \\nThe Pearson correlation coefficient ( r) is a very helpful statistical formula that measures the \\nstrength between variables and relationships. In the field of statistics, this formula is often referred to \\nas the Pearson R-test. Here is the formula to compute r  value and the suggested way to interpret the \\nresult:\\n \\nr\\nNx yx y\\nNx xN yy\\n=\\n− ( )( )\\n− ( ) − ( )/uni23A1\\n/uni23A3\\n/uni23A4\\n/uni23A6\\n/uni2211/uni2211/uni2211\\n/uni2211/uni2211/uni2211/uni2211\\n2 2 2 2\\n][  \\nwhere N is number of pairs of scores; xy/uni2211 is the sum of the products of paired scores; x/uni2211 is sum of \\nx scores; y/uni2211 is sum of y scores; x2\\n/uni2211 is sum of squared x scores and y/uni2211\\n2\\nis sum of squared y scores.\\nr value = \\nVery strong positive relationship\\nStrong positive relationship\\nModerate positive relationship\\nWeak positive relationship\\nNo or negligible relationship\\nNo relationship\\n+.70 or higher\\n+.40 to +.69\\n+.30 to +.39\\n+.20 to +.29\\n+. 10 to +.19\\n0\\nHowever, if a scatter plot shows a linear pattern, and the data are found to have a strong correlation, \\nit does not necessarily mean that a cause-and-effect relationship exists between the two variables. A \\ncause-and-effect relationship is one where a change in X causes a change in Y. '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 343}, page_content='Understanding Statistics • 319\\n10.3 statistical tests\\nIn the field of statistics it is usually impossible to collect data from all individuals of interest, that is, the \\nPopulation. The standard approach is to collect data from a subset or sample of the population, but our \\nreal desire is to know the “truth” about the population. Quantities such as means, standard deviations \\nand proportions are important values and are called “Parameters” when we are talking about a popula-\\ntion. Since we usually cannot get data for the whole population, we cannot know the values of the \\nparameters for that population. We can, however, calculate estimates of these quantities for our sample. \\nWhen they are calculated from sample data, these quantities are called “statistics”. A statistic estimates \\na parameter. The field of statistics focused on statistical procedures or tests is called parametric tests. \\n1.  Parametric Statistical tests are based on assumptions that observations are independent, the \\nsample data have a normal distribution and data values in different groups have homogeneous \\nvariances.\\n2.  Non-Parametric Statistical tests focus on statistical methods wherein the data is not required \\nto fit a normal distribution. It uses data that is often ordinal, meaning it does not rely on num-\\nbers, but rather a ranking or order of sorts.\\n10.3.1 paired and unpaired Data sets\\nT wo data sets are “paired” when the following one-to-one relationship exists between values in the two \\ndata sets:\\n1. Each data set has the same number of data points.\\n2. Each data point in one data set is related to one, and only one, data point in the other data set.\\nAn example of paired data would be a before−after treatment test. The researcher might record the \\nmedical parameters of each subject in the study, before and after a treatment is administered. These \\nmeasurements would be paired data, since each “before” measure is related only to the “after” measure \\nfrom the same subject.\\nThis data is described as unpaired or independent when the sets of data arise from separate indi-\\nviduals or paired when it arises from the same individual at different points in time. For example, one \\nclinical trial might involve measuring the blood pressure from one group of patients who were given a \\nmedicine and the blood pressure from another group not given the medicine. This would be unpaired \\ndata. Another clinical trial might record the blood pressure in the same group of patients before and \\nafter giving the medicine. In this case the data is “paired” as it is likely the blood pressure after giving the \\nmedicine will be related to the blood pressure of that patient before the medicine was given.\\n10.3.2 matched pair Groups in Data sets\\nMany times we may need to design samples that use several pairs of subjects that have common attri-\\nbutes or profile. For example, let us say you want to compare the face-to-face and virtual learning effec-\\ntiveness in a class. If one chooses different classes taught by different experts then there could be \\nvariations in lecture style, teaching approach, assessment methods and so on. On the other hand, if we \\npick a class taught by the same expert and pair the students with similar characteristics like learning \\nstyle, gender and typical performance grade and then in each pair randomly assign them to take face-\\nto-face and virtual sessions, we will be able to compare the performance more accurately. Hence the '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 344}, page_content='320 • Fundamentals of Business Analytics\\nfindings of matched pair will be robust. Thus we can define a matched pairs design as a special case of \\na randomized block design. It can be used when the experiment has only two treatment conditions; and \\nsubjects can be grouped into pairs, based on some blocking variable. Then, within each pair, subjects \\nare randomly assigned to different treatments.\\nA proportion refers to the fraction of the total that possesses a certain attribute. For example, sup-\\npose we have a sample of four pets − a bird, a fish, a dog, and a cat. We might ask what proportion has \\nfour legs? Only two pets (the dog and the cat) have four legs. Therefore, the proportion of pets with \\nfour legs is 2/4 or 0.50.\\nWith this background we can learn about the common statistical tests.\\nSelection of appropriate statistical test is very important for analysis of gathered data and its type. \\nSelection of appropriate statistical tests depends on the following two things:\\n1. What kind of data are we dealing with?\\n2. Whether our data follows normal distribution or not?\\nWhat kind of data are we dealing with? \\nMost often the collected data fall in one out of the following four types of data, that is, nominal data, \\nordinal data, interval data, and ratio data. \\n1.  Nominal data is the collection of facts against a single name/categorical entity, for example, say \\nSalary of Managers. Nominal data cannot be ordered or measured but can ONLY be counted. \\nData that consist of only two classes like male/female or owned/rented are called binomial data. \\nThose that consist of more than two classes like tablet/capsule/syrup are known as multinomial \\ndata. Data of these types are usually presented in the form of contingency tables. \\n2.  Ordinal data is also a type of categorical data but in this, categories are ordered logically. These \\ndata can be ranked in order of magnitude. One can say definitely that one measurement is \\nequal to, less than, or greater than another. For example, data on average family spending in \\ndifferent income groups of India such as lower middle class income group, middle class income \\ngroup, higher middle class income group etc.\\n3.  Interval data has a meaningful order and also has the quality that equal intervals between mea-\\nsurements represent equal changes in the quantity of whatever is being measured. For example, \\nroom temperature: Freezing, 5–6°C; cool, 16−22°C; warm, 24–28°C and hot, >29°C. There is \\nnothing called zero in range type of data. \\n4.  Ratio data has all the qualities of interval data plus a natural zero point. For example, ratio of \\nheights, lengths, etc.\\nWhether our data follow the normal distribution or not?\\n1. The data collected may follow normal distribution or different distribution pattern. \\n2.  There are various methods for checking the normal distribution of data including plotting his-\\ntogram, plotting box and whisker plot, plotting Q−Q plot or measuring skewness and kurtosis.\\n10.3.3 common statistical t esting scenarios\\nWhile there could be several forms of data like nominal, ordinal, ratio, and interval data in the samples \\ncollected relating to different experiments, let us first learn about most commonly occurring data forms \\nand methods of statistical analysis associated with these data forms. The following are some of the '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 345}, page_content='Understanding Statistics • 321\\ncommon goals such as description, comparison of two or more groups, measuring association or \\nprediction for using statistical tests.\\n1. Description of one group of observations with nominal data.\\n2. Description of one group of observations with ordinal data.\\n3. Comparison of a group with nominal data with a hypothetical value.\\n4. Comparison of a group with ordinal data with a hypothetical value.\\n5. Comparison of two unpaired groups with nominal data.\\n6. Comparison of two unpaired groups with ordinal data.\\n7. Comparison of two paired groups with ordinal data. \\n8. Comparison of two paired groups with nominal data.\\n9. Comparison of three or more unmatched groups with nominal data.\\n10.  Comparison of there or more unmatched groups of equal or different sample sizes with ordinal \\ndata.\\n11.  Comparison of three or more matched groups of equal or different sample sizes with ordinal \\ndata.\\n12.  Comparison of three or more unmatched groups of equal or different sample sizes with ratio/\\ninterval data with normal distribution.\\n13. Measuring association between two variables with nominal data.\\n14. Measuring association between two variables with ordinal data.\\n15. Prediction from another measured variable with nominal data.\\n16. Prediction from another measured variable with ratio or interval data with normal distribution.\\n17. Prediction with several measured or binomial variables.\\n10.4 unDerstanDinG hypothesis anD t-test\\nHypothesis is a tentative explanation based on observations you have made.  Example: Students in \\nNorth India spend more on movies than students in South India OR adding fertilizer to a plant makes \\nit grow better. \\nThe basic logic of hypothesis testing is to prove or disprove the statistical research question such as \\nthe examples above. By allowing an error of 5% or 1% (termed as alpha values of 0.05 or 0.01) and \\nmaking correct decisions based on statistical principles, the researcher can conclude that the result must \\nbe real if chance alone could produce the same result only 5% or 1% of the time or less.\\nThe following are the major types of statistical hypotheses: \\n1.  H0: Null Hypothesis − It is usually the hypothesis that sample observations result purely based \\non chance. A hypothesis that attempts to nullify the difference between two sample means (by \\nsuggesting that the difference is of no statistical significance) is called a null hypothesis. \\n2.  H1: Alternative Hypothesis − It is the hypothesis that sample observations are influenced by \\nsome non-random cause. \\nNull hypothesis is a more formal statement of your original hypothesis.  It is usually written in the \\nfollowing form:  There is no significant difference between population A and population B. The reason \\nwe write it in this form is to prove a hypothesis false.  In fact, you can never really prove that a hypoth-\\nesis is true.  '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 346}, page_content='322 • Fundamentals of Business Analytics\\nExample: There is no significant difference in spending for movies in North India vs. South \\nIndia OR There is no significant difference in the growth of fertilized plants vs. unfertilized plants.\\n10.4.1 the t-t est\\nWe use this statistical test to compare our sample groups (A and B) and determine if there is a significant \\ndifference between their means. The result of the t-test is a ‘t-value’; this value is then used to determine \\nthe p-value demonstrating probability of hypothesis being true or false in the entire population.\\n10.4.2 the p-Value\\nIt is the probability that ‘t-value’ falls into a certain range.  In other words, this is the value you use to \\ndetermine if the difference between the means in your sample populations is significant.  In general, a \\np-value < 0.05 suggests a significant difference between the means of our sample population and we \\nwould reject our null hypothesis.  A p-value > 0.05 suggests no significant difference between the means \\nof our sample populations and we would not reject our null hypothesis.\\nUnpaired t-test is used when you have independent samples. Paired t-test is used when your samples \\nare related. For example, you collected data (pulse rate) of your subjects before and after they had 3 \\ncups of coffee. \\n10.4.3 z-t est\\nA Z-test is a hypothesis test based on the Z-statistic, which follows the standard normal distribution \\nunder the null hypothesis. The simplest Z-test is the 1-sample Z-test, which tests the mean of a nor-\\nmally distributed population with known variance. For example, the manager of a Gems Candy wants \\nto know whether the mean weight of a batch of candy packs is equal to the target value of 100 gm. From \\nhistorical data, they know that the filling machine has a standard deviation of 5 gm, so they should use \\nthis value as the population standard deviation in a 1-sample Z-test.\\nZ-test for single proportion is used to test a hypothesis on a specific value of the population propor-\\ntion. Statistically speaking, we test the null hypothesis H0: p = p0 against the alternate hypothesis H1: \\np >< p0, where p is the population proportion and p0 is a specific value of the population proportion we \\nwould like to test for acceptance.  Example: If you want to prove that tea and coffee are equally popu-\\nlar in the college campus you require this test. In this example, p 0 = 0.5. Notice that in this particular \\nexample, proportion refers to the proportion of tea drinkers.\\nZ-test for difference of proportions is used to test the hypothesis that two populations have the \\nsame proportion. Example: Suppose one is interested to test if there is any significant difference in the \\nhabit of tea drinking between male and female students in the college campus. In such a situation, \\nZ-test for difference of proportions can be applied. One would have to obtain two independent samples \\nfrom the college campus − one from males and the other from females and determine the proportion \\nof tea drinkers in each sample in order to perform this test. You must know the standard deviation of \\nthe population and your sample size must be above 30 in order for you to be able to use the Z-score. \\nOtherwise, use the t-score.\\nBefore we move further to examine statistical tests associated with more than two groups of data, let \\nus understand the two key concepts of correlation and linear regression in little more detail.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 347}, page_content='Understanding Statistics • 323\\n10.5 correlation analysis\\nCorrelation analysis measures the direction and strength of the relationship between two variables. \\nCorrelation can predict or calculate the value of one variable from the given value of the other variable. \\nThus, correlation is a measure of the degree to which two variables are related. \\nA correlation coefficient is a statistical measure of the degree to which changes to the value of one \\nvariable predict change to the value of another. For instance, if x and y are two variables, then correla-\\ntion would be a linear association between them (a straight line graph) and would help determine the \\nrelationship between the two. The correlation coefficient lies in the range of -1.00 to +1.00 as a positive \\nor negative probability that the members of a data pair relate to each other. It gives an estimate of the \\ndegree of association between two or more variables. Correlation analysis also tests the interdependence \\nof the variables. \\nSome of the types of correlations we could think of include:\\n1. Positive correlation.  \\n2. Negative correlation. \\n3. Simple correlation. \\n4. Multiple correlation. \\n5. Partial correlation.  \\n6. T otal correlation. \\n7. Linear correlation.\\n8. Non-linear correlation.\\nPositive and negative correlation depend on the direction of change of the variables. \\n1.  If two variables tend to move together in the same direction, that is, an increase in the value \\nof one variable is accompanied by an increase in the value of the other variable or a decrease in \\nthe value of one variable is accompanied by a decrease in the value of other variable, then the \\ncorrelation is called direct or positive correlation. Some of the examples could be product price \\nand supply, exercise and weight change, etc. \\n2.  If two variables tend to move together in opposite directions so that decrease in the value \\nof one variable is accompanied by the increase in the value of the other or vice-versa, then \\nthe correlation is said to be inverse or negative correlation, for example, product price and \\ndemand. \\nThe study of the relationship of two variables is called simple correlation. However, in a multiple cor-\\nrelation, researchers study more than two variables simultaneously. An example of multiple correlations \\nwould be the relationship between demand, supply of commodity and price. The study of two variables \\nexcluding one or more variables is called partial correlation. In total correlation, all the variables are taken \\ninto account. If the ratio of change between two variables is uniform, that is, the value of interval of  \\n2 data series is constant, then there exists a linear correlation between them. \\nT o examine whether two random variables are interrelated, you should plot a scatter diagram. '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 348}, page_content='324 • Fundamentals of Business Analytics\\n10.6 reGression\\nRegression To Mean (RTM) is a statistical phenomenon that occurs when repeated measurements are \\nmade on the same subject. It happens because values are observed with random error. By random error \\nwe mean a non-systematic variation in the observed values around a true mean. Systematic error, where \\nthe observed values are consistently biased, is not the cause of RTM. \\nSir Francis Galton introduced the word “regression” in 1877 when studying the relationship between \\nthe heights of fathers and sons. He studied over 100 such pairs and expressed the opinion that short \\nfathers had short sons while tall fathers had tall sons. He also found that the average height of the sons \\nof tall fathers was less than the average height of the tall fathers. Similarly, he also found that the aver-\\nage height of the sons of short fathers was more than the average height of the short fathers. In general, \\nwhen observing repeated measurements in the same subject, relatively high (or relatively low) observa-\\ntions are likely to be followed by less extreme ones nearer the subject’s true mean. Galton referred to the \\ntendency to regression as the “Line of Regression”. The line describing the average relationship between \\ntwo variables is known as the line of regression. Regression analysis, when used for studying more than \\ntwo or three variables at a time, is called as multiple regression. \\nThe primary objective of regression analysis is to provide estimates of the values of the dependent \\nvariables from independent variables. A simple linear regression allows you to determine functional \\ndependency between two sets of numbers. For example, we can use regression to determine the relation \\nbetween cool drink sales and average outside temperature. Since we are talking about functional depen-\\ndency between two sets of variables, we need an independent variable and one dependent variable. In \\nthis example, if change in temperature leads to change in cool drinks sales, then temperature is an inde-\\npendent variable and cool drink sales is a dependent variable. Prediction or estimation is very important \\nin business and science. Using this statistical tool, you can predict the unknown values. Regression \\nanalysis is used in all the fields of statistics, where two or more relative variables have the tendency to go \\nback to the average. It is used to estimate the relationship between two economic variables like income \\nand expenditure. For example, if you know the income, you can predict the probable expenditure. \\nIn regression analysis, given a bunch of points, we find a line that “fits” them the best. For any line \\nyou try, each point has a distance to that line. This is known as your “error”, since the further the point \\nis from the line, the less good your line is at fitting that point. If you add up those errors, you have the \\ntotal error. You are trying to find the line that makes that error as small as possible.\\nCorrelation Regression\\nIt is the relationship between two or more variables \\nand varies with the other in the same or the opposite \\ndirection.\\nIt is a mathematical measure of viewing the average \\nrelationship between two variables. \\nCorrelation identifies the degree of relationship \\nbetween two variables. \\nRegression identifies the cause and effect relationship \\nbetween the variables. \\nThe coefficient of correlation is a relative measure and \\nthe range of relationship lies between −1 and +1. \\nThe regression coefficient is an absolute figure. It helps to \\nfind the value of the dependent variable if we know the \\nvalue of the independent variable. \\nIf the coefficient of correlation is positive, then the two \\nvariables are positive correlated and vice versa. \\nRegression indicates that decrease in one variable is \\nassociated with increase in the other variable. '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 349}, page_content='Understanding Statistics • 325\\nIt turns out that if instead of adding up the errors, you add up the “squared errors”, the math becomes \\nreally more accurate, and given any set of points you can just figure out what that line should be.\\n10.7 anoV a\\nANOVA (Analysis of Variance) analysis method was developed by Ronald Fisher in 1918 and is the \\nextension of the t-test and the Z-test. When you have more than two groups to compare, for example \\nin a drugs trial when you have a high dose, low dose, and a placebo group (so 3 groups), you use \\nANOVA to examine whether there are any differences between the groups. \\nThe one-way analysis of variance (ANOVA) is used to determine whether there are any significant \\ndifferences between the means of three or more independent (unrelated) groups. Specifically, it tests the \\nnull hypothesis:\\n \\nH k01 23: /uni03BC/uni03BC/uni03BC/uni03BC== ==/midhorizellipsis \\nwhere μ = group mean and k = number of groups. If, however, the one-way ANOVA returns a signifi-\\ncant result, we accept the alternative hypothesis (HA), which is that there are at least two group means \\nthat are significantly different from each other.\\nANOVA is based on comparing the variance between the data samples to variation within each \\nparticular sample. If the “between variation” is much larger than the “within variation”, the means of \\ndifferent samples will not be equal. If the “between and within” variations are approximately the same \\nsize, then there will be no significant difference between sample means. \\nThe following are some of the popular types of ANOVA: \\n1. One-way between groups.  \\n2. One-way repeated measures. \\n3. T wo-way between groups.  \\n4. T wo-way repeated measures. \\nSometimes, we will need to understand inter-relationships that have influence and sub-categories. Let us \\nsuppose that the HR department of a company desires to know if occupational stress varies according to \\nage and gender. The variable of interest is therefore occupational stress as measured by a scale. There are two \\nfactors being studied − age and gender. Further suppose that the employees have been classified into three \\ngroups or levels: Age less than 40 years, age between 40 and 55 years and above 55 years. Factor age has \\nthree levels and gender two. In such situations we need to use two-way ANOVA for testing the hypothesis.\\n10.8 the f-test\\nF-test is similar to t-test but useful to compare multiple groups and determine if a group of variables is \\njointly significant. The F-distribution is named after the famous statistician R. A. Fisher.  F is the ratio \\nof two variances. The F-distribution is most commonly used in Analysis of Variance (ANOVA) and the \\nF-test (to determine if two variances are equal).  The F-distribution is the ratio of two chi-square distri-\\nbutions, and hence is right skewed. It has a minimum of 0, but no maximum value (all values are posi-\\ntive).  The peak of the distribution is not far from 0.\\nIn summary, several specialized approaches have been designed to study the relationship among two \\nor more numerical variables and fine-tuned by several renowned statisticians. '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 350}, page_content='326 • Fundamentals of Business Analytics\\nGoal of Statistical T esting Suggested Statistical T est\\nDescription of one group with nominal data Proportion\\nDescription of one group with ordinal data Median, Interquartile range\\nComparison of a group with nominal data with \\na hypothetical value \\nChi-Square test or Binomial test\\nComparison of a group with ordinal data with \\na hypothetical value\\nWilcoxon test – can be used when comparing two related samples \\n(matched samples, or repeated measurements on a single sample) \\nto assess whether their population mean ranks differ.\\nComparison of two unpaired groups with \\nnominal data\\nChi-Square test\\nComparison of two unpaired groups with \\nordinal data\\nMann−Whitney test − The test involves the calculation of a statistic \\ncalled U, whose distribution under the null hypothesis is known.\\nComparison of two paired groups with ordinal \\ndata \\nWilcoxon test \\nComparison of two paired groups with nominal \\ndata\\nMcNemar’s test – This test is applied to 2 × 2 contingency tables \\nto determine whether the row and column marginal frequencies \\nare equal.\\nComparison of there or more unmatched \\ngroups with nominal data\\nChi-Square test\\nComparison of there or more unmatched \\ngroups of equal or different sample sizes with \\nordinal data\\nKrushkal−Wallis test − A significant Kruskal−Wallis test indicates \\nthat at least one sample dominates the other sample.\\nComparison of there or more matched groups \\nof equal or different sample sizes with ordinal \\ndata\\nFriedman test − It is used to detect differences in treatments \\nacross multiple test attempts. The procedure involves ranking \\neach row (or block) together, then considering the values of ranks \\nby columns.\\nComparison of there or more unmatched \\ngroups of equal or different sample sizes with \\nratio/interval data with normal distribution\\nOne-way ANOVA\\nMeasuring association between two variables \\nwith nominal data\\nContingency coefficients\\nMeasuring association between two variables \\nwith ordinal data\\nSpearman correlation − It assesses how well the relationship is \\nbetween two variables that are strictly increasing or decreasing \\nvalues (i.e., monotonic function). If there are no repeated data \\nvalues, a perfect Spearman correlation of +1 or −1 occurs when \\neach of the variables is a perfect monotone function of the other.\\nPrediction from another measured variable with \\nnominal data\\nLogistic regression\\nPrediction from another measured variable with \\nratio or interval data with normal distribution\\nLinear regression\\nPrediction with several measured or binomial \\nvariables\\nMultiple logistic regression\\nTable 10.1 Goal of statistical testing along with suggested statistical test to accomplish the goal\\nTable 10.1 provides the statistical testing approaches (described earlier) and methods. '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 351}, page_content='Understanding Statistics • 327\\nMicrosoft Excel 2013 provides functions to perform the analysis discussed so far and more. Inter-\\nested learners may want to explore these to get deeper understanding of the statistical testing concepts \\nand its applications in real-life scenarios.\\nTill now, this chapter has given you quick overview of the power of statistic in understanding nature \\nof data distribution, their association, comparison and prediction. You may study any of the methods \\nmore deeply by referring to specific approach of statistical testing references. \\n10.9 time series analysis\\nA time series is a sequence of observations that are arranged according to the time of their occurrence. \\nA univariate time series is a sequence of measurements of the same variable collected over time.  Most \\noften, the measurements are made at regular time intervals. The annual yield of wheat and their price \\nper ton, for example, is recorded in agriculture. We have seen daily reports of stock prices, weekly bul-\\nlion rates, and monthly rates of industry unemployment. Meteorology department records wind veloc-\\nity, daily maximum and minimum temperatures, and annual rainfall. Seismographs continuously record \\nearthquakes. ECG and EEG record series of waves of human being for study of potential health ail-\\nments. Governments record and analyze births, deaths, and entry into school, dropouts, and many \\nother facts. Manufacturing industries record defects in batches and analyze data for quality improve-\\nment. An epidemiologist might be interested in the number of typhoid fever cases observed over some \\ntime period. In medicine, blood sugar measurements traced over time could be useful for evaluating \\ndrugs used in treating diabetes. \\nFrom these situations we can conclude that there must be good reasons to record and to analyze the \\ndata of a time series. Among these is the wish to gain a better understanding of the data generating \\nmechanism, the prediction of future values, or the optimal control of a system. The characteristic prop-\\nerty of a time series is the fact that the data are not generated independently, their dispersion varies in \\ntime, they are often governed by a trend and they have cyclic components. The analysis of data that \\nhave been observed at different points in time leads to new and unique problems in statistical model-\\ning and inference. A seasonal effect is a systematic and calendar-related effect. Examples include the \\ndecrease in retail price of white goods, which occurs around December in response to the Christmas \\nperiod or an increase in water consumption in summer due to warmer weather. Seasonal adjustment \\nis the process of estimating and then removing from a time series influences that are systematic and \\ncalendar related.\\nThe basic objective of time series analysis is to determine a model that describes the pattern of the \\ntime series.  Benefits of such a model are:\\n1. T o describe the important features of the time series pattern.\\n2. T o explain how the past affects the future or how two time series interact.\\n3. T o forecast future values of the series.\\nThe time domain analysis approach focuses on modeling some future value of a time series as a para-\\nmetric function of the current and past values. In this scenario, we begin with linear regressions of the \\npresent value of a time series on its own past values and on the past values of other series. A newer \\napproach to the same problem uses additive models. In this method, the observed data are assumed to \\nresult from sums of series, each with a specified time series structure; for example, a series is generated '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 352}, page_content='328 • Fundamentals of Business Analytics\\nas the sum of trend, a seasonal effect, and error. The steps involved in time series analysis could be sum-\\nmarized as description, modeling and prediction.\\nThe frequency domain approach assumes that the primary characteristics of interest in time series \\nanalyses relate to periodic or systematic sinusoidal variations found naturally in most data. These peri-\\nodic variations are often caused by biological, physical, or environmental phenomena such as global \\nwarming due to El Nino effect. \\nIn spectral analysis, the partition of the various kinds of periodic variation in a time series is accom-\\nplished by evaluating separately the variance associated with each periodicity of interest. This variance \\nprofile over frequency is called the power spectrum. \\nThere are two basic types of “time domain” models:\\n1.  Ordinary regression models that use time indices as x-axis variables. These can be helpful for an \\ninitial description of the data and form the basis.\\n2.  Models that relate the present value of a series to past values and past prediction errors − these \\nare called ARIMA models (for Autoregressive Integrated Moving Average) of several simple \\nforecasting methods.\\nR programming language is widely used for time series analysis and interested learners could explore \\nfurther about time series analysis and implementation using R.\\n •  The data set is described as unpaired or in-\\ndependent when the sets of data arise from \\nseparate individuals or paired when it arises \\nfrom the same individual at different points \\nin time.\\n • A proportion refers to the fraction of the total \\nthat possesses a certain attribute. \\n • Nominal data cannot be ordered or measured \\nbut can ONLY be counted. \\n • Ordinal data can be ranked in order of mag-\\nnitude. \\n •  Interval data has a meaningful order and also \\nhas the quality that equal intervals between \\nmeasurements represent equal changes in the \\nquantity of whatever is being measured.\\n • Ratio data has all the qualities of interval data \\nplus a natural zero point. \\n •  Correlation analysis measures the direction \\nand strength of the relationship between two \\nvariables.\\n •  A correlation coefficient is a statistical measure of \\nthe degree to which changes to the value of one \\nvariable predict change to the value of another. \\n • The study of the relationship of two variables \\nis called simple correlation.\\n •  Regression T o Mean (RTM) is a statistical \\nphenomenon that occurs when repeated mea-\\nsurements are made on the same subject. \\n Remind Me'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 353}, page_content='Understanding Statistics • 329\\n •  ANOVA is based on comparing the variance \\nbetween the data samples to variation within \\neach particular sample. \\n •  A time series is a sequence of observations \\nthat are arranged according to the time of \\ntheir occurrence. \\n •  Descriptive statistics allows one to show, de-\\nscribe or present data in a meaningful way \\nsuch that patterns might emerge from the \\ndata. \\n •  Inferential Statistics help to make predictions \\nor inferences about a population based on the \\nobservation or analysis of a sample. \\n •  Variance is calculated by taking the differ-\\nences between each number in the set and the \\nmean, squaring the differences (to make them \\npositive) and dividing the sum of the squares \\nby the number of values in the set. \\n •  Standard Deviation is a statistic used as a \\nmeasure of the dispersion or variation in a \\ndistribution, equal to the square root of the \\narithmetic mean of the squares of the devia-\\ntions from the arithmetic mean.\\n •  When the pattern appears like line, it will be \\nlinear and if the curve bends the association it \\nwill be non-linear. \\n • First Course in Probability by Sheldon Ross\\n • Discovering Statistics using R by Andy Field\\n • An Introduction to Probability Theory and \\nIts Applications by William Feller\\n • A course in Probability Theory by Kai Lai \\nChung\\n Point Me (Books)\\n Connect Me (Internet Resources)\\n • https://www.coursera.org/course/stats1\\n • http://online.stanford.edu/course/statistical-\\nlearning-winter-2014\\n • http://www.springer.com/us/book/9781461\\n443421?token=prtst0416p'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 354}, page_content='330 • Fundamentals of Business Analytics\\nFill in the blanks\\n(a)  A ____________ is a statistical measure of \\nthe degree to which changes to the value of \\none variable predict change to the value of \\nanother. \\n(b)   ____________ quantifies the strength of \\nthe linear association between two numeri-\\ncal variables. \\n(c)   In order to study or investigate the possible \\ninfluence of two numerical variables on each \\nother we use ____________.\\n(d)  The interquartile range is the diffe-\\nrence between the ____________ and \\n____________. \\n(e)  A ____________ time series is a sequence \\nof measurements of the same variable col-\\nlected over time. \\n(f)  ____________ programming language is \\nwidely used for time series analysis.\\n(g)  The study of two variables excluding one or \\nmore variables is called ____________ cor-\\nrelation. \\n(h)  ____________ is a system of measures \\nbased on standard UOM with a business \\ncontext. \\n(i)  ____________ in data is a predictable \\narrangement or feature.\\n(j)  ____________ provides information about \\npossible relationship between categorical \\nvariables. \\n(k)  ANOVA (Analysis of Variance) analy-\\nsis method was developed by Ronald \\nFisher in 1918 and is the extension of the \\n____________ and the ____________.\\nSolution:\\n(a) Correlation Coefficient\\n(b) Covariance\\n(c) Scatter plot\\n(d) Q3 and Q1\\n(e) Univariate\\n(f) R\\n(g) Partial \\n(h) Metric\\n(i) Pattern\\n(j) Contingency table\\n(k) t-test, Z-test\\nTest Me Exercises'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 355}, page_content='What’s in store?\\nThis chapter deals with the application of analytics and looks at the application of analytics in business \\nfunctions like HR, Sales, Marketing as well as T elecom, Retail and Healthcare. The chapter concludes \\nwith the Anatomy of Social Media Analytics and the Anatomy of Recommendation Systems.\\n11.1 application of analytics\\nWe have defined analytics as the computational field of examining raw data with the purpose of finding \\nnew insights, drawing conclusions and communicating inferences to support business decisions and \\nactions. Analytics relies on the simultaneous application of statistics, operations research, programming \\nand mathematical modeling techniques to quantify observations. It is evident that, to build analytical \\napplications for businesses, you need to have different competencies. Let us first understand how \\ndifferent industries harness the power of analytics for business benefits. Then, we will look into common \\napproaches used to build analytical applications. This will provide us with clues about common \\nBrief Contents\\nApplication of Analytics\\nAnalytics in Business Support Functions\\nHuman Capital Analytics\\nIT Analytics\\nSales & Marketing Analytics\\nAnalytics in Industries\\nAnalytics in T elecom\\nAnalytics in Retail\\nAnalytics in Healthcare (Hospitals or \\nHealthcare Providers)\\nAnalytical applications development\\nWidely Used applications of analytics\\nAnatomy of Social Media Analytics\\nAnatomy of Recommendation Systems\\nApplication of Analytics\\n11'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 356}, page_content='332 • Fundamentals of Business Analytics\\nalgorithms that form the core of such analytical applications. Finally, with this background we will delve \\ndeep into some of the algorithms. We will not cover how these algorithms can be implemented in a \\nlanguage like R. We will only point to resources that can help to get to that level. This structured \\napproach of starting from big picture of business application, then moving to identification of common \\nalgorithms and understanding the details of the algorithm will provide you good foundation to start \\nyour analytics journey.\\nFirst, let us look at how analytics is used in businesses from different perspectives.\\n1.  How can analytics help decision making in business support or business enabling functions like \\nHR, Finance, IT , Procurement, Marketing, etc.?\\n2.  What are the common areas of analytics deployment in different industries like Retail, Health-\\ncare, Banking, Insurance, T elecom, etc.?\\n3.  How analytics provides competitive advantage in business functions by focusing on customer \\nfacing functions like: \\n o Understanding customer or market segment.\\n o Customizing products/services to customers and market segments.\\n o Continuously listening to customer wants and needs.\\n4. Learn how social media analytics and recommendation systems are built.\\n11.1.1 analytics in Business support functions\\n1.  Human Capital Analytics: Every enterprise will have strategic and secure information about \\ntheir human capital, that is, employees. The internal data sources may range from employee \\nprofiles, compensation and benefits, employee performance, employee productivity and so \\non, stored in variety of technologies like ERP systems, OLTP RDBMS, Hadoop ecosystem, \\nspread-marts, data-marts and data warehouses. Some of the external data sources may include \\ncompensation benchmarks, employee sentiments, thought leadership contributions, etc. \\nEnterprises have started gaining benefits from the following areas by deployment of analytics:\\n o  Workforce planning analytics to acquire talent at the right time for right positions. Human \\ncapital investment analysis will lead to identification of positions that drive business results \\nand critical competencies needed for those positions. Dow Chemical developed a custom \\nmodeling tool that predicts future hiring needs for each business unit and can adjust its \\npredictions based on industry trends. (Acquisition)\\n o  Workforce talent development analytics aligned to business goals. (Development)\\n o  Workforce sentiment analytics for enhancing employee engagement. (Ability to simulate \\nbusiness impact of employee attrition) (Engagement)\\n o  Workforce utilization analytics to ensure optimized deployment of right talent in right \\nfunctions. This helps to connect employee performance to business results. (Optimization) \\nRetail companies can use analytics to predict incoming call-center volume and release hourly \\nemployees early if it is expected to drop. \\n o  Workforce compensation analytics helps to optimize benefits using big data sources \\nincluding performance and benchmarks. (Pay)\\n o  Compliance analytics helps to detect any anomalies relating to enterprise compliance \\npolicies and initiate proactive corrective actions. (Compliance)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 357}, page_content='Application of Analytics • 333\\n2.  IT Analytics: All enterprises use IT as business enabler. Enterprises invest in a variety of IT \\nresources like data networks, servers, data center/cloud services, software licenses, maintenance \\nof software, end user support and many productivity tools. IT operations of enterprises are \\nbecoming complex due to multiple technology platforms, outsourcing partners, complex de-\\nmands of users and geographic spread of operations. Investing in right IT resources for business \\nresults is certainly a strategic decision. \\n o  IT infrastructure analytics provide the insight into the health (availability and performance) \\nof IT infrastructure. Service desks can prevent major outages by using predictive analytics.\\n o  Data network and storage utilization analytics will lead to optimization of servers and \\nbandwidth.\\n o  Security analytics can provide vital clues about potential information security threats and \\nalert teams.\\n o  Service quality analytics will provide insights into root causes of SLA deviations and trigger \\nprocess improvement initiatives.\\n o  IT assets analytics supports optimal investment forecasts.\\n o  IT policy compliance analytics can report policy enforcement deviations and trigger \\ncorrective actions.\\n3.  Sales and Marketing Analytics: All enterprises leverage IT for many marketing activities. \\nIn its most basic form, marketing managers study reports relating to the customer segments, \\nrevenue share, revenue mix, marketing expenses trend, sales pipeline, marketing campaign per-\\nformance and so on. Many enterprises use business intelligence solutions to slice-dice customer \\ndata, understand buyer behavior in various market segments and generate alerts against preset \\nthresholds. In the world of analytics, these are termed as ‘Descriptive Analytics’. Managers are \\naware of what has happened and what is happening in the businesses. Analytics allows enter-\\nprises to move three steps further. First, ‘Exploratory Analytics’ allows knowledge workers to \\nfind new business opportunities by discovering hidden data patterns. Second, mature organiza-\\ntions use ‘Predictive Analytics’ to influence the future business. Finally, enterprises embark \\non ‘Prescriptive Analytics’ to use the power of ‘Algorithms, Machine learning and Artificial \\nintelligence’ techniques to make routine decisions almost instantaneous, thereby reducing the \\ndecision cycle times dramatically. Let us look at some of the common applications of analytics \\nin sales and marketing functions of an enterprise. \\n o  Customer behavior analytics: Customer behavior data, which tells decision makers what \\nthe customer does and where he/she chooses to do it, sits in multiple transaction systems \\nacross the company. Customer attitudinal data, which tells decision makers why a customer \\nbehaves in a certain manner or how he/she feels about a product, comes from surveys, social \\nmedia, call center reports and so on. Using analytics to mine new patterns, conduct proof of \\nconcept analytics to find areas of business impact, develop predictive analytics solutions are \\nsome of the application areas.\\n o  Customer segmentation: This application allows enterprises to define newer and sizable \\ngroups of target prospects using analytics. This enables enterprises to customize products \\nand services to new segments and position them for competitive advantage. Segmentation \\ncan be more strategic, such as behavior-based profiling, predictive modeling, or customer-\\nstate and event-based segmentation. '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 358}, page_content='334 • Fundamentals of Business Analytics\\n o  Modeling for pricing automation: Deeper machine learning applications may fall in areas \\nsuch as price elasticity modeling, channel affinity modeling, influence group link modeling \\nand customer life event modeling.\\n o  Recommendation systems: Next best offer models can leverage many data sources and \\nbehavior of similar buyers to predict next best product or service your customer will look for \\nand proactively recommend the perfect fit solution.\\nIn the above examples we have considered examples of application of analytics for decision support in \\ncommon enterprise functions like HR, Marketing and IT . Here are some of the important points to \\nremember:\\n1.  Data for analytics can be taken from many sources including OLTP data, data marts, data \\nwarehouses, big data sources and even data streams.\\n2.  Analytics could be performed with the goal of Discovery, Exploration, Prediction or \\nPrescription. Different visualization techniques will help decision makers interpret the results \\nand initiate actions.\\n3.  Analytics will need different types of tools for data transformation, exploration, modeling and \\nvisualization.\\n4.  Knowledge of statistics, data mining, and business intelligence are some of the key skills \\nneeded to develop analytical applications. It is imperative that you have good functional \\nknowledge of HR or Sales or Marketing or IT before you can design and develop the analytics. \\nNext let us understand application of analytics in different industries. It is also important to note that \\ndevelopment of analytical applications will need hands-on experience in programming language, devel-\\nopment methodology, concepts relating to architecture, security, user experience design and application \\nperformance requirements.\\n11.2 analytics in industries\\nIn this section let us look at how different industries apply analytics for business benefits. One needs \\nto have some understanding of industry domain basics, trends, common current challenges in order to \\ndevelop industry specific analytics solutions.\\n11.2.1 analytics in t elecom\\nIn the telecom industry, people and devices generate data 24 × 7, globally. Whether we are speaking \\nwith our friends, browsing a website, streaming a video, playing the latest game with friends, or mak-\\ning in-app purchases, user activity generates data about our needs, preferences, spending, complaints \\nand so on. T raditionally, communication service providers (CSPs) have leveraged this tsunami of data \\nthey generate to make decisions in areas of improving financial performance, increasing operational \\nefficiency or managing subscriber relationship. They have adopted advanced reporting and BI tools to \\nbring facts and trends to decision makers. We have chosen some examples of strategic focus areas for \\ndeploying analytics, but this is not an exhaustive coverage of all possible areas of application of analytics. \\nLet us look at the role of analytics in CSP business:'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 359}, page_content='Application of Analytics • 335\\nOperational Analytics\\n1.  Network Performance: CSPs need to understand the bottlenecks in the network performance \\nand optimize network utilization. They can use analytics to model capacity plans needed to \\nmeet service levels.\\n2.  Service Analytics: This domain deals with analysis of customer problems, speed of resolution \\nand identification of priority customers and ensures their satisfaction. Advanced analytics will \\ndeliver customer sentiment through social media analysis.\\n3.  Regulatory Analytics: CSPs collaborate with other carriers and partners to support roaming, \\nsharing infrastructure, etc. They need to track regulatory compliance as per agreed contract \\nnorms and handle deviations through anomalies detection. \\n4.  Product Analysis: It involves analysis of data to enhance revenue, launch promotions, create \\ncampaigns, create new segments, strategize pricing and study churn.\\nSubscriber Analytics\\n1.  Subscriber Acquisition: CSPs study customer behavior to identify the most suitable channels \\nand sales strategy for each product. \\n2.  Fraud Detection: Analytics helps to detect billing and device theft, cloned SIMs and related \\nfrauds as well as misuse of credentials.\\n3.  Churn Analytics: This helps CSPs to not only model the loyalty programs but also predict \\nchurn and destination CSP .\\n4.  Value Segment Prediction: Here CSPs will be able to enhance revenue by defining new \\nsubscriber base ahead of competition by matching their profitable offerings to subscribers \\nneeding them.\\nFinancial Analytics\\n1.  Infrastructure Analytics: CSPs study CAPEX and optimize investments in infrastructure and \\nsave money by considering utilization options.\\n2.  Product Portfolio Analytics: This area provides information into the profitable products and \\nservices and helps to exit from loss making products.\\n3.  Channel Analytics: Helps CSPs to optimize the commercial terms with partners to optimize \\ndistributor margins.\\n4.  Cost Reduction: This area focuses on reducing service management cost, operations cost, \\ncompliance risks related cost, etc.\\n11.2.2 analytics in retail\\nOnly some industries have greater access to data around consumers, products they buy and use, and \\ndifferent channels that sell and service products − and the lucky vertical is retail industry. Data coupled \\nwith insights are at the heart of what drives the retail business. \\nT echnologies like Point of Sale (PoS), CRM, SCM, Big Data, Mobility and Social Media offer a \\nmeans to understand shoppers via numerous digital touch points ranging from their online purchases, \\nto their presence on social networks, to their visits to brick and mortar stores as well as tweets, images, \\nvideo, and more. Even today retailers are grappling with how to meaningfully leverage and ultimately '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 360}, page_content='336 • Fundamentals of Business Analytics\\nmonetize the hidden insights around huge amounts of structured and unstructured data about a \\nconsumer.\\nValue of analytics can come from three sources:\\n1. Gaining insight to improve processes and resource optimization.\\n2. Personalizing and localizing offers. \\n3. Creating community for branding and customer engagement. \\nGaining insight to improve processes and resource optimization\\n1.  Supply Chain Analytics: Every retailer needs to optimize the vendors of products, its cost and \\nquality. They need to constantly track the performance of supply chain and initiate proactive \\nactions for competitive advantage.\\n2.  Pricing Analytics: Helps retailers to optimize the product pricing, special offers, merchandizing, \\nloyalty programs and campaigns that attract maximum number of consumers both from \\nphysical store and online store perspective.\\n3.  Buying Experience Analytics: Retails can gain insight into the path taken to purchase, com-\\nplaints registered, help provided by store personnel, store layout/item search time, product \\ndetails availability, pricing, etc. and enhance the buying experience and train personnel for \\nenhancing consumer loyalty.\\nPersonalizing and localizing offers\\n1.  Inventory Analytics: Retailers aim to fulfill consumer demand by optimizing stocks and ability \\nto replenish when consumer demand increases due to seasonal effects or as a result of powerful \\ncampaigns. This area of analytics will alert store managers about the potential need for stocking \\nhighly moving items and reduce slow moving items.\\n2.  Consumer Analytics: Every region around the world has people with different taste for goods \\nand service levels. The purpose of consumer analytics is to equip store managers with insights \\nto customize their products and services to the local consumer profile.\\n3.  Campaign Analytics: All retailers will have digital marketing programs to entice consumers \\nwith value offers. Retails invest in this area of analytics to design most effective campaigns that \\nconvert maximum number of consumers into buyers.\\n4.  Fraud Detection: All retailers strive to eliminate fraud relating to payments, shipping, and \\nchange of price tags and so on. Analytics can study transactions in real-time to detect fraud and \\nalert store personnel or online commerce teams.\\nCreating community for branding and customer engagement\\n1.  Web Analytics: Here the different perspectives of each consumer’s online behavior such as \\nsurfacing traffic, visitor and conversion trends, location of smart devices, access to kiosks will be \\nanalyzed to recommend the best sales approach in response to each of the customer’s real-time \\nactions. \\n2.  Market Basket Analytics: The promotion, price, offer, and loyalty dimension of shopping be-\\nhaviors will be used to understand sales patterns, customer preferences, and buying patterns to \\ncreate targeted and profitable product promotions, customer offers and shelf arrangements. \\n3.  Social Media Analytics: Listening and learning from the social community dimension of \\neach consumer’s online behavior is the scope of this area of analytics. Here store taps into '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 361}, page_content='Application of Analytics • 337\\ncustomer-generated content with sentiment and behavioral analysis to answer key merchan-\\ndise, service, and marketing strategy questions.\\n4.  Consumer Behavioral Analytics: The focus area is consumer preferences such as channels, \\ncategories, brands, and product attributes; return and exchange patterns; usage level of service \\nprograms; and participation in loyalty programs.\\n11.2.3 analytics in healthcare (hospitals or healthcare providers)\\nHealthcare is a very complex eco-system of multiple industries interconnected to achieve the health-\\ncare goals of a country. These entities include healthcare providers, physicians, insurance companies, \\npharmaceutical companies, laboratories, healthcare volunteers, regulatory bodies, retail medicine dis-\\ntributors and so on centered on a patient. You can imagine the complexity, variety, volume, velocity \\nof data that gets generated in each of these independent enterprises and multitude of interconnected \\nheterogeneous IT applications. Analytics is applicable for all these enterprises, viz. insurance companies, \\npharmaceutical manufacturers, hospitals, etc. Here we will focus on how hospitals, that is, healthcare \\nproviders, can leverage analytics for goals like:\\n1.  Hospital Management Analytics: It focuses on cost reduction, enhancing quality of care, \\nimproving patient satisfaction, improving outcomes (performance of diagnosis, testing and \\ntreatment), providing secure access to patient data (Electronic Health Records – EHR). \\nAnalytics in this area can support fact-based decisions in areas of reduction of medical errors, \\nmanage diseases, understand physician performance and retain patients.\\n2.  Compliance Analytics: Provide healthcare compliance metrics to regulatory authorities and \\nbenchmark against world-class hospitals using Baldridge criteria. Improvement in widespread \\nuse of digital data will support audits, analytics and improve hospital processes needed for \\nregulatory compliance.\\n3.  Financial Analytics: This area of analytics will lead to enhance RoI (Return on Investment), \\nimproved utilization of hospital infrastructure and human resources, optimize capital \\nmanagement, optimize supply chain and reduce fraud. \\n4.  Predictive Models: They can help healthcare professionals go beyond traditional search and \\nanalysis of unstructured data by applying predictive root cause analysis, natural language and \\nbuilt-in medical terminology support to identify trends and patterns to achieve clinical and \\noperational insights. Healthcare predictive analytics can help healthcare organizations get to \\nknow their patients better, so that they can understand their individual patient’s needs, while \\ndelivering quality, cost-effective life-saving services. \\n5.  Social Analytic: It can help hospitals listen to patient sentiments, requirements, affordability, \\nand insurance to model care and wellness programs customizing services by localization of \\nneeds.\\n6.  Clinical Analytics: A number of other critical clinical situations can be detected by analytics \\napplied to EHR such as: \\n o Detecting postoperative complications. \\n o Predicting 30-day risk of readmission. \\n o Risk-adjusting hospital mortality rates. \\n o Detecting potential delays in diagnosis.\\n o Predicting out of intensive care unit death. '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 362}, page_content='338 • Fundamentals of Business Analytics\\n11.2.4 analytical application development\\nBefore we dive deep to understand some of the common applications of analytics in businesses, it \\nis important to know the development methodology. Here we are trying to summarize the design, \\ndevelopment and deployment steps in their simplified form.\\nStage 1: Defining the problem. After this step you should be able to explain − what business question(s) \\nare you trying to answer? Once you understand this, you need to think about what data is available to \\nyou to answer the question: \\n1. Is the data directly related to the question?  \\n2. Is the data you need even available within the enterprise or elsewhere? \\n3.  What measure of accuracy and granularity are you going to use? Is that level of summaries good \\nenough for the business users? \\n4.  What criteria are you going to use to determine success or failure? Determine, up front, how \\nyou are going to measure the results. \\nStage 2: Setting-up technical environment and processing the data. Collect the data and perform \\nbasic data quality checks to ensure accuracy and consistency. While this may end up taking the most \\ntime, it is critical and erroneous data will create erroneous results. You may need to transform the data \\nto make it conducive for analysis.  You will need to pick the analytics approach and possible choice of \\nalgorithms and visualization requirements. \\nStage 3: Running the initial analysis or model. You may like to split the data set into a test data set \\nand a validation data set. This is also the step whereby you will choose the method or methods by which \\nyou want to build the model and process the data. As you become more familiar with predictive \\nmodeling and with your own data, you will find that certain types of problems align with certain types \\nof modeling approaches or algorithms. \\nStage 4: Evaluate the initial results. Are the results in line with what you were expecting to see? Are \\nyou able to interpret the results? Do they answer the business question you are trying to answer? If the \\nanswer is yes, then move on to the next step. If the answer is no, then consider the following: \\n1. T ry using different algorithms/models. \\n2. Consider collecting more or different data. \\n3.  Consider redefining or reframing the problem, changing the question and the means to an \\nanswer as you  better understand your data and your environment. \\nStage 5: Select the final model. You may want to try a number of different models and then when you \\nare satisfied with the results, choose the best one. Run the selected model or analysis and re-examine the \\nresults. \\nStage 6: T est the final model. It is important to test the final model and the only way to do so is to take \\nthe selected model and run it against the validation data set and assess the results. Do not tweak or \\nchange the model in any way at this stage, as it will invalidate any comparison to the initial results.  \\nIf the results are similar and you are satisfied with them you can move on to the final stage. If you are \\nnot, then go back (to stage 3) to reassessing the model and the data, make any necessary or desired \\nchanges and try re-running the model again. \\nStep 7: Apply the model and validate by usage. There could be some data exceptions that the analysis \\nmodel may not handle. You may need to keep checking for impact of such data on results and '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 363}, page_content='Application of Analytics • 339\\nvisualization. You may consider adding incremental features and newer visualizations once the analytical \\nmodel is stable and provides consistent results for decision-making.\\n11.3 Widely used application of analytics \\nAfter looking at some of the applications of analytics that are common to many industries and \\napplications specific to industries, we are now in a position to find some general patterns of application. \\nWe will use examples of some powerful application areas of analytics and then understand “How these \\nare built?”, “What are the components of such application?”, and “What algorithms are used to develop \\nsuch applications?” We have provided detailed explanation of the algorithms used in these types of \\nanalytical applications in the data mining section. The only step remaining will be to understand how \\nthese algorithms are coded in language like R.\\nFrom the previous sections it is clear that most industries tend to look at applying analytics in areas of:\\n1.  Processing social media data for business benefits – T elecom CSPs stand to understand the \\nvoice-of-the subscribers; HR will understand the sentiment of employees and partners; hospitals \\ndiscover unmet needs of patients; IT function will understand the business user challenges and \\nservice level expectations. Hence we will take-up Social Media Analytics for diving deeper. \\nWeb analytics or digital analytics is another area that is leveraged by product and services \\nenterprises.\\n2.  All product and service enterprises would be striving to acquire new customers without any \\nexception. Each one would like to customize and personalize offers so that prospects see \\nvalue and make a buying decision. One of the most common approaches enterprises take is \\nthe recommendation system or engine to predict the most potential buyers. So we will see \\nwhat is inside a recommendation engine. This common analytics paradigm is being used to \\nrecommend books, gift items for various occasions, doctors in a local area, household items for \\nonline purchase − the list is endless.\\n11.3.1 anatomy of social Media analytics\\nT oday, there are over 2 billion social media users. The major social networking platforms include:\\n1. Nearly 50% of Internet users are on Facebook.\\n2. Over 500 million tweets are sent each day.\\n3. The +1 button on Google Plus is hit 5 billion times each day.\\n4. 70 million photos and videos are exchanged in Instagram.\\n5. There are 39 million recent college graduates on LinkedIn.\\n6. 600 million Skype calls are active each day.\\n7. Similar number of users are on WhatsApp.\\nWe can define social media as the technology-enabled interactions among peer-to-peer, employees-and-\\ncustomers as well as among employees. T oday, businesses use social media for achieving business goals \\nlike:\\n1. Deploying a contest to make robust consumer engagement. \\n2. Launching campaigns that are targeted to specific target segments.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 364}, page_content='340 • Fundamentals of Business Analytics\\n3. Providing customers with a wide range of products, offers, and initiatives via social media.\\n4. Recommending “e-commerce offers” to promote the online purchase.\\n5. Alerting customers about events they look forward to.\\n6. Managing risk and fraud by creating awareness.\\n7. Creating dedicated forums with topic to enable followers joining live discussions.\\nSocial media has given business results like increased customer acquisition, increased cross-sell, enhanced \\nbrand image, accurately capture market requirements and reduced cost to serve or sell. The actions \\ninitiated by decision makers using social media analytics could be learning from consumers, reacting \\nto consumer sentiments/feedback, supporting consumer ideas, driving product or service messages and \\nserving multiple communities with specific profiles.\\nUsing techniques like opinion mining, text mining, audio analytics, sentiment analysis, and \\npredictive analytics allows you to look at historical patterns and make predictions about future behavior \\nfor specific individuals. By taking customer data that you hold internally and adding what people have \\nsaid and done, you can predict what your customers are likely to do in similar set-ups.\\nFigure 11.1 shows a typical process for designing and developing social media analytics application. \\nSome questions that would come to our minds include:\\n1. How to identify data sources that directly relate to business goals?\\n2. How to get social media data from the applications introduced above?\\n3. What technologies are available for storing and processing such data?\\n4. What are the common algorithms or analytics methods used to extract insight from such data?\\n5.  What are some of the common tools used for social media analytics and how to report the \\nresults of such analytics?\\nFigure 11.1 A typical process for designing and developing social media analytics application.\\nTopic-/trend-\\nrelated\\nData base\\nSocial media\\nTracking method\\nTracking approach\\nAPIs\\nRSS/HTML parsing\\nKeyword related\\nActor related\\nURL related\\nApproaches Methods\\nStructured data\\nunstructured data\\nStatistical\\nanalysis\\nSocial network\\nanalysis\\nSentiment\\nanalysis\\nMethod\\nmixture\\nReport/\\nsummary\\nContent\\nanalysis\\nTrend\\nanalysis\\nAnalysisPreparationTracking\\nStructural\\nattributes (e.g.,\\nanswering\\nbehavior,\\nlocation of\\nnodes in the\\nnetwork)\\nOptional-/\\nsentiment-\\nrelated'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 365}, page_content='Application of Analytics • 341\\nThe following paragraphs will exactly provide these insights. \\nPoints to consider while designing and developing a Social Media Analytics Application:\\n1.  Relating business goals to data sources: Typically, social media analytics projects start with \\nidentification of business goal. Some of the common business goals include customer insight \\nmanagement, product or brand reputation management, innovation management, general \\nopinion tracking and product/service value management. These goals will have specific target \\naudience with specific demographic and psychographic profiles. Not all social media applica-\\ntions attract all the population. Hence once you are clear about the business goal associated \\nwith target groups, the first job will be to identify the social media applications they use. \\n2.  Collecting and storing social media data: The next step is to track the relevant data needed for \\nthe goal. Different social media applications provide different methods of data extraction from \\nthe huge amounts of social media transactions that happen in real time. Some applications allow \\ndata tracking by keywords while other use URLs. Depending on the social media platform(s), \\nAPIs, RSS, or HTML parsing can be used to track structured data or unstructured data like \\ntextual content in social media. There are many third-party applications that help you interface \\nwith social media platform and provide required data. REST API is a common method used \\nfor this purpose.\\n    \\n50\\nTweet rate: Number of tweets per 10 minutes, last 24 hours\\n40\\n30\\n20\\n0\\nDec 6 20:20 20:30\\n10'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 366}, page_content='342 • Fundamentals of Business Analytics\\n3.  Approaches to process gathered data: Data analysis approaches depends on end result you \\nneed. For example, if you are interested in behavioral analysis using data attributes like location, \\ndemographic details, and influencers in the network, then you will use structured data store and \\nqueries. Statistical analysis on this data is also a common requirement. On the other hand, if \\nthe aim is to mine opinion or perform sentiment analysis, you will need to focus on sentiment \\nindicators. You may need different set of approach to look into the content of the interactions \\nto find the trend or analyze content. T ext analysis is one of the common requirements in such \\nsituations.\\n4.  Data analysis methods and tools: Some of the common methods used for data analysis \\ninclude filtering, statistics, regression, social network analysis, text analysis, trend analysis and \\nsentiment analysis. Many times multiple methods are employed to get the final results needed. \\nIn big data (Hadoop HDFS) scenarios, MongoDB could be used for storing T witter data. You \\nmay collect user tweets using REST APIs and user data using open authentication (OAuth). \\nNetwork diagrams, heat maps, tweet volume charts and word clouds are used to display the \\nresults of T witter data analysis as shown below. R and Python languages are the commonly used \\nfor programming.\\n11.3.2 anatomy of recommendation systems\\nRecommendation engines are not totally new; they take results from market basket analysis of retail \\nbusiness data to advanced analytic systems and suggest the next best offer or next best activity for a \\nspecific customer. They are also very popular for making suggestions or recommendations when an \\nonline store visitor starts looking at a product or service. Amazon is probably the most famous example \\nthat uses recommendation engine analytics. In the past, all types of recommendation-based analytics \\nwere quite difficult to automate as the data storage, preprocessing, model creation, visualization and \\nintegration were complex and generally needed multiple IT systems working together. \\nT oday, we can see recommendation systems being used in a variety of scenarios such as:\\n1. A restaurant to dine in a new location you are visiting.\\n2. Music you may want to listen to next.\\n3. Newspaper or magazine articles to read next.\\n4. Right doctor in your neighborhood for treatment.\\n5. Best auto insurance policy to buy.\\n6. Next vacation travel spot.\\n7. Best online store for your grocery and so on.\\nApplications of recommendation systems have transcended customers’ shopping experience. Market \\nresearch has shown that recommendation systems bring in anything between 10% and 30% of additional \\nrevenue for a company. Early adopters of recommendation engine technologies such as Amazon and \\nNetflix have outperformed their competitors by leveraging the unparalleled customer insights generated \\nby their proprietary recommendation systems. \\nBoth Recommendations and Pricing are classic topics for advanced analytic modeling, and both \\noffer possibilities for real-time scoring. As we build more accurate models and train them with real-life \\ndata, the more accurate will be the recommendations and the prices the company can offer. It will be \\na great advantage for retailers to change the price dynamically to acquire more customers. When an \\nitem is desired, there is more of a willingness to pay a premium price. When an item is less desired, the '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 367}, page_content='Application of Analytics • 343\\nprice the customer will pay, will play an important role in the decision-making process. Discounts are \\na classic way of helping customers not only choose a particular supplier, but to help a customer move \\nfrom undecided state to purchase commitment. At the same time, discounts are expensive. They eat \\ninto the profit a company makes. In an ideal world, we would make discounting decision based on the \\nconfidence of closing the deal immediately. \\nRecommendation systems predict customer needs based on previous purchase history, online search \\nand navigations, social media interactions content, ratings users have provided for a product/service, \\nanalysis of reviews of products/services and other personalized attributes captured. Such recommenda-\\ntion engines need to track each customer interaction such as log-in, price comparison, product selection \\nto cart, actual purchase, comment or rating posted. \\nThere are many commercial eCommerce platforms such as Baynote, Omniture and RichRelenace that \\nprovide multiple approaches to determine the most appropriate product or service for recommendation. \\nSome of the common algorithms or mechanisms supported by these platforms include rule engine, \\nmodified rule engine, recommendations based on social media traffic like Facebook, T witter, etc., \\nrecommendations based on reviews and ratings, Ad-Word, Internet search terms used, syndicated \\nrecommendations and collaborative recommendations. \\nStructures built in the recommendation system include item-to-item association, many items-to-\\nitem(s) association, person-to-person associations, person-to-item associations and user behavioral \\nheuristics. \\nIn the following section let us understand the generic model of such recommendation systems.\\n11.3.3 components of recommendation systems\\nRecommender systems may be based on several different techniques such as collaborative filtering, \\ncontent filtering, social filtering, or various hybrid approaches that use a combination of these. Though \\nthe design of these systems vary in their detail, it is possible to abstract their characteristics and behavior \\nto arrive at a common structure:\\n1.  Tracking user actions and behavior: The users’ behavior as they use the application is observed \\nto know the items they may be looking for, their specifications, the preferences, experience and \\nfeedback of the user, and so on. The techniques used to track user behavior include capturing \\nand analyzing click sequences, tracking eye movement, tracking navigation sequences and \\nmeasuring time spent in specific sections of the application, items searched, attributes specified \\nin search, number of similar items typically viewed, etc. They help in identifying and/or \\ndeducing user interests and preferences.\\n2.  Capturing, cleansing, normalization and storing of data: The users’ actions result in \\ngenerating data that represents their interests, preferences, feedback on the information \\ndisplayed, etc. which helps to build a model of the user and to compute similarities with other \\nusers. This helps to profile the user to personalize the information presented to the user and \\nto improve the recommendations made. The collection of data may be based on observing \\nthe users’ explicit actions such as searching for items, ratings, feedback on recommendations \\nprovided, etc. or implicit behavior such as the time spent looking at a certain item, navigation \\npatterns, bookmarking, etc. As data is collected across users and over a period of time, it is \\nessential to eliminate any aberrations or contradictions that may have crept in and keep it \\nconsistent.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 368}, page_content='344 • Fundamentals of Business Analytics\\n   The data store typically also includes one or more indexes created based on full-text search of \\nthe contents of the items, and their description and other metadata. These indexes are usually \\npre-computed in order to improve the real-time performance of the recommender.\\n   Biases and anomalies such as undue dominance of certain parameters are compensated for \\nor eliminated by applying techniques such as term frequency–inverse document frequency  \\n(tf-idf). The process of index creation may also involve pruning of frequently occurring but \\nnon-significant terms and coalescing variants of terms through techniques such as stemming \\nand substitution of synonyms with an equivalent term. Such steps are often collectively referred \\nto as normalization.\\n   The components employed in the implementation of this module may include a full-text \\nsearch engine such as Lucene or Solr. Very high volume and volatile data together with strin-\\ngent scalability requirements may call for the use of a distributed search technology such as \\nElasticsearch to sustain performance in the face of heavy user loads.\\n3.  Prediction of relevant items and their ratings: The current actions and data inputs from the \\nuser are overlaid on the information in the data store to generate the predictions. As mentioned \\nabove, a variety of approaches such as collaborative filtering, item-to-item filtering, content \\nfiltering, and their hybrids using algorithms ranging from primitive Euclidean distance-based \\nsimilarity measures to sophisticated ones based on advanced machine learning algorithms can \\nbe applied for this purpose. Typically, this results in a list of items scored and ranked on rel-\\nevance to the items that the user is looking for in order to determine relevance and improve the \\nrecommendations made.\\n   Components required for implementation of this module include feature analyzers/extrac-\\ntors, components implementing logic for analysis, dimensionality reduction and validation of \\nhigh-value features, modules for user/item clustering, one or more types of similarity finders \\nbased on user models and item data, which implement prediction algorithms based on sta-\\ntistical and machine learning techniques, and so on, depending on the sophistication of the \\nimplementation. Comparison and similarity analysis of user models is especially important in \\ncollaborative filtering scenarios which are specifically suited for content which is not amenable \\nto machine analysis such as images and videos.\\n   T echnologies used in the implementation of these modules typically consist of the Big Data \\ntools like Hadoop, M apReduce, and Spark, leveraging a wide-array of NoSQL horizontally-\\nscalable Big Data stores such as HBase, Cassandra, Neo4j. Machine learning technologies spe-\\ncifically built for Big Data like Mahout with several built-in algorithms for predictions are \\ngaining popularity for generating real-time results while serving millions of simultaneous user \\nrequests.\\n4.  Recommendation based on the predictions: This module consists of the logic to generate \\nuser-friendly and valuable recommendations based on the ranked or weighted predictions \\nfrom the previous step. The predictions are scored and combined with some application con-\\ntext and user choices to generate a set of recommendations catering to the user’s interest. For \\nexample, the recommendations may be items that have a similarity index above a certain \\nthreshold determined by the algorithm or specified by the user or the top “n ” similar items. \\nRecommendations are often based on user “neighborhood” considerations which confines the \\n“distance” between users to a certain computed or configured limit specified in terms of simi-\\nlarity parameters.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 369}, page_content='Application of Analytics • 345\\n   Considering the potentially very large number of combinations of diverse factors on which \\nrecommendations can be based, this module will typically allow extensive configuration at \\nseveral levels – administrators, business users and consumers – for filtering, formatting and \\npresentation of results.\\n   The above description outlines the essential components of basic recommendation system. \\nAs mentioned earlier, real-world implementations may vary in their complexity and sophistica-\\ntion. Primarily, in addition to the components described above, these implementations may \\nhave components for caching data such as user profiles and user models, item data, computed \\nsimilarity metrics, etc. for real-time performance optimization. \\n   In addition, the design may be further fine-tuned for maximizing online performance \\nthrough moving the data store maintenance offline or asynchronous operation. A recent inno-\\nvation in recommendation systems is to improve the quality of recommendations by factoring \\nin the user location and other types of context information that mobile devices are capable of \\ndelivering. In such cases, the recommendation system may include additional components to \\ncater to such scenarios.\\nThus in this chapter, we have seen application of analytics in business functions, various industries \\nand also looked at two common analytics systems viz. social media analytics and recommendation sys-\\ntems. We have also shared the typical analytical application development process as well as technologies \\nneeded. We will familiarize you with the algorithms such as k-means, clustering, association, etc. in \\nChapter 12, Data Mining.\\n • Predictive Analytics: The Power to Predict \\nWho Will Click, Buy, Lie, Or Die by Eric \\nSiegel.\\n • The Elements of Statistical Learning: Data \\nMining, Inference, and Prediction, Second \\nEdition (Springer Series in Statistics) by \\nT revor Hastie, Robert Tibshirani and Jerome \\nFriedman.\\n Point Me (Books)\\n Connect Me (Internet Resources)\\n • https://www.informs.org/Recognize-\\nExcellence/Community-Prizes-and-Awards/\\nAnalytics-Society/Innovative-Applications-\\nin-Analytics-Award\\n • http://www.mckinsey.com/industries/\\nconsumer-packaged-goods/our-insights/\\napplying-advanced-analytics-in-consumer-\\ncompanies'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 370}, page_content=''),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 371}, page_content='What’s in store?\\nThe focus of this chapter is to build knowledge about Data Mining Algorithms. We will discuss \\nAssociation Rule Mining, k-Means Clustering and Decision T ress. We will also discuss implementation \\nof Association Rule Mining, k-Means Clustering and Decision T rees using R statistical tool.\\nWe suggest you refer to some of the learning resources provided at the end of this chapter for better \\nlearning. \\n12.1 association rule Mining \\nPicture this:\\nYou are at your favorite salon for a hair-cut. The hair-dresser offers you a rather appealing deal. A head \\nmassage, hair wash or hair coloring at a slightly more price. You think about it and find the offer too \\ngood to refuse. You settle for hair-coloring along with hair-cut. After all you have been wanting to color \\nyour hair a different color for quite a while.\\nBrief Contents\\nAssociation Rule Mining\\nBinary Representation\\nItem Set and Support Count\\nWhy should you consider support and \\nconfidence?\\nImplementation in R\\nk-Means Clustering\\nWhy should you learn about clustering?\\nWhat is k-means clustering?\\nDecision T ree\\nWhat are the uncertainties?\\nWhat is a decision tree?\\nWhere it is used?\\nAdvantages of Decision T ree\\nDisadvantages of Decision T ree\\nData Mining Algorithms\\n12'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 372}, page_content='348 • Fundamentals of Business Analytics\\nYou are shopping online. You are about to make a check-out. Just then, a rather relevant product is \\nrecommended to you at discounted price. You pull the product into the shopping cart and proceed to \\ncheckout.\\nWhat happened here is: that the hair-dresser at the salon and the online retailer just cross-sold to you.\\nWhy should you learn about Association Rule Mining?\\n1. You wish to retain your existing customers and keep them happy.\\n2.  You wish to enhance quality of customer experience by recommending the most relevant \\nproduct.\\n3. You wish to have the deals made to your customers convert to sales.\\nHow will you accomplish the above stated?\\nThe answer is simple − by using the power of association rule mining. Association rule mining is also \\nreferred to as Market Basket Analysis (MBA). Few also prefer to call it as affinity analysis. \\nWhat is Market Basket Analysis (MBA)?\\nIt is a data analysis and data mining technique. It is used to determine co-occurrence relationship \\namong activities performed by individuals and groups. Wikipedia defines cross-selling as “an action \\nor practice of selling an additional product or service to an existing customer”. Association analysis is \\nmostly done based on an algorithm named “Apriori Algorithm”.\\nWhat questions does MBA help to answer?\\n1.  Should detergents be stocked together with other cleaning agents such as window cleaning \\nagents or floor cleaners? Where should they be stocked in the store to maximize sales?\\n2. Should floor mats and runners be placed alongside health and personal care products?\\n3. Are chips and wafers purchased alongside soft drinks? Does the brand of soft drinks matter?\\nFew Examples of Market Basket Analysis\\nMarket basket analysis is widely used in retail wherein the retailer seeks to understand the buying \\nbehavior of customer. This insight is then used to cross-sell or up-sell to the customers.\\nIf you have ever bought a book from Amazon, this should sound familiar to you. The moment you \\nare done selecting and placing the desired book in the shopping cart, pop comes the recommendation \\nstating that customers who bought book “A” also bought book “B”.\\nWho can forget the urban legend, the very famous beer and diapers example. The legend goes… \\nthere was a retail firm wherein it was observed that when diapers were purchased alongside there was \\npurchase of beer as well by the customer. The retailer cashed in on this opportunity by stocking beer \\ncoolers close to the shelves that housed the diaper. This just to make it convenient for the customers to \\neasily pick both the products.\\nAn association rule has two parts: (a) An antecedent (if) and (b) a consequent (then). An antecedent \\nis an item found in the data. A consequent is an item that is found in combination with the antecedent.\\nPicture this:\\nA retailer “BigDailies” wants to cash in on its customers’ buying patterns. They want to be able to \\nenact targeted marketing campaigns for specific segments of customers. They wish to have a good \\ninventory management system in place. They wish to learn about which items/products should \\nbe stocked together to provide ease of buying to customers, in other words enhance customer \\nsatisfaction.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 373}, page_content='Data Mining Algorithms • 349\\nWhere should they start? They have had some internal discussions with their sales and IT staff. The \\nIT staff has been instructed to design an application that can house each customer transaction data. \\nThey wish to have it recorded every single day for every single customer and for every transaction made. \\nThey decide to meet after a quarter (3 months) to see if there is some buying pattern.\\nPresented in Table 12.1 is a subset of the transaction data collected over a period of three months:\\nTable 12.1 Sample transactional data set\\nTransaction ID Transaction Details\\n1 {bread, milk}\\n2 {bread, milk, eggs, diapers, beer}\\n3 {bread, milk, beer, diapers}\\n4 {diapers, beer}\\n5 {milk, bread, diapers, eggs}\\n6 {milk, bread, diapers, beer}\\nThis table presents an interesting methodology called association analysis to discover interesting \\nrelationship in large data sets. The unveiled relationship can be presented in the form of association \\nrules or sets of frequent items. For example, the following rule can be extracted from the above data set:\\n{Diapers} → {Beer}\\nIt is pretty obvious from the above rule that a strong relationship exists between the sale of diapers and \\nbeer. Customers who pick up a pack or two of diapers also happen to pick a few cans of beers. Retailers \\ncan leverage this sort of rules to partake of the opportunity to cross-sale products to their customers. \\nChallenges that need to be addressed while progressing with association rule mining are as follows:\\n1.  The larger the data set, the better would be the analysis results. However, working with large \\ntransactional data sets can be and is usually computationally expensive.\\n2.  Sometimes few of the discovered patterns could be spurious or misleading as it could have \\nhappened purely by chance or fluke.\\n12.1.1 Binary representation\\nLet us look at how we can represent the sample data set in Table 12.1 in binary format (see Table 12.2).\\nExplanation of the below binary representation: Each row of Table 12.2 represents a transaction identified \\nby a “T ransaction ID”. An item (such as Bread, Milk, Eggs, Diapers and Beer) is represented by a binary \\nvariable. A value of 1 denotes the presence of the item for the said transaction. A value of 0 denotes the \\nabsence of the item from the said transaction. Example: For transaction ID = 1, Bread and Milk are \\npresent and are depicted by 1. Eggs, Diapers and Beer are absent from the transaction and therefore \\ndenoted by zero. The presence of the item is more important than its absence, and for the same reason \\nan item is called as an asymmetric variable.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 374}, page_content='350 • Fundamentals of Business Analytics\\n12.1.2 itemset and support count\\nLet I = {i1, i2, i3, …, in} be the set of all items in the market basket data set.\\nLet T = {t1, t2, t3, … tn} be the set of all transactions.\\nItemset: Each transaction ti contains a subset of items from set I. A collection of zero or more items is \\ncalled an itemset. If an itemset contains k elements, it is called a k-item itemset. Example: the itemset \\n{Bread, Milk, Diapers, Beer} is called a 4-item itemset.\\nTransaction width: T ransaction width is defined as the number of items present in the transaction.  \\nA transaction tj contains an itemset X if X is a subset of tj. Example: T ransaction t6 contains the itemset \\n{Bread, Diapers} but does not contain the itemset {Bread, Eggs}.\\nItem support count: Support is an indication of how frequently the items appear in the data set. Item \\nsupport count is defined by the number of transactions that contain a particular itemset. \\nItem support count can be expressed as follows: Number of transactions that contain a particular \\nitemset.\\nExample: Support count for {Diapers, Beer} is 4.\\nMathematically, the support count /uni03C3()X  , for an item set X, can be expressed as\\n/uni03C3() {, }Xt Xt tTii i=/uni2282/uni2208\\nThe symbol | - | denotes the number of elements in the set.\\nAssociation rule: It is an implication rule of the form X → Y, where X and Y are disjoint items, that \\nis, XY/uni2229=/uni03D5 . T o measure the strength of an association rule, we rely on two factors: the support and \\nthe confidence.\\n1. Support for an itemset is defined as:\\n \\nSupport(  Number of transactions containing (xx xx\\n12\\n12,, ) ,…= ,, )\\n()\\n…\\nTotaln umbero ft ransactions n  \\nSupport for X → Y =  Number of transactions containing  and ,,  ...\\nTo\\n12xx yy12,, …\\nttaln umbero ft ransactions( )n  \\nTransaction ID Bread Milk Eggs Diapers Beer\\n1 1 1 0 0 0\\n2 1 1 1 1 1\\n3 1 1 0 1 1\\n4 0 0 0 1 1\\n5 1 1 1 1 0\\n6 1 1 0 1 1\\nTable 12.2 Sample transactional data set represented in binary format'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 375}, page_content='Data Mining Algorithms • 351\\nExample: Support for {Milk, Diapers} → {Beer} as per the data set in Table 12.1 is as follows:\\nSupport for {Milk, Diapers} → {Beer} = 3\\n6 05= .\\n2. Confidence of the rule is defined as:\\n Confidence of ( implie s ( Support for (xx yy x\\n12 12\\n1,, ), ,) ,…… = xxy y\\nxx\\n21 2\\n12\\n,) ,, )\\n,, )\\n……\\n…\\n implies(\\nSupport for (  \\n Confidence of Milk, Diapers} {Beer} Support for Milk, Di{ {/uni2192= aapers} {Beer}\\nSupport for Milk, Diapers}\\n/uni2192\\n{\\nSubstituting we get\\n \\nConfidence of Milk, Diapers} {Beer} { .\\n. ./uni2192==05\\n06 7 0 7462\\nWhy should you consider support and confidence?\\nIt is important to consider support and confidence owing to the following reasons:\\nA rule which has low support may occur simply by chance. T o place big bets on it may prove futile. \\nIt may prove rather uninteresting and non-profitable from a business perspective because it does not \\nmake sense to promote items that customers seldom buy together. Support is used to chuck off unin-\\nteresting rules.\\nConfidence is a measure of reliability of inference of an association rule. For a given rule X → Y, the \\nhigher the confidence, the more likely it is for Y to be present in transactions that contain X. Confidence \\nof a rule can also be used to provide an estimate of the conditional probability of Y given X.\\nThe results of association rule analysis should be considered with caution. It does not necessarily \\nimply causality. Causality, in fact, requires knowledge about the causal and effect attributes in the data. \\nIt requires the relationship to be observed, recorded and studied over a period of time. For example, \\nozone depletion leads to global warming. The association rule mining is more in the nature of establish-\\ning co-occurrence relationship between items in the antecedent and consequent of the rule.\\n12.1.3 implementation in r\\n> transdata <- read. csv(“d:/trans. Csv”)\\n> transdata\\nTransaction. ID Transaction. Details\\n1 1 bread\\n2 1 milk\\n3 2 bread\\n4 2 milk\\n5 2 eggs\\n6 2 diapers\\n7 2 beer\\n8 3 bread\\n9 3 milk\\n10 3 beer'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 376}, page_content='352 • Fundamentals of Business Analytics\\n11 3 diapers\\n12 4 diapers\\n13 4 beer\\n14 5 milk\\n15 5 bread\\n16 5 diapers\\n17 5 eggs\\n18 6 milk\\n19 6 bread\\n20 6 diapers\\n21 6 beer\\n> AggPosData <- split(transdata$Transaction. details, transdata$Transaction. ID)\\n> txns<-as (AggPosData,”transaction”)\\n> summary(txns)\\ntransactions as itemMatrix in sparse format with\\n 6 rows (elements/itemsets/transactions) and\\n 5 columns (items) and a density of 0.7\\nmost frequent items:\\n bread diapers milk beer eggs (Other)\\n 5 5  5 4 2 0\\nelement (item/transaction) length distribution:\\nsizes\\n2 4 5\\n2 3 1\\n Min.  1st Qu. Median  Mean  3rd Qu. Max.\\n 2.0 2.5  4.0  3.5 4.0  5.0\\nincludes extended item information – examples:\\n labels\\n1   beer\\n2  bread\\n3 diapers\\nincludes extended transaction information – examples:\\n transaction ID\\n1   1\\n2   2\\n3   3\\nincludes extended transaction information – examples:\\n transaction ID\\n1   1\\n2   2\\n3   3\\n> rules <-apriori(txns, parameter=list(supp=0.05, conf=0.4))\\nApriori'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 377}, page_content='Data Mining Algorithms • 353\\nParameter specification:\\n confidence minval smax arem aval origionalSupport support minlen maxlen target\\n 0.4 0.1 1 none FALSE   TRUE   0.05   1 10  rules\\n    ext\\n FALSE\\nAlgorithmic control:\\n   Filter tree  heap  memopt  load  sort  verbose\\n   0.1     TRUE  TRUE  FALSE   TRUE     2    TRUE\\nAbsolute minimum support count: 0\\nWarning in apriori(txns, parameter = list(sup = 0.05, conf = 0. 4)):\\n    You chose a very low absolute support count of 0. You might run out of \\nmemory! Increase minimum support.\\nset item appearances ....[0 items(s)] done [0.00s].\\nset transactions ....[5 items(s), 6 transaction(s)] done [0. 00s].\\nsorting and recoding items ....[5 items(s)] done [0. 00s].\\ncreating transaction tree ....done [0. 00s]\\nchecking subsets of size 1 2 3 4 5 done [0.00s].\\nwriting ....[71 rule(s)] done [0.00s].\\ncreating S4 object ....done [0.00s].\\n> inspect(rules)\\n 1hs     rhs  support confidence lift\\n1 {}  => {beer} 0.67  0.67  1.00\\n2 {}  => {milk} 0.83  0.83  1.00\\n3 {}  => {diapers} 0.83  0.83  1.00\\n4 {}  => {bread} 0.83  0.83  1.00\\n5 {eggs}  => {beer} 0.17  0.50  0.75\\n6 {eggs}  => {milk} 0.33  1.00  1.20\\n7 {milk}  => {eggs} 0.33  0.40  1.20\\n8 {eggs}  => {diapers} 0.33  1.00  1.20\\n9 {diapers} => {eggs} 0.33  0.40  1.20\\n10 {eggs}  => {bread} 0.33  1.00  1.20\\n11 {bread} => {eggs} 0.33  0.40  1.20\\n12 {beer}  => {milk} 0.50  0.75  0.90\\n13 {milk}  => {beer} 0.50  0.60  0.90\\n14 {beer}  => {diapers} 0.67  1.00  1.20\\n15 {diapers} => {beer} 0.67  0.80  1.20\\n16 {beer}  => {bread} 0.50  0.75  0.90\\n17 {bread} => {beer} 0.50  0.60  0.90\\n18 {milk}  => {diapers} 0.67  0.80  0.96\\n19 {diapers} => {milk} 0.67  0.80  0.96\\n20 {milk}  => {bread} 0.83  1.00  1.20\\n21 {bread} => {milk} 0.83  1.00  1.20\\n22 {diapers} => {bread} 0.67  0.80  0.96\\n23 {bread} => {diapers} 0.67  0.80  0.96\\n24 {beer,eggs} => {milk} 0.17  1.00  1.20'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 378}, page_content='354 • Fundamentals of Business Analytics\\n25 {eggs,milk}   => {beer}  0.17 0.50 0.75\\n26 {beer,eggs}   => {diapers}  0.17 1.00 1.20\\n27 {diapers,eggs}  => {beer}  0.17 0.50 0.75\\n28 {beer,eggs}   => {bread}  0.17 1.00 1.20\\n29 {bread,eggs}   => {beer}  0.17 0.50 0.75\\n30 {eggs,milk}   => {diapers}  0.33 1.00 1.20\\n31 {diapers,eggs}  => {milk}  0.33 1.00 1.20\\n32 {diapers,milk}  => {eggs}  0.33 0.50 1.50\\n33 {eggs,milk}   => {bread}  0.33 1.00 1.20\\n34 {bread,eggs}   => {milk}  0.33 1.00 1.20\\n35 {bread,milk}   => {eggs}  0.33 0.40 1.20\\n36 {diapers,eggs}  => {bread}  0.33 1.00 1.20\\n37 {bread,eggs}   => {diapers}  0.33 1.00 1.20\\n38 {bread,diapers}  => {eggs}  0.33 0.50 1.50\\n39 {beer,milk}   => {diapers}  0.50 1.00 1.20\\n40 {beer,diapers}  => {milk}  0.50 0.75 1.90\\n41 {diapers,milk}  => {beer}  0.50 0.75 1.12\\n42 {beer,milk}   => {bread}  0.50 1.00 1.20\\n43 {beer,bread}   => {milk}  0.50 1.00 1.20\\n44 {bread,milk}   => {beer}  0.50 0.60 0.90\\n45 {beer,diapers}  => {bread}  0.50 0.75 0.90\\n46 {beer,bread}   => {diapers}  0.50 1.00 1.20\\n47 {bread,diapers}  => {beer}  0.50 0.75 1.12\\n48 {diapers,milk}  => {bread}  0.67 1.00 1.20\\n49 {bread,milk}   => {diapers}  0.67 0.80 0.96\\n50 {bread,diapers}  => {milk}  0.67 1.00 1.20\\n51 {beer,eggs,milk}  => {diapers}  0.17 1.00 1.20\\n52 {beer,diapers,eggs}  => {milk}  0.17 1.00 1.20\\n53 {diapers,eggs,milk}  => {beer}  0.17 0.50 0.75\\n54 {beer,eggs,milk}  => {bread}  0.17 1.00 1.20\\n55 {beer,bread,eggs}  => {milk}  0.17 1.00 1.20\\n56 {bread,eggs,milk}  => {beer}  0.17 0.50 0.75\\n57 {beer,diapers,eggs}  => {bread}  0.17 1.00 1.20\\n58 {beer,bread,eggs}  => {diapers}  0.17 1.00 1.20\\n59 {bread,diapers,eggs} => {beer}  0.17 0.50 0.75\\n60 {diapers,eggs,milk}  => {bread}  0.33 1.00 1.20\\n61 {bread,eggs,milk}  => {diapers}  0.33 1.00 1.20\\n62 {bread,diapers,eggs} => {milk}  0.33 1.00 1.20\\n63 {bread,diapers,milk} => {eggs}  0.33 0.50 1.50\\n64 {beer,diapers,milk}  => {bread}  0.50 1.00 1.20\\n65 {beer,bread,milk}  => {diapers}  0.50 1.00 1.20\\n66 {beer,bread,diapers} => {milk}  0.50 1.00 1.20\\n67 {bread,diapers,milk} => {beer}  0.50 0.75 1.12\\n68 {beer,diapers,eggs,milk} => {bread}  0.17 1.00 1.20\\n69 {beer,bread,eggs,milk} => {diapers}  0.17 1.00 1.20\\n70 {beer,bread,diapers,eggs} => {milk}  0.17 1.00 1.20\\n71 {bread,diapers,eggs,milk} => {beer}  0.17 0.50 0.75'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 379}, page_content='Data Mining Algorithms • 355\\n12.2 k-Means clustering\\nPicture this:\\nAn automobile retailer wishes to open its service centers across a city. They analyze the areas/locales \\nwithin the city from where they get the maximum service requests/complaints.\\n1.  They need to understand as to how many service centers will have to be opened to service cus-\\ntomers in the area.\\n2.  They need to figure out the locations for the service centers within all these areas in such a way \\nthat the entire city is covered.\\nAnother example: Of late several accidents have been reported. A non-profit organization (NGO) wants \\nto open a series of Emergency-Care wards within a region. They have worked with the police department \\nand the traffic department to come up with a list of all the accident-prone areas in the region. They have \\nto decide the number of Emergency Units to be opened and the location of these Emergency Units, so \\nthat all the accident-prone areas are covered in the vicinity of these Emergency Units.\\nThey have a big task cut out for them, that of deciding on the location of these Emergency Units so \\nthat the whole region is covered.  A clear case wherein k-means clustering comes to rescue!\\nWhy should you learn about clustering?\\n1. You wish to offer your services to specific groups.\\n2. You wish to form groups around data that look similar.\\n3. You wish to understand the data sets better.\\n4. You wish to divide data into groups that are meaningful or useful.\\nHow will you accomplish the above stated?\\nThe answer is simple − by using the power of clustering. The terms cluster and group can be used in-\\nterchangeably. Form clusters or groups in such a way that the group/cluster members are more similar \\nthan non-group members. \\nWhat is k-means clustering?\\nA k-means clustering means to form k groups/clusters. Wikipedia explains it as “k-means clustering \\naims to partition n observations into k clusters in which each observation belongs to the cluster with the \\nnearest mean, serving as a prototype of the cluster”.\\nThe k-means clustering is the simplest, unsupervised learning algorithm. It is unsupervised because \\none has to only specify number of clusters. k-means “learns” the clusters on its own without any infor-\\nmation about which cluster an observation belongs to.\\nRaw data → Pass it through the clustering algorithm → Clusters of data\\nGiven below are the steps in performing k-means clustering:\\n1. Selects K centroids. A cluster centroid is the middle of the cluster. \\n2. Assigns each data point to its closest centroid.\\n3.  Recalculates the centroids as the average of all data points in a cluster (i.e., the centroids are \\np-length mean vectors, where p is the number of variables).\\n4. Assigns data points to their closest centroids.\\n5.  Continues steps 3 and 4 until the observations are not reassigned or the maximum number of \\niterations (R uses 10 as a default) is reached.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 380}, page_content='356 • Fundamentals of Business Analytics\\n12.2.1 implementation in r\\n1.  You can import data into the Environment as shown below. The name of the file is Cars.txt. \\nThis file contains entry for Petrol cars and its corresponding mileage in Kilometers.\\n2.  Apply k-means algorithm as shown below. The data set is split into 3 clusters and the maximum \\niteration is 10.\\n'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 381}, page_content='Data Mining Algorithms • 357\\n3. Next, you can plot clusters as shown below:\\n12.3 Decision tree\\nPicture this:\\nIt is that time of the year again. The college fest is going to be next week. It is going to be a week-long \\naffair. Your friends have started planning on the kind of stalls that they will put up. You too want to \\ntry out this stall thing. However, you are yet to decide on what stall you should go for. You have to \\ncommunicate your decision to the organizing committee in a day’s time. The time is short. The decision \\nhas to be made quickly. You do not want to end up with a wrong decision. It is your first time at putting \\nup a stall and you want to go for maximum profit.\\nYou have zeroed down your choice to either an ice-cream stall or a burger stall from a gamut of \\nchoices available. How about using a decision tree to decide on the same? Let us look at how we can go \\nabout creating a decision tree.\\nDecision to be made: Either an ice-cream stall or a burger stall.\\nPayoff: 350$ in profit if you put up a burger stall and a 400$ in profit if you put up an ice-cream stall.\\nWhat are the uncertainties? \\nThere is a 50% chance of you succeeding to make profit with a burger stall and a 50% chance of you \\nfailing at it.\\nAs per the weather forecast, it will be downcast sky and may drizzle or pour slightly throughout the \\nweek. Keeping this into consideration, there is a 40% chance of success and 60% chance of failure with \\nan ice-cream stall.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 382}, page_content='358 • Fundamentals of Business Analytics\\nLet us look at the cost of the raw materials:\\nFor Burger:  70$ for the burger buns, the fillings and a microwave oven to keep it warm.\\nFor Ice-creams: 100$ for the cone, the ice-cream and a freezer to keep it cold.\\nRefer Figure 12.1.\\n350$\\n70$\\n400$\\n100$\\nSuccess\\nFailure\\nSuccess\\nFailure\\n0.5\\n0.5\\n0.4\\n0.6\\nExpected\\nreturn?\\nExpected\\nreturn?\\nExpected\\nreturn?\\nBurger stall\\nIce-cream stall\\nFigure 12.1 A sample decision tree with expected return value yet to be arrived at.\\nLet us compute the effective value as per the below formula:\\nExpected value for burger = 0.5 * 350$ - 0.5 * 70$ = 140$\\nExpected value for ice-cream = 0.4 * 400$ - 0.6 * 100 = 100$\\nRefer Figure 12.2.\\nFigure 12.2 A sample decision tree with computed expected return. \\n350$\\n70$\\n400$\\n100$\\nSuccess\\nFailure\\nSuccess\\nFailure\\n0.5\\n0.5\\n0.4\\n0.6\\nExpected\\nreturn: 140$\\nExpected\\nreturn: 140$\\nExpected\\nreturn: 100$\\nBurger stall\\nIce-cream stall'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 383}, page_content='Data Mining Algorithms • 359\\nThe choice is obvious. Going by the expected value, you will gain by putting up a burger stall.\\nThe expected value does not imply that you will make a profit of 140$.\\nNevertheless, this amount is useful for decision-making, as it will maximize your expected returns in \\nthe long run if you continue to use this approach.\\nPicture this:\\nYou have just completed writing the script of a romantic story. There are two takers for it. \\n1.  The television network: They are interested in making a daily soap of it that will be telecast on \\nprime time. \\n2. XYZ Movie Company: They have also shown interest. \\nYou are confused. Should you sell the rights to the TV Network or XYZ Movie Company?\\nThe TV network payout will be a flat 500,000 USD. XYZ Movie Company will pay in accordance \\nto the audience response to the movie.\\nPayouts and probabilities\\nTV Network payout: \\nFlat Rate:  500,000 USD\\nXYZ Movie Company Payout:\\nSmall Box Office:  250,000 USD\\nMedium Box Office: 600,000 USD\\nLarge Box Office:  800,000 USD\\nProbabilities:\\nP (Small Box Office):  0.3\\nP (Medium Box Office):  0.5\\nP (Large Box Office):  0.2\\nFor greater understanding, let us create a payoff table:\\nDecisions Small Box Office Medium Box Office Large Box Office\\nSign up with TV Network 500,000 USD 500,000 USD 500,000 USD\\nSign up with XYZ Movie Company 250,000 USD 600,000 USD 800,000 USD\\nProbabilities 0.3 0.5 0.2\\nRefer Figure 12.3.\\nLet us compute the effective value as per the below formula:\\nExpected value for TV Network = 0.3 * 500,000 + 0.5 * 500,000 + 0.2 * 500,000 = 500,000 USD\\nExpected value for XYZ Movie  \\nCompany  = 0.3 * 250,000 + 0.5 * 600,000 + 0.2 * 800,000 = 535,000 USD'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 384}, page_content='360 • Fundamentals of Business Analytics\\nThe choice is obvious. Going by the expected value, you will gain by selling the rights of your script to \\nXYZ Movie Company.\\nThe expected value does not imply that you will make a profit of 535,000 USD.\\n12.3.1 What is a Decision tree?\\nA decision tree is a decision support tool. It uses a tree-like graph to depict decision and their  \\nconsequences.\\nFigure 12.3 A sample decision tree with expected return value yet to be arrived at. \\nExpected\\nreturn?\\nExpected\\nreturn?\\nExpected\\nreturn?\\n500,000$\\n500,000$\\n500,000$\\n250,000$\\n600,000$\\n800,000$\\nSmall box office\\nMedium box office\\nLarge box office\\nSmall box office\\nMedium box office\\nLarge box office\\nTV network\\nXYZ movie company\\n0.3\\n0.3\\n0. 5\\n0.2\\n0.2\\n0.5\\nFigure 12.4 A sample decision tree with computed expected return. \\n500,000$\\n500,000$\\n500,000$\\n250,000$\\n600,000$\\n800,000$\\nExpected return:\\n500,000 USD\\nExpected return:\\n535,000 USD\\nExpected return:\\n535,000 USD\\nSmall box office\\nMedium box office\\nLarge box office\\nSmall box office\\nMedium box office\\nLarge box office\\nTV network\\nXYZ movie company\\n0.3\\n0.3\\n0.5\\n0.2\\n0.2\\n0.5'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 385}, page_content='Data Mining Algorithms • 361\\nThe following are the three constituents of a decision tree:\\n1. Decision nodes: commonly represented by squares.\\n2. Chance nodes: represented by circles.\\n3. End nodes: represented by triangles.\\n12.3.2 Where is it used?\\nDecision trees are commonly used in operations research, specifically in decision analysis. They are \\nused to zero down on a strategy that is most likely to reach its goals. They can also be used to compute \\nconditional probabilities.\\n12.3.3 advantages from using a Decision t ree\\n1. Easy to interpret.\\n2.  Easy to plot even when there is little hard data. If one is aware of little data such as alternatives, \\nprobabilities and costs, it can be plotted and lead to useful insights.\\n3. Can be easily coupled with other decision techniques.\\n4. Helps in determining the best, worst and expected value for a given scenario or scenarios.\\n12.3.4 Disadvantages of Decision trees\\n1.  Requires experience: Business owners and managers should have a certain level of good \\n experience to complete the decision tree. It also calls for an understanding of quantitative and \\nstatistical analytical techniques.\\n2.  Incomplete information: It is difficult to plot a decision tree without having complete infor-\\nmation of the business and its operating environment.\\n3.  Too much information: T oo much information can be overwhelming and lead to what is \\ncalled as the “paralysis of analysis”.\\n 12.3.5 Decision tree in r\\nStep 1: Load the party package.\\n> library(party)\\nLoading required package: grid\\nLoading required package: mvtnorm\\nLoading required package: modeltools\\nLoading required package: stats4\\nLoading required package: strucchange\\nLoading required package: zoo\\nAttaching package: ’zoo’\\nThe following objects are masked from ‘package: base’:\\n as.Date, as.Date.numeric\\nLoading required package: sandwich'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 386}, page_content='362 • Fundamentals of Business Analytics\\nWarning messages:\\n1: package ‘party’ was built under R version 3. 2. 3\\n2: package ‘mvtnorm’ was built under R version 3. 2. 3\\n3: package ‘modeltools’ was built under R version 3. 2. 3\\n4: package ‘strucchange’ was built under R version 3. 2. 3\\n5: package ‘zoo’ was built under R version 3. 2. 3\\n6: package ‘sandwich’ was built under R version 3. 2. 3\\nThe above command loads the namespace of the package “party” and attaches it on the search list.\\nStep 2: Check the data set “readingSkills”.\\n> readingSkills[c(1:100),]\\n nativeSpeaker  age  shoeSize score\\n1  yes   5 24.83189 32.29385\\n2  yes   6 25.95238 36.63105\\n3  no  11 30.42170 49.60593\\n4  yes   7 28.66450 40.28456\\n5  yes  11 31.88207 55.46085\\n6  yes  10 30.07843 52.83124\\n7  no   7 27.25963 34.40229\\n8  yes  11 30.72398 55.52747\\n9  yes   5 25.64411 32.49935\\n10  no   7 26.69835 33.93269\\n11  yes  11 31.86645 55.46876\\n12  yes  10 29.15575 51.34140\\n13  no   9 29.13156 41.77098\\n14  no   6 26.86513 30.03304\\n15  no   5 24.23420 25.62268\\n16  yes   6 25.67538 35.30042\\n17  no   5 24.86357 25.62843\\n18  no   6 26.15357 30.76591\\n19  no   9 27.82057 41.93846\\n20  yes   5 24.86766 31.69986\\n21  no   6 25.21054 30.37086\\n22  no   6 27.36395 29.29951\\n23  no   8 28.66429 38.08837\\n24  yes   9 29.98455 48.62986\\n25  yes  10 30.84168 52.41079\\n26  no   7 26.80696 34.18835\\n27  yes   6 26.88768 35.34583\\n28  yes   8 28.42650 43.72037\\n29  no  11 31.71159 48.67965\\n30  yes   8 27.77712 44.14728\\n31  yes   9 28.88452 48.69638\\n32  yes   7 26.66743 39.65520\\n33  no   9 28.91362 41.79739\\n34  no   9 27.88048 42.42195\\n35  yes   7 25.64581 39.70293'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 387}, page_content='Data Mining Algorithms • 363\\n36  yes   8 27.71701 44.06255\\n37  no   7 25.18567 34.27840\\n38  yes  11  30.78970 55.98101\\n39  yes  11 30.75664 55.86037\\n40  yes  11 30.51397 56.60820\\n41  no   5 26.23732 26.18401\\n42  no   5 24.36030 25.36158\\n43  no   7 27.60571 32.88146\\n44  no  10 29.64754 45.76171\\n45  yes   8 29.49313 43.48726\\n46  yes   7 26.92283 38.91425\\n47  yes   8 28.35511 44.99324\\n48  no   6 26.10433 29.35036\\n49  yes   8 29.63552 43.66695\\n50  yes   8 27.25306 43.68387\\n51  no   8 26.22137 37.74103\\n52  yes   6 26.12942 36.26278\\n53  no   9 30.46199 42.50194\\n54  no   7 27.81342 34.33921\\n55  yes  10 29.37199 52.83951\\n56  yes  10 29.34366 51.94718\\n57  yes   7 25.46308 39.52239\\n58  no  10 28.77307 45.85540\\n59  no  11 30.35263 50.02399\\n60  no   8 29.32793 37.52172\\n61  yes  10 28.87461 51.53771\\n62  no   7 26.62042 33.96623\\n63  no   7 28.11487 33.39622\\n64  no  11 30.98741 50.28310\\n65  yes  10 29.25488 50.80650\\n66  yes   5 24.54372 31.95700\\n67  no   8 26.99163 37.61791\\n68  no  11 30.26624 50.22454\\n69  no   7 27.86489 34.20965\\n70  yes  10 30.16982 52.16763\\n71  yes   7 25.53495 40.24965\\n72  no   7 26.75747 34.72458\\n73  yes  10 29.62773 51.47984\\n74  no   5 24.41493 25.32841\\n75  no   9 30.64056 42.88392\\n76  yes   7 26.78045 39.36539\\n77  yes   8 28.51236 43.69140\\n78  yes   5 23.68071 32.33290\\n79  no   7 26.75671 33.12978\\n80  no  10 29.65228 47.08507\\n81  no   9 29.33337 41.29804\\n82  no   9 26.47543 29.52375\\n83  no   9 28.35925 41.92929\\n84  no   8 27.15459 38.30587'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 388}, page_content='364 • Fundamentals of Business Analytics\\n85  no  10 30.58496 45.20211\\n86  yes   9 30.08234 48.72401\\n87  no   9 28.34494 42.42763\\n88  yes  11 29.25025 55.98533\\n89  yes   9 28.21583 48.18957\\n90  no   8 28.10878 37.39201\\n91  no   8 26.78507 37.40460\\n92  yes  10 31.09258 51.95836\\n93  no   5 24.29214 26.37935\\n94  no   7 27.03635 33.52986\\n95  yes   7 24.92221 40.19923\\n96  no   6 27.22615 29.54096\\n97  yes   7 25.61014 41.15145\\n98  yes  10 28.44878 52.57931\\n99  yes   7 27.60034 40.01064\\n100  yes  11 31.97305 56.71151\\n“readingSkills” is a toy data set which exhibits a spurious/false correlation between a child’s shoe size \\nand the score in his/her reading skills. It has a total of 200 observations on 4 variables, namely, native-\\nSpeaker, age, shoeSize and score. The explanation for the variables are as follows:\\n•  nativeSpeaker: A factor that can have a value of yes or no. “yes” indicates that the child is a \\n native speaker of the language in the reading test.\\n• age: Age of the child.\\n• shoeSize: This variable stores the shoe size of the child in cms.\\n• score: This variable has the raw score of the child in the reading test.\\nStep 3: Create a data frame “Inputdata” and have it store from 1 to 105 records of the “readingSkills” \\ndata set.\\n> InputData <- readingSkills[c(1:105),]\\nThe above command extracts out a subset of the observations in “readingSkills” and places it in the data \\nframe “InputData”.\\nStep 4: Give the chart file a name.\\n> png(file = “decision_tree.png”)\\n“decision_tree.png” is the name of the output file. With this command, a plot device is opened and \\nnothing is returned to the R interpreter.\\nStep 5: Create the tree.\\n> OutputTree <- ctree(\\n+ nativeSpeaker ~ age + shoeSize + score,\\n+ data = InputData)\\nctree is the conditional inference tree. We have supplied two inputs: The first being the formula that is a \\nsymbolic description of the model to be fit; the second input “data” is to specify the data frame contain-\\ning the variables in the model. '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 389}, page_content='Data Mining Algorithms • 365\\nStep 6: Check out the content of “OutputT ree”.\\n> OutputTree\\n  Conditional inference tree with 4 terminal nodes\\nResponse: nativeSpeaker\\nInputs: age, shoeSize, score\\nNumber of observations: 105\\n1) score <=38.30587; criterion = 1, statistic = 24.932\\n 2) age <= 6; criterion = 0.993, statistic = 9.361\\n  3) score <= 30.76591; criterion = 0.999, statistic = 14.093\\n   4) * weights = 13\\n  3) score > 30.76591\\n   5) *weights = 9\\n 2) age > 6\\n   6) *weights = 21\\n1) score > 38.30587\\n 7) *weights = 62\\nStep 7: Save the file.\\n> dev.off()\\nnull device\\n    1\\nThis command is to shut down the specified device “png” in our example.\\nThe output from the whole exercise is as follows:\\n3\\n2\\n1\\nscore\\np < 0.001\\nscore\\np < 0.001\\nage\\np = 0.007\\n> 38.306\\n> 6\\n> 30.766\\n≤ 38.306\\n≤ 6\\n≤ 30.76\\nNode 4 (n = 13) Node 5 (n = 9) Node 6 (n = 21) Node 7 (n = 62)\\nno\\nno\\nyes\\nyes\\nyes\\nyes\\nno\\nno\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n1\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n1\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n1\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n1\\nInference: Anyone with a reading score <= 38.306 and age greater than 6 is NOT a native speaker.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 390}, page_content='366 • Fundamentals of Business Analytics\\n • Association rule mining is an example for \\nitem-based recommendation.\\n • Association analysis is mostly done based on \\nan algorithm named “Apriori Algorithm”.\\n • k-means clustering is the simplest, unsuper-\\nvised learning algorithm. It is unsupervised \\nbecause one has to only specify number of \\nclusters. k-means “learns” the clusters on its \\nown without any information about which \\ncluster an observation belongs to.\\n • Decision tree is a decision support system and \\nused in operation research\\n Remind Me (Forget Me Not!)\\n • A Programmer’s Guide to Data Mining by Ron \\nZacharski.\\n • Michael Berry and Gordon Linoff, Mastering \\nData Mining, John Wiley & Sons, 2000.\\n • K. Cios, W . Pedrycz, R. Swiniarski, and L. \\nKurgan, Data Mining: A Knowledge Discov-\\nery Approach, Springer, ISBN: 978-0-387-\\n33333-5, 2007.\\n • T revor Hastie, Robert Tibshirani, and Jerome \\nFriedman, The Elements of Statistical Learn-\\ning: Data Mining, Inference, and Prediction, \\nSpringer Verlag, 2001.\\n Point Me (Books)\\n Connect Me (Internet Resources)\\n • https://www.coursera.org/course/ml: \\nCoursera “Machine Learning” course from  \\nStanford\\n • http://www.cs.cmu.edu/~wcohen/collab-fil-\\ntering-tutorial.ppt?bcsi_scan_c9e2df1c0800a\\n1cc=OVLGC8gZhmJbc+8+tEic9Ufto+IYAA\\nAAT1v/gg==:1\\n • https://www.coursera.org/learn/r-program-\\nming: Coursera “R Programming” course \\nfrom John Hopkins University '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 391}, page_content='Data Mining Algorithms • 367\\nA. Fill in the Blanks\\n1. Decision tree is a __________ method.\\n2. R is __________ tool.\\n3. __________ is a user-based recommendation \\nalgorithm.\\n4. k-mean splits data set in to __________ of \\ncluster.\\nAnswers:\\n1. Supervised learning\\n2. Statistical\\n3. Collaborative filtering\\n4. Fixed number\\nTest Me\\nunsolveD exercises\\n1. Write an R program to implement Association Mining for frequently used item set. (Hint: You \\ncan construct your own data set.)\\n2. Write an R program to implement k-Means Clustering for a data set. (Hint: Download public \\ndata set from the Internet.)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 392}, page_content=''),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 393}, page_content='What’s in store\\nBy now you are already familiar with the concepts relating to Business Intelligence (BI), i.e., data \\nwarehousing and the fundamentals of business analytics. With this background it’s time to look \\nahead at various new possibilities in the field of BI, their applications and merits over the existing \\ntechnologies.\\nIn this chapter we will look ahead at the evolution of BI with mobility, cloud computing, ERP , and \\nSocial CRM. This chapter is a “Must Read” for those interested to learn about BI in depth and about \\nits new horizon of possibilities.\\nWe suggest you refer to some of the learning resources suggested at the end of this chapter and also \\ncomplete the “T est Me” exercises. You will get deeper knowledge by interacting with people who have \\nshared their project experiences in blogs. We suggest you make your own notes/bookmarks while read-\\ning through the chapter.\\n13.1 Understanding Bi and MoBility\\nBusiness Intelligence (BI), as a concept, is not new. Nor is the practice of storing data in databases, \\nanalyzing that data, and revealing useful information out of it in the form of reports or through more \\nBrief Contents\\nWhat’s in Store\\nUnderstanding BI and Mobility\\nBI and Cloud Computing\\nBusiness Intelligence for ERP Systems\\nSocial CRM and BI\\nUnsolved Exercises\\nBI Road Ahead\\n13'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 394}, page_content='370 • Fundamentals of Business Analytics\\nadvanced data visualization techniques. BI has leveraged business extensively over the past two decades \\nthrough ever-improving data management practices and through new technologies that together com-\\nprise what is now called the DSS or Decision Support System.\\nParallel to the development of BI technologies and methodologies continued rapid research and new \\ninnovations in mobile technology. Mobile technology offered a solution to people who wanted to do \\nthings on the move. Mobility had two major offerings that became its major selling points:\\n • 24 ×\\u20097 connectivity: Ability to stay in contact with others (mobile phones, wireless Internet, \\netc.) even when travelling or away from office/home.\\n • Mobile workability: The convenience of being able to work (using laptops, smartphones, etc.) \\nfrom anywhere.\\n13.1.1 the need for Business intelligence on the Move\\nWith the ever-increasing volumes of enterprise data (that began to run into thousands of tera-\\nbytes!) coupled with the fast-paced world of modern business, intelligent decisions needed to be \\ntaken much faster. This meant that there was a need for better and faster transfer of information \\nextracted by decision support systems to the people who consumed that information, i.e. the \\nmanagerial and administrative-level population. No longer did they want to be limited to their \\noffice-based desktops to access data and useful information through DSSs and applications \\ndesigned only for PCs.\\nFortunately, the pioneers in the field of BI and analytics were people with good foresight. They saw \\nthe huge potential in the rapidly developing area of mobile technologies. What could be better than the \\npower to be able to view performance metric reports, KPIs, etc. anywhere, anytime on your hand-held \\nmobile device, and hence make quicker decisions for your business? As soon as this was thought up, \\nresearch began in this area. Mobility gave business people an option to access real time data and make \\nimmediate decisions. T oday, the enormous progress in the field of mobile BI and analytics can be seen \\nall around.\\nLet us follow the gradual progress of BI mobility over the years.\\n13.1.2 Bi Mobility timeline\\nThe Antediluvian Era\\n • Initially, BI was generally delivered to the end-users by a system that consisted of a wired \\n local computer network. BI applications on a computer would connect to a database on the \\nnetwork and provide information through a channel, such as a web browser, or certain other \\nsoftware.\\n • Later, as mobile devices such as pagers and mobile phones came into the picture, they could \\nreceive data that was pushed through SMS service. However, not only would such messages \\ncontain a very limited and minimal amount of information, they also would not give the user \\nany interactivity at all.\\n • BI applications designed for mobile devices were primitive, cumbersome to develop, and their \\nmaintenance cost a lot. For the time and money spent on them, the information they delivered \\nwas too less.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 395}, page_content='BI Road Ahead • 371\\nTaking Up the Challenge\\n • Then came the era of smartphones, and with them came various applications designed to read \\ntables of data and a few charts too. However, there were still a few things that bothered their \\n users – small screens that couldn’t provide highly detailed information on charts, incapable \\n mobile browsers, poor connectivity, etc.\\n • Laptops were a better alternative to smartphones as far as the need for better data visualization \\nwas concerned. However, the advantage with smartphones was that they were smaller, lighter, \\nand hence less cumbersome to carry around. If data visualization could be improved on smart-\\nphones, history would be written.\\nThe Roadblocks\\n • Small screen for viewing reports and KPIs; hence lack of detail.\\n • Poor resolution.\\n • Poor connectivity.\\n • Poorly equipped browsers.\\n • Information is sent to recipients on fixed schedule. However, recipient has no control over it.\\n • Small amount of transmitted data.\\n • Limited user interactivity: no analysis capability; no drill-down; no drill-through to sub-reports; \\nno freedom to query either.\\n • Low on memory and processing power.\\n • Very limited functionality on keyboard.\\n…and many more like these.\\nWhat does one expect from mobile business intelligence technology?\\nAccording to Catriona McGauchie, who wrote an article on mobile BI at www.dashboardinsight.\\ncom, there are three major expectations from the adoption of mobile BI technology:\\n • Device maturity, i.e. the extent of the quality of information that the mobile device can show \\nthe user.\\n • End-user expectations, i.e. user-friendliness, user-interactivity, compatibility of mobile applica-\\ntions with desktop applications.\\n • Connectivity should be robust and secure.\\nOvercoming the Shortcomings\\n • In the 2000s, Blackberry smartphones began to establish their stronghold over the corporate and \\ngovernmental market. Their key selling points were:\\n \\x83 Wireless email.\\n \\x83 Larger screens.\\n \\x83 Advanced browser.\\n \\x83 Advanced MOS (mobile operating system).\\n \\x83 QWERTY keyboard and thumbwheel that provided better user-interactivity.\\n \\x83 A native application for the device that is specially designed for the mobile screen. This pro-\\nvides superior interactivity.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 396}, page_content='372 • Fundamentals of Business Analytics\\n • Another way of approaching the mini-computer-cum-mobile phone concept was to make \\n laptop computers smaller, lighter, and more easily portable. The ultimate aim was to combine \\nthe advantages of smartphones (small size, lightweight, portability) with the computing power \\nof laptops.\\nThe Present: A Result of Endless Research and Efforts\\nAs per www.dashboardinsight.com, MBI (Mobile BI) generally speaks of three usage models:\\n • Exceptions and alerts: At times some events may happen which were unexpected or unac-\\ncounted for. The concerned user should be alerted about such events that may hamper the busi-\\nness promptly. For example, if a delivery/shipment is delayed somehow, the sales executive must \\nreceive an alert about it on his mobile for immediate action.\\n • Push reporting: Sometimes KPIs, or certain other specific reports, are pushed to executives on a \\nregular basis according to a pre-determined schedule. Decision to push such reports to the user \\nis taken at the source. It could be daily (at EOD), weekly (e.g. every Friday), or monthly too. \\nFor example, every Monday morning (8:30 am to be precise), a report on the sales performance \\nfigures of last week is delivered to the senior marketing and sales executives.\\n • Pull reporting: Here, the decision to pull/generate a report is initiated by the end-user. The \\nuser gives inputs through his mobile device and can ask for information from a central server-\\nbased system. For example, an executive uses an application to get the list of his top 5 sales \\nexecutives.\\nMobile Devices/Applications as of Today\\n • MOS (Mobile Operating Systems): Blackberry OS, Windows Phone, Symbian, Android, etc. \\nare today the most popular mobile operating systems available in the market. They are best \\nknown for their flexibility, operability, and compatibility with desktop OSs. Also, it is easy to \\ndevelop mobile applications for these MOSs. Currently, the most popular MOS is Android. \\nOver 80,000 applications are available for mobile devices operating on Android OS.\\n • Apple iPhone: iPhone is a revolutionary device that set a new standard and a greater level of \\nexpectation from mobile devices. iPhone became hugely popular and sold many units within the \\nfirst few months of its release into the market. Apple released the software development kit for \\nbuilding apps that can run natively on iPhone and iPad.\\n • Apple iPad: iPad came to be hailed as the harbinger of the future of mobile computing. It com-\\nbines the portability of a smartphone with the computational power and boasts of a larger screen \\nand more interactive display of a computer. iPhone and iPad have transformed the way data is \\nviewed on mobile devices. BI applications can now generate reports that can be converted into \\nmobile dashboards for delivery to an iPhone or iPad. iPad is virtually a laptop without a physi-\\ncal keyboard (though that functionality can be accessed using the on-screen virtual keyboard). \\nBesides, the iPad OS and applications are highly compatible with desktop applications. Navigat-\\ning through KPIs and dashboards using touch screen is user-intuitive and user-friendly, which is \\nwhy it appeals to the majority of the market.\\n • Examples of small BI mobile apps dealing with local data analysis:\\n \\x83 A simple example of mobile BI would be the calorimeter and pedometer apps on your Sony \\nErickson cellphone. The phone has a motion sensor apparatus within it. When you go jogging, '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 397}, page_content='the phone is capable of measuring the distance you cover through the pedometer app. The \\nphone also measures the heart-rate (if you are holding it in your hand). The calorimeter \\napp then combines the data from the pedometer with the heart-rate data and calculates the \\napproximate number of calories you have burnt during your jog using a complex algorithm. \\nThe accuracy of the app is usually about 95%, which is acceptable enough for the purpose \\nthat you use it for. In this example, the mobile phone collects real time data by itself and uses \\nBI applications to deliver information to the user. So, the data source and application system \\nare on the same device.\\n \\x83 Another example would be the iPod touch’s “music suggestions” functionality. It scans your \\nentire music collection, recognizes the genres of music you listen to, and if the iPod is connected \\nto the Internet (through its Wi-Fi), it can suggest you songs that you may find to your taste.\\n \\x83 Yet another example would be the iPhone. It provides a feature of map integration that shows \\nthe path you have taken for your jog/walk and graphically provides the gradient/pace changes \\nusing GPS capabilities.\\n \\x83 Various KPIs and dashboards are now designed specifically for the smartphone, iPad, and \\nother mobile devices. They include user-interactivity features (like drill-down) too. If the \\ndashboard is too wide for the screen, and you wish to view an individual sub-report on the \\ndashboard in more detail, then you can do so using the drill-through functionality. Click-\\ning/selecting a certain report on the dashboard will open up that report only over the entire \\nscreen. However, you can see the report up to a much greater level of detail.\\n \\x83 Blackberry smartphones are capable of displaying a variety of reports such as column charts, pie-\\ncharts, drillable tables, KPIs, trend graphs, etc. that are custom-designed for smartphone displays.\\n13.1.3 data security Concerns for Mobile Bi\\nAccording to an article by Maribel D. Lopez on http://us.blackberry.com, data security must be pro-\\nvided at three levels:\\n • Device security: Best to let the source data stay on centralized servers rather than on individual \\nmobile devices. That way, if the device is lost, the data is still secure. Also, access to the data \\ncenter is only permitted within the network. Most mobile device manufacturers today provide \\nencryption for email and phone memory, antivirus and firewall software, etc.\\n • Transmission security: Since the information is transmitted wirelessly to mobile devices, and \\nit also generally involves third-party members in the network, data security during transmission \\nbecomes a top priority. Some measures taken to ensure this are SSL (secure sockets layer), VPN \\n(virtual private network) connection, cryptographic encryption of data transmitted, etc.\\n • Authorization, authentication, and network security: It refers to controlling which user can \\naccess which data by assigning access privileges to users through IDs and/or passwords, all stored \\nin an encrypted database storing user credentials.\\n13.2 Bi and CloUd CoMpUting\\n13.2.1 What is Cloud Computing?\\nLet us consider the job of an executive, Mike, in a large organization. As an executive, he is responsible \\nto make sure that all the employees have the right hardware and software to do their jobs. Buying  \\nBI Road Ahead • 373'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 398}, page_content='374 • Fundamentals of Business Analytics\\ncomputers for every employee wouldn’t suffice; he will also have to purchase software licences to provide \\nemployees the tools with which to perform their job. Whenever a new employee joins the company, the \\nexecutive has to purchase additional software licences or make sure that the present software licence can \\nbe used by this new recruit. Mike’s is a growing organization, with recruits joining the company almost \\nevery alternate fortnight. We agree that making available the requisite hardware and software for all the \\nnew employees is indeed a stressful job for Mike.\\nWouldn’t it be nice if instead of installing a suite of software for each computer, we have to load just \\none application on the system? That application would allow employees to log into a Web-based service \\nwhich hosts the required programs that would enable the user to do his or her job. This remote server \\nwould be owned by another company, and it would be their responsibility to make available everything \\nfrom word processing to email to complex data analysis programs. The world calls this arrangement \\ncloud computing.\\nCloud computing can be defined as location-independent computing, whereby shared servers pro-\\nvide data, software, and services to computers and other devices as and when required. These services \\nare offered through data centers all over the world, which collectively are referred to as the “cloud”. Any \\nuser who has access to the Internet can use the cloud and the services provided by it. Since all these ser-\\nvices are connected, users can share information between multiple systems as well as with other users.\\nIn a cloud computing system, there’s a significant shift of workload. Local computers need not take \\nthe heavy load when it comes to running applications. The network of computers that forms the cloud \\nhandles the load instead. Due to this, hardware and software demands reduce on the user’s side. The \\nonly thing the user’s computer needs to run the cloud computing systems interface software is a Web \\nbrowser, and the cloud’s network takes care of everything else.\\nFigure 13.1 Some prominent users of cloud computing.\\nGoogle\\nSalesforce\\nMicrosoft\\nAmazon\\nYahoo\\nZoho\\nThe Cloud\\nRackspace'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 399}, page_content='A familiar example of cloud computing is any Web-based email service such as Hotmail, Yahoo! \\nMail, or Gmail. Instead of running an email program on computer, we log in to a Web email account \\non a remote system. The software and storage for the account doesn’t exist on our computer; it’s on the \\ncloud computer of the service provider.\\nAnother example is that of Google Docs. Through Google Docs we can have multiple people col-\\nlaborating on the same document in real time. It is also possible to share these documents with people \\noutside your organization. When it comes to public cloud computing, this is one of the more basic \\nexamples.\\n13.2.2 Why Cloud Computing?\\nThe answer is simple: Rapid implementation, ease of use, and subscription pricing. Cloud computing \\ncustomers generally do not set up their own physical infrastructure; instead they go for renting usage \\nfrom a third-party provider to reduce capital expenditure. They use resources as a service, and they only \\npay for the part that they have used. This model is analogous to traditional utility services such as elec-\\ntricity or water. However, some cloud service providers’ bill on subscription basis. The cloud is becom-\\ning very popular with small and medium enterprises (SMEs) because it is difficult for them to afford the \\nlarge capital expenditure of traditional IT .\\nSome benefits of using cloud computing are\\n • Software as a subscription.\\n • Reduced software maintenance.\\n • Increased reliability.\\n • Increased scalability.\\n • Cost reduction.\\n • Matches current computing trends.\\n • Portability/accessibility.\\n • Efficient use of computer resources.\\n • Version-less software.\\n • Environment-friendly.\\n • Pay per use.\\nWhat are the barriers to adoption of cloud-based applications and platforms? There seem to be two \\nprime concerns: data privacy and data security. Most of the enterprises are still hesitant to move their \\ncritical business data off their premises.\\n13.2.3 Why Business intelligence should be on the Cloud?\\nIn today’s economy, smart businesses are trying to utilize every available opportunity to increase their \\nperformance and reduce cost. BI tools are thus continuously gaining popularity among companies of all \\nsizes as they try to increase efficiency and effectiveness and thus gain a competitive edge. While large \\ninvestments in conventional BI solutions are impractical and unattractive to most businesses, the popu-\\nlarity of software-as-a-service or cloud BI solutions is increasing enormously. Consider a scenario where \\na business unit of an IT company (let us call it “A”) received an ETL (extract, transform, load) project \\nfor building a data warehouse, which requires 10 people to work for one month on an ETL tool, the \\nlicences of which are very costly. The business unit “A” purchases the licence for the same and starts \\nBI Road Ahead • 375'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 400}, page_content='376 • Fundamentals of Business Analytics\\nworking on the project. Now assume that after some time another business unit (let us call it “B”) of the \\nsame company bids for and gets another ETL project which requires 20 people to work for two months \\non another ETL tool. The business unit “B” is now required to purchase the licences for this ETL tool \\nwhich again leads to a huge investment. Also after the completion of the respective projects, there is no \\nuse of the licences unless another project with a similar requirement arrives. The result: a huge wastage \\nof resources and capital investment. This is where the cloud comes to the rescue. Instead of purchasing \\nlicences, it is a better option for the company to set up a private cloud and allow all its business units to \\nuse the software present on the cloud as a service as and when required, and pay for it on the basis of \\nusage. This is a more efficient and cost effective way of using resources.\\nCloud BI has a great potential to substantially disrupt the existing BI market because of its low cost, flex-\\nibility, and scalability. Cloud BI solutions offer all the benefits of traditional BI solutions while substantially \\nreducing the investment required. Cloud BI solutions not only provide powerful and flexible business insight, \\nbut are also faster, easier, and cheaper than traditional BI solutions. The benefits of cloud BI are appealing \\nand real. As compared to traditional business intelligence, cloud BI offers the following business benefits:\\n • Increased access, maximum results: T raditional BI solutions are costly and require IT resources. \\nThese limitations restrict their availability to professional analysts. On the other hand, cloud \\n solutions are easier and less costly to deploy, and also require little expertise to operate. As a result, \\nthey are more accessible to non-technical users. Analysts and others who have to struggle with \\nExcel for making sales forecasts and resource management, and for servicing customer  accounts \\ncan make use of cloud BI tools to perform the analysis and for quick and easy reporting. There \\nwould be no need to install the required BI tool on their systems; instead, they can just access \\nthe cloud and conduct their work. This helps them to discover opportunities for performance \\nimprovements that are hidden in the data using BI.\\n • Faster ROI: Cloud BI offers a quick deployment. Unlike traditional BI implementation, which \\nmay take 12 to 18 months or more, cloud BI solutions can typically be setup in just few weeks. \\nThis is due to the reason that there is no extra hardware required to be installed and no database \\nto be set. With the solution up and running in a short time, companies can start getting a return \\non their investment (ROI) quickly. Also the maintenance and customization is faster and easier. \\nSince the hardware and infrastructure are maintained by the vendor, software upgrades and archi-\\ntectural changes are also handled by the vendor and delivered to the customer automatically.\\n • Lower implementation costs: Cloud BI providers manage the entire infrastructure required for \\ntheir service as well as for hosting their applications, so we are spared the hardware and setup \\ncosts required to deploy a BI solution. Also, as software-as-a-service BI solutions can be set up in \\na small time as compared to traditional solutions, the time and resources required for a finished \\nsolution are drastically reduced.\\n • Lower on-going costs: In cloud BI solutions, there are no servers to maintain, no on-going soft-\\nware maintenance, no patches to be installed, and minimal IT resources are required. This leads \\nto low on-going costs. Cloud BI vendors generally charge a subscription fee which is decided \\naccording to the application service, maintenance, and support. These subscriptions are usually \\nbased on the number of users accessing the cloud, the amount of data analyzed, and the software \\nusage, and are much lower as compared to the cost of purchasing a conventional on-premises BI \\nsolution. This billing approach makes sure that customers have to pay only for what they need \\nor what they use. Hence the customer retains financial control of the project thus maintaining \\nthe flexibility to scale up as the needs expand. As the customer’s solution is running on a shared \\ninfrastructure, this increased financial control and flexibility comes at lower cost.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 401}, page_content=' • Scalability: Cloud solutions are made to support a large number of users simultaneously. This \\nmeans an enterprise can expand its cloud solution easily and quickly just by requesting a larger \\naccount size or access for more users. Unlike on-premise BI solutions, cloud solutions can be \\nexpanded without buying more hardware or installing different software. Since the vendor is \\nresponsible for capacity, organizations can begin with a small number of users and a small set of \\ndata, and can later increase the number as and when required.\\n • Flexibility: Unlike traditional solutions, cloud BI solutions are more flexible. A cloud BI solu-\\ntion can be easily changed. So it is easy for non-technical users to quickly add new reports and \\ndashboards, data sources, and analysis. On the contrary, traditional BI solutions would take \\nweeks or months to change and will also involve significant IT resources.\\n • Greater visibility: Cloud applications are run over the Internet, so a user is able to share data \\nwith others easily, both inside as well as outside the organization. The users can integrate data \\nfrom various sources in different parts of the world, from other business units, and also from \\npartners of the organization. This is important for any firm which has multiple sites at various \\nlocations.\\n • Data warehouse on cloud: Cloud BI also provides a lot of data warehousing options to its \\ncustomers, from SaaS (software-as-a-service) or DaaS (data-as-a-service) offerings, which pro-\\nvide software, to PaaS (platform-as-a-service) and IaaS (infrastructure-as-a-service) solutions on \\nwhich you can build your data warehouse. The cloud has proved to be a fertile ground for man-\\naging large volumes of data. Once the data is on the cloud, it is easy and quick to access it and \\nalso it is not location-specific, i.e. it can be accessed from any location.\\nWith all the above-stated advantages, cloud BI has proved to be a more beneficial and better solution \\nthan traditional on-premise BI solutions. These are reasons enough for the world to move from tradi-\\ntional BI solutions towards cloud BI. Cloud computing allows one to focus on their key competencies \\nand worry less about the IT infrastructure cost.\\n13.3 BUsiness intelligenCe for erp systeMs\\nBI and ERP grew as two separate entities, but their coming together is akin to bringing two sides of the \\ncritical business coin together.\\npicture this…\\n“PlusSales”, a typical manufacturing enterprise, has a chaotic mix of business applications. While a few \\nof these applications exist in silos, a few others are tied together with the help of complex interface \\nprograms. Owing to some applications existence in silos, there is a huge probability that the same data \\nmay exist at more than one place, raising questions about the accuracy and consistency of data. The \\nsenior management of “PlusSales” felt the need for a system that could integrate and automate the busi-\\nness processes from end to end, for example from planning to manufacturing to sales. Enter the ERP \\nsoftware…. The ERP system provides several business benefits. Here, we enumerate the top three:\\n • Consistency and reliability of data across the various units of the organization.\\n • Streamlining the transactional process.\\n • A few basic reports to serve the operational (day-to-day) needs.\\nFigure 13.2 depicts a typical ERP system.\\nBI Road Ahead • 377'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 402}, page_content='378 • Fundamentals of Business Analytics\\n13.3.1 Why Bi in erp?\\nThe mammoth growth in the volume of data today is compelling organizations all over the world to \\nstart harnessing the power of data to make better and faster decisions. An ERP system was able to solve \\nsome, if not all, the information needs of the organization. It was able to successfully integrate several \\nbusiness processes across the organization’s supply chain. It was adept at capturing, storing, and moving \\ndata across the various units smoothly. What it lacked was the ability to integrate data from other \\nexisting applications and external sources, which is imperative to serve the analytical and reporting \\nneeds of the organization. Let us explain this further with the help of our example of the company \\n“PlusSales”.\\n“PlusSales” has humungous amount of data in a multitude of systems. Most, if not all, of the organi-\\nzation’s financial data is safely housed in the ERP system. But Kevin, a senior executive, looking to gain \\na quick view of how the business is progressing requires not only the financial data but also the data \\nfrom sales, inventory, CRM, etc. His needs can be satisfied from a merged data set that combines data \\nfrom all the systems. Business Intelligence could do just that, i.e. it can include data from internal and \\nexternal sources; it can support information access to external parties, vendors, and customers; it can \\nprovide real time actionable business insights; it can provide single version of the critical information; it \\ncan support the analytics and reporting needs of the organization; and much more.\\nOne way to bring order to the chaos prevalent in the organization is by an extension of ERP to BI. It \\nis time to think of BI as a layer which sits on top of or is embedded within ERP and other applications \\nwhich stockpile giant repositories of data. T oday is an era of an extended enterprise. The term “extended \\nenterprise” implies that not just the employees, members of the board, managers, and executives make \\na company but a company also comprises its business partners and investors, its suppliers and vendors, \\nand even its customers and prospects. The extended enterprise can only be successful if all of the com-\\nponent groups and individuals have the information they need in order to do business effectively. Refer \\nto Figure 13.3.\\nWhen we say that the ERP systems alone cannot cater to the reporting and analytical needs of the \\norganization, it is not to connote that the ERP systems cannot generate reports, but the built-in stan-\\ndard reports of the ERP systems are very basic and pretty generic across industries. The ERP systems \\ninitially were using data from live operational and transactional systems in queries and reports. One \\nproblem they posed was that most of their reports were hard-coded. Hence the stage was set for BI. Few \\nof the forward-thinking and progressive ERP vendors started off by adding useful and powerful analyti-\\ncal and reporting capabilities to their suite to add on to the value provided to their customers. One such \\nvendor was SAP which came out with SAP BW (Business Warehouse) in 1997.\\nFigure 13.2 A typical ERP system.\\n Enterprise Resource Planning\\nHuman Resource Management\\nInventory Management\\nFinancial Management\\nSales & Marketing  \\nOrder Management\\nPurchase Management'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 403}, page_content='13.3.2 Benefits of Bi in erp\\n • ERP today is considered as “T rusted Data Source” and hence basing decisions on ERP data is \\nconsidered more “Safe” by decision makers.\\n • Employs customized analytics to meet business needs.\\n • Enables users to perform “what if” forecasting.\\n • Enables users to develop customized reports.\\n • Presents key information in dashboard views using charts, pivots, gauges, etc.\\n • Drills down to view data at a more detailed level.\\n • Drills across from dimension to dimension at the same hierarchical level.\\n • Merges information from multiple varied systems to provide a “unified source” of data.\\n • Performs trend analysis using historical data.\\n • Searches for hidden patterns.\\nThere are packaged BI solutions available with the ERP tools for implementing the key components \\nrequired for a BI solution. Let us look at the key components of a BI solution:\\n • Reporting tool: One of the key strengths of BI solutions is to provide a robust front-end that \\nallows users to view and analyze data in a dashboard view (summary level) and then drill-\\nthrough/drill-across into data elements to launch detailed reports. Many BI solutions also \\nprovide ready-made customizable templates for users to create their own reports.\\n • ETL tool: It is a known fact that the data model for ERP is dramatically different from the data \\nmodel for BI. ETL (extract, transform, and load) tools packaged with ERP solutions can be leveraged \\nto transform, load, and merge external data for a comprehensive BI solution. There are pre-packaged \\nscripts available for ETL which can be customized and implemented for data cleansing and merging.\\n13.3.3 erp plus Bi equals More Value\\nRealizing the potential of BI to leverage ERP systems for performance improvement, a few ERP vendors \\nsuch as Oracle, SAP [SAP NetWeaver 7.0; ERP and BI in one system: MCOS (Multiple Components \\nOne System)], PeopleSoft, etc., have already ventured to provide BI support with ERP . There are several \\nBI tools and applications available in the market, and it will be interesting to see how they will be able \\nFigure 13.3 Components of an extended enterprise and ERP .\\nPartners & Investors  \\nMobile Access\\nBusiness Intelligence\\nEnterprise Logistics\\nCustomers & Prospects  \\nVendors & Suppliers  \\nExtended Enterprise\\nManagers & Executives  \\nEnterprise Resource Planning\\nHuman Resource Management\\nInventory Management\\nFinancial Management\\nSales & Marketing  \\nOrder Management\\nPurchase Management\\nBI Road Ahead • 379'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 404}, page_content='380 • Fundamentals of Business Analytics\\nto unlock the data that is available in the ERP systems, integrate it with the data from other internal and \\nexternal sources and support the analytics and reporting needs of the organization.\\nBut this is not as easy as it sounds. ERP and BI are essentially different entities which came into exis-\\ntence for different purposes, but can they join hands to leverage the power of each other. There is the need \\nto transform data to information and information to intelligence. ERP can transform data into informa-\\ntion, but BI tools are required to complete the transformation from information to intelligence.\\n13.4 soCial CrM and Bi\\nJust the other day, I happened to be with one of my friends when she received a call from a shop in an \\nuptown mall informing her that the particular style of clothing is available with them and she should \\nmake the time to check it out. I asked my friend if she had placed one such order and left her contact \\nnumber with them. She answered in the negative and simply said that she was a regular at their mall and \\nthey know her for quite some time now.\\nThat was the beginning of the understanding the one-to-one relationship that the shop had man-\\naged to forge with its customers. This had certainly not happened overnight. Let us zero down to four \\nessentials that could have improved the shop’s customer relationship and thereby its business:\\n • Notice/observe the customer’s requirements, habits, choices and preferences, etc.\\n • Remember the customer’s behavior over time.\\n • Learn from the past interactions with its customers.\\n • Act on what it has learned to make customers more profitable.\\nA small business will allow the liberty to notice/observe all its customers. This comfort, however, is \\n neither affordable nor possible with large firms/enterprises. This is where technology comes to the \\nrescue. Let us explore further on the four essentials of customer relationship stated above.\\n • Notice/observe the customer’s requirements, habits, choices and preferences, etc.: The \\n details of each and every interaction with the customer can be recorded using a transaction \\nprocessing system. These recordings might have been done for operational needs of the firm but \\nfew can debate the fact that these are the customer touchpoints where information about the \\ncustomer behavior first makes its way into the enterprise.\\n • Remember the customer’s behavior over time: The transaction processing system can collect \\nhumungous amount of data, but this enormous amount of data will simply remain data mounds \\nif it is not carefully cleaned, sorted, merged, organized, and summarized. That leads to the data \\nwarehouse. Information gleaned from multiple disparate sources is stored in a data warehouse in \\na friendlier format than that maintained by operational systems. The data warehouse thus allows \\nthe bigger firms/enterprises to remember the customer’s behavior over time. In other words, the \\ndata warehouse serves as the enterprise’s memory.\\n • Learn from the past interactions with its customers: Now is the time to apply intelligence to \\nmemory. This will help recognize patterns, propose hypothesis, accept or dismiss hypothesis, make \\npredictions, etc. The data warehouse is used to capture the differing needs, preferences, choices, \\npropensities, etc. of the customers. Data mining allows corroborating questions such as “Which \\npromotional scheme will work best for which customer segment?”, “Who will remain a loyal \\ncustomer and vouch for the product or service offered?”, “Who will also prefer product Z?”, etc.  \\nIn other words, data mining is about skimming through the colossal data to find patterns. The \\ntask is arduous, more so because the signals sent out by customers are not always very clean.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 405}, page_content='In conclusion, although it is easier for small firms/organizations to know their customers, it is not \\nimpossible for large firms/organizations to learn about their customers and build a strong relationship \\nwith them. Customer Relationship Management (CRM) systems have been around for about 20 years \\nnow and are used by big and small organizations alike. Few examples of popular CRM systems are: \\nSalesforce, Zoho, and Sugar CRM.\\nIn traditional CRM one essentially starts out with information on a list of people/companies whom you \\nknow, how you know them, when and how you have interacted with them, etc. The next step is to clas-\\nsify or categorize people in your CRM tool as leads, friends, prospects, etc. that helps you define who that \\nperson is and how you know him/her. So now, you have data about the people/companies whom you know \\nand you use that data to help manage your relationship with them. What is the advantage of having a CRM \\nsystem in place? CRM systems are designed to create a process around the interaction that your company \\nhas with its customers in the hope of more efficiently closing a sale or resolving some sort of an issue.\\nSocial CRM requires dealing with conversations and relationships with social customers in addition \\nto the data or information that you might have about them. These conversations and relationships take \\nplace not just from the company to the consumer but also from consumer to consumer.\\nThink of Facebook and T witter (the social media). Facebook has more than 500 million registered \\nusers who spend more than 3 billion hours a month on the Facebook site. It’s a veritable interaction \\nhub, where many businesses have a significant presence. The requirement is now for the companies to \\nuse Facebook in a way that’s integrated with their other communication channels.\\nLet us look at T witter as another example. Assume you are a large brand on T witter such as XYZ Air-\\nlines. You are in the process of building relationships with your followers. At the same time you have the \\nopportunity to build relationships with and listen to (and engage) the customers having conversations \\nabout you. T raditional CRM didn’t work with T witter or Facebook or with any other social platform; \\nit was just a collection of data and information. So again, the big difference between CRM and Social \\nCRM is that we now have all these conversations and relationships to consider.\\nPaul Greenberg, a leader in Social CRM, defines it as:\\nCRM is a philosophy and a business strategy, supported by a technology platform, business rules, workflow, \\nprocesses and social characteristics, designed to engage the customer in a collaborative conversation in order to \\nprovide mutually beneficial value in a trusted and transparent business environment. It’s the company’s \\nresponse to the customer’s ownership of the conversation.\\nThe time is right for the organizations to consider the following:\\n • How must the organization take action based on the conversations and relationships that it \\nfosters or engages in with its customers?\\n • How to structure the organization in a way that is both efficient and scalable to take advantage \\nof Social CRM?\\n • How to take all of the unstructured data from the social web and structure it in a way that allows \\nyou to get actionable insight?\\n • How to use Social CRM to empower your customers and grow your customer base?\\nThere is a huge opportunity in this space and BI vendors are starting to see the growing opportunity. \\nEnterprise business intelligence tools play a key role in successfully integrating and measuring the \\nunstructured and semi-structured data that drives the social space. A few vendors such as SAS, SAP \\nOracle, IBM, DataFlux, Information Builders, etc. have already started addressing the challenges that \\nSocial CRM poses.\\nBI Road Ahead • 381'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 406}, page_content='382 • Fundamentals of Business Analytics\\nRemind Me \\n•   Mobility had two major offerings that became \\nits major selling points:\\n\\u2003\\u2003\\x83   24 ë 7 connectivity: Ability to stay in \\ncontact with others (mobile phones, wire-\\nless Internet, etc.) even when travelling or \\naway from office/home.\\n\\u2003\\u2003\\x83   Mobile workability: The convenience of \\nbeing able to work (using laptops, smart-\\nphones, etc.) from anywhere.\\n • There are three major expectations from the \\nadoption of mobile BI technology:\\n\\u2003\\u2003\\x83   Device maturity, i.e. the extent of the qual-\\nity of information that the mobile device \\ncan show the user.\\n\\u2003\\u2003\\x83   End-user expectations, i.e. user-friendliness, \\nuser-interactivity, compatibility of mobile \\napplications with desktop applications.\\n\\u2003\\u2003\\x83  Connectivity should be robust and secure.\\n • Mobile devices and mobile software/applica-\\ntions in the market, as of today:\\n\\u2003\\u2003\\x83  Mobile operating system (MOS)\\n\\u2003\\u2003\\x83  Apple iPad\\n\\u2003\\u2003\\x83  Apple iPhone\\n • Cloud computing can be defined as location-\\n independent computing, whereby shared servers \\nprovide data, software, and services to comput-\\ners and other devices as and when required.\\n • A familiar example of cloud computing is any \\nWeb-based email service like Hotmail, Yahoo! \\nMail, or Gmail.\\n • Why cloud computing? The answer is simple: \\nRapid implementation, ease of use, and sub-\\nscription pricing.\\n • Some benefits of using cloud computing are\\n\\u2003\\u2003\\x83  Software as a subscription.\\n\\u2003\\u2003\\x83  Reduced software maintenance.\\n\\u2003\\u2003\\x83  Increased reliability.\\n\\u2003\\u2003\\x83  Increased scalability.\\n\\u2003\\u2003\\x83  Cost reduction.\\n\\u2003\\u2003\\x83  Pay per use.\\n • Cloud solutions are made to support a large \\nnumber of users simultaneously.\\n • Barriers to cloud-based solutions and plat-\\nforms:\\n\\u2003\\u2003\\x83   T wo prime concerns: Data privacy and se-\\ncurity. Most of the enterprises are still hesi-\\ntant to move their critical business data off \\ntheir premises.\\n • ETL tools available with ERP systems can be \\nleveraged to extract, transform, and load exter-\\nnal data for a comprehensive BI solution.\\n • BI enables users to perform “what if” analysis.\\n • ERP systems cannot cater to the analytics \\nand reporting needs of the organization, but \\ntogether with BI they can support analytics \\nand reporting.\\n • ERP can transform data into information, but \\nBI tools are required to complete the transfor-\\nmation from information to intelligence.\\n • ERP plus BI equals more value.\\n • Social CRM requires dealing with conversa-\\ntions and relationships with social customers \\nin addition to the data or information that \\nyou might have about them. These conver-\\nsations and relationships take place not just \\nfrom the company to the consumer but also \\nfrom consumer to consumer.\\n • A few vendors such as SAS, SAP Oracle, \\nIBM, DataFlux, Information Builders, etc. \\nhave  already started addressing the challenges \\nthat Social CRM poses.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 407}, page_content='Connect Me (Internet Resources)\\n • http://www.information-management.com/issues/20010601/3492-1.html\\n • http://www.information-management.com/infodirect/20000721/2499-1.html\\n • http://www.information-management.com/issues/20000701/2352-1.html\\n • http://www.cio.com/article/498904/ERP_and_BI_A_Match_Made_in_Heav-\\nen_If_You_re_in_Data_Hell\\nMatch me\\nIt is for data input Basic operational reports\\nIt is for data retrieval Advanced analytics and reporting\\nBI ERP\\nERP BI\\nCharts, gauges, matrix Dashboard\\nColumn A Column B\\nTest Me Exercises\\nFill me\\n1.  T o further enhance its ERP package with BI \\ncapabilities, SAP came up with _______.\\n2. BI supports SAP in meeting the _______ and \\n_______ needs of the organization.\\n3. ERP software provides several business ben-\\nefits. For example, it provides _______ and \\n_______ of data across various units of the \\norganization.\\n4. ERP stands for _______ _______ _______.\\n5. Few examples of popular CRM systems  \\ninclude _______, _______, and _______.\\n6. Social CRM requires dealing with _______ \\nand _______ with social customers.\\n7. Some benefits of using cloud computing are: \\n_______, _______, _______, _______, \\n_______, etc.\\nSolution:\\n1. SAP BW (Business Warehouse)\\n2. Analytics and reporting\\n3. Consistency and reliability\\n4. Enterprise Resource Planning\\n5. Salesforce, Zoho, Sugar CRM\\n6. Conversations and relationships\\n7. Software as a subscription, reduced soft-\\nware maintenance, increased reliability, \\nincreased scalability, cost reduction\\nBI Road Ahead • 383'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 408}, page_content='384 • Fundamentals of Business Analytics\\nUnsolVed exerCises\\n1. “BI + ERP = increased value”. Explain giving example.\\n2. What are the key data security concerns for mobile BI? Explain.\\n3. Why is it important for Business Intelligence space to take into consideration the Social CRM? \\nExplain.\\n4. “BI on the cloud”. Why do you think this is important? Explain.\\n5. What are the benefits of BI in ERP? Explain.\\n6. What according to you are the differences between ERP and BI? Explain.\\n7. List a few popular CRM tools.\\n8. What are the benefits of integrating social media information into BI applications? What are the \\ndrawbacks?\\n9. Will organizations that embrace social BI be at a competitive advantage compared to companies \\nthat don’t?\\n10. Given the variability of freeform text, how can social media information be used?\\nSolution:\\nIt is for data input ERP\\nIt is for data retrieval BI\\nBI Advanced analytics and reporting\\nERP Basic operational reports\\nCharts, gauges, matrix Dashboard\\nColumn A Column B'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 409}, page_content='Attribute: The literal meaning is quality, characteristic, trait, or feature. In the context of RDBMS (Relational \\nDatabase Management System), a set of attributes are used to describe an entity. An entity is a physical or \\nabstract object about which we can store information. The relationship between entities is depicted using \\nan ER (Entity Relationship) model. While physically implementing the ER model, an entity gets converted \\ninto a table/relation and the attributes get converted into columns or fields. For example, think about a bank \\nsystem having several entities such as “Loan”, “Account”, “Customers”, etc. Let us describe the entity, \\n“Customers” using attributes such as CustomerID (10 digit integer, mandatory field), CustomerEmailID \\n(text variable length, case sensitive, typical format x@y), CustomerName, CustomerAddress, etc.\\nAlso refer to terms: Entities, ER (Entity Relationship) model, Relation and Relationship.\\nBalanced Scorecard (BSC): It is a strategic performance management framework used by organiza-\\ntions to measure and communicate their business performance. The concept of BSC was introduced by \\nDr. Robert S. Kaplan and David P . Norton. It suggests business performance to be looked at from four \\nperspectives: (i) financial – how do we look to our shareholders? (ii) customer – how do we look to our \\ncustomers? (iii) internal processes – what processes we must excel at? (iv) learning and growth – what \\nshould be done to build the competencies of the employee base?\\nAlso refer to terms: Dashboards, KPIs, Metrics, KRIs.\\nBusiness Analytics: The analysis of enterprise data from multiple perspectives to gauge and enhance \\nthe performance of business. Business analytics is heavily dependent on data. For its successful imple-\\nmentation, business analytics requires a high volume of high quality data. The challenge faced by busi-\\nness analytics remains the storage, integration, reconciliation of data from multiple disparate sources \\nacross several business functions and the continuous updates to the data warehouse.\\nAlso refer to term: BI component framework.\\nBusiness Driver: This is a term used in the Management field to describe the influence of a particular \\nfunction or activity on business performance. Business drivers are the force that causes/propels the \\nbusinesses to move/change in a certain way. Examples: changing economy, changing technology, \\nchanging workforce, changing labor laws, changing competitive markets, etc. In the context of \\nGlossary'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 410}, page_content='386 • Fundamentals of Business Analytics\\n“Business Intelligence component framework”, business driver is one of the four components analyzed \\nto gather data-related requirements. (Business requirements can be studied with reference to business \\ndrivers, business goals, business strategies, and business tactics.)\\nAlso refer to term: BI component framework.\\nBusiness Goal: In the context of “BI component framework”, business goal refers to the objectives that \\nbusinesses set out to achieve such as increase in customer base, increased market share, increase in pro-\\nductivity, increase in profitability, retention of employees, etc.\\nBusiness Intelligence (BI): Business Intelligence is about making available the right information in the \\nright format at the right time to the right decision makers. It supports fact-based decision making. It \\nfocuses on ensuring “single version of truth”. BI helps provide 360 degree perspective on the business. \\nAccording to Howard Dresner (he coined the term Business Intelligence in 1989), BI is a set of concepts \\nand methodologies to improve decision making in business through use of facts and fact-based systems.\\nAlso refer to terms: Business component framework, Data warehouse, Data marts, Data mining, and Business \\nanalytics.\\nBusiness Rules: This is a term typically used in the area of Business Process Management (BPM) and \\nworkflow automation. T raditionally, business rules or business logic is closely tied-to program logic. \\nBusinesses have seen huge program maintenance load as and when formula or computation logic \\nchanges. Hence the industry evolved techniques to represent business rules outside the program and \\nhave program code dynamically take the latest business rule for computation or workflow. Example: \\nInsurance claims processing workflow is associated with many rules for computing eligible claim \\namount. These rules may change often times based on competitive products, government regulations, \\nnew business models, and so on.\\nBusiness Strategies: Strategy is an approach designed to achieve a particular goal. In the context of BI \\ncomponent framework, it is the methodology adopted to accomplish business goals such as use of tech-\\nnology to achieve the business goal of increase in productivity. Example: to achieve the business goal of \\nemployee retention, businesses can look at initiatives such as employee welfare program, etc.\\nAlso refer to term: BI component framework.\\nBusiness Users: The users who leverage IT applications to conduct business operations or evolve new \\nstrategies. In the context of BI, business users or business executives request IT for data to make informed \\ndecisions.\\nAlso refer to terms: Casual users, Power users.\\nBusiness Value: Typically, business value is measured in terms of ROI (Return on Investment), ROA \\n(Return on Asset), TCO (T otal Cost of Ownership), TVO (T otal Value of Ownership), etc. Example: \\nROI is the returns that accrue from capital investment, and also includes the operational expenses. ROA \\nis the returns that accrue from capital investment only. TCO is the total cost incurred from the date of \\npurchase of an asset to the date of retirement. TVO differs from TCO in that it considers the benefits \\nof alternative investments. It is a comparative measure that evaluates the TCO and any additional ben-\\nefits, such as the mobility of laptops when compared to desktop computers.\\nAlso refer to terms: Business drivers, Business strategies, Business intelligence, BI component framework.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 411}, page_content='Glossary • 387\\nCardinality of Relation: In the context of RDBMS, cardinality of a relation is the number of records/\\ntuples in a table/relation. Example: A table “Sample” with a cardinality of four and degree three implies \\nthat the table has four records/tuples/rows and three attribute/columns/fields.\\nAlso refer to terms: Attributes, Entity, Relation, Relationship, RDBMS, ER model, Cardinality of relationship.\\nCardinality of Relationship: The cardinality of a relationship defines the type of relationship between \\ntwo participating entities. In other words, the cardinality of a relationship specifies how many instances \\nof an entity relate to one instance of another entity. There are four types of cardinality relationships. \\nThey are (i) one-to-one, (ii) one-to-many, (iii) many-to-one, (iv) many-to-many.\\nPlease note that the cardinality of a relationship differs from the cardinality of a relation. The cardinality \\nof a relation is the number of records/tuples in a relation.\\nAlso refer to terms: Attributes, Entity, Relation, Relationship, RDBMS, ER model, Cardinality of relation.\\nCasual Users: In the context of BI, casual users are information consumers. Examples of casual users \\nare: executives, senior management, etc. They work with pre-defined reports produced by power users.\\nAlso refer to term: Power users.\\nConceptual Data Model: In the context of RDBMS, a conceptual data model implies the identifica-\\ntion of entities and the relationships between the entities. Example: let us look at a college scenario \\nwhere a teacher can be a part of only one department but a department can have n number of teachers \\nbelonging to it. In this case, there are two entities: (i) a teacher entity and (ii) a department entity. The \\nrelationship or the cardinality of the relationship is 1:N between Department and T eacher entities.\\nAlso refer to terms: Data model, Entity relationship model, Dimensional data model, Logical data model, \\nPhysical data model.\\nConstraints: The literal meaning is restriction, limitation. In RDBMS, constraints imply the restric-\\ntions imposed on the column(s) of a table. Example: a NOT NULL constraint on a column implies that \\nit is mandatory to read in a value in the column. A Primary Key constraint on a column implies that the \\ncolumn can take in only unique and not null values into it. A Foreign Key constraint on a column \\nimplies that the column can only take in values existing in the primary key column of its own table or \\nanother table to which it refers to. A foreign key column can take in a null value or a duplicate value. A \\nUnique constraint on a column implies that the column cannot have duplicate values. The column \\nhowever can take in null values.\\nAlso refer to term: Data quality.\\nCritical Success Factor (CSF): This is a term commonly used in management to focus attention on \\nactivities that must get done flawlessly in order to meet the business goal. The CSFs will take into con-\\nsideration constraints such as staffing, financial investments, competency development that influences \\nthe act of meeting goals positively.\\nAlso refer to terms: Balanced scorecard, Dashboard.\\nCube: The OLAP tools allow the user to turn data stored in relational databases into meaningful, easy  \\nto navigate business information by rearranging data in multidimensional format termed as a cube.  \\nThe dimensions of a cube represent distinct categories for analyzing business data. Categories such as \\ntime, geography, or product line breakdowns are typical cube dimensions. Example: The sales amount  '),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 412}, page_content='388 • Fundamentals of Business Analytics\\nof a retail store being analyzed along the time dimension, region dimension, and product category  \\ndimension.\\nAlso refer to term: Dimensional data modeling.\\nDatabase: A database is an organized collection of interrelated data. Data in the database: (i) is inte-\\ngrated; (ii) can be shared; (iii) can be concurrently accessed.\\nAlso refer to terms: Attribute, Entity, Relation, Relationship, RDBMS.\\nDashboard: The term has come from the automobile industry. Just like a vehicle dashboard gives a \\nclear idea about the status of the car such as the speed at which the car is being driven, the fuel indicator \\nthat indicates the amount of fuel, a corporate dashboard allows one to feel the pulse of the enterprise. \\nA look at the dashboard indicates the “pulse” in key areas of business performance and also alerts deci-\\nsion makers in comparison with thresholds.\\nAlso refer to terms: KPIs, Balanced scorecard.\\nData Governance: In the context of BI component framework, data governance is about proper storage, \\nmaintenance, management of enterprise data to ensure quality. Data governance is a quality regime that \\nincludes ensuring accuracy, consistency, completeness, and accountability of data. There are policies that \\ngovern the use of data in an organization. This is done primarily to secure data from hackers and data from \\ninadvertently leaking out. Data governance also ensures compliance with regulations. It helps to define stan-\\ndards that are required to maintain data quality. The distribution of roles for governance of data is as follows:\\n • Data ownership\\n•\\t Data stewardship\\n • Data custodianship\\nAlso refer to terms: Enterprise, Data integrity constraint.\\nData Integrity Constraints: These are the constraints imposed to ensure data integrity in RDBMS. \\nExample: Entity Integrity Constraint (Primary Key Constraint), Referential Integrity Constraint (Foreign \\nKey Constraint), etc. An entity integrity constraint on a column implies that the column can take in only \\nunique and not null values into it. A Foreign Key constraint on a column implies that the column can \\nonly take in values existing in the primary key column of its own table or another table to which it refers \\nto. A foreign key column can take in a null value or a duplicate value. A Unique constraint on a column \\nimplies that the column cannot have duplicate values. The column, however, can take in null value.\\nAlso refer to terms: Data integrity constraints, Data quality.\\nData Mart: In the context of BI, a data mart is a focused subset of a data warehouse that deals with a \\nsingle area of data and is organized for quick analysis. A data mart can be dependent or independent. A \\ndependent data mart is sourced from data from the enterprise-wide data warehouse. An independent \\ndata mart is sourced directly from the OLTP systems.\\nAlso refer to terms: Data warehouse, Database, Data mining.\\nData Mining: In the context of BI, data mining is the process of processing large volumes of data stored \\nin the data warehouse, searching for patterns and relationships within that data.\\nAlso refer to terms: Data warehouse, Database, Data marts.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 413}, page_content='Glossary • 389\\nData Model: It is a conceptual data tool to describe data, data relationships, data semantics, and \\n consistency constraints. There are two popular data models:\\n • Object Based Logical Model: ER Model.\\n • Record Based Logical Model:\\n\\uf0a7 Hierarchical Data Model: Example: IMS.\\n\\uf0a7 Network Model: Example: IDMS.\\n\\uf0a7 Relational Data Model: Relational data model uses a collection of tables (relations) to rep-\\nresent data and the relationships among those data. Example: Oracle, Sybase.\\nAlso refer to terms: Conceptual model, Logical model, Physical model.\\nData Quality: It is about accuracy, consistency, completeness, and timeliness of data. Example: Let us \\nconsider a list of participants attending a training program. The participants have been asked to provide \\ntheir name, email id, and address for further communication. All the participants clearly provide the \\nasked details. The data here is accurate. A couple of participants, however, do not provide their address. \\nThe data here is incomplete. This whole process took two days time but the training coordinator \\nrequired this information in a day’s time as he wanted the information to reach the printer who would \\nthen print out participation certificates for the participants. As the information was delayed, the cer-\\ntificates could not be handed over to the participants. This is about the timeliness of data.\\nAlso refer to terms: Constraints, Data governance, Data integrity constraint.\\nData Warehouse: In terms of BI, data warehouse is a repository which stores integrated information \\nfrom multiple disparate sources for efficient querying and analysis. The key characteristics of data ware-\\nhouse are: (i) subject-centric, (ii) integrated, (iii) non-volatile, (iv) time-invariant. There are two \\napproaches to building a data warehouse: (i) the top–down approach given by Bill Inmon and (ii) the \\nbottom–up approach given by Ralph Kimball.\\nAlso refer to terms: Data marts, Database, Data mining.\\nDDL (Data Definition Language): In the context of RDBMS, it allows a user to define and alter the \\nstructure and the organization of the data to be stored and the relationships among the stored data \\nitems. A few common DDL statements are: Create table < table name > …, Drop Table < table name \\n> …., Create Index …., Drop Index …, etc.\\nAlso refer to terms: Database, Data model, Entity relation, DML.\\nDimension Table: In the context of multidimensional modeling, a dimension table contains attributes \\nthat describe fact records on the fact table. Some of these attributes provide descriptive information; \\nothers are used to specify how fact table data should be summarized to provide useful information to \\nthe analyst. Refer to Chapter 7 for more details.\\nAlso refer to terms: Dimensional model, Star schema, Snowflake schema, Fact.\\nDimensional Model: A data model considered apt for OLAP . In the context of dimensional modeling, \\nit is also known as Star schema because in dimensional modeling there is a large central fact table with \\nmany dimensional tables surrounding it.\\nAlso refer to terms: Dimensional table, Star schema, Snowflake schema, Fact.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 414}, page_content='390 • Fundamentals of Business Analytics\\nDML (Data Manipulation Language): In the context of RDBMS, DML statements let a user or \\napplication program update the database by allowing adding new data, deleting the existing data, and \\nmodifying the existing data. A few common DML statements are: Insert into table …, delete from table \\n…, update table …, select * from table….\\nAlso refer to terms: Database, Data model, Entity relation, DDL.\\nDSS (Decision Support System): An IT application system that supports the decision making process \\nof business managers and leaders. Example: Customers at a car showroom use an application to provide \\ndetails such as model of the car, power engine, diesel or petrol, automatic transmission or manual trans-\\nmission, mileage etc, and the application can provide them with the range of cars (to select from) with \\nthe specified features. This application supports the decision making process of the customers.\\nAlso refer to terms: EIS, ERP , BI.\\nEnterprise: A Company or Organization. A typical enterprise will have functions such as Human \\nResources, Sales, Marketing, Finance, Production, Information T echnology (IT), etc.\\nExecutive Information System (EIS): A system that supports the decision making process of strategic \\nmanagers.\\nAlso refer to terms: DSS, ERP , BI.\\nEntity: It is an object or concept about which business user wants to store information. Example: A \\nproject idea is an entity. A business user can store information about the project such as project code, \\nproject manager, project location from where the project will be executed, the number of project team \\nmembers, the project start date, the project end date, etc.\\nAlso refer to terms: Attributes, ER (Entity Relationship) model, Relation, Relationship.\\nER (Entity Relationship) Model: Modeling the databases using ER diagrams is called ER Modeling. \\nIt is one of the many ways to represent business findings in pictorial format. ER model helps to identify \\nall entities and the relationships that exist between the entities.\\nAlso refer to terms: Attributes, Entities, Relation, Relationship.\\nEnterprise Resource Planning (ERP): This refers to a class of packaged software application that \\nautomates business processes of several important functions of a business enterprise. ERP provides uni-\\nfied data store for functions such as Finance, HR, Purchase, Sales, Marketing, and so on. ERP can \\nsupport with some pre-defined reports and interfaces needed for ad hoc reporting or the analytical \\nneeds of the enterprise.\\nAlso refer to terms: DSS, ERP , EIS.\\nExtraction: In building a data warehouse, extractions refers to the process of collecting/obtaining data \\nfrom multiple disparate data sources. The data sources are varied. Example: Data could come from .txt file/.\\nxls file/.csv file/any relational database. Data sources could also be in different geographical locations.\\nAlso refer to terms: Data marts, Database, Data warehouse, Data mining, Transformation, Loading.\\nFact: In the context of multidimensional modeling, a fact is a measure. It is usually a numeric value that \\ncan be aggregated. Example: SalesAmount, UnitQuantity, etc.\\nAlso refer to terms: Dimensional table, Dimensional model, Star schema, Snowflake schema.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 415}, page_content='Glossary • 391\\nFact Constellation: The constellation schema is shaped like a constellation of stars (i.e. star schemas). \\nThis is more complex than star or snowflake schema variations, as it contains multiple fact tables. This \\nallows the dimension tables to be shared among the various fact tables. It is also called “galaxy schema”. \\nThe main disadvantage of the fact constellation is more complicated design because multiple aggrega-\\ntions must be taken into consideration. Refer to Chapter 7 for more details.\\nAlso refer to terms: Star schema, Snowflake schema, Dimensional model, Dimensional table, Fact.\\nFact Table: In the context of multidimensional modeling, a fact is a measure. It is usually a numeric \\nvalue that can be aggregated. Example: SalesAmount, UnitQuantity, etc. It is central to a Star or \\nSnowflake schema, and captures the data that measures the organization’s business operations. It usually \\ncontains large number of rows.\\nAlso refer to terms: Star schema, Snowflake schema, Dimensional model, Dimensional table, Fact.\\nGrains: In the context of multidimensional modeling, given the hierarchy as Year → Quarter → Month \\n→ Week → Day, Day is said to be the grain. It refers to level at which data is summarized.\\nAlso refer to terms: Star schema, Snowflake schema, Dimensional model, Dimensional table, Fact, Hierarchies.\\nHierarchies: In the context of multidimensional modeling, an example of a hierarchy is Year → Quarter \\n→ Month → Week → Day. Year is said to be at the highest level in the hierarchy and Day is said to be \\nat the lowest level in the hierarchy.\\nAlso refer to terms: Star schema, Snowflake schema, Dimensional model, Dimensional table, Grains.\\nHOLAP (Hybrid On-Line Analytical Processing): In the context of OLAP (on-line analytical pro-\\ncessing), this model combines the features of ROLAP (Relational On-Line Analytical Processing) and \\nMOLAP (Multidimensional On-Line Analytical) processing. This model has the scalability feature of \\nrelational tables and the multiple perspectives of a cube.\\nAlso refer to terms: OLTP , OLAP , ROLAP , MOLAP .\\nKey Performance Indicators (KPIs): KPIs are important business health indicators used to steer \\nthe team member actions to meet business goals. KPIs influence the way business team members \\ndo their jobs, approach their daily work, and deal with alerts. KPIs help people focus on the “big \\npicture”.\\nAlso refer to terms: balanced scorecard, measures, metrics and KRIs.\\nKey Result Indicators (KRIs ): These tell us how we have done. Example: A feedback of 4.5 on a scale \\nof 5 (with 5 being the highest) for measuring the effectiveness of the learning program implies that the \\nlearning program was effective.\\nAlso refer to terms: Balanced scorecard, Measures, Metrics, KPIs.\\nLoading : In building a data warehouse, loading refers to the process of loading cleansed, corrected, and \\ntransformed data into the data warehouse or data mart. It is the third step in building a data warehouse. \\nThe first step is extracting the data from multiple disparate sources and the second is transforming the \\ndata to have it in alignment with a universal data warehouse format.\\nAlso refer to terms: Data warehouse, Data mart, Data mining, Extraction, Transformation.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 416}, page_content='392 • Fundamentals of Business Analytics\\nMetadata: It is the information about the data. In other words, it is data about data. This is the layer of \\nthe data warehouse which stores the information like the name and type of data sources, data about the \\ntransformation process, date and time of extraction, target databases, date and time of data loading, etc. \\nThere are four categories of metadata: application metadata, business metadata, process metadata, and \\ntechnical metadata.\\nAlso refer to terms: Database, Data warehouse, Data mart.\\nMetrics: Metrics refer to a system of measures/facts based on standard unit of measurement with a \\nbusiness context. In business management terms, metrics are used to track business performance in \\nnumeric terms. Examples include employee attrition rate, product defect rate, frequency of goods \\nreturned, etc.\\nAlso refer to terms: Balanced scorecard, Measures, KPIs, KRIs.\\nMOLAP (Multidimensional On-Line Analytical Processing): In the context of OLAP (On-Line \\nAnalytical Processing), this data model helps view the data in the form of a cube. MOLAP requires pre-\\ncomputation and storage of information in the cube. The advantages of using MOLAP are: (i) Fast \\nquery performance due to optimized storage; (ii) multidimensional indexing and caching; (iii) smaller \\non-disk size of data compared to relational databases.\\nAlso refer to terms: OLTP , OLAP , ROLAP , MOLAP .\\nNormalization: In the context of RDBMS, it is a process followed to organize data such that the redun-\\ndancy of data is kept to the minimum possible level. It is a refinement process. It helps in removing \\nanomalies present in insert, update and delete operations. Few normal forms are 1NF , 2NF , 3NF , \\nBCNF , etc.\\nAlso refer to terms: ER model, Database, OLTP , OLAP , Dimensional model.\\nObject Based Logical Data Model: ER model is a widely known object-based logical model. It is used \\nto describe data at the conceptual and the view level. The ER model is based on the perception of the \\nreal world that consists of a collection of basic objects called entities, and of relationships among these \\nobjects.\\nAlso refer to terms: Database, ER model, Dimensional model, Entity, Attributes.\\nODS (Operational Data Store): In the context of data warehouse, ODS is a database to store data \\nextracted and integrated from multiple sources for additional operations on the data. The data may be \\npassed back and forth to operational systems for updates and to the data warehouse for reporting. In \\nother words, it is a repository where clean operational data of the enterprise is placed. It helps to answer \\nad hoc queries for operational decision making.\\nAlso refer to terms: OLTP , OLAP , Database, Data warehouse, Data marts, Staging.\\nOLAP (On-Line Analytical Processing): In OLAP , data is held in dimensional form rather than rela-\\ntional form. OLAP’s life blood is multidimensional data. OLAP tools are based on multidimensional \\ndata model. The multidimensional data model views data in the form of a data cube. Example: The sales \\nfigure of a retail outlet analyzed along the product categories, time, and region dimension.\\nAlso refer to terms: OLTP , ROLAP , MOLAP , HOLAP .'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 417}, page_content='Glossary • 393\\nOLTP (On-Line Transactional Processing): OLTP systems refer to a class of systems that manage \\ntransaction-oriented applications. These applications are mainly concerned with the entry, storage, \\nupdate, and retrieval of data. Example: Airline/railway ticket reservation, point of sale system (POS) at \\na supermarket store.\\nAlso refer to terms: OLAP , ROLAP , MOLAP , HOLAP .\\nPhysical Data Model: Physical data model is a representation of how the model will be built in the \\ndatabase. A physical database model will exhibit all the table structures, including the column names, \\nthe columns data type, the column constraints, primary key, foreign key, and the relationships between \\ntables. Example: A project table.\\nProjectCode Varchar(5) Primary Key\\nProjectName Varchar(30) Not Null\\nProjectLocation Varchar(30) Not Null\\nProjectStartDate Date\\nProjectEndDate Date\\nColumnName Data type and length DescriptionColumn Name Constraints\\nAlso refer to terms: Conceptual data model, Logical data model, Data model, ER model, Dimensional \\nmodel.\\nPivot/Cross Tab: In data processing, a pivot table is a data summarization tool found in data visualiza-\\ntion programs such as spreadsheets (Micorsoft Excel, Google Docs, etc.). Pivot is also called as rotate. \\nIn order to provide an alternative representation or perspective of the data, the pivot operation rotates \\nthe data axes in view.\\nAlso refer to terms: OLTP , OLAP , MOLAP , ROLAP , HOLAP .\\nPower Users: In the context of BI, there are essentially two kinds of users: casual users or consumers of \\ninformation and power users. They are the producers of information. They rely on ad hoc query and \\nother explorative mechanisms. Examples of power users are developers, analysts, etc.\\nAlso refer to terms: Casual users.\\nQuery: In general, a query is a form of questioning, a line of enquiry. In the context of RDBMS, a \\nquery is essentially a request that a user makes on the database to retrieve data. Database queries are \\nperformed using a specific language termed Structured Query Language (SQL).\\nAlso refer to terms: Database, DDL, DML.\\nRDBMS: It is a class of system software that manages digital data and is based on relational theory \\nconcepts. The relational model uses a collection of tables (relations), each of which is assigned a unique \\nname, to represent both data and the relationships among those data. It is a type of DBMS that stores \\ndata in the form of related tables.\\nAlso refer to terms: Database.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 418}, page_content='394 • Fundamentals of Business Analytics\\nReal Time Data Warehouse: Real time data warehouse is known to house real time business data. If \\nsuch a data warehouse is queried, it will reflect the state of the business at the time the query was run.\\nAlso refer to terms: Database, Data warehouse, Data marts.\\nRelation/Table: A data structure that is based on the relational model and stores the data in the form \\nof rows and columns. Example: Employee Table as shown below.\\n101 Alex Senior Project Manager\\n103 Felix Software Engineer\\nColumnName EmployeeName DescriptionEmployeeID EmployeeDesignation\\nAlso refer to terms: Entity, Attributes, Relationships, ER model.\\nRelationships: It illustrates how two entities share information in the database structure. Example: \\nLet us consider two entities: Employee and Project. An employee can work on only one project \\nwhereas a project can have several employees allocated to it. The relationship between Employee and \\nProject is 1:M.\\nAlso refer to terms: Entity, Attributes, ER model.\\nROLAP: In ROLAP , data is stored in a relational database. ROLAP differs significantly from MOLAP \\nin that it does not require the pre-computation and storage of information. Instead, ROLAP tools \\naccess the data in a relational database and generate SQL queries to calculate information at the appro-\\npriate level when an end user requests it.\\nAlso refer to terms: OLTP , OLAP , MOLAP , HOLAP.\\nSchema: In a relational database schema refers to a collection of database tables, the fields in each table, \\nand the relationships between fields and tables. Schemas are generally stored in a data dictionary.\\nAlso refer to terms: Database, Relation, Attributes, Entity, Data constraints.\\nSemi-Structured Data: Semi-structured data does not conform to any data model, i.e. it is difficult to \\ndetermine the meaning of data. Also, the data cannot be stored in rows and columns as in a database. \\nSemi-structured data, however, has tags and markers which help to group the data and describe how the \\ndata is stored, giving some metadata, but it is not sufficient for management and automation of data. \\nExample: XML (eXtensible Markup Language).\\nAlso refer to terms: Unstructured data, Structured data.\\nSnowflake Schema: In the context of multidimensional data model, Snowflake schema is a complex \\ndata warehouse schema. It has a single, central fact table surrounded by normalized dimension hierar-\\nchies. In the Snowflake schema, dimensions are present in a normalized form in multiple related tables. \\nA Snowflake structure materializes when the dimensions of a star schema are detailed and highly struc-\\ntured, having several levels of relationship, and the child tables have multiple parent tables. Refer to \\nChapter 7 for more details.\\nAlso refer to terms: Star schema, Fact constellation.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf', 'page': 419}, page_content='Glossary • 395\\nStaging Area: A data staging area can be defined as an intermediate storage area that falls in between \\nthe operational/transactional sources of data and the data warehouse (DW) or data mart (DM). \\nAlso refer to terms: Data warehouse, Data marts, Extraction, Transformation, Loading, ODS.\\nStar Schema: It is the simplest data warehouse schema. It resembles a star. The center of the star consists \\nof one or more fact tables and the points radiating from the center are the dimensions table. Refer to \\nChapter 7 for more details.\\nAlso refer to terms: Snowflake schema, Fact constellation.\\nStructured Data: Data coming from databases such as Access, OLTP systems, SQL as well spreadsheets \\nsuch as Excel, etc. are all in the structured format. Structured data conforms to a data model. Here, the \\ndata is organized in fixed/variable length fields of a record/file. Example: A project table with its schema \\ndefinition.\\nProjectCode Varchar(5) Primary Key\\nProjectName Varchar(30) Not Null\\nProjectLocation Varchar(30) Not Null\\nProjectStartDate Date\\nProjectEndDate Date\\nColumnName Data type and length DescriptionColumn Name Constraints\\nFew records in the project table:\\nProjectName ProjectLocation ProjectstartDate\\nP1001 FinanceProject Mexico 22 July 2011 22 Oct. 2011\\nP1002 HealthProject New Jersey 22 Aug 2011 22 Nov. 2011\\nProjectCode ProjectEndDate\\nAlso refer to terms: Unstructured data, Semi-structured data.\\nSurrogate Key: Surrogate key is a substitution for the natural primary key. It is simply a unique identi-\\nfier or number for each row that can be used for the primary key to the table. The only requirement for \\na surrogate primary key is that it is unique for each row in the table. Surrogate keys are always integer \\nor numeric.\\nAlso refer to terms: Relation, RDBMS, Data integrity constraint.\\nTransformation: In building a data warehouse, transformation refers to the process of converting the \\ndata from host or legacy format to data warehouse format. These transformations may include opera-\\ntions like making fields into uniform length, converting text to upper case, changing data format to one \\nstandard, and so on.\\nAlso refer to terms: Data marts, Database, Data warehouse, Data mining, Extraction, Loading.'),\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32e601ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Data into Text Chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "569556df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Chunks 4596\n"
     ]
    }
   ],
   "source": [
    "text_chunks=text_split(extracted_data)\n",
    "print(\"Length of Text Chunks\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d422f3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 0}, page_content=', Intelligence \\nRoadmap \\n~ lhe Complete \\nProject Lifecycle for \\nDecision-Support \\nApplications \\nLarissa T. Moss ¢ Shaku Atre \\nForeword by Edward Yourdon'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 1}, page_content='Digitized by the Internet Archive \\nin 2022 with funding from \\nKahle/Austin Foundation \\nhttps://archive.org/details/businessintelligo00Omoss'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 2}, page_content='Business Intelligence Roadmap'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 3}, page_content='Addison-Wesley Information Technology Series \\nCapers Jones and David S. Linthicum, Consulting Editors \\nThe information technology (IT) industry is in the public eye now more than ever before because of a number of \\nmajor issues in which software technology and national policies are closely related. As the use of software expands, \\nthere is a continuing need for business and software professionals to stay current with the state of the art in soft-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 3}, page_content='ware methodologies and technologies. The goal of the Addison-Wesley Information Technology Series is to \\ncover any and all topics that affect the IT community. These books illustrate and explore how information technology \\ncan be aligned with business practices to achieve business goals and support business imperatives. Addison-Wesley \\nhas created this innovative series to empower you with the benefits of the industry experts’ experience.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 3}, page_content=\"For more information point your browser to www.awprofessional.com/itseries \\nSid Adelman, Larissa Terpeluk Moss, Data Warehouse \\nProject Management. ISBN: 0-201-61635-1 \\nSid Adelman et al., Impossible Data Warehouse \\nSituations: Solutions from the Experts. ISBN: 0-201- \\n76033-9 \\nWayne Applehans, Alden Globe, and Greg Laugero, \\nManaging Knowledge: A Practical Web-Based \\nApproach. ISBN: 0-201-43315-X \\nDavid Leon Clark, Enterprise Security: The Manager's \\nDefense Guide. ISBN: 0-201-71972-X\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 3}, page_content='Frank P. Coyle, XML, Web Services, and the Data \\nRevolution. ISBN: 0-201-77641-3 \\nKevin Dick, XML, Second Edition: A Manager’s Guide. \\nISBN: 0-201-77006-7 \\nJill Dyché, e-Data: Turning Data into Information with \\nData Warehousing. ISBN: 0-201-65780-5 \\nJill Dyché, The CRM Handbook: A Business Guide \\nto Customer Relationship Management. ISBN: 0-201- \\n73062-6 \\nPatricia L. Ferdinandi, A Requirements Pattern: \\nSucceeding in the Internet Economy. ISBN: 0-201- \\n73826-0'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 3}, page_content=\"73826-0 \\nDavid Garmus and David Herron, Function Point \\nAnalysis: Measurement Practices for Successful \\nSoftware Projects. ISBN: 0-201-69944-3 \\nJohn Harney, Application Service Providers (ASPs): A \\nManager's Guide. ISBN: 0-201-72659-9 \\nInternational Function Point Users Group, /T \\nMeasurement: Practical Advice from the Experts. \\nISBN: 0-201-74158-X \\nCapers Jones, Software Assessments, Benchmarks, and \\nBest Practices. ISBN: 0-201-48542-7 \\nRavi Kalakota and Marcia Robinson, e-Business 2.0:\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 3}, page_content='Roadmap for Success. ISBN: 0-201-72165-1 \\nRavi Kalakota and Marcia Robinson, Services Blueprint: \\nRoadmap for Execution. ISBN: 0-321-15039-2 \\nGreg Laugero and Alden Globe, Enterprise Content \\nServices: Connecting Information and Profitability. \\nISBN: 0-201-73016-2 \\nDavid S. Linthicum, B2B Application Integration: e- \\nBusiness-Enable Your Enterprise. ISBN: 0-201-70936-8 \\nDavid S. Linthicum, Enterprise Application Integration. \\nISBN: 0-201-61583-5 \\nDavid S. Linthicum, Next Generation Application'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 3}, page_content='Integration: From Simple Information to Web Services. \\nISBN: 0-201-84456-7 \\nSergio Lozinsky, Enterprise-Wide Software Solutions: \\nIntegration Strategies and Practices. ISBN: 0-201- \\n30971-8 \\nAnne Thomas Manes, Web Services: A Manager’s \\nGuide. ISBN: 0-321-18577-3 \\nLarissa T. Moss and Shaku Atre, Business Intelligence \\nRoadmap: The Complete Project Lifecycle for Decision- \\nSupport Applications. ISBN: 0-201-78420-3 \\nBud Porter-Roth, Request for Proposal: A Guide to'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 3}, page_content='Effective RFP Development. ISBN: 0-201-77575-1 \\nRonald G. Ross, Principles of the Business Rule \\nApproach. ISBN: 0-201-78893-4 \\nDan Sullivan, Proven Portals: Best Practices for \\nPlanning, Designing, and Developing Enterprise \\nPortals. ISBN: 0-321-12520-7 \\nKarl E. Wiegers, Peer Reviews in Software: A Practical \\nGuide. ISBN: 0-201-73485-0 \\nRalph R. Young, Effective Requirements Practices. \\nISBN: 0-201-70912-0 \\nBill Zoellick, CyberRegs: A Business Guide to Web'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 3}, page_content='Property, Privacy, and Patents. ISBN: 0-201-72230-5'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 4}, page_content='Business Intelligence \\nRoadmap \\nThe Complete Project Lifecycle for \\nDecision-Support Applications \\nLarissa T. Moss, Shaku Atre \\nvv Addison-Wesley \\nBoston « San Francisco * New York * Toronto * Montreal \\nLondon * Munich ° Paris * Madrid \\nCapetown * Sydney * Tokyo * Singapore * Mexico City'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 5}, page_content='Many of the designations used by manufacturers and sellers to distinguish their products are \\nclaimed as trademarks. Where those designations appear in this book, and Addison-Wesley was \\naware of a trademark claim, the designations have been printed with initial capital letters or in all \\ncapitals. \\nThe authors and publisher have taken care in the preparation of this book, but make no expressed \\nor implied warranty of any kind and assume no responsibility for errors or omissions. No liability'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 5}, page_content='is assumed for incidental or consequential damages in connection with or arising out of the use of \\nthe information or programs contained herein. \\nThe publisher offers discounts on this book when ordered in quantity for bulk purchases and spe- \\ncial sales. For more information, please contact: \\nU.S. Corporate and Government Sales \\n(800) 382-3419 \\ncorpsales@pearsontechgroup.com \\nFor sales outside of the U.S., please contact: \\nInternational Sales \\n(317) 581-3793'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 5}, page_content='(317) 581-3793 \\ninternational@pearsontechgroup.com \\nVisit Addison-Wesley on the Web: www.awprofessional.com \\nLibrary of Congress Cataloging-in-Publication Data \\nMoss, Larissa Terpeluk. \\nBusiness intelligence roadmap : the complete project lifecycle for decision-support \\napplications / Larissa T. Moss, Shaku Atre. \\np. cm. \\nIncludes bibliographical references and index. \\nISBN 0-201-78420-3 (pbk. : alk. paper) \\n1. Business intelligence 2. Decision support systems. I. Atre, S., 1940— II. Title.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 5}, page_content=\"HD38.7 .M67 2003 \\n658.4'03—dc21 \\n2002026196 \\nCopyright © 2003 by Pearson Education, Inc., Larissa T. Moss, and Shaku Atre \\nAll rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or \\ntransmitted, in any form, or by any means, electronic, mechanical, photocopying, recording, or \\notherwise, without the prior consent of the publisher. Printed in the United States of America. \\nPublished simultaneously in Canada.\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 5}, page_content='For information on obtaining permission for use of material from this work, please submit a writ- \\nten request to: \\nPearson Education, Inc. \\nRights and Contracts Department \\n75 Arlington Street, Suite 300 \\nBoston, MA 02116 \\nFax: (617) 848-7047 \\nISBN 0-201-78420-3 \\nText printed on recycled paper \\n6789 10 11—DOC—09080706 \\nSixth printing, February 2006'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 6}, page_content='DEDICATION \\nTo my soul mate, Donald P. Sherman, \\nwhose love and support have encouraged me to \\nachieve goals that once seemed unreachable and \\nto face life’s events that at times seemed unbearable. \\n—Larissa T. Moss \\nTo Tante Lisel, and to my mother. \\n—Shaku Atre'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 7}, page_content='Meme? @ xa eats. tem gc Lovie ’ : \\nOO U senses: in ty Agee Vet 7 \\naeag”** ‘ ’ a \\nGeom od (nd . Sat oe hb baw a \\nDt enter pre Me oar ecttitaee = Spend ts fielded 3 + comma) age 9 ap” ths @ aoBy a \\n© mre pais: ap est ig aoe eet \\nfer p@ite: bei beasties aK» ab pennevt ein & \\naot te. Rr aie Si ee a ae a if oe \\nChopats © 1 oruenirtadsa thane nati Tencd en OF : joni mguny oro Lggny burs eoudl hegenec tan san] mow : — \\nDed oes cay? os Neila raced tie ‘evaitlon a :'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 7}, page_content='raat ei : mee tym indents an es is Sant us 7 \\nWF) ter t? sai . ; = \\nWe qeasr - ae sear _——_— - ae - \\nae Ore et ee oll : 7 : \\nNapee “ares Pg Vik a - \\n—— eee Gate OS — es wl Pee @ow 4 ~- © \\nSyeee tne © leaeleraewie of but dos.) Snel of = Le - a => —— : \\na eT a ‘ a. \\nSe 23710 ° OR. | Seo \\nee en ore ® coals a me © —_ \\n126% ake ans \\nCBA 411i \\na > -_ \\n—_ \\nOF \\n= Yr Hie” \\n| (patig) O 7s @ hearer, 7 sbhne O.. oa FV \\nCh tighty sass + 1) pt 1d Gh oe me wey \\nteenie’ A} ow bem 0 te ns Qe ad ;'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 7}, page_content='athiy um wide ad Ocan eons = 6! *s @ = a \\nPu hte) Stringer rah yp Cates <= \\nBer Se idne « laering pe cepaty oy Came e \\nOo tenet & \\nAcar Oie oon, ip \\nae co Coton ts Cnpeertns Ge rf \\n24 ire: writ Jee OH \\nGeer 1 7 is 7 T) Vas ji 7 = ry \\nVe Sco clas i oF \\noe rag! ~« @ehioye * as \\nwm 4) IU 1d ee ey \\nMo 4G)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 8}, page_content='Contents \\nAbout the Authors xvii \\nForeword xix \\nPreface xxi \\nThe Purpose of This Book xxii \\nComplexity xxii \\nStep-by-Step Guide xxii \\nHow This Book Is Organized xxiii \\nPart I: Stages and Steps xxiv \\nPart II: Ata Glance xxv \\nHow to Use This Book  xxvi \\nWho Should Read This Book xxvi \\nBusiness Representatives xxvi \\nBusiness Sponsors xxvi \\nProject Managers xxviii \\nTechnicians xxvix \\nComments xxx \\nAcknowlegments xxxi \\nPARTI STAGES AND STEPS 1 \\nChapter Zero Guide to the Development Steps 3'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 8}, page_content='Business Intelligence Definition 4 \\nBI Decision-Support Initiatives 5 \\nDevelopment Approaches 5 \\nThe Traditional Development Approach 6 \\nThe Cross-Organizational Development Approach 8 \\nEngineering Stages and the Development Steps 11 \\nParallel Development Tracks 17 \\nBI Project Team Structure 20 \\nThe Core Team 20 \\nThe Extended Team 23 \\nThe BI Arbitration Board 26 \\nvii'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 9}, page_content='Viii Contents \\nJustification for Using This Project Lifecycle Guide 26 \\nBibliography and Additional Reading 27 \\nChapter One Step 1: Business Case Assessment 29 \\nBusiness Justification 31 \\nBusiness Drivers 33 \\nBusiness Analysis Issues 35 \\nInformation Needs 35 \\nTypes of Data Sources 35 \\nSource Data Quality 37 \\nCost-Benefit Analysis 37 \\nRisk Assessment 40 \\nBusiness Case Assessment Activities 45 \\nDeliverable Resulting from These Activities 48 \\nRoles Involved in These Activities 49'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 9}, page_content='Risks of Not Performing Step 1 49 \\nBibliography and Additional Reading 50 \\nChapter Two Step 2: Enterprise Infrastructure Evaluation \\nStep 2, Section A: Technical Infrastructure Evaluation 53 \\nThe Hardware Platform 54 \\nControlled Chaos 54 \\nHardware Platform Requirements 55 \\nThe Middleware Platform 57 \\nDBMS Gateways 58 \\nThe DBMS Platform 58 \\nCriteria for Selecting a DBMS 59 \\nTechnical Infrastructure Evaluation Activities 61 \\nDeliverables Resulting from These Activities 62'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 9}, page_content='Roles Involved in These Activities 63 \\nRisks of Not Performing Step 2, Section A 63 \\nStep 2, Section B: Nontechnical Infrastructure Evaluation 64 \\nThe Effects of Stovepipe Development 65 \\nThe Need for Nontechnical Infrastructure 66 \\nEnterprise Architecture 68 \\nEnterprise Standards 71 \\nNontechnical Infrastructure Evaluation Activities 75 \\nDeliverable Resulting from These Activities 76 \\nRoles Involved in These Activities 77 \\na) |'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 10}, page_content='Contents ix \\nRisks of Not Performing Step 2, Section B 78 \\nBibliography and Additional Reading 78 \\nTechnical Infrastructure Evaluation 78 \\nNontechnical Infrastructure Evaluation 79 \\nChapter Three Step 3: Project Planning 81 \\nManaging the BI Project 83 \\nDefining the BI Project 84 \\nProject Goals and Objectives 85 \\nProject Scope 85 \\nProject Risks 85 \\nProject Constraints 86 \\nAssumptions 87 \\nChange-Control Procedures 88 \\nIssues Management Procedures 90 \\nPlanning the BI Project 90'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 10}, page_content='Activities and Tasks 90 \\nEstimating Techniques 92 \\nResource Assignment 93 \\nTask Dependencies 94 \\nResource Dependencies 95 \\nCritical Path Method 95 \\nProject Schedules 96 \\nProject Planning Activities 98 \\nDeliverables Resulting from These Activities 100 \\nRoles Involved in These Activities 101 \\nRisks of Not Performing Step 3 103 \\nBibliography and Additional Reading 103 \\nChapter Four Step 4: Project Requirements Definition 105 \\nGeneral Business Requirements 108'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 10}, page_content='Interviewees for General Business Requirements 109 \\nData Quality Requirements 110 \\nBusiness Requirements Report 111 \\nProject-Specific Requirements 112 \\nInterviewees for Project-Specific Requirements 113 \\nApplication Requirements Document 114 \\nThe Interviewing Process 116 \\nInterviewing Considerations 116 \\nInterviewing Tips 117'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 11}, page_content='x Contents \\nProject Requirements Definition Activities 118 \\nDeliverable Resulting from These Activities 121 \\nRoles Involved in These Activities 121 \\nRisks of Not Performing Step 4 122 \\nBibliography and Additional Reading 123 \\nChapter Five Step 5: Data Analysis 125 \\nBusiness-Focused Data Analysis 127 \\nTop-Down Logical Data Modeling 128 \\nProject-Specific Logical Data Model 128 \\nEnterprise Logical Data Model 129 \\nLogical Data Modeling Participants 131 \\nStandardized Business Meta Data 131'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 11}, page_content='Bottom-Up Source Data Analysis 133 \\nTechnical Data Conversion Rules 134 \\nBusiness Data Domain Rules 134 \\nBusiness Data Integrity Rules 135 \\nData Cleansing 136 \\nData Quality Responsibility 137 \\nSource Data Selection Process 137 \\nKey Points of Data Selection 139 \\nTo Cleanse or Not to Cleanse 140 \\nCleansing Operational Systems 141 \\nData Analysis Activities 141 \\nDeliverables Resulting from These Activities 143 \\nRoles Involved in These Activities 144 \\nRisks of Not Performing Step5 145'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 11}, page_content='Bibliography and Additional Reading 146 \\nChapter Six Step 6: Application Prototyping 149 \\nPurposes of Prototyping 151 \\nTime-Boxing 152 \\nBest Practices for Prototyping 153 \\nConsiderations for Prototyping 154 \\nTypes of Prototypes 156 \\nShow-and-Tell Prototype 156 \\nMock-Up Prototype 156 \\nProof-of-Concept Prototype 157 \\nVisual-Design Prototype 157'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 12}, page_content='Contents \\nDemo Prototype 158 \\nOperational Prototype 159 \\nBuilding Successful Prototypes 159 \\nPrototype Charter 160 \\nGuidelines for Prototyping 161 \\nSkills Survey 162 \\nApplication Prototyping Activities 163 \\nDeliverables Resulting from These Activities 165 \\nRoles Involved in These Activities 165 \\nRisks of Not Performing Step 6 166 \\nBibliography and Additional Reading 167 \\nChapter Seven Step 7: Meta Data Repository Analysis 169 \\nThe Importance of Meta Data 172 \\nMeta Data Categories 173'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 12}, page_content='Meta Data Repository as Navigation Tool 174 \\nData Standardization 175 \\nMeta Data Classifications 176 \\nGroupings of Meta DataComponents 176 \\nPrioritization of Meta Data Components 179 \\nMeta Data Repository Challenges 182 \\nTechnical Challenges 182 \\nStaffing Challenges 183 \\nBudget Challenges 183 \\nUsability Challenges 183 \\nPolitical Challenges 184 \\nThe Logical Meta Model 184 \\nThe Entity-Relationship Meta Model 185 \\nMeta-Meta Data 186 \\nMeta Data Repository Analysis Activities 186'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 12}, page_content='Deliverables Resulting from These Activities 188 \\nRoles Involved in These Activities 188 \\nRisks of Not Performing Step 7 189 \\nBibliography and Additional Reading 190 \\nChapter Eight Step 8: Database Design 191 \\nDifferences in Database Design Philosophies 193 \\nOperational Databases 193 \\nBI Target Databases 196'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 13}, page_content='xii Contents \\n| ER APSE SESE STEGER TEP TBE SOE TERE ESSA RE TEA OSE IBS TEL ETE DE REE EPRI ELIE CELE OEE LEE LEE IE OE A II IEE ELE \\nLogical Database Design 197 \\nThe Star Schema 197 \\nThe Snowflake Schema 200 \\nPhysical Database Design 201 \\nImplementation Options 201 \\nPhysical Dataset Placement 201 \\nPartitioning 202 \\nClustering 202 \\nIndexing 202 \\nReorganizations 203 \\nBackup and Recovery 203 \\nParallel Query Execution 204 \\nDatabase Design Activities 204'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 13}, page_content='Deliverables Resulting from These Activities 207 \\nRoles Involved in These Activities 208 \\nRisks of Not Performing Step 8 209 \\nBibliography and Additional Reading 209 \\nChapter Nine Step 9: Extract/Transform/Load Design 211 \\nImplementation Strategies 213 \\nPreparing for the ETL Process 215 \\nThe Initial Load 216 \\nThe Historical Load 217 \\nThe Incremental Load 217 \\nDesigning the Extract Programs 219 \\nDesigning the Transformation Programs 221 \\nSource Data Problems 221 \\nData Transformations 222'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 13}, page_content='Designing the Load Programs 223 \\nReferential Integrity 224 \\nIndexing 224 \\nDesigning the ETL Process Flow 225 \\nThe Source-to-Target Mapping Document 225 \\nThe ETL Process Flow Diagram 225 \\nThe Staging Area 228 \\nEvaluating ETL Tools 229 \\nETL Design Activities 231 \\nDeliverables Resulting from These Activities 233 \\nRoles Involved in These Activities 233'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 14}, page_content='Contents xiii \\nRisks of Not Performing Step9 234 \\nBibliography and Additional Reading 234 \\nChapter Ten Step 10: Meta Data Repository Design 237 \\nMeta Data Silos 239 \\nSources of Meta Data 240 \\nMeta Data Repository Solutions 242 \\nCentralized Meta Data Repository 242 \\nDecentralized Meta Data Repository 244 \\nDistributed XML-Enabled Meta Data Solution 245 \\nDesigning a Meta Data Repository 247 \\nEntity-Relationship Design 247 \\nObject-Oriented Design 248 \\nLicensing (Buying) a Meta Data Repository 250'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 14}, page_content='Product Evaluation 251 \\nVendor Evaluation 252 \\nMeta Data Repository Design Activities 254 \\nDeliverables Resulting from These Activities 255 \\nRoles Involved in These Activities 256 \\nRisks of Not Performing Step 10 257 \\nBibliography and Additional Reading 257 \\nChapter Eleven Step 11: Extract/Transform/Load Development 259 \\nSource Data Transformation 261 \\nData Transformation Activities 261 \\nUnderestimating Data Transformation Efforts 262 \\nReconciliation 263 \\nCalculating Reconciliation Totals 264'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 14}, page_content='Storing Reconciliation Statistics 266 \\nPeer Reviews 267 \\nETL Testing 268 \\nUnit Testing 269 \\nIntegration Testing 270 \\nRegression Testing 271 \\nPerformance Testing 271 \\nQuality Assurance Testing 272 \\nAcceptance Testing 272 \\nFormal Test Plan 273 \\nETL Development Activities 276'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 15}, page_content='Xiv Contents \\nDeliverables Resulting from These Activities 277 \\nRoles Involved in These Activities 278 \\nRisks of Not Performing Step 11 279 \\nBibliography and Additional Reading 279 \\nChapter Twelve Step 12: Application Development 281 \\nOnline Analytical Processing Tools 283 \\nAdvantages of OLAP Tools 284 \\nOLAP Tool Features 285 \\nMultidimensional Analysis Factors 287 \\nMultivariate Analysis 289 \\nOnline Analytical Processing Architecture 289 \\nPresentation Services 290 \\nOLAP Services 291'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 15}, page_content='OLAP Services 291 \\nDatabase Services 292 \\nDevelopment Environments 292 \\nApplication Development Activities 295 \\nDeliverables Resulting from These Activities 297 \\nRoles Involved in These Activities 298 \\nRisks of Not Performing Step 12 299 \\nBibliography and Additional Reading 299 \\nChapter Thirteen Step 13: Data Mining 301 \\nDefining Data Mining 303 \\nThe Importance of Data Mining 305 \\nData Sources for Data Mining 306 \\nData Mining Techniques 307 \\nAssociations Discovery 307'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 15}, page_content='Sequential Pattern Discovery 308 \\nClassification 309 \\nClustering 309 \\nForecasting 309 \\nData Mining Operations 310 \\nPredictive and Classification Modeling 310 \\nLink Analysis 311 \\nDatabase Segmentation 311 \\nDeviation Detection 311 \\nApplications of Data Mining 311 \\nData Mining Activities 313 \\nDeliverables Resulting from These Activities 315'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 16}, page_content='Contents XV \\nRoles Involved in These Activities 316 \\nRisks of Not Performing Step 13 316 \\nBibliography and Additional Reading 317 \\nChapter Fourteen Step 14: Meta Data Repository Development 319 \\nPopulating the Meta Data Repository 321 \\nMeta Data Repository Interface Processes 324 \\nThe Tool Interface Process 324 \\nThe Access Interface Process 325 \\nMeta Data Repository Testing 326 \\nPreparing for the Meta Data Repository Rollout 327 \\nMeta Data Repository Directory 330'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 16}, page_content='Meta Data Repository Development Activities 331 \\nDeliverables Resulting from These Activities 332 \\nRoles Involved in These Activities 333 \\nRisks of Not Performing Step 14 334 \\nBibliography and Additional Reading 335 \\nChapter Fifteen Step 15:Implementation 337 \\nIncremental Rollout 339 \\nSecurity Management 340 \\nSecurity Measures for BI Applications 340 \\nSecurity in a Multi-Tier Environment 341 \\nSecurity for Internet Access 344 \\nData Backup and Recovery 345'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 16}, page_content='Monitoring the Utilization of Resources 347 \\nComputer Utilization 347 \\nNetwork Utilization 347 \\nPersonnel Utilization 348 \\nGrowth Management 349 \\nGrowth in Data 349 \\nGrowth in Usage 350 \\nGrowth in Hardware 351 \\nImplementation Activities 352 \\nDeliverables Resulting from These Activities 354 \\nRoles Involved in These Activities 355 \\nRisks of Not Performing Step 15 356 \\nBibliography and Additional Reading 356'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 17}, page_content='xvi Contents \\nChapter Sixteen Step 16: Release Evaluation 359 \\nThe Application Release Concept 361 \\nGuidelines for Using the Release Concept 362 \\nPost-Implementation Reviews 364 \\nOrganizing a Post-Implementation Review 366 \\nPost-Implementation Review Session Flow 368 \\nRelease Evaluation Activities 369 \\nDeliverables Resulting from These Activities 371 \\nRoles Involved in These Activities 371 \\nRisks of Not Performing Step 16 374 \\nBibliography and Additional Reading 375 \\nPARTIIT ATAGLANCE 377'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 17}, page_content='Chapter Seventeen Human Resource Allocation Matrix 379 \\nChapter Eighteen Entry & Exit Criteria and Deliverables Matrix 387 \\nChapter Nineteen Activity Dependency Matrix 405 \\nChapter Twenty ‘Task/Subtask Matrix 411 \\nChapter Twenty-one Practical Guidelines Matrix 455 \\nAppendix Work Breakdown Structure 491 \\nIndex 525'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 18}, page_content='About the Authors \\nLarissa T. Moss \\nMs. Moss is president of Method Focus, Inc. She consults, lectures, and \\nspeaks at conferences worldwide on the topics of business intelligence, \\ndata warehousing, customer relationship management, information \\nquality, data integration, and cross-organizational application develop- \\nment. She has coauthored the books Data Warehouse Project Management \\n(Addison-Wesley, 2000) and Impossible Data Warehouse Situations (Addison-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 18}, page_content='Wesley, 2002). She publishes white papers through the Cutter Consortium \\nand articles in TDWI Journal of Data Warehousing, DM Review, Cutter IT \\nJournal, The Navigator, and Analytic Edge. She is a member of the IBM \\nGold Group and a senior consultant of the Cutter Consortium. She is a \\ncontributing member to the “Ask the Experts” forum of DM Review. She \\nwas a part-time faculty member at the Extended University of California \\nPolytechnic University, Pomona, and an associate of the Codd & Date'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 18}, page_content='Consulting Group. Ms. Moss can be reached at Imoss@methodfocus.com. \\nShaku Atre \\nMs. Atre is president of Atre Group, Inc., specializing in business intelli- \\ngence, data warehousing, and DBMS. She is on the board of AtreNet, \\nInc., a Web agency in Santa Cruz, CA. Ms. Atre was a partner with Price- \\nWaterhouseCoopers. She held a wide variety of management and techni- \\ncal positions at IBM. She is a renowned expert, consultant, and a speaker'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 18}, page_content='in business intelligence, data warehousing, end-user computing, and “Politics \\nand IT.” She has taught graduate-level courses in databases at New York \\nUniversity. Ms. Atre lectures on these topics worldwide. She is a columnist \\nwith Computerworld. Her articles are available at http://www.atre.com. \\nMs. Atre is the author of five books, including Data Base: Structured Tech- \\nniques for Design, Performance and Management, and Distributed Data-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 18}, page_content='bases, Cooperative Processing & Networking. Ms. Atre holds a master’s \\ndegree in statistics and has done research at the University of Heidelberg, \\nGermany, in mathematics. She can be reached at shaku@atre.com. \\nxvii'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 19}, page_content='= 7 7 * : 7 ; ; \\nbat cole Mien SA Ti ED thie oe \\n(ie 2? Qo Se — =e EES (US Cages \\nPaspie ti se ah rredh - i Oe on eee | > \\nfear meat bel) 1 7 é : a \\n= n \\na a Pam hee 7 i \\ndl \\n(Pyicinesg 0 t--? beter a 2 e ams 3 ene \\n(oh MaehT TY Higa! ML o> Sem ltire aot je aa — \\nBae oe “tin A ae tHhiby fh hist Sueno aw Peay) al \\nE Wetto ath ay ean hs notivicld vial: 5¢! Mg | \\nrd , Way Seis ys ae st iduod oat bg vung edd ae tear \\n) wala a2 ig oe AAT il fit eegael hers (WO, ede eae'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 19}, page_content='imathairnena) vie!) och: dew? (rng wlitw conti. we let \\naed sere Pile Soho co) 5 vp Marcie. Vortt ai esiige bow : ; \\nA) aii Xa ¥ebrrars s aj Maple siF2 Wh st ae sotecrenets wht veal, —_ \\noe eee ee ee Sale beuwNA TAG Lo cma? “eeseega! ‘att tad? alt <2 Sere game Onna 4 \\nPuayplly Je, cteg tw\\\\y belyrrey, ea pe ebony 2 ar aw ¢ ope . \\naalt & Sbold adi hu “ri PE OE. Aw) qurerirtk airy! maa \\n(ears alaee Serta alae 0: ceil eet en \\nPants Teeyny imines “em? 61 * i \\nCRApits Tipit ce | eee) Coins De 4'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 19}, page_content=', eee. \\nCpr ie aT] fits Saha AIBA Fare rmneeey a Gath al \\nspies 1g Giel sift np ai ote ORME Bowe greg eagy ater pot \\nSee io te gage SA oh’, > care) pane i etd ant Gre ste sor ai WA, russ str G. Sige &.- \\nAsutvas bite trarasgsoect te ciece shiw s Glut al? cope eae \\nTElosg? © brs.tosiusny) Jreqe Lenwoiees § 0 ae MGT te = , : \\nciti * bean anit sorte yseur-betes \\\\arleaoctoriet s nual eg eet 7 \\ndl walt je eradanb ni ooo ivesk easly tga el SHES Bn 4'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 19}, page_content='wurtuiler « sit idwuhow suyor seed? mouse Wah a4 Ergot ie \\nneh Ota wren an ‘ w oidalcvs oye — nih Pamrrgeone? ce \\neet tqpenwené a5 wie sbalsni gine \\nwil Weivted” fom Apsineyere hy Meee \\napie » éblad oA 2h ane = \\ngnedisbick to viieiovi) oft ty does \\naw AiG ats & baths eine \\nWve'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 20}, page_content='Foreword \\nIn today’s highly competitive and increasingly uncertain world, the quality and \\ntimeliness of an organization’s “business intelligence” (BI) can mean not only the \\ndifference between profit and loss but even the difference between survival and \\nbankruptcy. \\nIn helping senior executives and information technology (IT) managers, \\nMoss and Atre’s greatest contribution, I believe, is the comprehensive nature of'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 20}, page_content='their “roadmap”; as the subtitle of their book promises, they have provided a \\ncomplete project lifecycle for the development of such systems. Because BI and \\ndecision-support systems ultimately rely on a rich treasure trove of data, there is a \\nsignificant emphasis in Business Intelligence Roadmap on various technical \\naspects of data: meta data, data mining, data warehousing, multidimensional \\ndata analysis (online analytical processing [OLAP]), data security, and so on. But'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 20}, page_content='there is also significant emphasis on the business justification, project planning, \\nanalysis, implementation, and deployment details of BI systems. In addition to \\nthe more traditional details of systems analysis, Moss and Atre also provide prac- \\ntical advice on the structure and organization of the project team, as well as the \\nskills and talents of the human resource roles required for such project teams. \\nAnd, because of the importance of building enterprise-wide BI systems, the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 20}, page_content=\"authors also describe the lifecycle activities that must be carried out in a cross- \\norganizational fashion. \\nAnyone planning to lead a BI project initiative, as well as the data analysts, \\nsystems architects, and other senior IT professionals involved in such an initia- \\ntive, should definitely read Business Intelligence Roadmap from cover to cover. It \\nwouldn't hurt senior executives to read the entire book, too, for then they might\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 20}, page_content=\"have a better appreciation for the careful planning and disciplined project organi- \\nzation required to make a BI project succeed. But Moss and Atre have wisely rec- \\nognized that many senior executives are too busy, or too technophobic, to read \\nthe entire book; for such people, they have provided an “at a glance” section of \\nthe book that concludes with a final chapter summarizing dos, don'ts, and tips \\nxix\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 21}, page_content='xXx Foreword \\nfor each of the project lifecycle steps that they discuss in detail. For example, the \\npenultimate tip, in the final chapter of the book, advises the reader to \\nImplement your BI applications using the release concept. It is much better to \\ndeliver high-quality, partially functioning application releases over time than to \\ndeliver a low-quality, completed application that is fraught with many defects \\nand with dirty data. If the first release is successful, new requirements will'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 21}, page_content='emerge as the business people get used to the iterative development process. \\nEdward Yourdon \\nNew York City \\nSeptember 2002'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 22}, page_content='Preface \\nMany organizations are already well equipped to implement successful \\nbusiness intelligence (BI) decision-support applications, such as data \\nwarehouses, data marts, and other business analytics applications. How- \\never, during our consulting and teaching engagements, we have encoun- \\ntered many ill-equipped organizations as well. We observed some common \\nfactors among them, which we address in this book: \\n* Lack of understanding of the complexity of BI decision-support \\nprojects'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 22}, page_content='projects \\n* Lack of recognizing BI decision-support projects as cross-organizational \\nbusiness initiatives and not understanding that cross-organizational ini- \\ntiatives are different from stand-alone solutions \\n* Unavailable or unwilling business representatives \\n* Unengaged business sponsors or business sponsors who have little or \\nno authority due to their low-level positions within the organization \\n* Lack of skilled and available staff as well as suboptimum staff utilization'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 22}, page_content='* Inappropriate project team structure and dynamics \\n* No software release concept (no iterative development method) \\n* No work breakdown structure (no methodology) \\n* Ineffective project management (only project administration) \\n* No business analysis and no standardization activities \\n* No appreciation of the impact of dirty data on business profitability \\n* No understanding of the necessity for and the usage of meta data'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 22}, page_content='* Too much reliance on disparate methods and tools (the “silver bullet” \\nsyndrome) \\nBI project managers and project teams can use this book to improve \\ntheir project life cycles. They can also use it to obtain the appropriate rec- \\nognition for their BI projects from the business community and to solicit \\nXxi'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 23}, page_content='xxii Preface \\nSP SF RET EA AT EE TT IE I IT TD IE \\nthe required support from their executive management. BI project team \\nmembers and the business representatives assigned to them can use this \\nbook to gain a better understanding of the development effort required \\nto build and deploy successful BI decision-support applications. \\nTHE PURPOSE OF THIS BOOK \\nBusiness Intelligence Roadmap is a guide for developing BI decision-support \\napplications. The two main purposes of this book are to'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 23}, page_content='1. Explain the complexity of BI decision-support projects \\n2. Present a step-by-step guide for the entire BI project lifecycle \\nComplexity \\nIn order to give you an appreciation of the complexity of BI decision-support \\nprojects, we describe all of the components that go into a BI decision- \\nsupport development effort. For example: \\n* You should know what makes a BI decision-support application dif- \\nferent from a traditional decision-support system so that you can \\navoid costly mistakes.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 23}, page_content='* You should understand the infrastructure components of your new \\nBI decision-support application, such as the tools available (for \\ndevelopment and for access and analysis). \\n* You should be able to recognize items that could impair the success of \\nyour new BI decision-support application. \\n* You should determine how many resources you need and what type \\nof resources, both technical and human. \\n* You should decide on the design or architecture of your BI decision-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 23}, page_content='support application, such as designing for multidimensional report- \\ning or ad hoc querying. \\nStep-by-Step Guide \\nOur step-by-step guide across the breadth of a complete development \\nlifecycle includes activities, deliverables, roles and responsibilities, dos and'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 24}, page_content=\"How This Book Is Organized xxiii \\ndon'ts, and entry and exit criteria, plus tips and rules of thumb to lead \\nyou to a successful BI decision-support implementation. For example: \\n* You should choose which steps you ought to perform on your BI \\nproject because no two BI decision-support projects are exactly alike. \\n* You should know whether to start with a cross-organizational deci- \\nsion-support solution or a tailored departmental solution with the \\nbasis for expansion.\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 24}, page_content='* You should understand the sequence in which to perform develop- \\nment activities, that is, which ones can be performed in parallel \\ntracks and which ones have a strong dependency on one another. \\nIn contrast to topic-specific materials available on BI, this book is a \\nsingle-source development guide written specifically for BI decision-sup- \\nport applications. The guidelines presented in this book are based not \\nonly on our personal experiences but also on some of the best practices'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 24}, page_content='covered in topic-specific books, articles, and Web sites. \\nHow THIS BOOK IS ORGANIZED \\nAll software development projects are complicated engineering projects, \\nas demonstrated by the breadth of topics covered in this book. Chapter 0, \\nGuide to the Development Steps, explains the general organization of the \\ndevelopment guidelines in Business Intelligence Roadmap, which is as follows: \\nEngineering stages \\nily Parallel development tracks \\nau Development steps \\nkes) Major activities'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 24}, page_content='ii> Tasks and subtasks \\nThis book is organized into two major parts. Part I, Stages and Steps, \\ndescribes the 16 development steps, which are introduced in Chapter 0. \\nPart I gives you a broad understanding of the development effort involved \\nin BI decision-support projects. Part H, At a Glance, supplements the text'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 25}, page_content='Xxiv Preface \\ncontained in the first part of the book with several matrices that should \\nbe used together as a reference guide for all BI decision-support projects. \\nPart I: Stages and Steps \\nPart I begins with Chapter 0, Guide to the Development Steps, and is fol- \\nlowed by 16 development chapters. Each of the 16 development chapters \\nis dedicated to one unique development step and describes the effort \\nrequired to perform the activities of that step.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 25}, page_content='Guide to the Development Steps (Chapter 0) describes the general \\nlayout of the development guidelines presented in this book, contrasting \\nthose guidelines with a traditional development methodology. It dis- \\ncusses the six engineering stages as well as the three parallel development \\ntracks, and it groups the applicable development steps under both. Chap- \\nter 0 explains the application release concept and shows how to organize'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 25}, page_content='a BI project with the appropriate roles and responsibilities for the core \\nteam and the extended team. \\nEach of the development steps (Chapters 1-16) begins with an individ- \\nual chapter overview followed by a section called Things to Consider. \\nThese are general questions BI project teams usually contemplate when \\ndeciding which activities need to be performed under each development \\nstep. These questions are merely presented as “food for thought” and are'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 25}, page_content='not necessarily explored in the chapters; nor are they all-inclusive. Each \\nchapter discusses the main topics applicable to the development step cov- \\nered by that chapter. Some topics apply to more than one development \\nstep, such as testing or product evaluation. However, to avoid redun- \\ndancy these common topics are covered in only one chapter and are only \\nbriefly referenced in the other chapters. \\nEach of the 16 chapters contains a list of major activities for that'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 25}, page_content='development step, accompanied by a figure showing what activities could \\nbe performed concurrently. The list of activities is followed by descrip- \\ntions of the deliverables resulting from these activities and the roles \\ninvolved in performing these activities. Each chapter concludes with a \\nbrief discussion of risks to weigh in case you decide not to perform that \\nstep on your project. Do not interpret the risks of not performing the step'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 25}, page_content='to mean that every BI project team must perform every development step'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 26}, page_content='How This Book Is Organized XXV \\nexactly as suggested. Instead, use the risk section to determine whether \\nthe activities in that development step are—or should be—mandatory on \\nyour project. If they are not, you may decide not to perform some or all \\nof those activities after discussing the risks with the business sponsor. \\nPart II: At a Glance \\nPart II contains the following matrices. \\nThe Human Resource Allocation Matrix (Chapter 17) lists all the vital'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 26}, page_content='roles involved in performing the step activities, tasks, and subtasks. \\nThe roles listed in this matrix need to be assigned to project team \\nmembers. In order to help you discover and avoid potential resource \\nallocation problems, the steps that can be performed in parallel and \\ntheir appropriate roles are listed together. \\nThe Entry & Exit Criteria and Deliverables Matrix (Chapter 18) indi- \\ncates the prerequisites, results, and deliverables for each development'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 26}, page_content='step. Not every BI project team will need to perform all activities for \\nall development steps. This matrix should help you determine whether \\nyou can skip a step or incorporate some of its activities into other steps. \\nThe Activity Dependency Matrix (Chapter 19) is a collection of activ- \\nity dependency charts for the development steps. This matrix shows \\nat a glance which activities in each step can be performed concur- \\nrently. It should be used to determine workflow and task assignments'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 26}, page_content='for project team members. \\nThe Task/Subtask Matrix (Chapter 20) itemizes all pertinent tasks, \\nand in some cases subtasks, for all the major activities under each \\nstep. This matrix should be used to prepare the work breakdown \\nstructure for the project plan. You can customize (expand or reduce) \\nthe tasks and subtasks on an as-needed basis for individual projects. \\nThe Practical Guidelines Matrix (Chapter 21) presents three subsec-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 26}, page_content=\"tions for each development step: Dos, Don'ts, and Tips and Rules of \\nThumb. Dos point out best practices for the development steps, and \\nDon'ts instruct you how to avoid traps and pitfalls. Tips and Rules of \\nThumb are our personal collection of experiences over several decades \\nof developing cross-organizational decision-support applications.\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 27}, page_content='Xxvi Preface \\nHow TO USE THIS BOOK \\nWe suggest that all core members of the BI project team make use of this \\nbook as follows. \\nIe First, read all the chapters in Part I to gain an overall understanding \\nof all the components of BI decision-support development. \\n. Next, compare your own BI project scope and requirements to the \\ntopics in the book. Use the discussions in the chapters to decide \\nwhich specific development steps apply to your project.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 27}, page_content='. Go to Chapter 18 and look up the entry and exit criteria for the steps \\nyou selected. Be sure that you have the prerequisites to implement \\nyour development approach and that you have a clear understanding \\nof what it takes to move forward. \\n. Put your project plan together for the steps you have chosen by con- \\nsulting the activity dependency flow charts in Chapter 19 and by using \\nthe tasks and subtasks listed in Chapter 20. To kick-start your project,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 27}, page_content='you may want to copy and customize the work breakdown structure \\nprovided on the CD included with this book to fit your needs. The \\nwork breakdown structure on the CD is a Microsoft Project file that \\nalready includes the step dependencies (shown in Figure 0.6 in Chap- \\nter 0) and the activity dependencies (shown in the flow charts in \\nChapter 19). In addition, the work breakdown structure contains \\nsome basic mandatory task dependencies.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 27}, page_content='. Use the matrices in Part II as a quick reference to help guide your \\ndevelopment work throughout the project. \\nWHO SHOULD READ THIS BOOK \\nSegments of this book should be read and referenced by every mem- \\nber of the BI project team, including business representatives. It is impor- \\ntant that all project participants understand “the big picture” and how \\nthey and their roles fit into it. This also applies to third-party consultants,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 27}, page_content='who can fill any technical role on the project team. Understanding this \\nlarger view of the project and its development effort is essential in main- \\ntaining a level of enthusiasm and cooperation necessary for the team.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 28}, page_content='Who Should Read This Book Xxvii \\nBelow we spotlight team members’ roles and provide lists of the most \\nuseful and applicable chapters for each specific role. \\nBusiness Representatives \\nAlthough the development steps are technical in nature, business repre- \\nsentatives involved in BI projects must understand what activities need to \\noccur during the development effort. Business representatives are \\nexpected to participate as full-time members of the project core teams,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 28}, page_content='and some of the activities described in this book will be assigned to them. \\nTable P.1 lists chapters of particular interest to business representatives. \\nTable P.1: Chapters for Business Representatives \\nChapter Title \\n0 Guide to the Development Steps \\n1 Step 1: Business Case Assessment \\n2 Step 2: Enterprise Infrastructure Evaluation \\n(especially Section B, Nontechnical Infrastructure Evaluation) \\nStep 3: Project Planning \\nStep 4: Project Requirements Definition \\nStep 5: Data Analysis'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 28}, page_content='Step 7: Meta Data Repository Analysis \\n3 \\n4 \\n5 \\n6 Step 6: Application Prototyping \\n7 \\n9 Step 9: Extract/Transform/Load Design \\n13 Step 13: Data Mining \\n16 Step 16: Release Evaluation \\nBusiness Sponsors \\nAlthough business sponsors are not directly involved in the daily devel- \\nopment effort, they should make frequent checks on the health of the \\nproject as well as the project team. In order to do this, business sponsors'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 29}, page_content='Xxviii Preface \\nTable P.2: Chapters for Business Sponsors \\nChapter Title \\n0 Guide to the Development Steps \\n1 Step 1: Business Case Assessment \\n2 Step 2: Enterprise Infrastructure Evaluation \\n(especially Section B, Nontechnical Infrastructure Evaluation) \\n3 Step 3: Project Planning \\n4 Step 4: Project Requirements Definition \\n5 Step 5: Data Analysis \\n13 Step 13: Data Mining \\n16 Step 16: Release Evaluation \\nmust have a comprehensive, high-level understanding of the effort. Table'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 29}, page_content='P.2 lists the chapters recommended for business sponsors. \\nProject Managers \\nThe project manager is responsible for the entire development effort and \\nmust therefore be intimately familiar with all development steps. He or \\nshe must read all chapters in the book and use the matrices in Part II as \\nan ongoing reference guide, as shown in Table P.3. \\nBI projects are not for inexperienced project managers. A thorough under- \\nstanding of project management principles is required.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 29}, page_content='Table P.3: Chapters for Project Managers \\nChapter Title \\n0 Guide to the Development Steps \\nT=16 Part I: Stages and Steps \\nT7=2Z1 Part Il: At a Glance'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 30}, page_content='Who Should Read This Book xxix \\nTechnicians \\nVarious types of technicians work on BI projects. Some technicians are \\nassigned to the core team on a full-time basis, such as a lead developer; \\nothers are on the extended team supporting the development activities on \\nan as-needed basis, such as a security officer. (For an itemized list of roles \\nassigned to the core team and to the extended team, refer to Chapter 0.) \\n* Core team technicians should read all the chapters in the book and'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 30}, page_content='use the matrices as an ongoing reference guide, as shown in Table P.4. \\n* Extended team technicians should read, at a minimum, the chapters \\nlisted in Table P.5. However, these technicians would gain a greater \\nunderstanding of the BI decision-support development process if \\nthey read all the chapters in the book. \\nTable P.4: Chapters for Core Team Technicians \\nChapter Title \\n(6) Guide to the Development Steps \\n116 Part I: Stages and Steps \\nWe Part Il: At a Glance'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 30}, page_content='Table P.5: Chapters for Extended Team Technicians \\nChapter Title \\n0 Guide to the Development Steps \\n2 Step 2: Enterprise Infrastructure Evaluation \\n(especially Section A, Technical Infrastructure Evaluation) \\n3 Step 3: Project Planning \\n4 Step 4: Project Requirements Definition \\n16 Step 16: Release Evaluation \\nAdditional chapters on an as-needed basis \\n(For example, an ETL developer should read Step 9: Extract/ \\nTransform/Load Design, Step 11: Extract/Transform/Load'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 30}, page_content='Development, and Step 15: Implementation.) \\nrT a 0S ES SRT FE SS I SS ES ES ES'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 31}, page_content='XXX Preface \\nCOMMENTS \\nDespite the large collection of topic-specific BI material, we observed a \\nstrong need by project teams for a unified plan or method to follow. \\nTherefore, we started this book with the notion of writing a complete \\ndevelopment methodology for BI decision-support projects. We quickly \\nrealized that to meet such a goal we would have to produce a multivolume \\nwork—something not feasible for most project managers and project'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 31}, page_content='team members to read. Our original plan quickly gave way to a general \\nroadmap that would serve as an umbrella for all the major development \\nsteps, topics, considerations, and activities of a BI project. In addition, at \\nthe end of each chapter we provide a list of references that are most appli- \\ncable to the topics of the chapter. \\nWe also wanted to share with project managers, project teams, and \\nbusiness representatives our personal discoveries about what works and'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 31}, page_content='what doesn’t work on BI projects. Therefore, the information we present \\nin the matrices in Part II is an accumulation of our own personal obser- \\nvations, experiences, and judgments. \\nFinally, to enhance the readability of this complex technical material, \\nwe broke up the text with as many tables, graphs, pictures, and other \\nvisuals as possible. We hope these visual aids make this book easier to \\nread in addition to clarifying the topics presented.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 32}, page_content='Acknowledgments \\nWriting this all-encompassing development guide for BI decision-support \\napplications required extensive knowledge of traditional as well as current \\ninformation technology (IT) development disciplines. While we have over \\n50 years of combined IT experience, many colleagues and friends con- \\ntributed their expertise and time to this book. \\nOur special appreciation goes to Melvin Rusakoff, who came out of \\nretirement to help us jump-start the book. We want to thank him for all'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 32}, page_content='of his contributions, in particular on testing and peer reviews. His exten- \\nsive knowledge of methodologies provided a benchmark for quality \\nassurance of our book. \\nWe thank Sid Adelman and Florence Alcorn for their extensive and \\nmerciless critiques of our first draft. Their input profoundly changed the \\nscope and content of this book. \\nWe are grateful to David Marco for his early contribution on meta \\ndata repositories. Our appreciation also goes to Mike Schmitz for his'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 32}, page_content='database suggestions, to Joyce Bischoff for her ETL comments, and to \\nHerb Edelstein and Arun Swami for their data mining remarks. \\nThe extensive critiques provided by two IT journalists, Paul Gillin \\nand Peter Krass, made our technical jargon more comprehensible. We are \\nindebted to John Tiglias who, based on his high-level management expe- \\nrience, provided us valuable insights into the needs of CIOs and gave us \\nsuggestions for addressing them.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 32}, page_content='We are also very thankful for the real-life comments from the \\n“trenches” provided by Tom McCullough, Ross Armstrong, Bill Tillman, \\nMajid Abai, Pat Higgs, and Jane Aubol. \\nOur special thanks go to Ed Yourdon for taking time out of his very \\nbusy schedule and for giving us encouragement from the very beginning \\nof this long project to the very end. We are also very thankful to Bill \\nInmon for reviewing our manuscript on very short notice. \\nXXxi'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 33}, page_content='XXxii Acknowledgments \\nWe are indebted to Info-Edge Inc. for working with us on this \\nproject. We also want to thank Anthony Ianniciello and Tushar Atre of \\nAtreNet, Inc. for helping us with the cover design. \\nOur sincere appreciation goes to our executive editor, Mary O’Brien, \\nat Addison-Wesley, who displayed extraordinary patience while accom- \\nmodating our every out-of-the-ordinary book-formatting request. In \\naddition, we thank the many Addison-Wesley team members for their'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 33}, page_content='individual contributions to making our book a success, in particular \\nBrenda Mulligan for coordinating all aspects of the editorial process, \\nSimone Payment and Jacquelyn Doucette for managing the production \\nprocess, Chrysta Meadowbrooke for copyediting, and Curt Johnson and \\nChanda Leary-Coutu for their tireless efforts in marketing. \\nOur special gratitude goes to Donald P. Sherman, who spent an \\nextraordinary amount of his time editing and cross-checking the book'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 33}, page_content='multiple times to ensure consistency and readability. We also thank \\nBlanca Eusse-Patino for being our liaison and for providing assistance to \\nmeet our deadlines. \\nFinally, we thank our families for putting precious family time on \\nhold while the book was in the making. They have been the main pillars \\nof support for our professional endeavors. \\n—Larissa T. Moss and Shaku Atre'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 34}, page_content='Stages and Steps'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 35}, page_content='1é a, Pe, oe Ste, G2 xe PR 332 oe a! \\nva ¢ soo DS 20981 cm \\n\" thle. Vn tis Erlayed es \\noo) ao ard fy conde. adel AG) - ; Ey 7 \\nabiiths ac Geri, de pac es ame \\nPES IE Os mic ite eG : \\nkirae © “wes Se sondinsidy i ance OES \\norn Ts ew at? Pcqucds Dasa Oe \\n(rdaLaes Capes Peel or as si ameter om = \\nChiat) eile -~Suhaenl aXsedees we i wee, \\nie etl @pI2s @c) ® Lew 4: \\nmi guieasepeoun! of ’e Cow ckiins, seb c \\nrohygis tet = overt serntdte? ah mcebabirs. \\nfires . soe Brim be Be » Mie welds ings'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 35}, page_content='Filet ~ec cae. \\nLb \\n“eath —— > = > tas & patry PSL a \\nbceolt be he’ eee Am rer tee ee \\nO68 bd sat ee 8 * i SS \\n; cunt ie'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 36}, page_content='| Business Case \\nAssesment / \\no \\nEnterprise \\nInfrastructure \\n\\\\. Evaluation \\nProject \\nA. Planning \\nProject \\nRequirements \\n\\\\_ Definition \\n7 \\nMeta Data \\nRepository \\nAnalysis \\nData \\nAnalysis \\nApplication \\nPrototyping \\n8 \\nDatabase \\nDesign \\n10 \\nMeta Data \\nRepository \\nDesign \\n14 \\nMeta Data \\nRepository \\nDevelopment \\n15 \\nImplementation \\n16 \\nRelease \\nEvaluation \\nCHAPTER ZERO \\nGuide to \\nthe Development Steps \\nCHAPTER OVERVIEW \\nThis chapter covers the following topics:'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 36}, page_content='@ Business intelligence (BI), with a focus on BI decision- \\nsupport applications, such as sales forecasting \\n@ The need for and the structure of Business Intelligence Road- \\nmap as a development guide \\n@ The 16 development steps applicable to BI decision-sup- \\nport projects \\n@ The three parallel development tracks usually followed by \\nBI project teams \\n@ Project team structure, including the roles and responsibili- \\nties assigned to the core team members and the extended \\nteam members'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 36}, page_content='team members \\n@ A brief justification for using Business Intelligence Roadmap \\nas your development guide for BI decision-support projects'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 37}, page_content='4 Guide to the Development Steps \\nBUSINESS INTELLIGENCE DEFINITION \\nBI is neither a product nor a system. It is an architecture and a collection of inte- \\ngrated operational as well as decision-support applications and databases that \\nprovide the business community easy access to business data. Business Intelligence \\nRoadmap specifically addresses decision-support applications and databases. \\nBI decision-support applications facilitate many activities, including those \\nlisted below:'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 37}, page_content='listed below: \\n* Multidimensional analysis, for example, online analytical processing (OLAP) \\n* Click-stream analysis \\n- Data mining \\n* Forecasting \\n* Business analysis \\n- Balanced scorecard preparation \\n* Visualization \\n* Querying, reporting, and charting (including just-in-time and agent-based \\nalerts) \\n* Geospatial analysis \\n- Knowledge management \\n+ Enterprise portal implementation \\n+ Mining for text, content, and voice \\n+ Digital dashboard access \\n* Other cross-functional activities'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 37}, page_content='Examples of BI decision-support databases include the following: \\n- Enterprise-wide data warehouses \\n* Data marts (functional and departmental) \\n* Exploration warehouses (statistical) \\n* Data mining databases \\n* Web warehouses (for click-stream data) \\n* Operational data stores (ODSs) \\n* Operational marts (oper marts) \\n* Other cross-functional decision-support databases'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 38}, page_content='Development Approaches 5 \\nBusiness Intelligence Roadmap is primarily a project lifecycle guide for devel- \\noping BI decision-support applications using structured data. For BI applications \\nwith specialized requirements, such as using unstructured data (e.g., mining for \\ntext, content, and voice), building an enterprise portal, or incorporating XML- \\nenabled features and services, you will need to expand the activities and roles in'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 38}, page_content='the relevant development steps. Consult the topic-specific references listed at the \\nend of each chapter. \\nBI DECISION-SUPPORT INITIATIVES \\nBI decision-support initiatives are expensive endeavors. Disparate business data \\nmust be extracted and merged from online transaction processing (OLTP) systems, \\nfrom batch systems, and from externally syndicated data sources. BI decision- \\nsupport initiatives also call for new technology to be considered, additional tasks'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 38}, page_content='to be performed, roles and responsibilities to be shifted, and analysis and decision- \\nsupport applications to be delivered quickly while maintaining acceptable quality. \\nA staggering 60 percent of BI projects end in abandonment or failure because \\nof inadequate planning, missed tasks, missed deadlines, poor project manage- \\nment, undelivered business requirements, or poor quality deliverables. Project \\nmanagers need to know the dos and don’ts of BI implementations based on reli-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 38}, page_content='able hands-on experience. \\nWhat is needed is a new, proven method for understanding and implement- \\ning the processes required in the successful deployment of BI decision-support \\napplications. \\nDEVELOPMENT APPROACHES \\nAlmost every kind of engineering project—structural engineering as well as soft- \\nware engineering—goes through six stages between inception and implementa- \\ntion, as illustrated in Figure 0.1. \\nAs the arrow in Figure 0.1 indicates, engineering processes are iterative. Once'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 38}, page_content='deployed, a product is continually improved and enhanced based on the feedback \\nfrom the business community that uses the product. Each iteration produces a \\nnew product release (version) as the product evolves and matures. (This release \\nconcept is explained in detail in Step 16, Release Evaluation. )'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 39}, page_content='6 Guide to the Development Steps \\nSS I A IOS SS, \\nStage 6: \\nDeployment \\nStage 1: \\nJustification \\nEngineering \\nae Project Construction \\nStage 2: \\nPlanning \\nStage 4: \\nDesign \\nStage 3: \\nBusiness Analysis \\nFigure 0.1: Engineering Stages \\nStage 1. Justification: Assess the Stage 4. Design: Conceive a product \\nbusiness need that gives rise that solves the business \\nto the new engineering problem or enables the \\nproject. business opportunity.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 39}, page_content='Stage 2. Planning: Develop strate- Stage 5. Construction: Build the \\ngic and tactical plans, which product, which should pro- \\nlay out how the engineering vide a return on investment \\nproject will be accomplished within a predefined time \\nand deployed. frame. \\nStage 3. Business analysis: Perform Stage 6. Deployment: Implement \\ndetailed analysis of the busi- or sell the finished product, \\nness problem or business then measure its effective- \\nopportunity to gain a solid ness to determine whether'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 39}, page_content='understanding of the busi- the solution meets, exceeds, \\nness requirements for a or fails to meet the expected \\npotential solution (product). return on investment. \\nThe Traditional Development Approach \\nSince BI is an enterprise-wide evolving environment that is continually improved \\nand enhanced based on feedback from the business community, the system \\ndevelopment practices of the past are inadequate and inappropriate.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 40}, page_content='Development Approaches 7 \\nIn the past, systems were never designed or built with integration in mind. \\nEvery system had a beginning and an end, and every system was designed to solve \\nonly one isolated problem for one set of business people from one line of business. \\nThe old “single-swim-lane” development practices were suitable for such static \\nstand-alone systems. However, they are not well suited for integrated BI initia-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 40}, page_content='tives because the old practices do not include any cross-organizational activities \\nnecessary to sustain an enterprise-wide decision-support environment. In the \\npast, cross-organizational activities were not only deemed unnecessary but were \\nalso perceived to stand in the way of progress because they slowed down the projects. \\nFor nonintegrated system development, conventional waterfall methodolo- \\ngies are sufficient. They provide enough guidance for planning, building, and'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 40}, page_content='implementing stand-alone systems. However, these traditional methodologies do \\nnot cover strategic planning, cross-organizational business analysis, or evaluation \\nof new technologies with every project; nor do they embrace the concept of \\napplication releases. Traditional methodologies typically start with a functional \\nbusiness need, then concentrate on design and development, and finally end in \\nmaintenance, as illustrated in Figure 0.2.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 40}, page_content='Unlike static stand-alone systems, a dynamic, integrated BI decision-support \\nenvironment cannot be built in one big bang. Data and functionality must be \\nBusiness \\nNeed \\nProject \\nPlanning \\nFunctional \\nRequirements \\nSystem \\nAnalysis \\nImplementation Bey \\nCnr \\nFigure 0.2: Conventional Waterfall Deployment'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 41}, page_content='8 Guide to the Development Steps \\nDecision-Support \\nStrategy \\nmn Business \\nOpportunity \\nProject \\nPlanning \\nRelease \\nEvaluation \\nBI Application \\nReleases \\nTesting \\nDevelopment \\nFigure 0.3: The BI Application Release Concept \\nrolled out in iterative releases, and each deployment is likely to trigger new \\nrequirements for the next release, as shown in Figure 0.3. \\nFigure 0.3 highlights other major differences between BI applications and \\nstand-alone systems.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 41}, page_content='* BI applications are mostly driven by business opportunity rather than busi- \\nness need. \\n+ BI applications implement a cross-organizational decision-support strategy \\nrather than departmental decision-support silos. \\n* BI decision-support requirements are mostly strategic information require- \\nments rather than operational functional requirements. \\n* Analysis of BI projects emphasizes business analysis rather than system analy-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 41}, page_content='sis, and analysis is the most important activity when developing a BI decision- \\nsupport environment. \\n* Ongoing BI application release evaluations promote iterative development \\nand the software release concept rather than big-bang development. \\nThe Cross-Organizational Development Approach \\nWith the expansion of e-business comes an increasing demand for cross-organizational \\nintegration. This integration does not refer merely to bridging old systems across'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 41}, page_content='different platforms using enterprise application integration (EAI) middleware. \\nInstead, it refers to:'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 42}, page_content='Development Approaches 9 \\nSS TI A PS EST SS EAB A SS RR FO SS SY SL TSS \\n* Information consolidation \\n* Information integration \\n* Information integrity \\n* Seamless business functionality \\n* Streamlined organizational business processes \\nMoving an organization from a “single-swim-lane” development approach to \\na cross-organizational, “cross-swim-lane” development approach requires orga- \\nnizational changes, including a culture shift. No other initiative demonstrates this'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 42}, page_content='as vividly as customer relationship management (CRM). If organizations would \\nimplement more cross-organizational BI operational applications (front-office as \\nwell as back-office) like CRM, they could significantly reduce their construction \\nefforts on BI decision-support applications. \\nAlthough in Business Intelligence Roadmap we do not address organizational \\nchanges and culture shifts, we do define the necessary BI project activities that'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 42}, page_content='support an integrated enterprise-wide infrastructure. Both technical infrastruc- \\nture and nontechnical infrastructure are required core competencies for cross- \\norganizational integration. In addition to defining project activities, we identify \\nthe roles and responsibilities to be assigned to project team members for each \\ndevelopment step. \\nThe development steps outlined in this book form an engineering roadmap \\nthat provides a framework for developing different kinds of BI decision-support'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 42}, page_content='projects. The flexible entry and exit points of this framework allow you to start \\nwith any step as long as you meet the “entry criteria” outlined in the Entry and \\nExit Criteria and Deliverables Matrix. We also designed these steps to be agile and \\nadaptive so that you can organize and manage the development of a BI application \\nas multiple subprojects, each going through several of its own iterations or releases. \\nFor example, Figure 0.4 shows two iterations each for the Extract/Transform/'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 42}, page_content='Load (ETL), Application, and Meta Data Repository subprojects. \\nThe approach presented in Business Intelligence Roadmap encourages the use \\nof parallel development tracks (subprojects) so that multiple development steps \\ncan be performed simultaneously and multiple project activities can occur con- \\ncurrently. Some project teams may choose to roll up project activities from mul- \\ntiple development steps into one step, while other project teams may not need to'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 42}, page_content='perform some steps or activities at all. Figure 0.5 illustrates the dynamics of a typ- \\nical BI decision-support project, showing several steps running simultaneously'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 43}, page_content='10 Guide to the Development Steps \\nSee RS ESP SRT EE eA ETRE EEE OER RE I ES ENTE TT EE DE EC TS IE IE NEE A STEEL LDL SE \\nEne \\n1s‘ Iteration \\nMeta Data \\nRepository \\n2\" Iteration \\nApplication \\n1s Iteration \\nApplication \\nRelease \\nMeta Data \\nRepository \\n1s\\' Iteration \\nApplication \\n2\"4 Iteration \\nETL \\n2” Iteration \\nFigure 0.4: Iterative Subprojects of an Application Release \\n{Business Case\\\\ / \\nAssesment // Planning and \\nRequiremnnts \\nData \\nAnalysis Development \\n\\\\ Application \\nDevelopment Meta Data'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 43}, page_content='\\\\ Repository \\nDevelopment \\nApplication \\nPrototyping \\nMeta Data \\nRepository \\nApplication Analysis \\nPrototyping \\nMeta Data \\nRepository \\nDevelopment / \\n{ Application \\n|\\\\ Prototyping \\nETE \\nDevelopment Application \\nPrototyping Meta Data \\nRepository \\nDesign \\nDatabase \\nDesign \\nFigure 0.5: The Dynamics of a BI Decision-Support Project'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 44}, page_content='Engineering Stages and the Development Steps 11 \\n(such as Step 5, Data Analysis, and Step 6, Application Prototyping) and multiple \\niterations of the same step (such as Step 9, ETL Design). \\nENGINEERING STAGES AND THE DEVELOPMENT STEPS \\nBI projects are organized according to the same six stages common to every engi- \\nneering project. Within each engineering stage, certain steps are carried out to see \\nthe engineering project through to its completion. Business Intelligence Roadmap'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 44}, page_content='describes 16 development steps within these stages, as outlined below. \\nThe Justification Stage \\nStep 1: Business Case Assessment \\nThe business problem or business opportunity is defined and a BI solution is \\nproposed. Each BI application release should be cost-justified and should clearly \\ndefine the benefits of either solving a business problem or taking advantage of \\na business opportunity. \\nThe Planning Stage \\nStep 2: Enterprise Infrastructure Evaluation'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 44}, page_content='Since BI applications are cross-organizational initiatives, an enterprise infra- \\nstructure must be created to support them. Some infrastructure components \\nmay already be in place before the first BI project is launched. Other infra- \\nstructure components may have to be developed over time as part of the BI \\nprojects. An enterprise infrastructure has two components: \\n1. Technical infrastructure, which includes hardware, software, middle-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 44}, page_content='ware, database management systems, operating systems, network compo- \\nnents, meta data repositories, utilities, and so on. \\n2. Nontechnical infrastructure, which includes meta data standards, data- \\nnaming standards, the enterprise logical data model (evolving), method- \\nologies, guidelines, testing procedures, change-control processes, proce- \\ndures for issues management and dispute resolution, and so on. \\nStep 3: Project Planning'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 44}, page_content='BI decision-support projects are extremely dynamic. Changes to scope, staff, \\nbudget, technology, business representatives, and sponsors can severely impact \\nthe success of a project. Therefore, project planning must be detailed, and \\nactual progress must be closely watched and reported.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 45}, page_content='12 Guide to the Development Steps \\nThe Business Analysis Stage \\nStep 4: Project Requirements Definition \\nManaging project scope is one of the most difficult tasks on BI decision-sup- \\nport projects. The desire to have everything instantly is difficult to curtail, but \\ncurtailing that desire is one of the most important aspects of negotiating the \\nrequirements for each deliverable. Project teams should expect these require- \\nments to change throughout the development cycle as the business people'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 45}, page_content='learn more about the possibilities and the limitations of BI technology during \\nthe project. \\nStep 5: Data Analysis \\nThe biggest challenge to all BI decision-support projects is the quality of the \\nsource data. Bad habits developed over decades are difficult to break, and the \\ndamages resulting from bad habits are very expensive, time consuming, and \\ntedious to find and correct. In addition, data analysis in the past was confined'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 45}, page_content='to the view of one line of business and was never consolidated or reconciled \\nwith other views in the organization. This step takes a significant percentage \\nof the time allotted to the entire project schedule. \\nStep 6: Application Prototyping \\nAnalysis of the functional deliverables, which used to be called system analy- \\nsis, is best done through prototyping so it can be combined with application \\ndesign. New tools and programming languages enable developers to relatively'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 45}, page_content='quickly prove or disprove a concept or an idea. Prototyping also allows business \\npeople to see the potential and the limits of the technology, which gives them \\nan opportunity to adjust their project requirements and their expectations. \\nStep 7: Meta Data Repository Analysis \\nHaving more tools means having more technical meta data in addition to the \\nbusiness meta data, which is usually captured in a computer-aided software'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 45}, page_content='engineering (CASE) modeling tool. The technical meta data needs to be \\nmapped to the business meta data, and all meta data must be stored in a meta \\ndata repository. Meta data repositories can be licensed (bought) or built. In \\neither case, the requirements for what type of meta data to capture and store \\nshould be documented in a logical meta model. When licensing a meta data \\nrepository product, the requirements documented on this logical meta model'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 45}, page_content='should be compared to the vendor’s meta model, if one is provided. In addi- \\ntion, the requirements for delivering meta data to the business community \\nhave to be analyzed (e.g., online help function).'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 46}, page_content='Engineering Stages and the Development Steps 13 \\nThe Design Stage \\nStep 8: Database Design \\nOne or more BI target databases will store the business data in detailed or \\naggregated form, depending on the reporting requirements of the business \\ncommunity. Not all reporting requirements are strategic, and not all of them \\nare multidimensional. The database design schemas must match the infor- \\nmation access requirements of the business community. \\nStep 9: Extract/Transform/Load Design'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 46}, page_content='The ETL process is the most complicated process of the entire BI decision- \\nsupport project. It is also the least glamorous one. ETL processing windows \\n(batch windows) are typically small, yet the poor quality of the source data \\nusually requires a lot of time to run the transformation and cleansing pro- \\ngrams. Finishing the ETL process within the available batch window is a chal- \\nlenge for most organizations. \\nStep 10: Meta Data Repository Design'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 46}, page_content='If a meta data repository is licensed, it will most likely have to be enhanced \\nwith features that were documented on the logical meta model but are not \\nprovided by the product. If a meta data repository is being built, the decision \\nmust be made whether the meta data repository database design will be \\nentity-relationship based or object oriented. In either case, the design has to \\nmeet the requirements of the logical meta model. \\nThe Construction Stage'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 46}, page_content='Step 11: Extract/Transform/Load Development \\nMany tools are available for the ETL process, some sophisticated and some \\nsimple. Depending on the requirements for data cleansing and data transfor- \\nmation developed during Step 5, Data Analysis, and Step 9, ETL Design, an \\nETL tool may or may not be the best solution. In either case, preprocessing \\nthe data and writing extensions to supplement the capabilities of the ETL tool \\nis frequently required. \\nStep 12: Application Development'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 46}, page_content='Once the prototyping effort has firmed up the functional requirements, true \\ndevelopment of the access and analysis application can begin. Developing the \\napplication can be a simple matter of finalizing an operational prototype, or \\nit can be a more involved development effort using different, more robust \\naccess and analysis tools. In either case, the front-end application development'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 47}, page_content='14 Guide to the Development Steps \\nactivities are usually performed in parallel with the activities of back-end ETL \\ndevelopment and meta data repository development. \\nStep 13: Data Mining \\nMany organizations do not use their BI decision-support environment to the \\nfullest extent. BI applications are often limited to prewritten reports, some of \\nwhich are not even new types of reports but replacements of old reports. The'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 47}, page_content='real payback comes from the information hidden in the organization’s data, \\nwhich can be discovered only with data mining tools. \\nStep 14: Meta Data Repository Development \\nIf the decision is made to build a meta data repository rather than to license \\none, a separate team is usually charged with the development process. This \\nbecomes a sizable subproject in the overall BI project. \\nThe Deployment Stage \\nStep 15: Implementation'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 47}, page_content='Once the team has thoroughly tested all components of the BI application, \\nthe team rolls out the databases and applications. Training is scheduled for \\nthe business staff and other stakeholders who will be using the BI application \\nand the meta data repository. The support functions begin, which includes \\noperating the help desk, maintaining the BI target databases, scheduling and \\nrunning ETL batch jobs, monitoring performance, and tuning databases. \\nStep 16: Release Evaluation'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 47}, page_content='With an application release concept, it is very important to benefit from les- \\nsons learned from the previous projects. Any missed deadlines, cost overruns, \\ndisputes, and dispute resolutions should be examined, and process adjust- \\nments should be made before the next release begins. Any tools, techniques, \\nguidelines, and processes that were not helpful should be reevaluated and \\nadjusted, possibly even discarded. \\nYou do not need to perform the development steps in sequence; most project'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 47}, page_content='teams will likely perform them in parallel. However, because there is a natural \\norder of progression from one engineering stage to another, certain dependencies \\nexist between some of the development steps, as illustrated in Figure 0.6. Steps \\nstacked on top of each other in the diagram can be performed simultaneously, \\nwhile steps that appear to the right or left of each other are performed relatively \\nlinearly (with less overlap) because of their dependencies.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 48}, page_content=\"15 \\nsalsuapuadagq \\ndais \\n}uatdojanaq \\n:9'0 \\nainSi4 \\nEngineering Stages and the Development Steps \\njuawAojdaq \\nuonenjeag \\naseajay \\nQL \\nuolyejuswejduy| \\nSl \\njuawdojaneq uoneoiddy \\nAs \\njuawdojaneq \\n113 tL \\nUO!JONAJSUOD \\njuawdojenag \\nubiseq \\nsishjeuy \\nAioysoday \\nAsoysoday \\nAioy'sodey \\nReg \\nBaw \\neyeq \\nejay \\neyeq \\neo \\nvb \\nOL \\nZ \\nuonNuyaq \\nsjuewasinbay \\nBuidA\\\\ojo1g uolyeoiddy \\n9 \\nsiskjeuy \\nejeq \\nsishjeuy \\nssauisng \\nBuluueld \\nuoleoiisne \\nBujuuelg \\npealoig \\nS \\nuolyenjeng aunjonuysedju| eslidiejuy \\ncA\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 48}, page_content='cA \\njuowsessy aseg \\nsseuisng i'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 49}, page_content='16 Guide to the Development Steps \\nWhile some development steps are clearly project-specific, most development \\nsteps must be performed from a cross-organizational perspective. Thus the focus \\nof those project activities takes on a cross-functional dimension, and the review- \\ners of those activities should include business representatives from other lines of \\nbusiness. The main task for the business representatives from the other lines of'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 49}, page_content='business is to validate and ratify the strategies, policies, business rules, and stan- \\ndards either being used or being developed during the BI project. Table 0.1 indi- \\ncates which steps are project-specific and which ones are cross-organizational. \\nTable 0.1: Project-Specific versus Cross-Organizational Steps \\nDevelopment Step Project-Specific versus \\nCross-Organizational \\n1. Business Case Assessment Cross-organizational'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 49}, page_content='2. Enterprise Infrastructure Evaluation (technical and Cross-organizational \\nnontechnical) \\n3. Project Planning Project-specific \\n4. Project Requirements Definition Project-specific \\n5. Data Analysis Cross-organizational \\n6. Application Prototyping Project-specific \\n7. Meta Data Repository Analysis Cross-organizational \\n8. Database Design Cross-organizational \\n9. ETL Design Cross-organizational \\n10. Meta Data Repository Design Cross-organizational \\n11. ETL Development Cross-organizational'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 49}, page_content='12. Application Development Project-specific \\n13. Data Mining Cross-organizational \\n14. Meta Data Repository Development Cross-organizational \\n15. Implementation Project-specific \\n16. Release Evaluation Cross-organizational \\nLS SE NS TET AB I RS I SEL TEE A SE TIE'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 50}, page_content='Parallel Development Tracks 17 \\nPARALLEL DEVELOPMENT TRACKS \\nAs illustrated in Figure 0.7, every BI decision-support project has at least three \\ndevelopment tracks running in parallel after the project requirements have been \\ndefined and before implementation. \\n1. The ETL Track \\nThe ETL track is often referred to as the back end. The purpose of this devel- \\nopment track is to design and populate the BI target databases. The ETL track'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 50}, page_content='is the most complicated and important track of a BI decision-support \\nproject. The fanciest OLAP tools in the world will not provide major benefits \\nif the BI target databases are not designed properly or if they are populated \\nwith dirty data. The team working on the ETL track is usually staffed with \\nknowledgeable business analysts, experienced database administrators, and \\nsenior programmers. \\n2. The Application Track'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 50}, page_content='The Application track is often referred to as the front end. The purpose of this \\ndevelopment track is to design and build the access and analysis applications. \\nJustification Stage: \\n1. Business Case Assessment \\nDeployment Stage: \\n15. Implementation \\n16. Release Evaluation \\nPlanning Stage: \\n2. Enterprise Infrastructure Evaluation \\n3. Project Planning \\nBusiness Analysis Stage: \\n4. Project Requirements Definition \\n5. Data Analysis \\n6. Application Prototyping \\n7. Meta Data Repository Analysis'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 50}, page_content='Design Stage: Construction Stage: \\n11. ETL Development : , D 12. Application Development a a eee \\n13. Data Mining ; R : Desi \\n14. Meta Data Repository Development 10. Meta Data Repository Design \\nFigure 0.7: Parallel Development Tracks (for Steps 5-14)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 51}, page_content='18 Guide to the Development Steps \\nAfter all, the key reasons for building a BI decision-support environment \\nare to: \\n* Deliver value-added information \\n* Provide easy, spontaneous access to the business data \\nThe team for the Application track is usually staffed with subject matter \\nexperts, “power users,” and programmers who know Web languages, can \\neffectively use OLAP tools, and have experience building client/server-based'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 51}, page_content='decision-support applications that incorporate graphical user interfaces. \\n3. The Meta Data Repository Track \\nMeta data is a mandatory deliverable with every BI application. It can no \\nlonger be shoved aside as documentation because it must serve the business \\ncommunity as a navigation tool for the BI decision-support environment. \\nTherefore, the purpose of this development track is to design, build, and \\npopulate a meta data repository. The team members are responsible for'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 51}, page_content='designing and building the access interfaces as well as the reporting and que- \\nrying capabilities for the meta data repository. The team working on the Meta \\nData Repository track is usually staffed with a meta data administrator and \\ndevelopers who have experience with building client/server-based interfaces \\nand are knowledgeable about Web applications. \\nTable 0.2 maps the Business Intelligence Roadmap stages and steps across these \\nthree development tracks.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 51}, page_content='These three parallel tracks can be considered major subprojects of a BI \\nproject. Each will have its own team members and its own set of activities after \\nthe project requirements have been formalized. Discoveries made in one track \\ncan (and often do) impact the other tracks. Figure 0.8 shows the interaction of \\nthe three tracks across the development steps. \\nEach development track has specific deliverables that contribute to the over- \\nall BI project objectives.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 51}, page_content='* The ETL track delivers loaded BI target databases. \\n- The Application track delivers the BI reports and queries. \\n* The Meta Data Repository track delivers the meta data.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 52}, page_content='Parallel Development Tracks \\nTable 0.2: Stages and Steps across Development Tracks \\nStages ETL Application MDR \\nSteps Track Track Track \\nJustification \\nBusiness Case Assessment J JY v \\nPlanning \\nEnterprise Infrastructure Evaluation / J v \\nProject Planning J J Vv \\nBusiness Analysis \\nProject Requirements Definition J JY v \\nData Analysis J \\nApplication Prototyping J J \\nMDR Analysis / \\nDesign \\nDatabase Design Jv J \\nETL Design J \\nMDR Design J \\nConstruction \\nETL Development J'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 52}, page_content='ETL Development J \\nApplication Development J \\nData Mining Vv \\nMDR Development J \\nDeployment \\nImplementation J J J \\nRelease Evaluation J J v \\nAbbreviations: ETL, extract/transform/load; MDR, meta data repository.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 53}, page_content='20 Guide to the Development Steps \\nGo/No-Go Decision I Project Kickoff \\nSteps performed before and after the project \\nis split into the parallel development tracks \\n(Steps 1, 2, 3, 4, 15, and 16) \\nSteps performed in the ETL track (Steps 5, \\n8, 9, 11, and partial participation in Step 6) \\nSteps performed in the Application track (Steps \\n6, 12, 13, and partial participation in Step 8) \\nSteps performed in the Meta Data \\nRepository track (Steps 7, 10, and 14)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 53}, page_content='Figure 0.8: Steps Performed in Parallel Development Tracks \\nBI PROJECT TEAM STRUCTURE \\nEvery BI project team must have a complementary skill set to perform the neces- \\nsary activities for the three development tracks. Although each track will have its \\nown subproject team members, from the overall BI project management perspec- \\ntive the BI project team structure contains only two types of teams: \\n1. The core team \\n2. The extended team \\nThe Core Team'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 53}, page_content='The Core Team \\nThe core team can be thought of as a SWAT team. A project SWAT team is a self- \\norganizing team—the members redistribute the workload among themselves, \\npeer-review each other’s task deliverables, make decisions together, brainstorm \\ntogether, and co-lead the project. The core team has permanent project core team \\nmembers and permanent step core team members.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 54}, page_content='BI Project Team Structure 21 \\n* Permanent project core team members must be available 100 percent of \\ntheir time from beginning to end of the BI project to perform project activities \\napplicable to the roles assigned to them. More importantly, they must co-lead \\nthe project. The optimum size for this team is four or five people, never \\nexceeding seven people. This team should be staffed with: \\n— One project manager (not an administrator) \\n— One representative from the business side'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 54}, page_content='— One business analyst from the information technology (IT) department \\n(either a data administrator or a business liaison) \\n— One technical person from the IT department (either a senior systems ana- \\nlyst or a senior programmer) \\nPaw The business person’s full-time availability is a critical success factor for all Bl \\nprojects. If the business executives resist releasing one business person full- \\ntime, it indicates that they neither view nor support the BI project as a critical'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 54}, page_content='cross-organizational strategic business initiative. \\n* Permanent step core team members must be available 100 percent of their \\ntime from beginning to end of those development steps that require their \\nfull-time involvement. For example, the ETL lead developer must be fully \\ndedicated to lead the activities of the ETL track. \\nAll core team members brainstorm together, assign work to each other, \\nreview each other’s deliverables, resolve issues, and make project-related deci- \\nsions together.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 54}, page_content='sions together. \\nPaw Each person on the core team can and probably will be assigned multiple \\nroles, regardless of whether they are permanent project core team members \\nor permanent step core team members. \\nTable 0.3 lists the core team roles (in alphabetical order) and their major \\nresponsibilities. \\nPaw The business representative role on the core team is usually assigned to the \\nprimary business person representing the business community for whom the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 54}, page_content='BI application is being developed. He or she participates on the project as a \\nfull-time member of the project core team. If necessary or desired, this role \\ncan be assigned to more than one business person, with the stipulation that \\nevery business person will dedicate 100 percent of his or her time to the BI \\nproject.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 55}, page_content='22 Guide to the Development Steps \\nTable 0.3: Core Team Roles and Responsibilities \\nRole Major Responsibilities \\nApplication lead developer Designing and overseeing the development of the \\naccess and analysis application (e.g., reports, queries) \\nBI infrastructure architect Establishing and maintaining the BI technical \\ninfrastructure (in some organizations, overseeing the \\nnontechnical infrastructure as well); usually reports to \\nthe strategic architect on the extended team'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 55}, page_content='Business representative Participating in modeling sessions, providing data \\ndefinitions, writing test cases, making business \\ndecisions, resolving disputes between business units, \\nand improving the data quality under the control of the \\nbusiness unit represented by this role \\nData administrator Performing cross-organizational data analysis, creating \\nthe project-specific logical data models, and merging \\nthe logical data models into an enterprise logical data \\nmodel'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 55}, page_content='model \\nData mining expert Choosing and running the data mining tool; must have \\na Statistical background \\nData quality analyst Assessing source data quality and preparing data- \\ncleansing specifications for the ETL process \\nDatabase administrator Designing, loading, monitoring, and tuning the BI target \\ndatabases \\nETL lead developer Designing and overseeing the ETL process \\nMeta data administrator Building or licensing (buying), enhancing, loading, and \\nmaintaining the meta data repository'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 55}, page_content='Project manager Defining, planning, coordinating, controlling, and \\nreviewing all project activities; tracking and reporting \\nprogress; resolving technical and business issues; \\nmentoring the team; negotiating with vendors, the \\nbusiness representative, and the business sponsor; has \\noverall responsibility for the project \\nSubject matter expert Providing business knowledge about data, processes, \\nand requirements \\nSSS SI EER EES SS EE ES TT SN I FS ES SS'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 56}, page_content='BI Project Team Structure 23 \\nSome roles can be combined and some are mutually exclusive. For example, \\none person can perform one of the following combinations of roles: \\n* Application lead developer and ETL lead developer (assuming the person has \\nthe different skill sets required for both) \\n* Data administrator, data quality analyst, and meta data administrator \\n(assuming the person has the required technical skills) \\n* Data quality analyst, subject matter expert, and business representative'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 56}, page_content='Mutually exclusive roles, which should never be assigned to the same person, \\nare listed below. \\n* Data administrator and database administrator: The data administrator pro- \\nduces process-independent logical data models, while the database adminis- \\ntrator produces process-dependent physical data models (logical database \\ndesigns). It would be difficult for one person to perform these bipolar activi- \\nties on the same project, even if the person had the skills to do both.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 56}, page_content='* Project manager and any nonlead role: Managing a BI decision-support project \\nis a full-time job and cannot be put in second position to any development work. \\nOne person will simply not have time to both manage the project and do the work. \\nThe Extended Team \\nThe extended team members also have responsibilities on the BI project, but for \\nthese members the BI project is not their main priority during the entire project'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 56}, page_content='schedule. These members have to schedule time to work with the full-time core \\nteam members. They can also be called into sessions when their expertise is \\nneeded to resolve a problem or to help make a decision. \\nEach member on the extended team can be assigned one or multiple roles \\nand is responsible for the activities performed under each assigned role. Table 0.4 \\nlists the extended team roles (in alphabetical order) and their major responsibilities.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 56}, page_content='As on the core team, some roles on the extended team can be combined and \\nsome are mutually exclusive. For example, one person can perform one of the fol- \\nlowing combinations of roles: \\n- Application developer, ETL developer, and meta data repository developer \\n(assuming the person has the different skill sets required for the three devel- \\nopment tracks) \\n* Web developer and Web master'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 57}, page_content='Guide to the Development Steps \\nTable 0.4: Extended Team Roles and Responsibilities \\nRole Major Responsibilities \\nApplication developer(s) Coding the report programs, writing query scripts, \\nand developing the access and analysis \\napplications \\nBI support (help desk staff) \\nBusiness sponsor \\nMentoring and training the business staff \\nChampioning the BI initiative and removing \\nbusiness-related roadblocks for the BI project team \\nETL developer(s) \\nIT auditor or QA analyst'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 57}, page_content='Coding the ETL programs and/or preparing the \\ninstructions for the ETL tool \\nDetermining the risks and exposures of the BI \\nproject due to internal lack of controls or external \\nforces \\nMeta data repository developer(s) \\nNetwork services staff \\nCoding the meta data repository migration \\nprograms to load the meta data repository \\ndatabase; providing meta data reports and an \\nonline help function \\nMaintaining the network environment \\nOperations staff \\nSecurity officer'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 57}, page_content='Security officer \\nRunning the batch processes for the ETL cycles, the \\naccess and analysis application, and the meta data \\nrepository \\nEnsuring that security requirements are defined \\nand that security features are tested across all tools \\nand databases \\nStakeholders (other business \\nrepresentatives or IT managers) \\nHandling limited responsibilities on the BI project, \\nsuch as reviewing and ratifying the cross- \\norganizational standards and business rules the Bi \\nproject team uses or develops'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 57}, page_content='Strategic architect Managing the overall technical infrastructure for \\nthe organization, including the BI technical \\ninfrastructure \\nTechnical services staff Maintaining the hardware infrastructure and the \\noperating systems \\n(Continued)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 58}, page_content='BI Project Team Structure 25 \\nTable 0.4: (Continued) \\nRole Major Responsibilities \\nTesters Testing programming code created by the \\ndevelopers from the ETL, Application, and Meta \\nData Repository tracks \\nTool administrators Installing and maintaining the developer tools and \\nthe access and analysis tools \\nWeb developer(s) Designing the Web site and creating the Web \\npages for displaying reports and queries on the \\nintranet, extranet, or Internet'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 58}, page_content='Web master Setting up the Web server and Web security \\nMutually exclusive roles, which should never be assigned to the same person, \\nare: \\n* Developer (of any type) and tester: A developer testing his or her own pro- \\ngrams is like the fox guarding the henhouse. Even if the developer were moti- \\nvated to break his or her own code, it is unlikely that he or she would think of \\nall the possible test cases and carry out an objective test plan. However, a'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 58}, page_content='developer can take on the role of a tester for another developer’s programs, as \\ndone in peer reviews and integration testing. \\nAdditional Limited Roles \\nOther roles participate on the BI project on a limited, as-needed basis. \\n* Data owners are the major stakeholders in any BI initiative. They are respon- \\nsible for the quality of business data under their ownership and for validating \\nthe business meta data. \\n* The facilitator is a third-party participant during post-implementation'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 58}, page_content='reviews. His or her responsibility is to lead the review meetings. \\n* The scribe is also a third-party participant during post-implementation \\nreviews. He or she is responsible for taking notes and documenting the meet- \\ning minutes and the resulting action items.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 59}, page_content='26 Guide to the Development Steps \\nThe BI Arbitration Board \\nThe discussion on roles and responsibilities cannot end without mention of the \\nBI arbitration board. On cross-organizational BI projects, technical as well as \\nbusiness disputes will arise that neither the core team nor the extended team will \\nbe able to resolve. A dispute resolution procedure should be established with \\nguidelines for handling these types of disputes. If a resolution cannot be achieved'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 59}, page_content='through other prescribed means, the project team must have access to a body of \\nexecutives with the authority to be the tiebreaker. This body of executives is the \\nBI arbitration board, sometimes known as the BI steering committee. \\nBI arbitration boards can be organized in a variety of ways. A BI arbitration \\nboard can be a newly created group whose members include the business spon- \\nsor, the chief technology/information officer (CTO/CIO), IT managers, the chief'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 59}, page_content='operating officer (COO), the chief financial officer (CFO), and line-of-business \\nmanagers. In some smaller organizations, even the chief executive officer (CEO) \\ncould be a member of this board. \\nIn other organizations, the BI arbitration board can be an existing commit- \\ntee. Most organizations already have some official or unofficial executive com- \\nmittee. For example, the CTO/CIO typically meets monthly with the employees'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 59}, page_content='who report directly to him or her, and the CEO typically meets monthly with \\nline-of-business executives, the CFO, and the COO. If a separate BI arbitration \\nboard cannot be established, then the BI project teams must have access to the \\nexisting executive committees. \\nJUSTIFICATION FOR USING THIS PROJECT LIFECYCLE GUIDE \\nIt has been said in the industry that “a paper airplane can be constructed with lit- \\ntle forethought, but a jet airplane cannot.” Similarly, a stand-alone system that'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 59}, page_content='has only a handful of business people using it can get by without a set of carefully \\nplanned and executed project activities, but a cross-organizational BI initiative \\ncertainly cannot. \\nAs the BI decision-support environment evolves over time, it is imperative \\nthat a strong foundation exists to support such expansion. To build a strong \\nfoundation, many things have to be considered and many tasks have to be per- \\nformed by many people. It is irresponsible to casually “make up” who does what'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 59}, page_content='and when along the way. That type of ad hoc development approach would put'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 60}, page_content='Bibliography and Additional Reading 27 \\nthe organization’s large investment at risk and would pose an even bigger risk for \\nlosing business opportunities. There are quite a few casualties in the trenches of \\nlost opportunities! \\nThe question is not whether or not a set of formalized guidelines must be \\nused but what type of guidelines to use. A waterfall methodology is not suitable \\nfor the iterative releases of BI decision-support applications, but an agile and'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 60}, page_content='adaptive development guide specifically geared toward BI decision-support \\napplications is. Business Intelligence Roadmap is such a guide. \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nAdelman, Sid, and Larissa Terpeluk Moss. Data Warehouse Project Management. \\nBoston, MA: Addison-Wesley, 2000. \\nBeck, Kent. Extreme Programming Explained: Embrace Change. Boston, MA: \\nAddison-Wesley, 2000. \\nHumphrey, Watts S. Winning with Software: An Executive Strategy. Boston, MA: \\nAddison-Wesley, 2002.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 60}, page_content='Inmon, William H., Claudia Imhoff, and Ryan Sousa. Corporate Information Fac- \\ntory. New York: John Wiley & Sons, 1997. \\nZachman, John. The Zachman Framework: A Primer for Enterprise Engineering \\nand Manufacturing. La Canada, CA: Zachman International, 2002. \\nDM Review: http://www.dmreview.com \\nJournal of Data Warehousing: http://www.dw-institute.com \\nGlossaries: http://www.techweb.com/encyclopedia and \\nhttp://www.ncits.org/tc_home/k5htm/ANSDIT.htm'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 61}, page_content='Cah dar amyish etre anne, {fame to is w mca i weg \\n7a * \\nae \\npars ¥ \\nPaige 0p nol gy Loeonap apdl aepD oc [ot sd Dihenece tord UP croc mgeustied MM pr yee’ oR Pe \\neect Ming hs od OS eo hematin: vals Pav cto \\nBirds were ele colar tae « 10 ster ani ee Loc eousitm he hws dareciuitng. free ecs. mat TE teen ae \\nhing setinpemard nek: qaeed ia thes leg Sy egy ality bare itis. i. .~ \\naR (4G Ot) Os sadly’ taint \\nWV entetrwie<i (<2 vo Got Sew: 2s Fae ft? én. art ior 9'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 61}, page_content=\"i paweee oa) 4s on Oe orien Wa Sains oho 4, BE \\npant So's overt a! aap lS ae tA Tae \\nPaik Sg # ‘vos trababrt Sy he FAG (OCG Abe : adin, 62 ae luider 7 \\nSa iis og sy ok? sail a Tate St ¥ Mie. H is Meat \\nSob See \\n‘A Metta genres: shot ea enn ane \\nS Are oS aw. 2 sow at =) Seid eis \\nSP alters a oie) =e ie Le %* “ei ta “— Th | T = Aer; ii : Le Jn * “ah - \\n. ots ~ at tre ~ Tt) Cs oP rn el « 5 a \\norreenegh Sov caW ene y ai ice eer ¢ a i a 7 . x ~~ =) \\npantie 29: Eo app TA Ma EES AS Lames aT ye\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 61}, page_content='- ouch: ccieean \\nMISTRAL Tere tow Users Yoga ee lle vrei age! a a \\n4 Nas ‘eo Ws Se «tebe di nia Paipiacateectneliiven \\nip @rraeiwW—s. bw ¢ Zip ee RMP ieee \\nliege tity & fas : jag Vee 5 : ws \\nones \\nyaad and we Mow ech rae itz \\nve =) An \\nbe Gee fi cece ou? oo, taneniel ir oem ae © \\nUnits 4hhi@ f/h.aqe coats Agtti Of aa \\nPeverte Wa. G2riyrre eek SAVE ly bon ole S=tal 5% \\n(1 é “Loge “=~ ro uw ate ramnebly ist \\nand) ts » Gres iw way tad oc od a Ng,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 62}, page_content='Justification — \\n1 C Business Case \\ny Assesment , \\nbd See icon \\nrole Ot \\nCHAPTER ONE \\nStep 1: Business Case \\nAssessment \\nCHAPTER OVERVIEW \\nThis chapter covers the following topics: \\nm@ Things to consider during a business case assessment \\n@ The importance of developing a business justification and \\na business strategy for BI decision-support initiatives \\n@ Business drivers and strategic business goals, rather than \\nnew technology, as the motivating forces behind every BI \\nproject'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 62}, page_content='project \\n@ Business analysis issues such as defining the organization’s \\ninformation needs, identifying data sources, and analyzing \\nthe current and desired quality of data \\n@ The use of cost-benefit analyses to demonstrate how (and \\nhow soon) a return on investment (ROI) can be achieved \\nm Risk assessment and the six major risk categories of tech- \\nnology, complexity, integration, organization, project team, \\nand financial investment'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 62}, page_content='@ Brief descriptions of the activities involved in business case \\nassessment, the deliverables resulting from those activities, \\nand the roles involved \\nm@ The risks of not performing Step 1 \\n29'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 63}, page_content='30 Step 1: Business Case Assessment \\nTHINGS TO CONSIDER \\nAccess to Information \\nV Where do we get the information we need for making decisions today? \\nY What information do we already have? What additional information do we \\nneed? \\nBusiness Drivers and Sponsorship \\n/ What are the business drivers for an overall BI decision-support initiative? \\n¥ What are the specific business drivers for this BI application? \\n¥Y Who could be a potential business sponsor?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 63}, page_content='/ Do we already have a business sponsor for this BI application? \\nReadiness Assessment \\nV Are we ready for a BI decision-support environment? \\nV Have we performed a readiness assessment? \\n/ What do we need to do to get ready? Buy hardware? Acquire tools? Establish \\nstandards? Hire more staff? \\nRisks \\n¥ What are the risks of building a BI decision-support environment? \\n¥ What are the risks of not building a BI decision-support environment? \\nCost Justification'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 63}, page_content='Cost Justification \\nV Is it worth building this BI application, or will it cost more than we can jus- \\ntify? \\nY Do we know what all the BI project costs will be? \\n¥ Will we have to buy new hardware? Upgrade our network? Buy new tools? \\nHire consultants? \\nReturn on Investment \\n¥Y How will we measure ROI? For example: \\n+ Will the BI application have an effect on our customer service? \\n* Will it help us increase customer satisfaction? \\n* Will it help us increase our revenue?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 63}, page_content='* Will it help us make strategic decisions that will lead to increased profits? \\n* Will it help us reduce our costs? \\n* Can we expect to gain a bigger market share as a result of the BI application?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 64}, page_content='Business Justification 31 \\nAlthough BI has captured the imagination of many organizations, the indus- \\ntry is still challenged to quantify benefits accurately, especially since an organiza- \\ntion cannot buy a BI product off the shelf and expect it to provide a complete \\nsolution to the business needs. “Business intelligence,” or intelligence about the \\nbusiness, is unique to every organization, as are the policies and business rules'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 64}, page_content='governing the organization’s business practices. This uniqueness should be explored \\nfor competitive advantage. Buying an off-the-shelf product, which was not built \\naround the unique features of an organization, reduces the likelihood for com- \\npetitive advantage. \\nBUSINESS JUSTIFICATION \\nSince it usually costs millions of dollars to create a BI environment, an organiza- \\ntion considering such an initiative needs a BI strategy and a business justification'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 64}, page_content='to show the balance between the costs involved and the benefits gained. A BI deci- \\nsion-support initiative provides numerous benefits—not only tangible benefits \\nsuch as increasing the sales volume but also intangible benefits such as enhancing \\nthe organization’s reputation. Many of these benefits, especially the intangible \\nones, are difficult to quantify in terms of monetary value. Nevertheless, you \\nshould prepare an itemized and detailed list of benefits in order to measure them'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 64}, page_content='against the high cost of a BI implementation. Although the general benefits of BI \\ndecision-support initiatives are documented widely, they cannot justify your BI \\ninitiative unless you can associate these benefits to your organization’s specific \\nbusiness problems and strategic business goals. \\nJustification for a BI decision-support initiative must always be business- \\ndriven and not technology-driven. It would not be wise to set up an expensive BI'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 64}, page_content='decision-support environment only to experiment with new technology. There- \\nfore, each proposed BI application must reduce measurable “business pain” \\n(problems affecting the profitability or efficiency of an organization) in order to \\njustify building the application. \\nIt is best to start the business justification process by identifying the organiza- \\ntion’s strategic business goals. The BI decision-support initiative as a whole, and'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 64}, page_content='the proposed BI application specifically, should support those strategic business \\ngoals. This enables the ongoing viability of the BI decision-support environment. \\nIf BI applications are built without a good business justification, management \\nwill most likely not support the effort.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 65}, page_content='32 Step 1: Business Case Assessment \\nThe business representative should be primarily responsible for determining \\nthe business value of the proposed BI application. The information technology \\n(IT) department can become a solution partner with the business representative \\nand can help explore the business problems and define the potential benefits of \\nthe BI application. IT can also help clarify and coordinate the different needs of'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 65}, page_content='the varied groups of business people (knowledge workers, business analysts, busi- \\nness executives). For example, there could be different requirements for: \\n> Ease of use \\n> Level of data granularity \\n* Timeliness \\n* Data quality \\n* Security \\n- Amount of external data \\n* Historical requirements \\n* Tool capabilities \\nWith the business representative leading the business case assessment effort, \\nIT staff can assist with the four business justification components (Figure 1.1). \\nBusiness'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 65}, page_content='Business \\nAnalysis \\nIssues \\n- Business \\nDrivers \\nCost- \\nBenefit \\nAnalysis \\nFigure 1.1: Business Justification Components \\n* Business drivers: Identify the business drivers, strategic business goals, and \\nBI application objectives. Ensure that the BI application objectives support \\nthe strategic business goals.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 66}, page_content='Business Drivers 33 \\n* Business analysis issues: Define the business analysis issues and the informa- \\ntion needed to meet the strategic business goals by stating the high-level \\ninformation requirements for the business. \\n- Cost-benefit analysis: Estimate costs for building and maintaining a success- \\nful BI decision-support environment. Determine the ROI by assigning mone- \\ntary value to the tangible benefits and highlighting the positive impact the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 66}, page_content='intangible benefits will have on the organization. \\n* Risk assessment: Assess the risks in terms of technology, complexity, integra- \\ntion, organization, project team, and financial investment. \\nThe next four sections in this chapter explore each of these components. \\nBUSINESS DRIVERS \\nWithout strong business drivers and without an alignment with the strategic \\nbusiness goals of the organization, the BI decision-support initiative may falter.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 66}, page_content='For example, let us assume that the organization wants to increase revenue by \\ndecreasing time to market. This translates into building BI applications as fast as \\npossible, no matter what other effects this might have (for example, as speed goes \\nup, quality goes down). Further, let us assume that the BI application objective is \\nto decrease operating costs by increasing productivity. This leads to building BI \\napplications that deliver business process improvements no matter what it takes'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 66}, page_content='(for example, as quality goes up, speed goes down). In this example, the organi- \\nzation’s strategic goal and the BI application objective are both worthy business \\ndrivers for building a BI solution. However, because the strategic goal and the BI \\napplication objective are not compatible in terms of speed and quality issues, it \\nwill be difficult to get management’s support for this BI application. \\nThis example illustrates the importance of understanding the organization’s'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 66}, page_content='strategic business goals as well as the IT strategic plan and ensuring that the BI \\napplication objectives support both. This may be more difficult to do than it \\nappears. Even some of the most sophisticated organizations often do not have easily \\naccessible or well-articulated strategic business goals statements. Become a “detec- \\ntive” and review the organization’s annual report, public statements, newspaper \\ncoverage, syndicated articles, and internal memos for valuable information.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 66}, page_content='Substantiate your business justification. Do not invent a business case where \\none does not exist just to get the BI project approved. Interview senior managers'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 67}, page_content='34 Step 1: Business Case Assessment \\nRE SS SEERA ES RE AE LEE EEE LE EEE LITA ALOE LIES \\nto confirm the organization’s strategic goals, and interview business managers \\nand business analysts to validate the BI application objectives. \\nLet us discuss an example of a valid business justification. An automobile \\nmanufacturer was rated near the bottom of a study on customer satisfaction and \\nproduct quality. This hurt the manufacturer in two ways.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 67}, page_content=\"1. The warranty costs were much higher than those of an average automobile \\nmanufacturer. These measurable costs were directly impacting the organiza- \\ntion’s bottom line. \\n2. Unsatisfied customers spread the word about the manufacturer: “I'll never \\nbuy another car from that company—and I'll tell all my friends.” The costs of \\ndamaged customer confidence and lost sales were immense but much more \\ndifficult to measure than the costs of warranty.\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 67}, page_content='In this example, the strategic business goals were to retain the customers and \\nto reduce the expenses on warranty costs. In order to achieve these two goals the \\nautomobile manufacturer had to be able to communicate the information about \\nmalfunctioning parts to the parts makers on a timely basis. If a parts maker did \\nnot improve the quality of a part, the automobile manufacturer would have to \\nbuy that part from a different parts maker. The automobile manufacturer also'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 67}, page_content='needed information about the customers who were returning the malfunctioning \\ncars in order to contact them for “damage control.” , \\nThis automobile manufacturer justified building a BI application to measure \\nmanufacturing quality and to relate the quality measures to loss of sales, cus- \\ntomer complaints, and customer defection. Quality measures were to be captured \\nat the time of assembly as well as from the warranty data. Since a major portion'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 67}, page_content='of overall product quality is based on the quality of the parts that go into the \\nautomobile, the quality measures were to be provided to the parts makers \\nthrough secure Web access. By giving the parts makers this information, the auto- \\nmobile manufacturer believed the parts makers would be able to improve the \\nquality of their parts, which, in turn, would improve the overall quality of the \\nassembled automobile. In this case, the BI application objectives directly sup-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 67}, page_content='ported the strategic business goals. \\nBusiness justification is an iterative process. As difficult as it might be to jus- \\ntify the business case, realize that business managers are aware of the buzz about \\nBI and would like to take advantage of any competitive benefit they can get. Reit- \\nerating the benefits will help crystallize the business justification and make every- \\none feel comfortable about funding the BI decision-support project.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 68}, page_content='Business Analysis Issues 35 \\nOnce the strategic business goals and BI application objectives are verified \\nand matched, you can define the business analysis requirements for the BI appli- \\ncation that will allow the organization to meet its strategic business goals. \\nBUSINESS ANALYSIS ISSUES \\nIn most organizations, business analysis issues usually revolve around unmet \\ninformation needs from current heterogeneous data sources and poor quality of \\nthe source data. \\nInformation Needs'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 68}, page_content='Information Needs \\nWith the help of business analysts, formulate the business issues that need to be \\nresolved by each BI application objective. Determine what results you want to \\nobtain from the business analysis, for example, answers to such questions as, \\n“Why are we losing 50 percent market share to ABC Company in New England?” \\nThen define the information requirements for the business issues at hand. Deter-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 68}, page_content='mine the subject areas, timing, level of detail, granularity of data, and even what \\nexternal data you need to answer the business questions. Identify the associated \\nbusiness roles (e.g., senior business management, business analyst, and so on) \\nthat would be active in the various decision-support functions. \\nIdentify possible data sources where the required information could reside. \\nData sources can be internal as well as external, and business insights often lie'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 68}, page_content='buried in the relationships among the multiple data sources. \\nTypes of Data Sources \\nOne of the challenges in building a BI decision-support environment is to merge \\ndata from different. types of data sources. There are three major types of data \\nsources: operational, private, and external (Figure 1.2). \\nOperational Private External \\nFigure 1.2: Three Major Data Sources'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 69}, page_content='36 Step 1: Business Case Assessment \\nOperational Data \\nOnline transaction processing (OLTP) and batch systems provide internal opera- \\ntional data about subject areas, such as the following: \\n* Financial \\n* Logistics \\n* Sales \\n* Order entry \\n* Personnel \\n: Billing \\n* Research and engineering \\nPrivate Data \\nThis internal departmental data usually comes from the desktops and worksta- \\ntions of business analysts, knowledge workers, statisticians, and managers. Exam- \\nples include the following:'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 69}, page_content='+ Product analysis spreadsheets \\n* Regional product usage spreadsheets \\n* Prospective customer databases \\nExternal Data \\nOrganizations often purchase external data from vendors that specialize in col- \\nlecting industry-specific information available in the public domain, such as the \\nfollowing: \\n* Health care statistics \\n* Customer profile information \\n* Customer catalog-ordering habits \\n* Customer credit reports \\nExternal data is usually clustered around the following categories:'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 69}, page_content='* Sales and marketing data: lists of prospective customers \\n* Credit data: individual credit ratings, business viability assessments \\n* Competitive data: products, services, prices, sales promotions, mergers, takeovers'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 70}, page_content='Cost-Benefit Analysis or \\n> Industry data: technology trends, marketing trends, management science, \\ntrade information \\n* Economic data: currency fluctuations, political indicators, interest rate move- \\nments, stock and bond prices \\n* Econometric data: income groups, consumer behavior \\n* Demographic data: age profiles, population density \\n* Commodity data: raw material prices \\n* Psychometric data: consumer profiling'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 70}, page_content='* Meteorological data: weather conditions, rainfall, temperature (especially for \\nagricultural and travel industries) \\nSource Data Quality \\nMerging and standardizing data is usually a requirement of every BI application \\nbut one that is not so easy to accomplish. One of the difficulties in merging and \\nstandardizing data from different types of data sources is that the data is stored in \\ndifferent file structures on different platforms. What makes the process even'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 70}, page_content='more difficult is that the keys for the same objects on different data sources usu- \\nally do not match, the definitions for the same apparent data are often inconsis- \\ntent, and the values are often missing or conflicting. In addition, different people \\nin the organization have authority to determine business rules and policies for \\ndata from different types of data sources, and resolving data conflicts among \\nthem or getting clarification is often all but impossible.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 70}, page_content='Standardizing data from internal operational data sources is difficult enough, \\nbut standardizing data from private and external data sources is a major chal- \\nlenge and could be costly. This cost should be calculated and included in the cost- \\nbenefit analysis. \\nCosT-BENEFIT ANALYSIS \\nA common complaint is that BI projects are hard to cost-justify. That can be true \\nif there is no obvious business problem to solve. One of the most difficult aspects'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 70}, page_content='in building a business case for a BI application is to show an adequate ROI. \\nDespite the difficulty, you must demonstrate how, by analyzing and mining the \\ninformation in the BI decision-support environment, the organization can more \\neffectively maneuver and adapt to an increasingly changing marketplace.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 71}, page_content='38 Step 1: Business Case Assessment \\nBenefits are usually harder to quantify than costs, and it will take many high- \\nvalued benefits to offset the costs. A very effective method for justifying the \\nexpenditure of a BI application is to tie it directly to a business problem of mea- \\nsurable proportion. For example, let us assume an organization is losing $5 mil- \\nlion each year because it cannot curb insurance fraud due to insufficient and'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 71}, page_content='unreliable data about its underwriting practices. If the proposed BI application \\ncan resolve that specific business problem, it will be relatively easy to justify. \\nTherefore, be as detailed as possible when identifying the benefits, even if it is dif- \\nficult to quantify a precise ROI. This way you can gain the confidence of business \\nexecutives and win approval for the BI project. \\nNote that not all business problems need a BI solution. For example, the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 71}, page_content='types of problems that do not require a BI application because they can be solved \\nin more economical and less complicated ways are: \\n* Provide easier online access to a flat file \\n+ Archive operational data \\n+ Merge two operational files for operational processing \\n* Separate the operational reporting function from the operational update \\nfunction \\nSometimes all you need to do to solve an operational problem is to buy a bet-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 71}, page_content='ter reporting tool or move the data into a relational database; neither should be \\ninterpreted as a need for a BI solution. However, if the business problem hinges \\non an inability to analyze integrated cross-functional data or to extract from the \\noperational systems hidden intelligence needed to make strategic business deci- \\nsions, then a BI decision-support initiative is probably the right solution. \\nThe results of the cost-benefit analysis should succinctly state how the BI'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 71}, page_content='application would solve a business problem or enable a business opportunity. It \\nshould also state what type of information will be available, how that informa- \\ntion can be used to make better business decisions, and when and how the infor- \\nmation will be presented to the business community (e.g., monthly reports, ad \\nhoc access through online analytical processing [OLAP] tools). Once you have \\nclearly stated the business need and outlined the benefits, the next step is to esti-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 71}, page_content='mate and compare the detailed costs and benefits so you can produce the pro- \\njected ROI, which provides the justification for the BI project. \\nAll BI decision-support initiatives should fulfill at least one of the five benefit \\ncategories listed below (Figure 1.3).'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 72}, page_content='Cost-Benefit Analysis 39 \\nSS RS a I SS ES SE \\n{ \\nRevenue \\nIncrease \\nIncrease | \\nCustomer \\nSatisfaction . \\nImprovement, \\n_ Savings \\n_ Increase \\nFigure 1.3: Benefit Categories \\n1. Revenue increase, possibly in the form of: \\n* Identification of new markets and niches \\n- More effective suggestive selling \\n* Faster opportunity recognition \\n* Faster time to market \\n2. Profit increase, including possibilities for: \\n- Better targeted promotional mailings \\n+ Early warning of declining markets'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 72}, page_content='* Identification of under-performing product lines or products \\n* Identification of internal inefficiencies \\n* More efficient merchandise management \\n3. Customer satisfaction improvement through: \\n- Improved understanding of customer preferences \\n* Improved customer-to-product matching \\n* Up-selling to customers \\n* Increased repeat business \\n- Faster resolution of customer complaints \\n4, Savings increase through: \\n* Reduction in wasted or out-of-date merchandise'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 72}, page_content='- Reduction in requests for customized reporting'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 73}, page_content='40 Step 1: Business Case Assessment \\n5. Market share gain through: \\n* Increased numbers of customers who defect from the competition \\n* Much higher customer retention rate as compared with previous years and \\nwith the competition \\nIn addition to determining ROI, a business case assessment must include an \\nappraisal of risk. Any project is bound to involve some risks and, given the high \\ncosts of BI projects, performing a risk assessment is a high priority. \\nRisK ASSESSMENT'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 73}, page_content='RisK ASSESSMENT \\nRisks are factors or conditions that may jeopardize a project. Risks should be \\nassessed for the following six major variables: \\n. The technology used for implementing the project \\n. The complexity of the capabilities and processes to be implemented \\n. The integration of various components and of data \\n. The organization and its financial and moral support \\n. The project team staff’s skills, attitudes, and commitment levels'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 73}, page_content='NO oO —_ & bw . The financial investment in terms of ROI \\nTable 1.1 depicts a basic risk assessment matrix for these six variables, using \\nthe colors of a traffic light to indicate the severity of the risk: \\nGreen = low risk—go ahead with the project \\nYellow = medium risk—caution, proceed slowly \\nRed = high risk—stop, reevaluate before proceeding \\nEach organization should develop its own appropriate variables and risk con-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 73}, page_content='ditions for analyzing the risks most likely to impact its BI project. In developing \\nthat detailed risk assessment matrix for your organization, expand on the ques- \\ntions listed below. \\n* Technology risk \\n— How mature are the selected technologies within the marketplace? \\n— How mature are the selected technologies within the organization? \\n— How many different technologies will co-exist? \\n— Do we have incompatible operating systems?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 73}, page_content='— Do we have incompatible database management systems (DBMSs)?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 74}, page_content='Risk Assessment 41 \\nTable 1.1: Basic Risk Assessment Matrix \\nLevel of Risk \\nVariable Green (Low) Yellow (Medium) Red (High) \\nTechnology Experienced with Minimal experience -Newtechnology, — \\nmature technology with technology little experience _ \\nComplexity Simple, minimal Moderate, some Mission critical, will \\nworkflow impact workflow impact require extensive \\n_ reengineering» \\nIntegration Stand-alone, no Limited integration Extensive _ \\nintegration required integration \\nrequired |'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 74}, page_content='required | \\nOrganization Solid internal Supportive to a large Little internal — \\nsupport extent support \\nProject team Business experience, | Some business No business _ \\nbusiness-driven, experience, business- experience, only — \\ntalented, great driven, talented, fair technology-driven, \\nattitude attitude limited talent, bad \\nattitude © \\nFinancial Possible ROI within —_— Possible ROI within a Possible ROI after \\nInvestment a very short time moderate time frame a few years | - \\n* Complexity risk'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 74}, page_content='* Complexity risk \\n— How complex is the overall IT environment? \\n— How complex is the BI application itself? \\n— How extensively will workflow have to change? Will it have to be com- \\npletely reengineered? \\n— How many sites will be supported? \\n— What is the degree of distribution of data, processes, and controls? \\n* Integration risk \\n— How many interfaces will the BI application have? \\n— Are there external interfaces? \\n— How much source data redundancy exists?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 74}, page_content='— Can the primary keys from various data sources be matched?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 75}, page_content='42 Step 1: Business Case Assessment \\n— Do we have incompatible standards? No standards? \\n— Do we have “orphan” records as a result of referential integrity problems? \\n* Organization risk \\n— How much risk will business management tolerate? \\n— How much risk will IT management tolerate? \\n— How much financial and moral support can we expect when the project \\nencounters hurdles? \\n* Project team risk \\n— How much experience does the team have with successful implementations \\nof BI applications?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 75}, page_content='— How broadly based is that experience? \\n— How well balanced is the team? \\n— How is team morale? \\n— How likely is it that we may lose one or more team members? \\n— Do our team members’ skills cover all the basic disciplines? \\n— Will the business representative be an active player? \\n— How strong is the project manager? \\n* Financial investment risk \\n— How fast can ROI be expected? \\n— How likely is it that the costs will outweigh the benefits?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 75}, page_content='— Can financial risk be mitigated by using only proven technologies? \\nThe combination of high complexity and greater integration often results in a \\nhigher risk of failure to the organization. \\nExpand each of these risk categories with organization-specific detailed vari- \\nables and detailed conditions for each of the three severity rankings (low, \\nmedium, high). Table 1.2 shows an example of a detailed risk assessment matrix \\ntaken from a case study.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 75}, page_content='The managers for the organization in this case study listed the detailed risk \\nvariables. Then for each variable, they described the conditions for each of the \\nthree risk severity rankings. For example, in the category for business workflow \\nsupport: \\n* Low risk = Supports business workflow seamlessly \\n* Medium risk = Requires some manual intervention \\n* High risk = Requires significant manual intervention'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 76}, page_content='Architecture \\nevaluation \\nExtensibility into \\nsubsequent \\nreleases \\nLogical data \\nmodel: \\ncompleteness \\nLogical data \\nmodel: \\nextensibility \\nMeta data \\n(business and \\ntechnical) \\nPhysical data \\nmodel: \\ncompleteness \\nPhysical data \\nmodel: extens- \\nibility for new \\nproduct types \\nWell-architected \\napplication \\nFully extensible into \\nsubsequent releases \\nAll information \\nrequirements met \\nFully extensible \\nComplete and easily \\nmaintainable \\nExistence of some \\narchitectural issues'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 76}, page_content='Risk Assessment 43 \\nTable 1.2: Case Study: A Detailed Risk Assessment Matrix \\nLevel of Risk \\nVariable Green (Low) Yellow (Medium) Red (High) — \\nProject Supports every Supports most critical _—_ Fails to support \\nrequirements: critical ad hoc ad hoc reporting critical ad hoc \\nad hoc reporting requirements reporting \\nreporting requirement requirements \\nProject Supports every key Supports most key Fails to support — . \\nrequirements: business business requirements key business oe'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 76}, page_content='AS/400 requirement requirements \\nBusiness Supports business Requires some Requires \\nworkflow workflow seamlessly manual intervention significant manual \\nsupport intervention \\nPoorly architected \\napplication \\nExtensible for most \\nrequirements \\nMost information \\nrequirements © \\ndocumented \\nNot extensible into \\nsubsequent \\nreleases \\nSignificantly mis- \\nsing information \\nrequirements \\nSome extensibility \\nissues \\nIncomplete or not \\neasily maintainable \\nComplete and tuned \\nFully extensible for'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 76}, page_content='new product types \\nComplete but not \\ntuned \\nNot extensible \\nNot incorporated — \\nIncomplete, cannot \\nbe evaluated — \\nLimited product type \\nextensibility \\nIncomplete, cannot \\nbe evaluated \\n(Continued)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 77}, page_content='Table 1.2: (Continued) \\nVariable \\nPhysical data \\nmodel: source \\nsystem feeds \\nGreen (Low) \\nAcceptable design \\nsupport for source \\nsystems \\nInterfaces Supports external \\n(external and and internal \\ninternal) interfaces \\nAnalysis Easy to add \\ndimensions and \\nmeasures: \\nadding new \\nproduct lines \\nAnalysis \\ndimensions and \\nmeasures: ad- \\nding new tools \\nfor data analysis \\nUse of meta \\ndata repository \\nLoading of the \\nBI target \\ndatabases \\nPhysical \\ndatabase issues \\nPerformance \\nissues \\nSystems'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 77}, page_content='issues \\nSystems \\nmanagement \\nissues: \\nmaintenance \\nProposed cubes and \\nset of dimensions \\nsufficient to support \\nthe business \\nanalysts \\nFully developed \\nLoad procedures \\nestablished and \\nperform well \\nEffective and \\nefficient physical \\ndatabase design \\nConforms to stated \\nperformance \\nrequirements \\nSupport procedures \\nwell established and \\ndocumented \\nbs ies \\nset of dimensions 7 \\nStep 1: Business Case Assessment \\nLevel of Risk \\nPerformance or timing \\nconcerns \\nnited support for —'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 77}, page_content='external and internal — \\ninterfaces \\nCan be sacedt ae \\nrequires significant \\ncube reconstruction \\nPropose d cubes and \\nLimited meta data \\nsupport \\nLoad procedures \\npoorly documented or \\nperform poorly \\nMinor issues with \\nphysical database \\ndesign \\nSome performance \\nissues \\nLimited support \\ndocumentation \\nPoor inne a \\nexternal and \\ninternal interfaces \\nProposed cubes \\nand set of \\ndimensions \\ninsufficient \\n(Continued)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 78}, page_content='Business Case Assessment Activities 45 \\nTable 1.2: (Continued) \\nLevel of Risk \\nVariable Green (Low) Yellow (Medium) Red (High) \\nSupport issues Backup and disaster | Backup and disaster oug \\nrecovery procedures _—_ recovery procedures \\ndeveloped and developed but not \\ninstalled installed \\nSecurity Satisfies application Difficult to maintain \\nimplementation needs and is easy to \\nmaintain \\nThe managers then selected the applicable risk severity ranking for each vari-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 78}, page_content='able by highlighting the description that most accurately portrayed the condition \\nof their BI project using the colors green, yellow, and red. Out of 21 variables, \\nthey rated only two variables low risk, six variables medium risk, and thirteen \\nvariables high risk. The managers decided that the overall risk for this BI project \\nwas high. \\nHaving a realistic assessment of the severity of potential risks will help the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 78}, page_content='project team create realistic estimates and expectations for the BI project. Con- \\nversely, unidentified and unmanaged risks can result in project failure or even \\njeopardize the entire BI initiative. \\nBUSINESS CASE ASSESSMENT ACTIVITIES \\nThe business case assessment activities do not need to be performed linearly. Fig- \\nure 1.4 indicates which activities can be performed concurrently. The list below \\nbriefly describes the activities associated with Step 1, Business Case Assessment.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 78}, page_content='1. Determine the business need. \\nJustification of a BI project is difficult only if there is no obvious business rea- \\nson for the BI application. There must be a clearly defined business informa- \\ntion need that cannot be satisfied with traditional decision-support methods. \\nThe business need should be tied to a financial consequence for the organiza- \\ntion, either as cost overruns or lost revenue. The financial consequence could'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 79}, page_content='46 Step 1: Business Case Assessment \\nSERRATE INE TS LA SST EB EE TE SS TD OI AE IT I! EO CLE IO EOL EELS SII SEE SOS ELE \\n1 \\nDetermine \\nbusiness need \\nis \\nAssess operational \\nsources and procedures \\nAssess current \\nDSS solutions \\nAssess competitors’ Bl \\ndecision-support initiatives \\nwy \\nDetermine Bl \\napplication objectives \\n8 \\nPerform risk \\nassessment \\nPerform cost- \\nbenefit analysis \\nPropose \\nBI solution \\nWrite assessment \\nreport \\nFigure 1.4: Business Case Assessment Activities'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 79}, page_content='be the result of a lost business opportunity (e.g., lack of access to vital infor- \\nmation) or a business problem (e.g., reporting inconsistencies or reliance on \\ndirty data). In either case, you must quantify the business need as a monetary \\nexpression (e.g., $5 million lost annually to the competition because of an \\ninability to cross-sell to current customers). \\n2. Assess the current decision-support system solutions.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 79}, page_content='Examine the current decision-support system (DSS) solutions and determine \\ntheir deficiencies. If the current solutions do not provide the information \\nneeded to mitigate the business problem, the reasons have to be understood. \\nIf the necessary information is not being delivered, it could be due to \\nresource shortages and long backlogs in IT’s workload. Other reasons could'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 80}, page_content='Business Case Assessment Activities 47 \\ninclude difficulty accessing and merging source data because of different key \\nstructures, missing keys, or data redundancy and inconsistencies. \\nAssess the operational sources and procedures. \\nWhile assessing the current DSS solutions, give special attention to the opera- \\ntional source data and operational procedures. The business problem could \\nexist because the business people cannot trust the information being deliv-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 80}, page_content='ered to them. Data quality problems may be the result of poor data entry \\npractices, lack of edits, defective program code, or lack of training. A solution \\nto the business problem may be to tighten those procedures. \\n. Assess the competitors’ BI decision-support initiatives. \\nStaying ahead of the competition is extremely important in today’s economy. \\nIn order to stay ahead, you must know what your competitors are doing. It'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 80}, page_content='would be helpful to know about the competitors’ successes and failures with \\ntheir BI decision-support initiatives and whether they have achieved higher \\nsales or introduced innovative products. \\n. Determine the BI application objectives. \\nOnce you define the business problem and understand the deficiencies of the \\ncurrent environment, you can clearly state the BI application objectives. \\nThese objectives must be compared to the organization’s strategic business'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 80}, page_content='goals to ensure that they are in synch. \\nPropose a BI solution. \\nUsing the BI application objectives and the analysis results of the current \\nenvironment, including the current DSS solutions, you can now propose a BI \\nsolution. The business problem may be too complicated to address all at \\nonce, in which case you will need to devise an iterative release approach. \\nUnfulfilled requirements from previous BI projects must be evaluated and'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 80}, page_content='the decision must be made whether or not to include them in this release. \\n. Perform a cost-benefit analysis. \\nDetermine the projected BI application costs. In addition to new hardware, \\nsoftware, and tools, include ongoing maintenance fees and training costs. \\nRemember to account for the costs of new employees if you need to hire \\nmore staff to administer the new tools or to perform new business activities, \\nsuch as data mining. Determine the benefits of the BI application, both the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 80}, page_content='tangible and intangible ones. Itemize how the BI application will solve the \\nbusiness problem and save the organization money or increase the organiza- \\ntion’s profit margin. Finally, calculate the ROI and indicate the time frame in \\nwhich it will be realized.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 81}, page_content='48 Step 1: Business Case Assessment \\n8. Perform a risk assessment. \\nList all the possible risks for your project and create a risk assessment matrix. \\nIf you do not have sufficient information to produce a detailed risk assess- \\nment matrix at this time, use the six basic risk categories: technology, com- \\nplexity, integration, organization, project team, and financial investment. \\nDetermine the severity of each risk: low, medium, or high. Also determine'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 81}, page_content='how likely it is that each risk will materialize and what impact it would have \\non the BI project. \\n. Write the assessment report. \\nDescribe the business need (whether it is a business problem or a business \\nopportunity), and suggest one or more BI decision-support solutions. \\nInclude the results of the costs-benefit analysis and the risk assessment. Add a \\nshort summary to the report, and deliver it to the business sponsor as well as \\nexecutive management.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 81}, page_content='DELIVERABLE RESULTING FROM THESE ACTIVITIES \\nJe Business case assessment report \\nThe business case assessment report should document the following: \\n— Strategic business goals of the organization \\n— Objectives of the proposed BI application \\n— Statement of the business need (business problem or business opportunity) \\n— Explanation of how the BI application will satisfy that need (proposed BI \\nsolution) \\n— Ramifications of not addressing the business need and not committing to'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 81}, page_content='the proposed BI solution \\n— Cost-benefit analysis results \\n— Risk assessment \\n— Recommendations for business process improvements to the operational \\nsystems or to the operational business processes and procedures \\nThe assessment report should also have a one- or two-page executive over- \\nview that summarizes the details of the report.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 82}, page_content='Risks of Not Performing Step 1 49 \\nROLES INVOLVED IN THESE ACTIVITIES \\n® Business representative \\nThe business representative is the business person who will directly benefit \\nfrom the BI application and who will participate as a full-time member on the \\nproject core team. He or she should complete the benefits portion of the cost- \\nbenefit analysis and should assist the project manager with the risk assess- \\nment. \\n@ Business sponsor'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 82}, page_content='@ Business sponsor \\nThe business sponsor is the person holding the “purse strings.” He or she \\nensures that proper objectives for the BI application are established and that \\nthose objectives support the strategic business goals of the organization. He or \\nshe approves the business case assessment and helps set and negotiate the BI \\nproject scope to meet the stated BI application objectives. \\n@ Data quality analyst'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 82}, page_content='The quality of the source data is always overestimated. In reality, source data \\nquality is much worse than anyone can imagine. The data quality analyst has \\nto be able to estimate the time, effort, and cost associated with finding the \\ndirty data and cleansing it. \\n@ Project manager \\nThe project manager should have experience as a systems integrator. The BI \\ndecision-support environment requires the management and integration of'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 82}, page_content='multiple types of software as well as hardware. In addition, the project man- \\nager needs skills in managing the staff, the project, and the expectations of the \\nbusiness community. \\n@ Subject matter expert \\nExpertise in the business is mandatory, and the subject matter expert brings \\nthat expertise to the BI project. He or she should also have an understanding \\nof the competition and of the trends in the industry. \\nRISKS OF NOT PERFORMING STEP 1'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 82}, page_content='One of the major risks of not performing this step is that you may end up build- \\ning a BI decision-support solution that has no strong business driver and does \\nnot support a strategic business goal. This can lead to a disappointed business'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 83}, page_content='50 Step 1: Business Case Assessment \\ncommunity and an unhappy management group at the end of the project. No \\nmatter how valuable the BI application is from an IT perspective, it may not meet \\nthe expectations of the business community. If the business people are not con- \\ntent with the information provided to them, they might reject other BI solutions \\nproposed by IT to solve other business problems. \\nBIBLIOGRAPHY AND ADDITIONAL READING'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 83}, page_content='Adelman, Sid, and Larissa Terpeluk Moss. Data Warehouse Project Management. \\nBoston, MA: Addison-Wesley, 2000. \\nBischoff, Joyce, and Ted Alexander. Data Warehouse: Practical Advice from the \\nExperts. Upper Saddle River, NJ: Prentice Hall, 1997. \\nDeMarco, Tom. Slack: Getting Past Burnout, Busywork, and the Myth of Total Effi- \\nciency. New York: Broadway Books, 2001. \\nDevlin, Barry. Data Warehouse: From Architecture to Implementation. Reading, \\nMA: Addison-Wesley, 1997.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 83}, page_content='Dyché, Jill. e-Data: Turning Data into Information with Data Warehousing. Bos- \\nton, MA: Addison-Wesley, 2000. \\nEnglish, Larry P. Improving Data Warehouse and Business Information Quality: \\nMethods for Reducing Costs and Increasing Profits. New York: John Wiley & Sons, \\n1900: \\nHackney, Douglas. Understanding and Implementing Successful Data Marts. Read- \\ning, MA: Addison-Wesley, 1997. \\nInmon, William H., Claudia Imhoff, and Greg Battas. Building the Operational'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 83}, page_content='Data Store. New York: John Wiley & Sons, 1996. \\nInmon, William H., Claudia Imhoff, and Ryan Sousa. Corporate Information Fac- \\ntory. New York: John Wiley & Sons, 1997. \\nInmon, William H., John A. Zachman, and Jonathon G. Geiger. Data Stores, Data \\nWarehousing and the Zachman Framework: Managing Enterprise Knowledge. New \\nYork: McGraw-Hill, 1997. \\nJarke, Matthias, Maurizio Lenzerini, Yannis Vassiliou, and Panos Vassiliadis. Fun- \\ndamentals of Data Warehouses. New York: Springer, 2000.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 83}, page_content='Kuan-Tsae, Huang, Yang W. Lee, and Richard Y. Wang. Quality Information and \\nKnowledge Management. Upper Saddle River, NJ: Prentice Hall, 1998.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 84}, page_content='Justification \\n2 \\nEnterprise \\nInfrastructure \\n\\\\ Evaluation \\nConstruction \\\\ \\nCHAPTER TWO \\nStep 2: Enterprise \\nInfrastructure Evaluation \\nCHAPTER OVERVIEW \\nAn enterprise infrastructure is to BI applications what a trans- \\nportation infrastructure is to automobile owners. In order to \\nsafely and comfortably travel with an automobile, there must \\nbe a physical infrastructure, such as roads, bridges, traffic \\nlights, and traffic signs, as well as nonphysical infrastructure,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 84}, page_content='such as standardized traffic rules and their interpretation. For \\nexample, without the universal interpretation of the rule that \\n“Green means go, red means stop,’ traffic lights would be of \\nno use. Similarly, an enterprise infrastructure consists of two \\nmajor components: \\n1. Technical infrastructure, such as hardware, middleware, \\nand database management systems (DBMSs) \\n2. Nontechnical infrastructure, such as standards, meta data, \\nbusiness rules, and policies'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 84}, page_content='Accordingly, this chapter is divided into two sections—Step 2, \\nSection A, Technical Infrastructure Evaluation, and Step 2, Sec- \\ntion B, Nontechnical Infrastructure Evaluation. The first sec- \\ntion covers the following topics: \\n@ Things to consider about technical infrastructure \\n@ The importance of scalability for the hardware platform \\n@ Middleware, with emphasis on DBMS gateways since they \\nare one of the most important middleware components for \\nBI applications'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 84}, page_content='BI applications \\n@ DBMS requirements for the specific functionality needed to \\nsupport BI applications \\n@ Brief descriptions of the technical infrastructure activities, \\nthe deliverables resulting from those activities, and the \\nroles involved \\nm@ The risks of not performing Step 2, Section A \\n51'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 85}, page_content='52 Step 2: Enterprise Infrastructure Evaluation \\nThe second section, on nontechnical infrastructure, covers the following topics: \\n@ Things to consider about nontechnical infrastructure \\n@ Bad practices and old habits that lead to stovepipe development (automation silos) \\n@ The need for a nontechnical infrastructure to enable an integrated BI decision-support \\nenvironment \\nm@ The enterprise architecture components: business function model, business process'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 85}, page_content='model, business data model, application inventory, and meta data repository \\n@ Enterprise standards for such things as data naming, data quality, and testing \\n@ Brief descriptions of the nontechnical infrastructure activities, the deliverables resulting \\nfrom those activities, and the roles involved \\n@ The risks of not performing Step 2, Section B'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 86}, page_content='Step 2, Section A: Technical Infrastructure Evaluation 53 \\nStep 2, Section A: Technical \\nInfrastructure Evaluation \\nTHINGS TO CONSIDER \\nHardware \\n¥ What hardware platforms do we already have or use? \\n¥ On which platform should we implement the BI application? \\n¥Y Do we need new hardware? What will it cost? \\n¥ Will we need more staff to maintain the new hardware? \\n¥ Will the new hardware integrate with our existing platforms?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 86}, page_content='V How will the new hardware scale to accommodate ever-increasing loads of \\nprocessing and volumes of data? \\nNetwork \\n¥ What type of local area network (LAN) are we using? \\nv¥ What type of wide area network (WAN) are we using? \\nV Is the bandwidth of our WAN sufficient to grow? \\nMiddleware \\n¥ What type of middleware do we already have or use? \\nVY Do we have the necessary middleware to retrieve the source data from heter- \\nogeneous platforms and transfer it to the BI decision-support environment?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 86}, page_content='¥ What is the operational source architecture? (e.g., enterprise resource plan- \\nning [ERP], legacy files) \\nVY Do we need new middleware? What will it cost? \\n¥ Will the connection be permanent between the source files (or source data- \\nbases) and the BI target databases? \\n¥ Which of our hardware, software, and middleware is proprietary? Have we \\npurchased it? Or are we leasing it? \\nDatabase Management Systems \\n/Y What DBMSs do we already have?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 86}, page_content='/ Will we need to buy a new DBMS? What will it cost? \\nVY Will the new DBMS be compatible with our operating system(s)? \\n/ What software tools can run with it?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 87}, page_content='54 Step 2: Enterprise Infrastructure Evaluation \\nY Does our staff have the skills to use and administer the new DBMS? \\nY Will we have to hire more database administrators? \\nTools and Standards \\nY How are the business analysts currently analyzing the data? What reporting \\nand querying tools do they use? \\n¥ What additional tools and utilities do we need? \\n/Y What other software do these tools need to interact with? \\nY Do we know of any major problems with our technical infrastructure?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 87}, page_content='¥Y What are our technical standards for compatibility and access? \\nThe development efforts of early BI applications, such as the early data ware- \\nhouses, were relatively slow, labor-intensive, risky, and expensive. Extraction and \\ntransformation of operational data into a data warehouse frequently involved \\ncreating new, custom-written application code. The target databases were either \\nbased on proprietary DBMSs or were using proprietary hardware platforms.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 87}, page_content='There was also a shortage of tools to administer, control, and expand the new \\ndecision-support environment. The lesson learned from the early BI days was \\nthat in order to reach the best performance results for data access and retrieval, a \\ncomprehensive application platform must be chosen. Therefore, it is important \\nto select the appropriate hardware, middleware, and DBMS and to ensure that \\nthese components are implemented properly. \\nTHE HARDWARE PLATFORM'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 87}, page_content='For adequate report and query performance, it is very important to have sufficient \\n“horsepower” with the hardware platform. Scalability is of utmost importance. \\nControlled Chaos \\nDo not despair if your computer environment looks like the one in Figure 2.1. \\nThis is more often the case than not in organizations of any size. What exists can \\nat best be described as controlled chaos! \\nAccompanying the hardware chaos are usually a huge portfolio of disparate'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 87}, page_content='software and a large staff with only enough skills to support the existing systems. \\nIn order to minimize the chaos, most organizations implementing a BI decision-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 88}, page_content='The Hardware Platform 55 \\nFigure 2.1: Controlled Hardware Chaos \\nsupport environment have to consider at least four imperatives in hardware plat- \\nform selection. \\n1. New hardware platforms have to fit into the existing hardware configuration. \\n2. The DBMS on the selected hardware platform must perform well as database \\naccess and usage grow. Scalability is therefore one of the major issues to be \\naddressed. \\n3. Platform selection is restricted by the need for interoperability between vari-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 88}, page_content='ous hardware platforms (if required). \\n4, Cost and return on investment (ROI) for the previous three qualifiers are \\ncontrolling factors. \\nHardware Platform Requirements \\nThe hardware must have sufficient power to handle complex access and analysis \\nrequirements against large volumes of data. It has to support not only predefined, \\nsimple queries on summary data but also ad hoc complex queries on detailed \\ndata. It must also be scalable because rapid changes will occur in:'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 89}, page_content='56 Step 2: Enterprise Infrastructure Evaluation \\n* Data volumes \\n* Updating frequencies \\n* Data access patterns \\n* Number of reports and queries \\n* Number of people accessing the BI target databases \\n* Number of tools running against the BI target databases \\n* Number of operational systems feeding the BI target databases \\nIt is useful to think of a BI decision-support environment in terms of a three- \\ntier computing architecture (Figure 2.2). First, the extract/transform/load (ETL)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 89}, page_content='engine extracts, cleanses, and transforms operational data. Then, using middle- \\nware, the BI target databases are populated. Finally, when data is requested, it is \\nmapped into suitable representations for the business community at the interface \\nlevel for running queries, reports, and online analytical processing (OLAP) appli- \\ncations. The interface level can be a customized graphical user interface (GUI) \\napplication, an enterprise portal, or Extensible Markup Language (XML) Web \\nservices.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 89}, page_content='services. \\nApplication Interface \\nReport \\nMiddleware \\nLogical view of BI data \\nPhysical data in BI target databases \\nt Middleware | \\nETL Engine | \\nFigure 2.2: Three-Tier Computing Architecture'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 90}, page_content='The Middleware Platform 57 \\nTHE MIDDLEWARE PLATFORM \\nThe term middleware refers to runtime system software, which is layered between \\nthe application programs and the operating system. It acts as a bridge to integrate \\napplication programs and other software components in an environment with \\nmultiple network nodes, several operating systems, and many software products. \\nMiddleware is needed to run client/server architectures and other complex net-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 90}, page_content='worked architectures in a distributed computing environment. Therefore, the \\nmiddleware should support directory services, message-passing mechanisms, \\nand database gateways. \\nMost middleware falls into two major categories: \\n1. Distributed logic middleware supports program-to-program communication \\nbetween two pieces of custom-written application code. \\n2. Data management middleware connects an application or DBMS on one plat- \\nform with a DBMS running on another platform.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 90}, page_content='Middleware can also be used to enable “reach-through” queries from sum- \\nmaries in the BI target databases to the underlying detail data held in operational \\nsystems. To keep the cost to a minimum, a number of organizations are already \\nusing gateways to transfer data from multiple heterogeneous sources of server \\ndata to client workstations, as illustrated in Figure 2.3. \\n* Client Workstations * Server Databases \\n* Client Interfaces * Server Interfaces'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 90}, page_content='* SQL Requests Sent * Relational Tables Returned \\nSe \\nApplication A \\nNonrelational \\nDatabases \\nRelational \\nDatabases \\nApplication B \\nGateway \\nFigure 2.3: Gateway Example'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 91}, page_content='58 Step 2: Enterprise Infrastructure Evaluation \\nDBMS Gateways \\nDMBS gateways, a form of middleware, are generally required to connect the dif- \\nferent network architectures of desktop computers, remote clients, or small \\nenterprise servers to industrial-strength enterprise servers. \\nGateways fall into four major categories. \\n1. Point-to-point gateways provide access to only one type of DBMS. Vendors \\nmarket each point-to-point gateway as a different product. A point-to-point'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 91}, page_content='gateway is easy to implement because it handles only one DBMS at a time. It \\nis also a less expensive solution compared with the other three gateway solu- \\ntions. However, when the organization requires access to multiple DBMSs, it \\nneeds multiple gateways. In that case, point-to-point gateways may not be a \\nless expensive solution than using a universal gateway. \\n2. Gateways that can be used universally provide access to different types of data-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 91}, page_content='bases on various platforms. Universal gateways require extensive effort to \\nimplement and maintain. As a result, these gateways become expensive. \\n3. Gateways using Structured Query Language (SQL) can access only “real” rela- \\ntional databases, not simulated ones. The SQL gateway translates the client \\nrequest into the native SQL syntax used by the server’s relational DBMS. \\n4, Gateways based on application programming interfaces (APIs) are driven by'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 91}, page_content='vendor specifications. One of the major gateways of this type is open database \\nconnectivity (ODBC). A number of ODBC vendors provide drivers for \\naccessing databases residing on various servers. \\nOrganizational data is distributed across multiple DBMS platforms, cooper- \\nating across a network with different instruction sets from multiple vendors. \\nODBC-enabled applications can access multiple distributed data sources concur- \\nrently via ODBC’s common interface approach (Figure 2.4).'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 91}, page_content='Modules called database drivers can be added to link the applications to the \\nDBMS of their choice. Database drivers consist of dynamic link libraries (DLLs) \\nthat applications can invoke on demand. \\nTHE DBMS PLATFORM \\nThe database infrastructure changes with the size of the BI decision-support \\nenvironment, which in turn influences the selection of the DBMS, as shown in \\nFigure 2.5. A small departmental data mart application may reside on a local file'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 92}, page_content='The DBMS Platform 59 \\nApplication Application Application \\nODBC Common Interface \\nOracle DB2 \\nDriver Driver \\nFigure 2.4: ODBC-Enabled Applications \\nSQL \\nServer \\nDriver \\nIndustrial-Strength \\n5 oupemumiaarnam Enterprise Server \\nSmall Wore(our . peenoral DBMS ow ne Ramote Client Enterprise Server : an ; Tete adh - Relational DBMS Multidimensional DBMS \\nFigure 2.5: Database Infrastructures \\nserver, but a larger BI application may need the infrastructure support of an enter-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 92}, page_content='prise server, and very large enterprise-wide BI solutions may need to use a mainframe. \\nCriteria for Selecting a DBMS \\nThe following functions are important and necessary attributes of a DBMS for \\nhandling the workload of a large BI target database or very large database (VLDB): \\n* Degree of parallelism in handling queries and data loads \\n* Intelligence in handling dimensional data models and optimizers \\n* Database scalability \\n- Internet integration \\n* Availability of advanced index schemes'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 92}, page_content='- Replication on heterogeneous platforms \\n* Unattended operations'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 93}, page_content='60 Step 2: Enterprise Infrastructure Evaluation \\nA DBMS is a sophisticated piece of software and consists of a number of fea- \\ntures that need to be evaluated. Features to look for in a DBMS for BI applica- \\ntions are listed below. \\n* Network support provided by the DBMS should be compatible with the orga- \\nnization’s data communications standards. \\n* Dimensional capability in the form of seamless support for fast and easy load- \\ning and maintenance of precompiled summaries is important.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 93}, page_content='* Adequate state-of-the-art triggers and stored procedures can be used as “event \\nalerters,” which trigger an action in response to a given set of circumstances. \\n* Administrative support features should provide for: \\n— Maintenance of consistent historical data \\n— Support for archiving (e.g., dropping the oldest week’s data when adding \\nthe data for a new week) \\n— Controls for implementing resource limits to display a warning when a'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 93}, page_content='query that consumes excessive resources is about to be terminated \\n— Workload tracking and tuning mechanisms \\n— Careful monitoring of activity and resource utilization \\n* Location transparency across the network must allow the access and analysis tools \\nto retrieve data from multiple BI target databases from a single workstation. \\n+ Future usage explosion must be supported by: \\n— Effective caching and sharing of data to minimize input/output (I/O) \\nbottlenecks'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 93}, page_content='bottlenecks \\n— Effective management of task switching while running many queries con- \\ncurrently \\n— Compatibility with multiple processors \\n- Scalability requires that the DBMS has the capability to support: \\n— Advanced functions for sorting and indexing \\n— Fault tolerance for uninterrupted processing \\n— Uninterrupted maintenance operations, such as unload, backup, and restore \\n— Checkpoints, recovery, and rapid restart of interrupted operations'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 93}, page_content='* Query performance optimization should address aspects of query processing \\n(such as JOINs, sorting, and grouping) that require intensive use of the cen- \\ntral processing unit (CPU). \\n* Load process and performance must address: \\n— Data obtained directly from a variety of feeds, including disk files, network \\nfeeds, mainframe channel connections, and magnetic tapes'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 94}, page_content='Technical Infrastructure Evaluation Activities 61 \\n— Complete data loading and preparation, including format conversion, \\nintegrity enforcement, and indexing \\nThe security system must support unique passwords, password protection, \\nand the authorization constraints necessary for specific persons and for specific \\ntables of the database. The system administrator should provide restricted \\naccess to the views and virtual tables.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 94}, page_content='The data dictionary should feed into a meta data repository, and the database \\nobjects should be linked to all data objects described in the enterprise logical \\ndata model. \\nSelecting and reevaluating the appropriate hardware, middleware, and DBMS \\ncomponents of the technical infrastructure are some of the most important activ- \\nities on BI projects because they ensure the continued scalability and high perfor- \\nmance of the BI applications. \\nTECHNICAL INFRASTRUCTURE EVALUATION ACTIVITIES'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 94}, page_content='The technical infrastructure evaluation activities do not need to be performed \\nlinearly. Figure 2.6 indicates two activities that can be performed concurrently. \\nThe list below briefly describes the activities associated with Step 2, Section A, \\nTechnical Infrastructure Evaluation. \\na \\nAssess existing \\nplatform \\nExpand current \\nplatform \\nWrite technical infrastructure \\nassessment report \\nNON \\n2 \\nEvaluate and \\nselect new products \\nFigure 2.6: Technical Infrastructure Evaluation Activities'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 94}, page_content='1. Assess the existing platform. \\nReview the existing platform in terms of hardware, middleware, DBMS, and \\ntools. It is important to evaluate the interdependence of the tools for their \\nvarious purposes, such as the interdependence between a multidimensional'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 95}, page_content='62 Step 2: Enterprise Infrastructure Evaluation \\nreporting tool and an ad hoc querying tool. In addition, review the existing \\nnetwork architecture. One of the biggest bottlenecks today, especially in orga- \\nnizations with decentralized applications, is the lack of bandwidth coupled \\nwith a limited capacity for network growth. \\n. Evaluate and select new products. \\nAfter assessing the existing platforms, identify which types of new hardware,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 95}, page_content='software, or networking components you must acquire. If the existing hard- \\nware platform appears to be sufficient, be sure to determine that it will be able \\nto provide the productivity and performance the organization expects from \\nit. Engage business representatives and stakeholders in the decision-making \\nprocess by including them in peer reviews during the selection process. \\n. Write the technical infrastructure assessment report.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 95}, page_content='Compile all findings about the existing platform into a report. Explain the \\nstrengths and weaknesses of the current hardware, middleware, DBMS, and \\ntools, and provide a list of missing technical infrastructure components nec- \\nessary to meet the project requirements. \\n. Expand the current platform. \\nOnce you have determined which new products need to be acquired, you can \\nbegin the process of evaluating, selecting, ordering, installing, and testing them.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 95}, page_content='DELIVERABLES RESULTING FROM THESE ACTIVITIES \\n1. Technical infrastructure assessment report \\nThis report should itemize the scalability and limitations of the hardware, \\nmiddleware, DBMS, and tool platform and should cover the following items: \\n— Servers \\n— Client workstations \\n— Operating systems \\n— Middleware (especially DBMS gateways) \\n— Custom interfaces \\n— Network components and bandwidth \\n— DBMS functionality and utilities (backup and recovery, performance \\nmonitoring)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 95}, page_content='monitoring) \\n— Development tools such as computer aided software engineering (CASE) \\nand ETL tools \\n— Access and analysis tools such as OLAP tools and report writers \\n— Meta data repository'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 96}, page_content='Risks of Not Performing Step 2, Section A 63 \\nInclude a gap analysis section and provide recommendations for upgrading \\nthe platform. Incorporate the product evaluation and selection results, listing \\nthe weighted requirements and the product features you evaluated. The \\nproduct and vendor evaluation and selection process is described in more \\ndetail in Step 10, Meta Data Repository Design. \\n2. Installation of selected products'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 96}, page_content='If you identified new products to purchase, write a request for proposal \\n(RFP) or a request for information (RFI) and send it to the vendors on the \\nshort list. After selecting a product, order, install, and test it. \\nROLES INVOLVED IN THESE ACTIVITIES \\n® Bl infrastructure architect \\nThe BI infrastructure architect is responsible for developing the capacity plans \\nfor the hardware, middleware, DBMS, and network in order to ensure the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 96}, page_content='scalability needed by the BI decision-support environment. The BI infrastruc- \\nture architect and the database administrator have to work side by side while \\nevaluating the current environment, determining the appropriate future plat- \\nforms, and implementing the selected technologies. \\n@ Database administrator \\nThe database administrator has to evaluate the current DBMS platform on the \\ncurrent hardware. The database administrator also has to evaluate the tools'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 96}, page_content='and the middleware as they relate to the DBMS. He or she has to determine \\nthe future DBMS requirements and should participate in performing the tech- \\nnical infrastructure gap analysis. \\nRISKS OF NOT PERFORMING STEP 2, SECTION A \\nIn order to provide adequate performance in a growing BI decision-support envi- \\nronment, it is mandatory to assess the hardware, middleware, DBMS, and tools \\nfrom time to time. If you do not perform this part of Step 2, technical perfor-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 96}, page_content='mance could degrade to such an extent that the BI decision-support environment \\nbecomes unusable. It is also necessary to stay current with the existing technol- \\nogy. Technology advances occur every few months. Not staying current and not \\ntaking advantage of new and improved features can turn the BI decision-support \\nenvironment into an extinct dinosaur in a very short time.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 97}, page_content='64 Step 2: Enterprise Infrastructure Evaluation \\nStep 2, Section B: Nontechnical \\nInfrastructure Evaluation \\nTHINGS TO CONSIDER \\nLogical Data Model \\nY Do we already have logical data models for the source systems? If not, who is \\nresponsible for creating a logical data model for this BI project? \\nY Who are the data owners and business people who have to participate in the \\nvalidation of the logical data model and the business meta data?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 97}, page_content='/Y How many trained data administrators do we have? Will we have to hire \\nmore? \\nY Who will integrate our logical data model into the enterprise logical data \\nmodel? \\nY Who will validate the expanded enterprise logical data model? \\n¥ What CASE tool do we have for logical data modeling? Will we need to \\nlicense (buy) one? \\nMeta Data \\nY Do we already have a meta data repository? Will we need to license (buy) or \\nbuild a meta data repository?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 97}, page_content='V If we have one, how easy is it for the business people to access and navigate \\nthrough the meta data repository? Do we need to enhance it? \\nY Who is responsible for capturing all the meta data components? Who is \\nresponsible for loading the meta data into the meta data repository? \\nV How will we merge the new business meta data from the CASE tool with the \\nnew technical meta data from the ETL tool and the OLAP tool? \\nStandards, Guidelines, and Procedures'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 97}, page_content='Y Are our current standards too lax or too stringent? \\nVv Where are the standards documented? Are they being followed? \\nV How effective are our data quality guidelines for measuring dirty data and. \\nand triaging data cleansing? \\nV Are our change-control procedures easy to use? Do we have a template?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 98}, page_content='The Effects of Stovepipe Development 65 \\nVv Do we have a template for an issue log? \\n¥ What are our testing standards? \\nVv Are we habitually testing too much or too little? Are we testing the right \\nthings? \\nVv How are we currently resolving technical and business disputes? \\nVv Do we need to create or change our dispute resolution procedure? \\n¥ What are the roles and responsibilities that will be assigned to the core team \\nmembers? \\nV Is our current team structure effective?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 98}, page_content='Enterprise-wide nontechnical infrastructure is a critical success factor for a \\nBI decision-support environment. Without a cross-organizational infrastructure, \\nBI applications would only contribute to the existing chaos of stovepipe applica- \\ntions and databases. \\nTHE EFFECTS OF STOVEPIPE DEVELOPMENT \\nIn the past, the mental model for providing an automated information technol- \\nogy (IT) solution to a business problem has been to “divide and conquer.”'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 98}, page_content='1. Divide a large problem into smaller “digestible” pieces, that is, prioritize and \\nseparate the deliverables. \\n2. Conquer the problem by working on each piece individually, that is, build \\neach deliverable separately. \\nThis approach works very well for reducing risk by breaking a complex prob- \\nlem into small, manageable chunks. However, this approach also has a severe \\ndrawback when applied without a nontechnical infrastructure. Namely, it produces'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 98}, page_content='stovepipe systems (automation silos). The effects of stovepipe systems are lost \\nbusiness knowledge and lost cross-organizational business view, which severely \\nimpact business analytics and data mining activities. \\nMost businesses are very complex, and as organizations mature, their busi- \\nness complexity increases. As business complexity is broken apart into smaller \\nand less complex components, the interrelationships among those individual'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 98}, page_content='components are lost. Much of the business intelligence is contained in these lost \\ninterrelationships, and that is a problem for BI applications. Most BI applications,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 99}, page_content='66 Step 2: Enterprise Infrastructure Evaluation \\nel \\nDo we have \\nany indication \\nof fraudulent \\nactivities? \\nDo we know how \\nmuch of the \\ncustomers’ wallet \\nshare we have? \\nAre our products \\npriced competitively? Do we know what \\nour best customers \\nhave in common? \\nDo we know why \\nwe are losing \\nmarket share? Do we know what \\ngeneral classes of \\ncustomers we have? Can we forecast the \\nlong-term buying habits \\nof our Generation X \\ncustomers? \\nFigure 2.7: Fundamental Business Questions'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 99}, page_content='and especially data mining applications, expect to find “golden nuggets” of busi- \\nness wisdom embedded in these complex interrelationships. \\nAlthough business managers can answer most questions about the business \\nfunctions of their own departments, when asked a question spanning two or \\nthree lines of business (where complex interrelationships have been lost), those \\nmanagers must scramble for weeks to piece together the answer. Fundamental'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 99}, page_content='business questions, such as the ones illustrated in Figure 2.7, present multimil- \\nlion-dollar problems to large organizations. \\nThe answers to these and many other questions do exist in the real business \\nworld. We have just been neglecting to design our systems in a cross-functional \\nmanner that would allow us to find these answers quickly. \\nTHE NEED FOR NONTECHNICAL INFRASTRUCTURE \\nAn organization needs to create a nontechnical infrastructure to prevent the BI'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 99}, page_content='decision-support environment from becoming as fragmented as the operational \\nand traditional decision-support environments, from which cross-organizational \\nquestions cannot be answered. Creating this infrastructure involves cross-organi- \\nzational activities such as those listed below.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 100}, page_content='The Need for Nontechnical Infrastructure 67 \\nConduct an extensive business analysis involving business people from many \\nlines of business. During this activity, define or redefine the lost complex \\ninterrelationships among business functions and business data. \\nAdopt a system of peer reviews to support cross-organizational attendance and \\nevaluation of business analysis activities. \\nResolve age-old disputes about data definitions and domains (valid data contents).'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 100}, page_content='Standardize data names and data values to reflect true business rules and \\nbusiness policies. \\nGet agreement from the business people on the business rules and business pol- \\nicies in the first place. \\nCreate a regular forum for business people to maintain and review the stan- \\ndards, business rules, and business policies on an ongoing basis. \\nOver time, create one consolidated, nonredundant data architecture for the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 100}, page_content='entire enterprise to reflect the complex reality of the business; that is, create \\nan enterprise logical data model. This model documents the data inventory \\nof an organization. It is also the primary vehicle for mapping the inventory of \\noperational data to the inventory of BI data. \\nCreate a meta data repository and populate it with nonredundant meta data. \\nCreate an inventory of source data and map it to the applicable BI target data-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 100}, page_content='bases. Also create an inventory of other system components, such as programs, \\nreports, screens, and so on, thereby identifying the reusability of data and \\nprocess components. \\nCreate and manage one expanding central staging area (per load periodicity) \\nfor the ETL processes. Do not allow independent ETL processes for each data \\nmart solution. \\nEnterprise infrastructure activities, technical as well as nontechnical, are stra-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 100}, page_content='tegic cross-organizational activities. A central enterprise architecture group (Fig- \\nure 2.8) must manage and coordinate these activities. Many large organizations \\nhave a strategic enterprise architecture group whose charter is to integrate and \\nmanage the IT infrastructure components as assets of an organization. These infra- \\nstructure components are inventories or models of business functions, business \\nprocesses, business data, meta data, applications, and other technical implemen-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 100}, page_content='tation elements. If an organization does not have an enterprise architecture group, \\nthen data administration can perform the information architecture subfunction,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 101}, page_content='68 Step 2: Enterprise Infrastructure Evaluation \\nBusiness | Business | Business | Business | Business | Business | Business \\njerloueul4 JewWosnD Joynquisig Aio\\\\uaau] \\n= \\nEnterprise \\nArchitecture \\nGroup \\nFigure 2.8: Enterprise Architecture Group \\nwhich includes creating and managing the enterprise logical data model and the \\nmeta data repository. If the organization has a separate meta data administration, \\nthe information architecture responsibilities would be divided between those two'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 101}, page_content='groups (data administration and meta data administration). \\nENTERPRISE ARCHITECTURE \\nAn enterprise architecture is comprised of a set of pictorial representations \\n(models) of the organization in terms of business functions, business processes, \\nand business data. Each enterprise architecture model is supplemented with support- \\ning meta data, such as standard definitions, business rules, and policies. The purpose'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 101}, page_content='of these models is to document the set of business actions performed on any real- \\nworld object in the course of conducting business. In other words, enterprise \\narchitecture models describe the actual business in which the organization engages. \\nEvery active organization has an enterprise architecture by default, even if it is \\nnot documented. With undocumented architecture, the organization’s business \\nactions and business objects are most likely not consistently understood by every-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 101}, page_content='one in the organization. The goal of documenting the architecture is to avoid'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 102}, page_content='Enterprise Architecture 69 \\n2 Business \\nProcess Model all \\n1 Business \\nFunction Model \\nBusiness \\nData Model \\nApplication \\nInventory \\nFile \\nPgm Cust | Emp | Prod \\nCmaster Cau D R \\nPayroll R Cc, U D \\nPmaster U,D R C,D \\nBonuses R U R \\nMeta Data \\nRepository \\nCrossref \\n+ Business Meta Data \\n* Technical Meta Data \\nFigure 2.9: Enterprise Architecture Components \\nabusing, misusing, or redundantly recreating unique processes or data about'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 102}, page_content='business objects, which can lead to losing sight of the cross-organizational picture. \\nA fully documented enterprise architecture includes at least five architectural \\ncomponents (Figure 2.9). The following subsections describe these components. \\nThe Business Function Model \\nThis model depicts the hierarchical decomposition of an organization’s nature of \\nbusiness; it shows what the organization does. This model is instrumental for'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 102}, page_content='organizing or reorganizing the structure of an organization into its lines of busi- \\nness. Usually one vertical line of business supports a major business function on \\nthis model. Two examples of such an alignment are the loan-origination division \\nand the loan-servicing division of a mortgage-lending institution.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 103}, page_content='70 Step 2: Enterprise Infrastructure Evaluation \\nThe Business Process Model \\nThis model depicts the processes implemented for the business functions; it shows \\nhow the organization performs its business functions. This model is essential for \\nbusiness process reengineering as well as business process improvement initia- \\ntives, which often result from BI projects. For example, a business process model \\ncould be analyzed to determine whether it is possible to streamline a current'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 103}, page_content='business process called loan payment processing because customers have com- \\nplained about the long delays in posting their loan payments while their loans \\ncontinue to accrue interest. \\nThe Business Data Model \\nThis model, which is commonly called the enterprise logical data model or enter- \\nprise information architecture, shows what data is part of the organization’s busi- \\nness activities. This model depicts the following: \\n* Data objects participating in a business activity'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 103}, page_content='* Relationships among these objects as they exist in the actual business activities \\n+ Data elements stored about these objects \\n* Business rules governing these objects \\nSince data objects and data elements are all unique, they appear in the real \\nworld only once. Therefore, they are documented in the business data model only \\nonce, regardless of the numbers of physical files and databases used for their stor- \\nage. There is only one business data model for an organization. This model and'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 103}, page_content='the meta data repository are the two most important nontechnical infrastructure \\ncomponents for an evolving BI decision-support environment. \\nThe Application Inventory \\nThe application inventory is an accounting of the physical implementation com- \\nponents of business functions, business processes, and business data (objects as \\nwell as data elements). It shows where the architectural pieces reside in the techni- \\ncal architecture. Application inventory entries include the relationships among'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 103}, page_content='the physical implementation components, such as programs, job streams, data- \\nbases, or files. \\nOrganizations should always identify, catalog, and document their applications \\nas well as the business rules about their business data as part of the development'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 104}, page_content='Enterprise Standards 71 \\nwork on every project—but they seldom do. Such inventories are paramount for \\nperforming impact analysis. Remember the colossal efforts of Y2K impact analy- \\nsis without such an inventory! \\nThe Meta Data Repository \\nAlthough “a picture is worth a thousand words,” business models without words \\nare not worth much. The descriptive details about the models are called meta \\ndata. Business meta data is collected during business analysis, and technical meta'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 104}, page_content='data is collected during design and construction. The two types of meta data are \\nlinked to each other and made available to the business community of the BI \\ndecision-support environment. Meta data is an essential navigation tool. Some \\nexamples of meta data components include the following: \\n* Column name \\n* Column domain (allowable values) \\n* Table name \\n* Program name \\n* Report name \\n* Report description \\n* Data owner \\n* Data definition \\n* Data quality metrics \\nENTERPRISE STANDARDS'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 104}, page_content='Organizations must establish architectural standards for their BI decision-sup- \\nport environments in the same way they set up standards for their Web sites. An \\norganization would never consider building its Web site with a different look and \\nfeel for each Web page. In the same vein, no organization should build a BI deci- \\nsion-support environment in which each BI application had a different look and \\nfeel. Therefore, all BI applications must adhere to the same enterprise standards'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 104}, page_content='within an organization. Figure 2.10 lists the categories of standards to develop, \\nwhich are briefly described below.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 105}, page_content='72 Step 2: Enterprise Infrastructure Evaluation \\na cae De EE, \\nRe er ee ee \\nye EN Z \\nb. a. \\nEnterprise Standards \\nDevelopment Approach \\n_ Data Naming and Abbreviations \\nMeta Data Capture \\nLogical Data Modeling \\nData Quality \\nTesting \\nReconciliation \\nSecurity \\nService-Level Agreements \\nPolicies and Procedures \\nMUYES hmm \\nWE \\nCF: \\ng Y Ye | \\n4 Mo ERO SYR \\nFigure 2.10: Enterprise Standards \\nDevelopment Approach \\nBusiness Intelligence Roadmap provides a complete list of all the major activities'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 105}, page_content='and tasks that are appropriate for BI projects. However, since scope and deliver- \\nables of BI projects can vary widely, not every BI project team has to perform \\nevery single activity in every step. Some BI projects may justifiably skip activities \\nwithin a step, combine activities from different steps into one, or skip entire \\nsteps. However, no BI project should be developed ad hoc. Organizations should \\nhave some guidelines that list the minimum number of activities required (mini-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 105}, page_content='mum work breakdown structure), the mandatory deliverables, sign-off require- \\nments, and workflow dependencies in order to control the project risks. \\nData Naming and Abbreviations \\nData naming and abbreviation standards for BI applications provide consistency \\nand a common look and feel useful for both developers and business people. \\nProven standards can be applied (such as the convention of name compositions \\nusing prime, qualifier or modifier, and class words), or new organization-specific'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 105}, page_content='standards can be created. The data administration group usually has been trained \\nin the various industry-standard naming conventions. \\nAbbreviations are part of naming standards, but they apply only to physical \\nnames (e.g., column names, table names, program names), not to business \\nnames. The organization should publish a standard enterprise-wide abbrevia- \\ntions list that includes industry-specific and organization-specific acronyms.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 105}, page_content='Every BI project team should use these abbreviations and acronyms.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 106}, page_content='Enterprise Standards 73 \\nMeta Data Capture \\nMeta data is a world unto itself. Large amounts of descriptive information can be \\ncollected about business functions, business processes, business data objects, \\nbusiness data elements, business rules, data quality, and other architectural com- \\nponents. The organization needs standards or guidelines that govern who cap- \\ntures which meta data components and how, when, and where to capture them.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 106}, page_content='The meta data repository should be set up in such a way that it supports the stan- \\ndards for meta data capture and usage. \\nLogical Data Modeling \\nLogical data modeling is a business analysis technique (not to be confused with \\nlogical database design). Every business activity or business function uses or \\nmanipulates business data in some fashion. A logical data model documents \\nthose logical data relationships irrespective of how the functions or the data are'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 106}, page_content='implemented in the physical databases and applications. \\nProject-specific logical data models should be merged into one cohesive, inte- \\ngrated enterprise logical data model. This activity usually is—and should be— \\nincluded in the job description for the data administration department, which may \\nbe part of the enterprise architecture group. The enterprise logical data model is \\nthe baseline business information architecture into which physical systems (oper-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 106}, page_content='ational or decision-support, including BI applications) are mapped. The organi- \\nzation should establish standards for creating the project-specific logical data models \\nfor BI projects and for merging the models into the enterprise logical data model. \\nData Quality \\nInformation can be only as good as the raw data on which it is based. Most orga- \\nnizations have a lot of dirty data—too much to cleanse it all. Each organization'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 106}, page_content='must establish guidelines about triaging (categorizing and prioritizing) dirty data \\nfor cleansing. In addition, the organization must create standards that define \\nacceptable quality thresholds and specify how to measure data quality during \\ndatabase loads. Instructions for error handling and suspending dirty data records \\nshould also be part of the standards. \\nTesting \\nTesting standards specify what types of tests should be performed and who should'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 106}, page_content='participate in the various types of testing. The organization should provide'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 107}, page_content='74 Step 2: Enterprise Infrastructure Evaluation \\nguidelines that describe the types of test cases required at a minimum, how much \\nregression testing to perform, and under what circumstances to regression test. A \\nbrief description of a test plan, perhaps even a template, as well as instructions for \\nhow to organize and manage the various testing activities should be included. \\nReconciliation \\nThe BI decision-support environment will have multiple target databases and'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 107}, page_content='multiple BI applications. Since BI applications are not stand-alone systems, their \\ndevelopment must be coordinated and reconciled to guarantee consistency across \\nthe BI decision-support environment. That includes having one (logical) central \\nstaging area with reconciliation programming for every input-process-output \\nmodule regardless of whether the module is written in native code or produced \\nby an ETL tool. \\nSecurity'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 107}, page_content='Security \\nBI data is derived from operational data. Therefore, security guidelines that apply \\nto the operational data also apply to the BI data. However, if data is summarized \\nand the ability to drill down to the details is not enabled, some of the security fea- \\ntures can be relaxed. But rather than allowing the members of each project team \\nto make up the rules as they please, the data owners should establish security'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 107}, page_content='standards to guide the project teams on what types of security measures are man- \\ndatory for what types of data exposure. These standards should include guide- \\nlines for categorizing security risks. Security risks should be considered for data \\nsensitivity, application security, network security, and security against intrusions, \\nhacks, viruses, and other nuisances on the Web. \\nService-Level Agreements \\nOrganizations function according to explicit or implicit business principles.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 107}, page_content='Business principles are explicit if stated in mission or vision statements, implicit if \\nthey are just “understood” by the staff. For example, if an organization rewards \\nproject managers for meeting deadlines even though their applications are full of \\nerrors while it punishes project managers for missing deadlines even though their \\napplications are flawless, the implicit business principle is “speed before quality.”'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 107}, page_content='Service-level agreements (SLAs) ordinarily support the explicit as well as the \\nimplicit business principles. Therefore, SLA standards should state the business \\nprinciples and outline the minimum acceptable SLA measures to support those \\nprinciples. For example, “All projects must meet a 98 percent data quality threshold'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 108}, page_content='Nontechnical Infrastructure Evaluation Activities 75 \\nfor financial data.” SLA measures can also apply to query response time, timeli- \\nness, availability, and level of ongoing support. \\nPolicies and Procedures \\nStandards and guidelines should also cover the policies and procedures of an \\norganization, such as operating procedures, project change-control procedures, \\nissues management procedures, and dispute resolution procedures. Additional'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 108}, page_content='topics (e.g., communication processes, estimating guidelines, roles and responsi- \\nbilities, standard document format) should also be part of the policies and proce- \\ndures. The purpose of having policies and procedures, along with standards and \\nguidelines, is to help streamline and standardize the BI decision-support envi- \\nronment. In other words, policies, procedures, standards, and guidelines must \\nadd value for the organization as a whole—or they should not exist.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 108}, page_content='NONTECHNICAL INFRASTRUCTURE EVALUATION ACTIVITIES \\nThe nontechnical infrastructure activities need to be performed linearly, as indi- \\ncated in Figure 2.11. The list below briefly describes the activities associated with \\nStep 2, Section B, Nontechnical Infrastructure Evaluation. \\nImprove nontechnical \\ninfrastructure \\no e 4 \\nWrite nontechnical infrastructure \\nassessment report \\nAssess effectiveness of \\nnontechnical infrastructure \\ncomponents'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 108}, page_content='components \\nFigure 2.11: Nontechnical Infrastructure Evaluation Activities \\n1. Assess the effectiveness of existing nontechnical infrastructure components. \\nThe policies, procedures, guidelines, and standards, which are all part of the \\nnontechnical infrastructure, exist to assist in the coordination and manage- \\nment of the BI decision-support environment. They should not hinder the \\nproject teams or slow them down unnecessarily. Therefore, review the appro-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 108}, page_content='priateness and effectiveness of all nontechnical infrastructure components at \\nthe beginning of each BI project. Expand, reduce, or revise any inadequate \\ncomponents as necessary. \\n- Eliminate unnecessary activities or tasks from the development methodol- \\nogy or add missing activities or tasks.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 109}, page_content='76 Step 2: Enterprise Infrastructure Evaluation \\n* Ensure that naming standards and abbreviations make sense and are com- \\nfortable to the business community. \\n* Review the logical data modeling and meta data strategies, and ensure that \\nthe data administration and meta data administration groups are adequately \\nstaffed. \\n* Refine the organization’s data quality initiative. \\n+ Examine the testing standards, and ensure that a sufficient amount of rec- \\nonciliation is being performed.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 109}, page_content='* Review the guidelines for SLAs and security. \\nTasks within this activity can be performed concurrently. \\n2. Write the nontechnical infrastructure assessment report. \\nSe \\nOnce you have assessed all the components of the existing nontechnical \\ninfrastructure, prepare a report that outlines your findings and gives recom- \\nmendations for improvement. If there are missing nontechnical infrastruc- \\nture components, prioritize which ones to include in the next BI project and \\nwhich ones to defer.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 109}, page_content='Improve the nontechnical infrastructure. \\nIn the project plan, give time estimates for modifying or improving nontech- \\nnical infrastructure components as well as for establishing new components. \\nIf the improvements must be completed prior to starting the BI project, cre- \\nate a separate infrastructure project with a separate team and a separate \\nproject plan. \\nDELIVERABLE RESULTING FROM THESE ACTIVITIES \\n1. Nontechnical infrastructure assessment report'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 109}, page_content='This report should document the deficiencies of the existing nontechnical \\ninfrastructure and should cover the following items: \\n— Standards \\n— Use of a development methodology \\n— Estimating guidelines \\n— Scope management procedure \\n— Issues management procedure \\n— Roles and responsibilities \\n— Security process \\n— Meta data capture and delivery'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 110}, page_content='Roles Involved in These Activities 77 \\n— Process for merging project-specific logical data models into the enterprise \\nlogical data model \\n— Data quality measures and triage process \\n— Testing process \\n— SLAs \\n— Support function \\n— Dispute resolution procedure \\n— Communication process \\nInclude a section for proposed improvements for those selected nontechnical \\ninfrastructure components that will be included in the BI project. \\nROLES INVOLVED IN THESE ACTIVITIES \\n® Bl infrastructure architect'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 110}, page_content='In some organizations, the BI infrastructure architect may have responsibility \\nover the nontechnical architectural components of the BI decision-support \\nenvironment. In other organizations, he or she works closely with the data \\nadministrator, meta data administrator, and data quality analyst. Occasionally \\nthe BI infrastructure architect oversees the activities of the data administrator, \\nmeta data administrator, and data quality analyst. It is up to the organization'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 110}, page_content='to select the enterprise architecture reporting structure that is most appropri- \\nate for its organizational culture. \\n@ Data administrator \\nIn many organizations, data administration has the responsibility for most of \\nthe nontechnical infrastructure components, in particular logical data model- \\ning, data quality, naming standards, and meta data. However, since the area of \\nnontechnical infrastructure involves so many disciplines, the traditional data'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 110}, page_content='administration responsibilities should be divided among the data administra- \\ntor, the meta data administrator, the data quality analyst, and sometimes even \\nthe BI infrastructure architect. All of these roles are usually staffed by mem- \\nbers of the enterprise architecture group. \\n@ Data quality analyst \\nThe data quality analyst takes charge of finding and analyzing dirty data in the \\nsource files. Since it is impossible to cleanse all the dirty data, the organization'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 110}, page_content='must establish triaging procedures and prioritization guidelines. The data \\nquality analyst is the steward of those data quality standards.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 111}, page_content='78 Step 2: Enterprise Infrastructure Evaluation \\n® Meta data administrator \\nThe meta data administrator is responsible for the meta data repository. He or \\nshe must create it (or buy and install it), maintain it, and populate it. During \\nthe BI project, the data administrator will provide the business meta data, and \\nthe database administrator and data quality analyst (with the help of the ETL \\nand application lead developers) will provide the technical meta data. The'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 111}, page_content='meta data administrator must then merge all the meta data into the meta data \\nrepository and make it available to IT staff and to the business people. The \\nmeta data administrator should therefore establish the standards related to the \\nmeta data repository activities. \\nRISKS OF NOT PERFORMING STEP 2, SECTION B \\nBusiness intelligence is all about creating an enterprise architecture solution to \\nthe decision-support chaos that exists today. It is a cross-organizational initiative.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 111}, page_content='Therefore, cross-organizational activities are of critical importance. The absence of \\nthose activities will lead to stovepipe development and will add to the “spaghetti \\nchart” more data marts and more stand-alone BI applications that are neither \\nintegrated nor reconciled. As a result, the organization would continue to lose the \\nopportunity to enhance its business decisions and competitive advantages. \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nTechnical Infrastructure Evaluation'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 111}, page_content='Bischoff, Joyce, and Ted Alexander. Data Warehouse: Practical Advice from the \\nExperts. Upper Saddle River, NJ: Prentice Hall, 1997. \\nDevlin, Barry. Data Warehouse: From Architecture to Implementation. Reading, \\nMA: Addison-Wesley, 1997. \\nInmon, William H. Building the Data Warehouse. New York: John Wiley & Sons, \\n1996. \\nInmon, William H., Claudia Imhoff, and Greg Battas. Building the Operational \\nData Store. New York: John Wiley & Sons, 1996.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 111}, page_content='Jarke, Matthias, Maurizio Lenzerini, Yannis Vassiliou, and Panos Vassiliadis. Fun- \\ndamentals of Data Warehouses. New York: Springer, 2000.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 112}, page_content='Bibliography and Additional Reading 79 \\nKelly, Sean. Data Warehousing: The Route to Mass Customization. New York: John \\nWiley & Sons, 1996. \\nKimball, Ralph, and Richard Merz. The Data Webhouse Toolkit: Building the Web- \\nEnabled Data Warehouse. New York: John Wiley & Sons, 2000. \\nLinthicum, David S. Enterprise Application Integration. Boston, MA: Addison- \\nWesley, 2000. \\nMoeller, R. A. Distributed Data Warehousing Using Web Technology: How to Build'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 112}, page_content='a More Cost-effective and Flexible Warehouse. New York: AMACOM American \\nManagement Association, 2001. \\nNontechnical Infrastructure Evaluation \\nAdelman, Sid, and Larissa Terpeluk Moss. Data Warehouse Project Management. \\nBoston, MA: Addison-Wesley, 2000. \\nBrackett, Michael H. Data Resource Quality: Turning Bad Habits into Good Prac- \\ntices. Boston, MA: Addison-Wesley, 2000. \\n. The Data Warehouse Challenge: Taming Data Chaos. New York: John \\nWiley & Sons, 1996.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 112}, page_content=\"Bruce, Thomas A. Designing Quality Databases with IDEF1X Information Models. \\nNew York: Dorset House, 1992. \\nEnglish, Larry P. Improving Data Warehouse and Business Information Quality: \\nMethods for Reducing Costs and Increasing Profits. New York: John Wiley & Sons, \\n1990. \\nHoberman, Steve. Data Modeler's Workbench: Tools and Techniques for Analysis \\nand Design. New York: John Wiley & Sons, 2001. \\nInmon, William H. Building the Data Warehouse. New York: John Wiley & Sons, \\n1996.\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 112}, page_content='1996. \\nInmon, William H., Claudia Imhoff, and Greg Battas. Building the Operational \\nData Store. New York: John Wiley & Sons, 1996. \\nInmon, William H., Claudia Imhoff, and Ryan Sousa. Corporate Information Fac- \\ntory. New York: John Wiley & Sons, 1997. \\nInmon, William H., John A. Zachman, and Jonathon G. Geiger. Data Stores, Data \\nWarehousing and the Zachman Framework: Managing Enterprise Knowledge. New \\nYork: McGraw-Hill, 1997.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 113}, page_content='80 Step 2: Enterprise Infrastructure Evaluation \\nKuan-Tsae, Huang, Yang W. Lee, and Richard Y. Wang. Quality Information and \\nKnowledge Management. Upper Saddle River, NJ: Prentice Hall, 1998. \\nReingruber, Michael C., and William W. Gregory. The Data Modeling Handbook: \\nA Best-Practice Approach to Building Quality Data Models. New York: John Wiley \\n& Sons, 1994. \\nRoss, Ronald G. Business Rule Concepts. Houston, TX: Business Rule Solutions, \\n1998.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 113}, page_content='1998. \\nSimsion, Graeme. Data Modeling Essentials: Analysis, Design, and Innovation. \\nBoston, MA: International Thomson Computer Press, 1994. \\nZachman, John. The Zachman Framework: A Primer for Enterprise Engineering \\nand Manufacturing. La Canada, CA: Zachman International, 2002. \\nZachman Institute for Framework Advancement: http://www.zifa.com'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 114}, page_content='Justification ula CHAPTER THREE \\nStep 3: Project Planning \\nCHAPTER OVERVIEW \\nThis chapter covers the following topics: \\n@ Things to consider about project planning \\n@ Managing the BI project and planning for setbacks \\nData Societien sy m Items to address when creating a project charter, such as \\nbh Analysis 2). Prototyping 4  Repc goals and objectives, scope issues, project risks, constraints, \\nree assumptions, change control, and issues management'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 114}, page_content='@ Aspects of project planning, with a focus on activities and \\nDesign ie ius tasks, estimating techniques, resource assignment, task \\nand resource dependencies, critical path determination, \\nand creation of the final project schedule \\nm Brief descriptions of the project planning activities, the \\n. deliverables resulting from those activities, and the roles \\n= involved \\n| / @ The risks of not performing Step 3 \\nConstruction \\n~ \\n81'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 115}, page_content='82 Step 3: Project Planning \\nTHINGS TO CONSIDER \\nBusiness Involvement \\nY Do we have a strong business sponsor? Do we have a backup business sponsor? \\nY Do we have stakeholders with whom we need to communicate regularly? \\n/Y How much time is the business representative committing to this project? Is \\nhe or she assigned to this project full-time, or will he or she be available on \\nrequest only? \\nProject Scope and Deliverables \\nVv Did we receive a formal request for a BI project?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 115}, page_content='VY How detailed are the requirements? \\nv¥ What are the requested deliverables? \\nY Can we implement the requested scope given the schedule and the available \\nresources? \\nCost-Benefit Analysis \\nVv Have we already performed a cost-benefit analysis? \\n¥ What is the expected return on investment (ROI)? \\nY How soon do we expect the ROI to materialize? \\nInfrastructure \\nV Did we review our technical and nontechnical infrastructure components? \\nY Does our infrastructure have any gaps?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 115}, page_content='¥ Which infrastructure components will we need to work on and deliver as \\npart of the BI project? \\n—Which technical infrastructure components? \\n—Which nontechnical infrastructure components? \\nStaffing and Skills \\nV Have we already identified the team members? \\n¥ Do all team members have the skills needed to perform the responsibilities \\nof their assigned roles? \\n¥ Should we schedule any training before the project kickoff?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 115}, page_content='V Is the project manager assigned to this project full-time? Or does he or she \\nhave other administrative responsibilities? If the latter, who will take over \\nthose other responsibilities for the duration of this project? \\nee'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 116}, page_content='Managing the BI Project 83 \\nBI projects are not like other projects with a finite and static set of require- \\nments from one business person or one department. Instead, the purpose of an \\nintegrated BI decision-support environment is to provide cross-organizational \\nbusiness analysis capabilities to all business people and all departments in the \\norganization. That involves a variety of new tasks, shifted roles and responsibili- \\nties, and a more hands-on project management approach.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 116}, page_content='MANAGING THE BI PROJECT \\nProject management in most organizations is treated as an administrative report- \\ning function. Detailed project planning and hands-on daily project control are \\noften minimized, if not ignored, especially when organizations try to get several \\nBI applications up and running very quickly. In their shortsightedness, organiza- \\ntions forget that extended planning activities often lead to shorter testing and'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 116}, page_content='implementation cycles and thus a shorter delivery time—exactly what the busi- \\nness community wants. \\nNo BI project gets off the ground without a few “kinks and bends”; delays are \\ncommon. For example, some products may not have enough capacity; others \\nmay not work well in a distributed environment. Switching vendors and products \\ncan prove costly in terms of time and money. Vendors often cannot offer the \\ncomprehensive solutions that businesses expect because the vendors are still'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 116}, page_content='struggling to integrate all the pieces of their BI products. This leaves integration \\nup to the organizations’ information technology (IT) staffs. \\nMany organizations do not adequately plan for these types of delays and set- \\nbacks, nor do they test their BI concepts and strategies adequately. Setbacks are \\ninevitable on a project as resource intensive as a BI application—even under the \\nbest of circumstances. Planning for setbacks will help management set realistic'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 116}, page_content='rollout dates for the project. \\nDescribing project management activities in the most simplistic terms, the \\ngoal is to answer four basic questions. \\n1. What will be delivered? \\n2. When will it be done? \\n3. How much will it cost? \\n4. Who will do it?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 117}, page_content='84 Step 3: Project Planning \\nFigure 3.1: Project Constraints \\nThese questions translate, respectively, into the four major project con- \\nstraints of scope, effort (time), budget, and resources (Figure 3.1). Before the \\nproject manager can create a project plan to address these constraints, he or she \\nmust spend some time defining the project to clearly understand the related \\nrequirements, risks, constraints, and assumptions. \\nDEFINING THE BI PROJECT'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 117}, page_content='Project planning includes creating a project charter, which defines the project in \\nterms of: \\n* Goals and objectives \\n* Scope (the expected project deliverable) \\n* Risks \\n* Constraints \\n- Assumptions \\n* Change-control procedures \\n* Issues management procedures \\nThe project charter is the agreement made between the business sponsor and \\nthe IT staff for developing the BI application. If any component of the project \\ncharter changes, the entire project has to be reevaluated and all project con-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 117}, page_content='straints have to be renegotiated.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 118}, page_content='Defining the BI Project 85 \\nProject Goals and Objectives \\nWhen defining a BI project, first address the goals and objectives. What is the rea- \\nson for building this BI application? How much business pain (in hard currency) \\ndoes that business problem, which the BI application is supposed to solve, cur- \\nrently cause? What are the strategic business drivers? Do the BI project objectives \\nfall in line with the strategic business objectives, or is this someone’s pet project?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 118}, page_content='Project objectives should be measurable statements, such as, “In order to \\nincrease market share by 10 percent next year, the sales department must have \\naccess to month-end sales data as well as pipeline data merged with prospect data \\nwithin five business days after the close of the weekly accounting cycle.” Project \\nobjectives must tie in with the expected ROI. The business representative will \\nhave to measure the effectiveness of the delivered BI application and report to the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 118}, page_content='business sponsor whether the project was successful or not. \\nProject Scope \\nIt is impossible to create valid estimates for a project without a solid understand- \\ning of the scope. Traditionally, scope has been measured by the number of func- \\ntions the system will perform (function point analysis). On BI projects that is a \\nsure way to underestimate effort, budget, and resources. BI applications are data- \\nintensive, not function-intensive. Therefore, scope must be measured by the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 118}, page_content='number of data elements that have to be extracted from the source systems, trans- \\nformed and cleansed, and loaded into the BI target databases. \\nThe main reason for concentrating on data rather than functions is that ana- \\nlyzing and preparing source data takes much longer than providing data access \\nand enabling data analysis through reports and queries. The typical 80/20 rule \\nusually applies: 80 percent effort for data and 20 percent effort for functionality. \\nProject Risks'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 118}, page_content='Project Risks \\nEvery project is subject to some risks—risks are unavoidable. Such risks could \\nseverely affect the project schedule as well as the project deliverables, depending \\non the likelihood that the risks will materialize and on the impact they would \\nhave on the project. Therefore, the risk assessment performed during Step 1, \\nBusiness Case Assessment, must be reviewed and expanded if necessary. The \\nproject manager must identify triggers for each risk and incorporate a mitigation'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 118}, page_content='plan as well as a contingency plan into the project plan.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 119}, page_content='86 Step 3: Project Planning \\nTriggers are situations that signal a potential, perhaps imminent materializa- \\ntion of a risk. For example, if management is reviewing the budget for the \\nproject for no apparent reason, this indicates a possible trigger for the risk of \\nlosing management support for your BI project. \\nThe mitigation plan specifies what actions the project team can take to pre- \\nvent the risk from materializing. Continuing with the example above, you'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 119}, page_content=\"could solicit support from your business sponsor and promote the BI initia- \\ntive to other key executives in your organization to keep management's inter- \\nest in the BI project. Should the project run into trouble, the risk of having it \\ncancelled is mitigated or prevented. \\nThe contingency plan specifies alternatives in case the risk does materialize. \\nFor example, if you lose management support for the BI project due to a long\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 119}, page_content='project schedule, plan to shorten the release cycles by delivering a smaller \\nscope sooner. If you lose management support due to the business sponsor’s \\ndeparture from the organization, have an alternate sponsor ready to become \\nthe champion for the BI project. \\nSome common project risks include the following: \\nLack of management commitment \\nLost sponsor \\nLack of business participation \\nImposed, unrealistic schedule \\nUnrealistic scope for the schedule \\nUnrealistic expectations'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 119}, page_content='Unrealistic budget \\nUntrained or unavailable staff \\nConstantly changing business priorities \\nIneffective project management \\nLimited scalability \\nProject Constraints \\nAll projects are subject to the same project constraints mentioned earlier: scope, \\neffort (time), budget, and resources (capable and available people). In reality, \\nthere is a fifth constraint: quality. Although quality is a measure of how well the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 120}, page_content='Defining the BI Project 87 \\ndeliverables meet the requirements, it can also be considered a constraint that \\nmust be balanced with the other four constraints. \\nWhile everyone on the business side and in the IT department wants quality, \\nrarely is the extra time given or taken to achieve it because quality and effort are \\npolarized constraints. Higher quality requires more effort and thus more time to \\ndeliver. Since time factors drive most organizations, effort is their number one'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 120}, page_content='constraint (highest priority), followed by scope, budget, and resources (usually in \\nthat order); and quality gets pushed to the bottom of the heap (lowest priority), \\nas illustrated in Table 3.1. BI project constraints should never be in this order. \\nFortunately, organizations have full control over changing the priority of \\nproject constraints. To insist that time and scope be the top two constraints is \\nacceptable only on projects that have requirements connected to government-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 120}, page_content='imposed regulations. But in most of those cases, the operational systems (and \\noperational reports) are the ones affected by government-imposed deadlines, \\nrarely the downstream strategic decision-support applications. We strongly \\nadvise you to get quality out from the bottom of the heap and put scope there \\nbecause scope can and will continually be expanded through future BI applica- \\ntion releases. Table 3.2 shows our recommended order of project constraints. \\nAssumptions'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 120}, page_content='Assumptions \\nAn assumption is anything taken for granted; it is a supposition or a presump- \\ntion. It is important to document assumptions because a wrong assumption \\ncould very quickly turn into a risk. Here is an example of how two assumptions \\non a project backfired. \\nTable 3.1: Typical Order of Project Constraints \\nPriority (Highest to Lowest) \\nConstraint 1 2 3 4 5 \\nEffort (time) Uf \\nScope v \\nBudget J \\nResources J \\nQuality J \\n| SS SSS SB EE ES ET I'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 121}, page_content='88 Step 3: Project Planning \\na SN ASS EE EE SE RS ST \\nTable 3.2: Recommended Order of Project Constraints \\nPriority (Highest to Lowest) \\nConstraint 1 2) 3 4 5 \\nQuality v \\nBudget v \\nResources J \\nEffort (time) vo \\nScope J \\nAssumption 1: “The vendor promises to deliver a new database server in May, \\nand by the end of June the IT staff will install and test a new database man- \\nagement system (DBMS) product on that server. This allows plenty of time'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 121}, page_content='before the project deadline, which is September 30, the fiscal year-end.” \\nAssumption 2: “Joe Bamberg will be the database administrator on the \\nproject because he is the only person in our organization who has that partic- \\nular DBMS uh which is needed for the project. He has already joined the \\nproject team.” \\nProblems: On June 20 (one month late) the new server finally arrives, and on \\nJuly 1 Joe Bamberg quits the organization. The new DBMS product does not'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 121}, page_content='get installed and tested on the new server until the end of September. \\nImpact: The project is delayed by three months at a budget overrun of \\n$60,000 (much of it paid as consulting fees for the high-priced consultant \\nwho had to fill in for Joe Bamberg). \\nImportant assumptions should have counterpart risks, in case the assumptions \\neither turn out to be false or do not materialize, as in the example above. For each'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 121}, page_content='counterpart risk, identify triggers, a mitigation plan, and a contingency plan. \\nChange-Control Procedures \\nTraditional waterfall methodologies became so popular in part because the \\nsigned-off, phased development approach attempted to curb scope creep. The \\nmental model was “Change is bad—business people must be held to their deci- \\nsions.” Since BI applications are supposed to be catalysts for improved decision'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 122}, page_content='Defining the BI Project 89 \\nmaking, the mental model must change to “Change is good—business people \\nshould refine and improve their decisions.” However, uncontrolled change can \\nstill kill a project. \\nThe solution is to manage the changes. Many organizations track their \\nchange requests by logging the date of the change request, the name of the \\nrequestor, the desired change, to whom it was assigned, and when it was imple-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 122}, page_content='mented. That is a good practice, but tracking changes is not the same thing as \\nmanaging them. \\nTo manage a change, you need to start with a baseline—the agreement \\nbetween the business sponsor and the IT staff, as documented in the project char- \\nter. Every change request, once logged, undergoes an impact analysis and a cost- \\nbenefit analysis to determine the effects of the change on the project. Changes, \\nunless they are minute, always impact the three constraints of effort (time),'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 122}, page_content='scope, and quality. Some changes also impact the other two constraints (budget \\nand resources). When one constraint changes, the remaining constraints will \\nhave to be renegotiated. Unfortunately, business managers and IT managers fre- \\nquently put the project teams under unwarranted pressure to incorporate scope \\nchanges without slipping the schedule. \\nPaw It is not rational to request a significant scope change to a carefully deliberated'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 122}, page_content='and agreed-upon project plan without adjusting any of the other constraints. \\nIt is not rational because the business representative, the project manager, \\nand the core team members who developed the plan together believed they could \\ncomplete the project under the agreed-upon constraints. When the scope con- \\nstraint changes, the plan is no longer doable without changes to some of the \\nother constraints, namely effort (time), budget, resources, and quality, to absorb'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 122}, page_content='the impact of the scope change. Therefore, depending on how critical the change \\nrequest is, the business representative has to decide whether to: \\n* Cut back from the current scope by eliminating some of the originally \\nrequested data and functionality \\n+ Extend the deadline \\n* Declare the requested change unfeasible at this time and postpone it \\n- Incorporate the requested change in the next release \\n- Eliminate complicated transformations, edit checking, and testing, which'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 122}, page_content='will impact the quality of the deliverable'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 123}, page_content='90 Step 3: Project Planning \\nIssues Management Procedures \\nIssues, whether related to business or technical concerns, always come up during \\nprojects. Similar to change requests, issues must be not only tracked but also \\nmanaged. Every issue must be assigned to a person who has the responsibility for \\nits resolution. Any activity regarding the issue must be dated and described on \\nthe issues log. At the end of the project, all issues must have a resolution, even if'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 123}, page_content='that resolution is a deferral of the issue to a future BI release. Table 3.3 shows an \\nexample of an issues log. \\nSome issues are minor and can be resolved without impact on the project. \\nOther issues can turn into risks or change requests and have to be dealt with \\naccordingly. Therefore, managing issues includes impact analysis and change \\ncontrol. \\nPLANNING THE BI PROJECT \\nProject planning is not a one-time activity. Since a project plan is based on esti-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 123}, page_content='mates, which are frequently no more than best guesses, project plans must be \\nadjusted constantly. The number one telltale sign that a project is not being man- \\naged is a static project plan on which estimates and milestones have never \\nchanged from the day they were first developed. \\nHere is the sequence of activities for preparing a project plan. \\n. Create a work breakdown structure listing activities, tasks, and subtasks.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 123}, page_content='. Estimate the effort hours for these activities, tasks, and subtasks. \\n. Assign resources to the activities, tasks, and subtasks. \\n. Determine the task dependencies. \\n. Determine the resource dependencies. \\n. Determine the critical path based on the dependencies. \\nN DB Oo & WO NH . Create the detailed project plan. \\nActivities and Tasks \\nBI projects are composed of many activities, each with a long checklist of tasks.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 123}, page_content='Regardless of how experienced the project manager is, it is impossible for any \\nperson to remember all the tasks that need to be performed on a BI project. At a'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 124}, page_content='91 Planning the BI Project \\n—_———————————————————————— \\n€00Z \\n‘QIGLIIEAR \\nSI \\nJAAJaS \\n‘pied \\n/1Z/8 \\nUOY \\nWO} \\n[JE \\nPIAladoy \\n\"Y9OM \\n3X9U \\ndIqeIIEAe \\n3q \\n0} \\npayadxq \\n€00Z \\n‘pajse} \\nSuleqg \\npuke \\npajje}sul \\n/VL/8 \\nS| \\nJBMJ9S \\n“pied] \\nUOY \\npajjey \\n\"Y89M \\n9UO \\nul \\nSl \\na}ep \\nAUaAtjag \\nualjddns \\nJOYJOUL \\nWO \\nJaAlas \\ne 1aB \\n€00Z \\n0} \\n9/ge \\naq \\n|[IM \\n9H \\n‘ples \\n/LE/L \\nUOY \\nWO \\n[Jed \\npaAladoy \\n\"yoom \\n“dIOW \\nJO \\nUJUOW \\n‘(1osuods) \\nduo \\nU! \\ndn-mojjo4 \\n“aijddns \\n9UO \\naq \\nP[NOD \\nsul|peap \\nyoelg \\nWeqoy \\nAq'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 124}, page_content='yoelg \\nWeqoy \\nAq \\npaidadze \\nJOYJOUL \\nO} \\nYDUMS \\n0} \\najqe \\npefoid \\nuo \\npeduy \\nAejaq \\n‘syaam \\n3aiu} \\nAjUO \\naq \\nAew \\ndH \\n‘sanieusaye \\n‘Jaijddns \\nyyM \\nwajqoldg \\n€007Z \\n‘ajnpaups \\npefoid \\nau} \\n0} \\n€00Z \\nssndsIp \\n0} \\nWOddns \\n‘yda} \\n‘paidedxa \\nuole]]e}sul \\n€00Z \\n/1Z/8 \\nAejaq \\n‘siatiddns \\npaysyms \\n/VC/L \\nWOJ} \\nP1ed] \\nUOY \\nYUM \\nJol \\nIa \\nJamas \\njo \\nAejaq \\nJEC/L \\nLOO \\najDq \\nuoHnjosay \\najpqd \\nuayb, \\nuoRDYy \\nOL \\nuondisaq \\nanss] \\najpq \\n‘ON \\nuonoy \\npaubissy \\nanssj \\nanss| \\npasoj[) \\nCCL \\nes \\n307 \\nSanss| \\n:€°€'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 124}, page_content='307 \\nSanss| \\n:€°€ \\najqel'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 125}, page_content='92 Step 3: Project Planning \\nminimum, the project manager must rely on some existing comprehensive list of \\nthe most necessary activities. Naturally, not all activities have to be performed on \\nevery project. Not even every step has to be performed on every project. The \\nproject manager selects the minimum number of steps and activities needed to \\nproduce an acceptable deliverable under the imposed constraints. \\nThe development approach in Business Intelligence Roadmap is neither as lin-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 125}, page_content='ear nor as rigorous as that followed in traditional methodologies. It is a much \\nmore dynamic approach to application development. When using our develop- \\nment approach, it may often look and feel like you are working on a prototype— \\nbut it is not a prototype. The same discipline applied under a traditional method- \\nology must be applied to BI projects in terms of controlling scope, mitigating \\nrisks, and time-boxing weekly activities. (Time-boxing refers to planning, assign-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 125}, page_content='ing, and managing activities on a detailed level in weekly increments.) Despite the \\ndiscipline, you must expect constant rework during the development cycle and build \\ntime for it into the project plan. For example, analysis activities can show up on your \\nproject plan as early as Step 3, Project Planning, and as late as Step 12, Applica- \\ntion Development. Or you may want to plan another short iteration through \\ndatabase design activities during Step 11: Extract/Transform/Load Development.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 125}, page_content='The project plan must reflect this dynamic nature of application development. \\nSince changes and setbacks are to be expected, certain “completed activities” will \\nhave to be revisited and reworked. The project plan should anticipate that and \\nreflect it on the schedule. The easiest way to plan for these internal iterations is to \\nuse the concept of “looping” or “refactoring” by dividing the project into multiple'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 125}, page_content='small subprojects, each with a deliverable, albeit not completed. Then revisit and \\nrevise each deliverable, adding more data and more functionality until the entire \\nBI application is completed with the desired deliverable. This iterative refinement \\napproach gives the project development effort the feeling of prototyping. \\nEstimating Techniques \\nOnce you have selected the activities and tasks for the project and organized the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 125}, page_content='project into subprojects, you can derive the base estimates by using one of three \\nmethods: \\n1. Historical, based on learned patterns (how long it took on the last project) \\n2. Intuitive, based on intuition and experience (“gut” estimating) \\n3. Formulaic, based on the average of possibilities (Figure 3.2)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 126}, page_content='Planning the BI Project 93 \\nBest Estimate + (4 x Average Estimate) + Worst Estimate \\n6 \\nFigure 3.2: Formula-Based Estimating \\nEstimating BI project activities is much more difficult than estimating tradi- \\ntional projects because no two BI projects are alike. For example, you may use a \\nnew tool, work with new team members, or have no experience with a new \\ndesign method. All three estimating techniques listed above expect you to relate \\nto some prior project experience.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 126}, page_content='- The historical estimating technique expects you to have statistics on how long \\nsimilar projects took in the past—but you may not have had a similar project \\nbefore. \\nThe intuitive estimating technique expects you to predict, or guess, based on \\nprior experience how long it will take to complete a similar activity—but you \\nmay have never performed a similar activity. \\nThe formula-based estimating technique expects you to know the longest'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 126}, page_content='time it may take to complete an activity, the shortest time, and the most \\nprobable time—but you would not know what the longest, shortest, and \\nmost probable times for an activity could be if you had never performed that \\nactivity before. \\nIn all those cases, it is best to consult with other people (in-house staff or out- \\nside consultants) who have already developed a similar BI application because \\nyour own uneducated guesses may be gross underestimates. This also demon-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 126}, page_content='strates how important it is to track actual time on BI projects. You will need that \\ninformation for estimating your next BI project. \\nResource Assignment \\nEffort estimates cannot be completed until the activities and tasks are assigned \\nbecause the estimates must take into consideration each team member’s skills \\nand subject matter expertise as well as the environmental factors that affect him \\nor her. \\n* Skills—the ability to perform specific tasks. Has the team member done this'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 126}, page_content='type of work before?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 127}, page_content='94 Step 3: Project Planning \\nTE SRS ETL RP EE DL CS I IS EE ED, \\nTable 3.4: Environmental Factors That Can Affect Team Members’ Availability \\nAdministrative Factors Non-Work-Related Factors \\nLack of computer access Vacation \\nTime required to troubleshoot other Illness \\nsystems Jury duty \\nMeetings Personal time off \\nE-mails and in-baskets Medical appointments \\nTraining seminars Religious holidays \\n* Subject matter expertise—the possession of facts or concepts about a specific'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 127}, page_content='subject matter. Is the team member an expert in this business area? \\n* Environmental factors—administrative and non-work-related activities. Table \\n3.4 lists some examples. \\nTask Dependencies \\nNot all activities and tasks have to be performed serially—many can be per- \\nformed in parallel as long as there is sufficient staff. The first step in determining \\nwhich tasks can be performed in parallel is to identify task dependencies and'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 127}, page_content='develop the critical path. Most project-planning tools support the four types of \\ntask dependencies (Figure 3.3). Finish to Start and Start to Start are the most \\ncommon task dependencies; Start to Finish is the most infrequent. \\nFinish to Start Start to Start \\nFinish to Finish Start to Finish \\nFigure 3.3: Task Dependencies'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 128}, page_content='Planning the BI Project 95 \\n1. Finish to Start indicates that Task 2 cannot start until Task 1 finishes. \\n2. Start to Start indicates that Task 2 can start at the same time as Task 1. \\n3. Finish to Finish indicates that Task 2 cannot finish until Task 1 finishes. \\n4. Start to Finish indicates that Task 2 cannot finish until Task 1 starts. \\nThe more tasks that can be performed simultaneously, the faster the project \\nwill get done. To take advantage of task dependencies, you need the right number'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 128}, page_content='of resources with the right skills at the right time. \\nResource Dependencies \\nA shortage of staff can quickly reverse the benefits of having few task dependen- \\ncies. For example, tasks that could have been performed in parallel but cannot be \\nassigned to multiple staff members because of a staff shortage must revert to \\nbeing executed in sequence. Figure 3.4 shows how four tasks can be accomplished \\nin 10 days with adequate staffing; Figure 3.5 shows that it will take 14 days to'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 128}, page_content='complete the same tasks if only one person is available to work on them. (Note \\nthat in Figure 3.5 the time required to compile the findings is reduced by one day \\nbecause there is no longer a need for two analysts to collaborate.) \\nCritical Path Method \\nOnce you have identified the task dependencies and leveled the resources (that is, \\nassigned the tasks and adjusted the dependencies for the available resources), use \\nConduct \\ninterviews \\n5 days \\nAnalyze \\nfiles \\n5 days \\nWrite \\nreport \\n3 days'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 128}, page_content='report \\n3 days \\nCompile \\nfindings \\n2 days \\nFigure 3.4: Elapsed Days When Two People Can Work on the Tasks \\nConduct Analyze Compile Write \\ninterviews files findings report \\n5 days | 5 days 1 day 3 days \\nResource dependency \\nFigure 3.5: Elapsed Days When Only One Person Is Available'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 129}, page_content='96 Step 3: Project Planning \\nDetermine problem Analyze cost-benefit Determine critical \\nor opportunity of new project success factors Project Approval \\nIdentify resources Pa o \\navailable a Critical Path \\nFigure 3.6: Critical Path Method \\nthe critical path method (CPM) to outline task duration, indicating any lag time \\nfor tasks not on the critical path (Figure 3.6). This provides the visibility needed \\nto reassign resources or to renegotiate project constraints.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 129}, page_content='In this example, the task “Identify resources available” can be performed in \\nparallel with the tasks “Analyze cost-benefit of new project” and “Determine crit- \\nical success factors.” Since the task “Identify resources available” is estimated to \\ntake 4 days, and the other two tasks combined are estimated to take only 3 days, \\nthe task “Identify resources available” is on the critical path. If this task were to \\ntake 5 days to complete instead of 4, it would delay the milestone “Project'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 129}, page_content='approval” by one day. However, if either of the other two tasks were delayed by \\none day, it would not affect the milestone “Project approval.” \\nProject Schedules \\nOnce you have determined all the tasks, resources, dependencies, and estimates, \\nyou can schedule the project on the calendar. The most common and most famil- \\niar representation of a project schedule is a Gantt chart. Figure 3.7 shows an example. \\nCreating a useful project plan requires some effort, but maintaining the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 129}, page_content='project plan (adjusting it) is not as labor intensive as it used to be prior to the \\navailability of project management tools. Becoming proficient on a sophisticated \\nproject management tool takes some time and requires a solid understanding of \\nproject management principles. \\nOnce you key into the tool all the planning components (e.g., tasks, esti- \\nmates, resources, dependencies), any adjustments you subsequently make to the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 129}, page_content='components automatically cascade through the entire project plan, updating all'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 130}, page_content='97 Planning the BI Project \\nWey) \\nHuey \\ne jo \\najdwexq \\n:7’¢ \\naun3i4 \\nBysm \\nII1g \\nHusn7 \\n|W!g \\nBysnq \\nie \\n| \\nHysn7 \\nIg \\nBasnq \\nm8 \\n| \\n6ysn7 \\n|IW!g \\nHysn7 \\n|I1g \\n‘ejuny \\nxejy \\nYadoog \\nwoy \\nSIN \\nxoly \\njadooa \\ncea \\nAuaems \\nauer \\n| \\nJadoog \\nwo, \\n‘6ysn7 \\njII1g \\n4o}e}) \\ne \\n| \\nAuaems \\neuer \\nKuaems \\nauer \\n| \\n[e \\na \\nAugams \\nauer \\na i —-. \\nAuaams \\nauer \\n| \\nJedoog \\nwo, \\n| \\n6ysn7 \\nja \\nJove \\nUIE \\n| \\nSIUNL \\nXaly \\n3jUNL \\nray \\n| \\nBsn II \\nlee \\nLelé \\nSMAINBY \\nSSAIHO1g \\nUl \\nYOM 9/€ \\nuonejuaseid \\naninoexe \\naAI5'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 130}, page_content='aninoexe \\naAI5 \\nyodai \\n|Buy \\nJaAlaq \\nyodai \\njeuy \\nasinay \\nyoda \\njeuy \\nmainay \\nyodai \\njeuy \\naredaiy \\nuejd \\nyoaloud \\nasedaig \\n| \\nSuojepuawwooes \\nSsnosiq \\nHuljeew \\nUOISsIA \\njONpUOD \\n| \\nsyJewyoueg \\nezAjeuy \\nsOulpuy \\nayepien \\nsBulpuy \\nayepyjosuoD \\nsuolsses \\ndnoib \\nayey!oe4 \\nSMAIAJAYUI \\nJONPUOD \\nSMAIAJOJU! \\nB|NDAYOS \\nS891NOS \\nJDB}aS \\nsajyoud \\nBuimaiasayul \\nay \\nseBeyoed \\nuoiejualo \\n1aAaq \\nsebeyoed \\nuolejuat0 \\ndojaneq \\nuoeyioey \\nuoleziueBio \\njonpuoD \\nJeueyew \\nezAjeuy \\njeuayew \\nJayaq \\n| \\nseireuuolsenb'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 130}, page_content='| \\nseireuuolsenb \\ndojaneq \\n| \\n7 \\nSSOYNOS3AY \\nAieniqe4 \\n002 \\nALIAILOV'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 131}, page_content='98 Step 3: Project Planning \\ncharts and reports. Although the results must still be reviewed and validated, an \\nexperienced project manager who is skilled on the project management tool does \\nnot need to become a slave to the tool or to the project planning activities. \\nPROJECT PLANNING ACTIVITIES \\nThe project planning activities do not need to be performed linearly. Figure 3.8 \\nindicates which activities can be performed concurrently. The list below briefly'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 131}, page_content='describes the activities associated with Step 3, Project Planning. \\nDetermine project \\nrequirements \\nDetermine condition of \\nsource files and databases \\nRevise risk \\nassessment \\nDetermine or revise \\ncost estimates \\nSy) \\nIdentify critical \\nsuccess factors \\nCreate high-level \\nproject plan \\nPrepare \\nproject charter \\nKick off \\nproject \\nFigure 3.8: Project Planning Activities \\n1. Determine the project requirements. \\nYou may have already prepared the objectives for the project and some high-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 131}, page_content='level requirements for the proposed scope during Step 1, Business Case Assess- \\nment. However, most likely they are not of sufficient detail to start the planning'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 132}, page_content='Project Planning Activities 99 \\n= \\noy \\nprocess. As part of the scope definition, review and revise the following \\nrequirements: data, functionality (reports and queries), and infrastructure \\n(technical and nontechnical). \\n. Determine the condition of the source files and databases. \\nYou can neither complete the project schedule nor commit to a delivery date \\nwithout a good understanding of the condition of the source files and data-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 132}, page_content='bases. Take some time to review the data content of these operational files \\nand databases. Although you will perform detailed source data analysis dur- \\ning Step 5, Data Analysis, right now you need to glean just enough informa- \\ntion to make an educated guess about the effort needed for data cleansing. \\nDetermine or revise the cost estimates. \\nDetailed cost estimates must include hardware and network costs as well as'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 132}, page_content='purchase prices and annual maintenance fees for tools. In addition, you must \\nascertain the costs for contractors, consultants, and training. A more indirect \\ncost is associated with the learning curve for the business and IT staff members. \\nRemember to factor that into the cost estimates as well as the time estimates. \\n. Revise the risk assessment. \\nReview and revise the risk assessment performed during Step 1, Business'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 132}, page_content=\"Case Assessment (or perform a risk assessment now if you skipped that step). \\nRank each risk on a scale of 1 to 5 according to the severity of its impact on \\nthe BI project, with 1 indicating low impact and 5 indicating high impact. \\nSimilarly, rank the likelihood of each risk materializing, with 1 being “proba- \\nbly won't happen” and 5 being “we can almost count on it.” \\n. Identify critical success factors. \\nA critical success factor is a condition that must exist for the project to have a\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 132}, page_content='high chance for success. Some common critical success factors are a proactive \\nand very supportive business sponsor, full-time involvement of a business \\nrepresentative, realistic budgets and schedules, realistic expectations, and a \\ncore team with the right skill set. \\nPrepare the project charter. \\nThe project charter is similar to a scope agreement, a document of under- \\nstanding, or a statement of work. However, the project charter is much more'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 132}, page_content='detailed than the usual 3- to 4-page general overview of the project that con- \\ntains only a brief description of resources, costs, and schedule. The project \\ncharter is a 20- to 30-page document developed by the core team, which \\nincludes the business representative. Present the project charter and the \\nproject plan to the business sponsor for approval.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 133}, page_content='100 Step 3: Project Planning \\nig Create a high-level project plan. \\nProject plans are usually presented in the form of a Gantt chart that shows \\nactivities, tasks, resources, dependencies, and effort mapped out on a calen- \\ndar (Figure 3.7). Some project managers also create Pert charts, which show \\nthe graphic representation of the CPM on the calendar. \\n. Kick off the project. \\nOnce you have planned the project, assigned the resources, and scheduled the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 133}, page_content='training, you are ready to kick off the project. This is usually accomplished \\nwith an orientation meeting for the entire team (the core team members as \\nwell as the extended team members). Project kickoff should also include set- \\nting up communication channels (e.g., newsletters, e-mails, Web pages) with \\nthe rest of the organization to keep stakeholders and interested parties up-to- \\ndate on the project’s progress. \\nDELIVERABLES RESULTING FROM THESE ACTIVITIES \\n1. Project charter'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 133}, page_content='1. Project charter \\nThis document represents the agreement between the IT staff and the busi- \\nness sponsor about the definition, scope, constraints, and schedule of the BI \\nproject. It also serves as the baseline for all change requests. A project charter \\ncontains the following sections: \\n— Goals and objectives (both strategic goals for the organization and specific \\nobjectives for the BI project) \\n— Statement of the business problem \\n— Proposed BI solution'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 133}, page_content='— Results from the cost-benefit analysis \\n— Results from the infrastructure gap analysis (technical and nontechnical) \\n— Functional project deliverables (reports, queries, Web portal) \\n— Historical requirements (how many years of history to store) \\n— Subject area to be delivered \\n— Entities (objects), significant attributes, relationships (high-level logical data \\nmodel) \\n—Items not within the project scope (originally requested but subsequently \\nexcluded from the scope)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 133}, page_content='— Condition of source files and databases \\n— Availability and security requirements \\n— Access tool requirements'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 134}, page_content='Rol es Involved in These Activities 101 \\n~ \\n— Roles and responsibilities \\n— Team structure for core team and extended team members \\n— Communication plan \\n— Assumptions \\n— Constraints \\n— Risk assessment \\n— Critical success factors \\nProject plan \\nA project plan may contain multiple graphs (such as a CPM chart, a Pert chart, \\nor a Gantt chart) detailing task estimates, task dependencies, and resource \\ndependencies. Most project-planning tools can also produce additional tabu-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 134}, page_content='lar reports on resources and schedule. \\nROLES INVOLVED IN THESE ACTIVITIES \\no Application lead developer \\nThe application lead developer works closely with the data administrator and \\nthe database administrator to understand the data access, data analysis, and \\ngeneral data requirements as well as the tool capabilities. He or she must esti- \\nmate the effort for application prototyping and development, which the \\nproject manager will include in the project plan. \\nBusiness representative'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 134}, page_content='Although the business representative does not actively produce estimates for \\nthe work to be performed by the technicians, he or she must be involved in the \\nentire planning process in order to negotiate the project constraints. The busi- \\nness representative must also understand how much of his or her time will be \\nrequired on the BI project and what is expected of him or her. \\nData administrator \\nThe data administrator needs to participate in the requirements discussions in'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 134}, page_content='order to determine the data scope of the BI project. The data administrator \\nwill provide any data models that exist for the objects and data elements in the \\nrequested subject area. If no data models exist, the data administrator can \\ndraw a straw-man model (that is, a first-cut draft of a logical data model) and \\nuse it to validate the understanding of the requirements and the scope. The \\ndata administrator works with the data quality analyst to assess the condition'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 134}, page_content='of the source files and databases.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 135}, page_content='102 Step 3: Project Planning \\no \\n® \\n® \\nData quality analyst \\nThe main responsibility of the data quality analyst is to assess the condition of \\nthe source files and databases and to estimate the data-cleansing effort based \\non that assessment. To assess the quality of the source data quickly, the data \\nquality analyst can use the functions of a data-cleansing tool, or he or she can \\nwrite customized domain analysis reports. \\nDatabase administrator'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 135}, page_content='The database administrator needs to understand the scope and schedule of the \\nproject from the DBMS perspective so that he or she can be available for data- \\nbase design and application design activities, as well as ongoing project reviews. \\nETL lead developer \\nThe ETL lead developer works with the data administrator and the data qual- \\nity analyst to understand what types of data transformations and data cleans- \\ning the BI application will require. Based on the condition of the source files'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 135}, page_content='and databases, he or she will give ETL estimates to the project manager for the \\nproject plan. \\nMeta data administrator \\nThe meta data administrator is responsible for defining the tasks and esti- \\nmates for the meta data repository track. Working closely with the data \\nadministrator, the meta data administrator has to start exploring what the \\nmeta data requirements for this BI project are and whether they can be met'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 135}, page_content='with the current meta data repository (if one exists). He or she has to deter- \\nmine the meta data repository effort for the project plan. \\nProject manager \\nBI projects are not for rookie project managers. The project manager must \\nhave successfully managed several large projects before. The project manager \\nmust also be familiar with a project management tool to minimize the time \\nrequired for preparing charts and reports. \\nSubject matter expert'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 135}, page_content='The subject matter expert will assist the other team members in preparing the \\nproject plan and the project charter. Either the subject matter expert or the \\nbusiness representative must be an active, full-time participant in this step.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 136}, page_content='Bibliography and Additional Reading 103 \\nRISKS OF NOT PERFORMING STEP 3 \\nIt is impossible to build a BI application ad hoc without a plan. You may as well \\ntake a dart, throw it at a calendar, and commit to the date the dart hits. In other \\nwords, the project will veer out of control if it is not planned well. You may miss \\ndeadlines, have runaway expenses without accountability, implement the wrong \\nsolution—or you may never get to the implementation. A BI decision-support'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 136}, page_content='environment is very complicated, and BI projects are very costly. The risks of \\nundertaking such projects without adequate planning and control are unacceptable. \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nAdelman, Sid, and Larissa Terpeluk Moss. Data Warehouse Project Management. \\nBoston, MA: Addison-Wesley, 2000. \\nAdelman, Sid, et al. Impossible Data Warehouse Situations: Solutions from the \\nExperts. Boston, MA: Addison-Wesley, 2003.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 136}, page_content='Brooks, Frederick P., Sr. The Mythical Man-Month: Essays on Software Engineer- \\ning, Second Edition. Reading, MA: Addison-Wesley, 1995. \\nCharvat, Jason. Project Management Nation: Tools, Techniques, and Goals for the \\nNew and Practicing IT Project Manager. New York: John Wiley & Sons, 2001. \\nDeMarco, Tom. Slack: Getting Past Burnout, Busywork, and the Myth of Total Effi- \\nciency. New York: Broadway Books, 2001. \\nHumphrey, Watts S. Winning with Software: An Executive Strategy. Boston, MA:'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 136}, page_content='Addison-Wesley, 2002. \\nJarke, Matthias, Maurizio Lenzerini, Yannis Vassiliou, and Panos Vassiliadis. Fun- \\ndamentals of Data Warehouses. New York: Springer, 2000. \\nLewis, James P. The Project Manager’s Desk Reference, Second Edition. McGraw- \\nHill Trade, 1999. \\nMarmel, Elaine. Microsoft Project 2000 Bible. New York: John Wiley & Sons, 2000. \\nMoeller, R. A. Distributed Data Warehousing Using Web Technology: How to Build \\na More Cost-Effective and Flexible Warehouse. New York: AMACOM American'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 136}, page_content='Management Association, 2001. \\nYourdon, Edward. Death March. Upper Saddle River, NJ: Prentice Hall, 1997. \\nProject Management Institute: http://www.pm.org .'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 137}, page_content=\"o> \\nas a ter Pal Sir waka my 4 hey ; \\ni \\n§ ie \\nyi wee etry, agile manngees \\nce) “cura, PAL ta UF ait eo img pre yam. \\nrst te cary A bas bom or ie : \\nHea bake Afi) Mia CP eo iF per See iite Ve It enrioy a6 \\nBoy, Ss \\ntig ts \\nod ee ee mn) urn, 2 ae eee \\nPARP aA Age BetATR JAM ie my ie Ata — \\neg r ce pp » Paras GR? 6 ete. sac. \\nDe malis cer. ean Ms mde: \\n48 4s Bie Sede-ncibiah sage \\n' dentiny Aer ore: om emp: Aten A an Rew ot 208 \\n7 fw Gon ee GRR gis ah 1 £40 ae \\nNEALE om wRT Se? shanna: Hie\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 137}, page_content='feat gyrak GZ? a ADEPT erin Fee 2k Hi O47 Hey \\nGRR eee ; z. . \\nof gpg aod Babee pin 4 shscret + a ai hs necae 4 sale Cay cael : \\n% ears sre ae \\noh Bit Liat ia ae Cree: os tutes ‘ . \\n~ wetted pink harman weeps Det poem rato. wit a exnal a \\n0 D> reas 29M 7 = Beet = iat +4 \\nSIS waned 2 (ADM ralokbecinwsh otha ane es Seat a \\nMoana esate tee a aetewed nehyrpauh Weak ec snlee apcnmebarenets Abi ea : ipa oS \\n- ¢ 7 7 pales \\nCee! pe one iit, Aiea \\nee a 2 aoe \\nLOWMAN Soe \\n(an'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 138}, page_content='Justification ae iad CHAPTER FOUR \\nbee Step 4: Project \\nie Requirements Definition \\nCHAPTER OVERVIEW \\nThis chapter covers the following topics: \\nProject \\nRequirements \\nDefinition \\n@ Things to consider when defining requirements \\n@ The differences between general business requirements \\nand project-specific requirements \\n@ The appropriate people to interview to determine general \\nbusiness requirements \\nm@ The sections to complete in a business requirements report Design : a i,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 138}, page_content='The appropriate people to interview when gathering \\nproject-specific requirements for a BI application \\n@ The sections to include in an application requirements \\ndocument \\n@ Interviewing considerations and interviewing tips \\ng@ Brief descriptions of the activities involved in requirements \\ndefinition, the deliverables resulting from those activities, \\nand the roles involved \\n@ The risks of not performing Step 4 \\nDeployment , \\n105'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 139}, page_content='106 Step 4: Project Requirements Definition \\nTHINGS TO CONSIDER | \\nFunctional Requirements \\n/ What types of information do the business people in our organization need? \\nWhat types of business questions are they unable to answer today and why? \\n¥ What reports do they want? \\nY Which reports are most important? Which are least important? Which \\nreports can be replaced with “canned” queries? \\n/¥ What types of queries will the business analysts run?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 139}, page_content='/Y Who will administer the query libraries and set up the universes, for exam- \\nple, data views in online analytical processing (OLAP) tools? \\nVY Are the business analysts and knowledge workers planning to write many ad \\nhoc queries? Can we get some samples of old queries from them? \\nData Requirements \\n¥ What data do the business people need? Where do they get that data today? \\nY How clean is the data today? How clean does it have to be?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 139}, page_content='¥ What data is considered most critical to the business? \\nY Can the data be summarized? If yes, by what dimensions? \\n¥ Will the business analysts want the capability to drill down to the detail? \\nHow granular does the detail have to be? \\n/Y Do other business people need the same data? Do we eee who they are? \\nWill they be available to validate the meta data? \\n¥ What are the expectations for the timeliness of the data and the availability \\nof the data? \\nHistorical Requirements'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 139}, page_content='¥ How many years of history do we need to keep? \\n¥ Can we start collecting history from this point forward or do we have to load \\ndata from old archived files? \\nSecurity Requirements \\nV How secure does the data have to be? What type of security exists on the \\noperational source data? \\nVv Are the security requirements homogeneous (should all the data have the \\nsame level of security)? \\nY Who should have access to the data?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 140}, page_content='107 \\nPerformance Requirements | \\n2 Vv What is the slowest response time the business people will accept for a query \\nY Can reports be run overnight rather than during the day in order to avoid \\nresource contention with interactive usage of the BI target databases? \\nY How often and for how long will knowledge workers and business analysts \\naccess the BI target databases during the day for ad hoc reporting and data \\nanalysis?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 140}, page_content='analysis? \\nRequirements come in two flavors: (1) general high-level business require- \\nments for the BI decision-support environment, which are identified at the onset of \\na BI initiative and are periodically reviewed, and (2) project-specific requirements, \\nwhich concentrate on the detailed deliverables expected from each BI application \\nrelease. Table 4.1 lists the differences between the two types of requirements.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 140}, page_content='Table 4.1: General Business Requirements versus Project-Specific Requirements \\nGeneral Business Requirements \\nPurpose * Determine the general \\nbusiness needs of the \\norganization for a BI decision- \\nsupport environment \\n* Business executives \\n¢ Information technology (IT) \\nmanagers \\n+ IT staff \\n¢ Line-of-business managers \\n* Subject matter experts \\nInterviewees \\nDeliverable ¢ Business requirements report \\nContent of \\ndeliverable \\n¢ Findings \\n° Issues \\n* Opportunities \\n* Recommendations'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 140}, page_content='* Recommendations \\n¢ Next steps \\nProject-Specific Requirements \\n¢ Define the specific functions and \\ndata to be delivered at the end of \\na BI project \\n* Business sponsor \\n* Business representative \\n¢ “Power users” \\n* Stakeholders (knowledge workers, \\nbusiness analysts, data owners) \\n¢ Subject matter experts \\n¢ Application requirements \\ndocument \\n¢ Functional requirements \\n¢ Data requirements \\n* Data-cleansing requirements \\n* Security requirements \\n¢ Performance requirements'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 140}, page_content='* Availability requirements \\n| SSS AS A SY SS IS SPOR EE FETS PE SEB REE CR LIE ESIC IE IEEE EO IEEE TEE BEE EEE AG EE'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 141}, page_content='108 Step 4: Project Requirements Definition \\nGENERAL BUSINESS REQUIREMENTS \\nMarketing strategies often propel the BI decision-support initiatives at organiza- \\ntions because of the constant challenge to keep up with the competition and to \\nretain market share. To a large degree, it is the marketing focus that drives the \\nimpetus for more knowledge about the business, in particular about its customers. \\nMarketing strategies have had an impact on the evolution of decision-support'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 141}, page_content='systems since the early days of IT. Figure 4.1 shows the effect this evolution has \\nhad on increasing the decision-support value of customer-centric applications. \\n* Traditional decision-support systems focused on product-related opera- \\ntional processes of the organization. Decision-support capabilities were lim- \\nited, and marketing efforts revolved around products, not customers. \\nCustomer information files were the first attempt to aggregate all customer-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 141}, page_content='related data from dozens, if not hundreds, of disparate operational systems \\ninto one central file. Decision-support focus started to shift from products to \\ncustomers. \\nHouse-holding databases contained customer hierarchies in order to help \\nbusiness managers understand customer-to-customer relationships. These data- \\nbases also contained organizational hierarchies in order to help business execu- \\ntives understand organizational and regional profitability. House-holding was'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 141}, page_content='the rudimentary precursor of customer relationship management (CRM). \\nBusiness \\nIntelligence \\nRelative \\nDecision- Customer \\nSupport Relationship \\nValue Management \\nData \\nWarehousing \\nHouse-Holding \\nDatabases Customer \\nInformation \\nFiles \\nTraditional \\nDecision-Support \\nSystems \\n1975 21.985 E995 ~ 2000 ~ 2005 \\nFigure 4.1: Increasing Decision-Support Value'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 142}, page_content='General Business Requirements 109 \\nData warehousing was the first ambitious undertaking of cross-organizational \\nintegration of data for decision-support purposes, such as sales reporting, \\nkey performance indicators, performance trend analysis, and so on. Due to \\nthe enormous effort involved, a wave of new tools started to flood the market, \\nwith extract/transform/load (ETL) and OLAP tools leading the pack. \\nCustomer relationship management focuses on customer-product (sales)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 142}, page_content='relationships, as well as on customer service, customer buying behavior, and \\nother knowledge about customers. The goal is to improve customer sales and \\nservices through personalization and mass customization. \\nBusiness intelligence is a more holistic and sophisticated approach to cross- \\norganizational decision-support needs. It uses data mining to gain hidden \\n(nonexplicit) knowledge about customers, general market conditions, and'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 142}, page_content='competitive products. The goal is to “predict” the future by analyzing the \\npresent, thereby gaining a competitive edge. \\nBesides marketing, other departments in the organization are also keen to \\ntake advantage of today’s technologies to solve their business needs. Such depart- \\nments include finance, product management, portfolio management, customer \\nservice, engineering, and inventory management, to name a few. \\nInterviewees for General Business Requirements'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 142}, page_content='Determining the general business needs of the organization requires interviewing \\nindividuals at every level of the organizational hierarchy, both on the business \\nside and on the IT side. \\nBusiness executives are the visionaries. They know which direction the orga- \\nnization should move and how to achieve new goals. They also know what \\nthe organization’s business pains are. The business executives’ requirements \\nwill be focused around strategic information from the BI decision-support'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 142}, page_content='environment. \\nIT managers support the operational systems of the business areas. They \\nknow the deficiencies of these systems very well, and they are aware of the \\nbacklog for decision-support requirements. Their input can be helpful in \\nidentifying unfulfilled decision-support requirements and in determining \\nhow the BI application can improve the workload for IT. \\nIT staff work directly with the business staff. The IT staff have firsthand'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 142}, page_content='knowledge of the unfulfilled requirements. They also know the technical'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 143}, page_content='110 Step 4: Project Requirements Definition \\nRS a SPS ES ARERR IPO SE SAPD SIRE FRPP RL REET SE FL ES EE OES SE TLE LIS LID \\nskills of the business people with whom they work. This information will \\nbecome valuable input for access and analysis tool selection. \\n- Line-of-business managers are responsible for the smooth operations of the \\norganization. They focus on tactical decisions on a daily basis. Their require- \\nments frequently include a mixture of strategic information and operational'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 143}, page_content='information. \\nSubject matter experts are the senior business analysts with the 10,000-foot \\nview of a department or a division. Sometimes they are the “power users”; \\nother times they act as internal business consultants. In addition to having an \\noverall business view, subject matter experts are usually very familiar with \\ndetailed operational data and can give a lot of insights into current data qual- \\nity problems. \\nData Quality Requirements'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 143}, page_content='Data quality must be discussed with all interviewees. Questions to ask fall into \\nthree categories: existing data quality, desired data quality, and prioritization for \\ndata cleansing. \\n1. Existing data quality: Different interviewees might have a different perspec- \\ntive of what is clean and what is not. They will also have a different perspec- \\ntive of what should be cleansed and what can remain “dirty.” \\n2. Desired data quality: Knowledge workers “in the trenches” typically have a'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 143}, page_content='higher tolerance for dirty data than business executives do, mainly because \\nthe knowledge workers have learned over the years how to decipher and \\ninterpret their bad data. \\n3. Prioritization for data cleansing: Critical and important data must be sorted \\nout from insignificant data. Business executives and line-of-business manag- \\ners should make that decision. \\nData quality affects business people in all critical business areas of an organi-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 143}, page_content='zation, especially strategic decision-makers, business operations staff, customer \\nsupport staff, and marketing staff. \\n* Strategic decision-makers: Probably more than anyone else, strategic decision- \\nmakers (the business executives of the organizations) are affected by poor- \\nquality data. The decisions they make have an effect on the organizational \\nlifeline.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 144}, page_content='General Business Requirements 111 \\n* Business operations staff: Line-of-business managers and their staff could \\nbe much more efficient if they did not have to constantly resolve errors and \\nwaste time on rework. \\n* Customer support staff: The customer representatives and the sales force \\nhave direct contact with the organizations’ customers. Poor-quality data puts \\na tremendous burden on this group to keep the customers satisfied and to \\nprevent them from leaving.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 144}, page_content='* Marketing staff: Managers and knowledge workers in the marketing department \\ndo not want to waste millions of dollars by soliciting customers who are not \\nworth soliciting, by sending marketing materials to customers who have moved, \\nor by pursuing dissatisfied customers who have defected to the competition. \\nBusiness Requirements Report \\nThe deliverable from a high-level business requirements activity is a report on the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 144}, page_content='findings, issues, opportunities, recommendations, and next steps, as shown in \\nFigure 4.2. \\nFindings, Issues, Opportunities Recommendations Next Steps \\nFigure 4.2: Business Requirements Report Content \\n* Findings: The compilation of all requirements from the interviewees should \\nbe sorted by topic. Each finding should be associated with the interviewees \\nand the interview dates. \\n* Issues: A separate list should highlight critical business issues, so that these'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 144}, page_content='issues can be addressed immediately. Not all business issues require a BI solution. \\n* Opportunities: Obvious business opportunities should also be extracted and \\nhighlighted from the findings. Again, not all business opportunities will \\ntranslate into BI requirements. \\n+ Recommendations: After analyzing the findings, issues, and opportunities, a \\nlist of recommendations should be added. These can be recommendations for'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 144}, page_content='correcting a problem on the existing systems or for building a new BI solution.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 145}, page_content='112 Step 4: Project Requirements Definition \\n* Next steps: Certain recommended actions are more critical than others, and \\nsome recommended actions may depend on the completion of others. This \\nsection of the report should list the prioritized sequence of actions to be \\ntaken toward implementing a BI solution. \\nThis report is not listed as a deliverable for a BI project because it occurs out- \\nside of an already approved BI project. It may be used in lieu of a business case'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 145}, page_content='assessment report, if the business case assessment is high-level and not specific to \\na BI application. \\nPROJECT-SPECIFIC REQUIREMENTS \\nRequirements gathering for a specific project deliverable focuses on defining the \\nexplicit business needs of the business sponsor for whom the BI application is \\nbeing developed. The project requirements should be stated in business terms \\nand should describe the business problem to be solved as well as the acceptance'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 145}, page_content='criteria for the BI solution. Figure 4.3 shows an example of a requirements \\nstatement. \\nPane A precompiled wish list of data elements and a stack of mock reports do not \\nconstitute a requirements definition. : \\n“It currently takes us 3 weeks to compile sales data from all regions \\nand another 3 weeks to analyze it and make an investment correction. \\nEvery week of delay is costing us an estimated $50,000. Our \\nexpectation is to reduce the delay to 1 week. If we could have the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 145}, page_content='data integrated and available within 3 days after close of business, \\nand if we could have the following query capabilities ..., we could \\ncomplete our analysis in 2 days. In order to do that we require the \\nfollowing data... .” \\nFigure 4.3: Requirements Definition Statement'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 146}, page_content='Project-Specific Requirements 113 \\nThe application requirements document must clearly state the BI project \\nobjectives and expected deliverables in terms of: \\nNature of the existing business problem \\nDamage (lost business opportunity, exceeded operating costs) caused to the \\norganization by the existing business problem \\nWhy the problems cannot be solved without a BI solution \\nHow the BI application will solve the problem'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 146}, page_content='Detailed requirements for reports and canned queries on the desired subject \\nareas \\nRequirements for graphical representation tools, such as OLAP \\nPrioritized, detailed data requirements for: \\n— All data required for the BI target database(s) as well as for reports and queries \\n— All potential data source files and source databases \\nPaw Source data requirements should be defined in as much detail as possible and \\nas early as possible to enable rigorous source data analysis in the next step.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 146}, page_content='Waiting until the design stage to determine how to source the BI target data- \\nbases is too late. \\nPrioritized, detailed functional requirements for the data-cleansing transfor- \\nmations \\nRequirements for historical data (how many years of history) \\nRequired security features \\nRequested service-level agreements (SLAs) for query response time, data \\ncleanliness, hours and days of the BI application’s availability, and tool func- \\ntionality'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 146}, page_content='tionality \\nDefining requirements is a different activity than designing a solution. Exer- \\ncise caution—do not jump into designing the BI application at this time, as \\nmany technicians tend to do. \\nInterviewees for Project-Specific Requirements \\nThe interviews for project-specific requirements are limited to those individuals \\nwho are directly involved with the BI project and those who are directly impacted \\nby the BI application.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 147}, page_content='114 Step 4: Project Requirements Definition \\n- The business representative should provide the details about the work he or \\nshe is performing. It is important to understand the business workflow and \\nwhere the bottlenecks are since they point to potential challenges with the \\ndata or the functionality. Overlooking these challenges could possibly lead to \\nunderestimating the project effort. \\nThe business sponsor sets the objectives for the BI application and states the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 147}, page_content='business need as well as the expectations for the return on investment. He or \\nshe should prioritize the requested deliverables if the scope is too large given \\nthe project constraints of effort (time), budget, resources, and quality. \\n“Power users” often perform the analysis functions, which the BI application \\nis supposed to replace. They have a wealth of information about the detailed \\nrequirements for solving the stated business problem.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 147}, page_content='Stakeholders could be other knowledge workers, business analysts, or busi- \\nness managers who are performing similar functions and who will use the \\ndata in the BI target databases for their own decision-support needs. The BI \\nproject team should identify these stakeholders early to determine potential \\noverlapping needs. Stakeholders could also be the data owners. The data own- \\ners should always be included in the interviewing process because it is their'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 147}, page_content='responsibility to verify that their data is being used and interpreted correctly. \\nSubject matter experts could be the same people as the “power users” or \\ncould be senior business analysts. They, along with the business representa- \\ntive, are the prime interviewees for project-specific requirements. \\nApplication Requirements Document \\nThe deliverable from a project-specific requirements definition activity is a \\nrequirements document itemizing the detailed functional requirements, the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 147}, page_content='detailed data requirements, and the potential sources of data. This document \\nshould also detail the requirements for data cleansing, performance, data secu- \\nrity, and availability, as shown in Figure 4.4. \\nRO \\nFunctions Data Cleansing Performance Security Availability \\nFigure 4.4: Application Requirements Document Content'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 148}, page_content='Project-Specific Requirements 115 \\nFunctions: All functional requirements for reporting and for data access and \\nanalysis should be listed and prioritized. This includes contents and algo- \\nrithms for reports and queries, ad hoc capabilities, Web displays, and other \\ngraphical representations. Summarization and aggregation requests as well as \\ndrill-down capabilities must be described as well. \\nData: The desired subject areas (e.g., product, customer, orders, campaign)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 148}, page_content=\"should be confirmed, and the required data elements should be defined. Be \\njudicious about the data scope because going after too much data “just in case \\nthey'll need it some day” leads to more complex data models and more time \\nand money spent for data extraction, cleansing, and maintenance. \\nPaw IT technicians can help identify which source data may not have to be \\nincluded in the BI target databases based on current low usage of data.\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 148}, page_content='However, the final decision on whether or not to include rarely used \\nsource data must be made by a business person, not by IT. \\nIn addition, all previously identified potential source files and source databases \\nshould be reviewed. If storing history is a requirement, the archived source \\nfiles must also be identified and reviewed. Additional data-specific require- \\nments should be defined, such as data load frequency (e.g., daily, weekly, \\nmonthly) and data security.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 148}, page_content='Data cleansing: The list of requested data elements must be prioritized into \\ncritical, important, and insignificant categories. The tolerance level for dirty \\ndata must be defined for each data element in the critical category, for exam- \\nple, “Monthly Sales Total: dirty data threshold = 2 percent; Daily Average \\nPortfolio Amount: dirty data threshold = 0.05 percent.” Next, the dirty data \\ntolerance level must be defined for each data element in the important cate-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 148}, page_content='gory. Insignificant data elements are often passed across without cleansing, \\nmainly due to time constraints. \\nPerformance: Most knowledge workers of operational systems are accus- \\ntomed to subsecond response times. Expectations must be set and managed \\nin this respect. Techniques and technologies can improve report and query \\nresponse times, but rarely—if ever—will the response times be as low as sub- \\nseconds. The question to ask is not what the desired response time is but what'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 148}, page_content='an acceptable response time is, followed by the question of how much busi- \\nness management is willing to pay in order to get a better response time. \\nSecurity: Since the data in the BI target databases is the same data as in the \\noperational systems, it should be given similar security considerations. Some'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 149}, page_content='116 Step 4: Project Requirements Definition \\nexceptions may apply if the data is highly summarized and no drill down to \\nthe detail is allowed or even available. \\nAvailability: Requests for 24/7 availability are rarely valid since a BI decision- \\nsupport environment primarily supports strategic decision making. The require- \\nment for 24/7 availability is typically an operational requirement. However, it \\ncould be valid under some circumstances, such as for international compa-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 149}, page_content='nies that have offices around the globe and that will access a centralized data- \\nbase. In addition to determining hours and days of availability, the \\npercentage of availability during scheduled hours should also be specified, for \\nexample, “97 percent availability Monday through Saturday between 5 A.M. and \\n11 P.M. EST and 90 percent availability Sunday between 5 A.M. and 3 P.M. EST.” \\nTHE INTERVIEWING PROCESS \\nThe more detailed the requirements document, the more the scope can be solidi-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 149}, page_content='fied and the more the estimates for the effort can be validated. To accumulate the \\nnecessary details in order to understand the business process, the interview team \\nmust spend some time interviewing all the stakeholders of the application and \\nstudying their environment. When documenting the project requirements, use \\ngraphic techniques whenever possible, such as bubble charts, cause-and-effect \\ndiagrams, entity-relationship diagrams, star schema models, and even functional'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 149}, page_content='decomposition diagrams and data flow diagrams where appropriate. Diagrams \\nmake excellent communication tools. Through visualization, the interviewee can \\nbetter verify the interviewer’s understanding of the requirements. \\nInterviewing Considerations \\nBefore scheduling the interviews, some preparation is required. Figure 4.5 lists \\nitems that need to be considered for the interviewing process. \\nInterview Team Interviewees Research Questionnaire Schedule'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 149}, page_content='Figure 4.5: Items to Consider for the Interviewing Process'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 150}, page_content='The Interviewing Process 117 \\nInterview team: Preferably, the interviewer should not conduct the interview \\nand take notes at the same time. He or she should team up with a “scribe” \\nwho can take notes during the interviews. It is difficult to keep the momen- \\ntum of the meeting going if you have to ask the questions, write down the \\nanswers, and think of the next question to ask all at the same time. \\nInterviewees: Interviews can be conducted with individuals or groups of'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 150}, page_content='individuals. Group interviews work well among peers from the same work \\narea if they share similar responsibilities. What one person says often triggers \\na thought in another person. This synergy can be very productive. The draw- \\nback of group interviewing is that some interviewees may not be as honest or \\nforthcoming in their responses. The most effective approach to interviewing \\nis often a balance between individual interviews and group interviews.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 150}, page_content='Research: Before scheduling the interviews, the interviewer should spend some \\ntime researching existing documents, reports, and Web sites, including competi- \\ntors’ Web sites. It helps to have as much understanding as possible of the indus- \\ntry, the business processes, and the organization’s terminology and acronyms. \\nQuestionnaire: A questionnaire for the major topics should be prepared and \\nmailed to the interviewees before the scheduled interviews. That gives the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 150}, page_content='interviewees a chance to prepare and to bring supporting documentation to \\nthe interview. \\nInterview schedule: Do not schedule more than four one-hour interviews \\nper day because it will take at least one hour after each interview to review, fill \\nin, or clarify the interview notes. It is imperative to complete or rewrite the \\nnotes taken during an interview on the same day of that interview, so that no \\nambiguity or incompleteness remains. \\nInterviewing Tips'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 150}, page_content='Interviewing Tips \\nThe following interviewing practices can make the process run smoothly and \\neffectively: \\nThe initial interview should focus on the basic requirements necessary to \\nsolve a specific business problem. Do not dwell on any of the mechanical and \\nlogistical aspects, and do not promise anything hastily. There will be time to \\nget into detailed analysis later. \\nFrequently, interviewees will be quite comfortable telling you what they cur-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 150}, page_content='rently have, but they can provide only minimal insight into what they want \\nbut do not have. Be prepared to guide them with leading questions.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 151}, page_content='118 Step 4: Project Requirements Definition \\n- Be prepared to hear and resolve conflicting views and priorities. This is espe- \\ncially true when speaking with knowledge workers, business analysts, and \\nbusiness managers from different departments and from different levels of \\nthe organizational hierarchy. \\n* Taking notes usually involves a fair amount of scribbling (or, if using a laptop, \\na fair amount of abbreviating). While the discussions are still fresh in the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 151}, page_content='minds of the interviewer and the scribe, they should review the notes imme- \\ndiately after each interview and expand on the scribbles and abbreviations. By \\nthe end of the day, the notes must be in such condition that they can be \\nunderstood several days or weeks later. \\nTape recording interviews can be very helpful when the interview team con- \\nsists of only one person. Making a tape allows the interviewer to concentrate'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 151}, page_content='on the questioning rather than on note taking. It is imperative to ask the \\ninterviewees for their permission to record the interview session. Many inter- \\nviewees do not like to be recorded, and other interviewees may not be as \\nforthcoming and honest when they know they are being recorded. \\nAs soon as time permits after each interview, transcribe the interview notes \\ninto a clean interview notes document and send it to all interviewees who'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 151}, page_content='participated in that interview for their approval. Ask the interviewees to \\nchange any misinterpretations and add anything they forgot to mention dur- \\ning the interview. \\nPROJECT REQUIREMENTS DEFINITION ACTIVITIES \\nThe activities for defining project requirements do not need to be performed lin- \\nearly. Figure 4.6 indicates which activities can be performed concurrently. The list \\nbelow briefly describes the activities associated with Step 4, Project Requirements \\nDefinition.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 151}, page_content='Definition. \\n1. Define the requirements for technical infrastructure enhancements. \\nYou should have already reviewed the technical infrastructure components to \\ndetermine whether they can support the BI application or whether changes \\nare required. Requirements for technical infrastructure components could \\ninclude one or more of the following: \\n— New or additional hardware \\n— New database management system (DBMS) or upgrades to the existing DBMS \\n— New development tools'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 152}, page_content='Project Requirements Definition Activities 119 \\nDefine requirements for \\ntechnical infrastructure \\nenhancements \\nExpand \\nlogical data model \\nDefine requirements for \\nnontechnical infrastructure \\nenhancements \\nWrite application \\nrequirements document \\nReview \\nproject scope \\nS77 as \\n” \\nDefine preliminary \\nservice-level agreements \\n3 \\nDefine reporting \\nrequirements \\nDefine requirements \\nfor source data \\nFigure 4.6: Project Requirements Definition Activities \\n— New data access or reporting tools'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 152}, page_content='— New data mining tool \\n— New meta data repository or enhancements to it \\n— New network requirements \\n2. Define the requirements for nontechnical infrastructure enhancements. \\nYou should have also reviewed and evaluated the nontechnical infrastructure \\ncomponents. If changes are required, define these requirements now. Non- \\ntechnical infrastructure components to be added or revised could include: \\n— Estimating guidelines \\n— Roles and responsibilities \\n— Standards \\n— Procedures for:'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 152}, page_content='— Procedures for: \\n» Use of a methodology \\n» Scope management (change control) \\n» Issues management \\n» Security process \\n» SLAs'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 153}, page_content='120 Step 4: Project Requirements Definition \\na RS ES nS \\n» Prioritization \\n» Testing process \\n» Support functions \\n» Dispute resolution \\n» Meta data capture and meta data delivery \\n» Data quality measures and triage process \\n» Communication \\n3. Define the reporting requirements. \\nDuring the interview process, collect or create sample report layouts and que- \\nries. Define and document business rules for deriving data and for creating'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 153}, page_content='aggregations and summaries. It is advisable to determine who will be the \\nstewards of the query libraries and universes (data views in OLAP tools). \\n4. Define the requirements for source data. \\nDefine the detailed data requirements and select the most appropriate source \\nfiles and source databases from the potential list of sources created during \\nprior steps. Spend some time on defining the data-cleansing requirements'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 153}, page_content='and the critical business rules for the data. Perform some cursory data analy- \\nsis on suspected poor-quality data so that the scope and the effort estimates \\ncreated during Step 3, Project Planning, can be validated. \\n5. Review the project scope. \\nCompare the detailed requirements to the high-level scope in the project \\ncharter. Determine whether the scope is still doable and whether the esti- \\nmates are still realistic. If you have learned something that puts the commit-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 153}, page_content='ment in the project charter in question, it is time to renegotiate. \\n6. Expand the logical data model. \\nA high-level logical data model was probably produced during earlier steps \\n(Step 1, Business Case Assessment, or Step 3, Project Planning). Using the \\ninformation from the interview sessions, expand the logical data model with \\nnewly discovered entities, relationships, and attributes. If a logical data model \\nwas not produced during prior steps, create a high-level logical data model'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 153}, page_content='for the data requirements in preparation for the data analysis activities. \\n7. Define preliminary service-level agreements. \\nAlthough many technicians may argue that it is much too early to commit to \\nSLAs, most business people will ask for them because they constitute the \\nacceptance criteria. It is best to find the outermost acceptable limits for each \\nof the following SLAs and refine them as the project progresses:'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 154}, page_content='Roles Involved in These Activities 121 \\n— Availability \\n— Security \\n— Response time \\n— Data cleanliness \\n— Ongoing support \\n. Write the application requirements document. \\nIn the application requirements document, itemize the requirements for \\nfunctions, data, cleansing, performance, security, and availability. In addi- \\ntion, list the requirements for enhancing technical and nontechnical infra- \\nstructure components during the BI project. Include the high-level logical'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 154}, page_content='data model in this document. \\nDELIVERABLE RESULTING FROM THESE ACTIVITIES \\n1. Application requirements document \\nThis document should contain the following sections: \\n— Technical infrastructure requirements \\n— Nontechnical infrastructure requirements \\n— Reporting requirements \\n— Ad hoc and canned query requirements \\n— Requirements for source data, including history \\n— High-level logical data model \\n— Data-cleansing requirements \\n— Security requirements \\n— Preliminary SLAs'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 154}, page_content='— Preliminary SLAs \\nInclude a list of conducted interviews in date order, a list of the interviewees, \\nand a summary of the interview notes. \\nROLES INVOLVED IN THESE ACTIVITIES \\n® Application lead developer \\nThe application lead developer should add application-specific data access \\nand data analysis questions to the interview questionnaire and should lead \\nthat portion of the interviews. He or she should not conduct separate inter-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 154}, page_content='views but should participate with the data quality analyst and data adminis- \\ntrator in the same interviews. Business people get very annoyed when different \\nIT people ask them the same questions in different interviews.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 155}, page_content='122 Step 4: Project Requirements Definition \\n® Business representative \\nIn addition to sharing the same responsibilities as the subject matter expert, \\nthe business representative should be prepared to demonstrate his or her daily \\nwork routine to the data quality analyst, data administrator, and application \\nlead developer either before or after the interview sessions. \\n@ Data administrator \\nThe data administrator can be of great help to the data quality analyst by par-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 155}, page_content='ticipating with follow-up questions and scribing the answers. In addition, the \\ndata administrator will get a jump start on his or her logical data modeling \\nactivities by hearing the interview discussions firsthand. Such participation in \\nthe interviews also eliminates the need for the data administrator to revisit \\nsome topics with the interviewees where he or she might have had questions. \\n@ Data quality analyst \\nThe data quality analyst, the data administrator, and the application lead'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 155}, page_content='developer should develop an approach for conducting the interviews. They \\nneed to decide when and how they will take turns being the interviewer, the \\nscribe, and the observer. Most likely, the data quality analyst will be the princi- \\npal interviewer. \\n@ Meta data administrator \\nThe meta data administrator may join the interview team either as a partici- \\npant or as an observer, depending on the scope of the proposed meta data'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 155}, page_content='repository solution. The meta data administrator should add his or her own \\nset of meta data requirements questions to the questionnaire and should lead \\nthat portion of the interviews. \\n@ Subject matter expert \\nThe subject matter expert together with the business representative must be \\nprepared to address the topics on the questionnaire. He or she should also \\nbring to the interview sessions any reports, forms, screen layouts, code manu-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 155}, page_content='als, and other documents that support or explain the project requirements. \\nRISKS OF NOT PERFORMING STEP 4 \\nSome organizations combine requirements definition activities with data analysis \\nor with application prototyping activities. While that can be an effective \\napproach, the danger lies in losing sight of the big picture, that is, the objectives \\nand scope of the project. When data modelers dig into the data details too soon,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 156}, page_content='Bibliography and Additional Reading 123 \\nanalysis paralysis often results. When the application developers start prototyp- \\ning too soon, scope creep often occurs. Other potential risks are that functional- \\nity or data are missed, security issues are ignored, requirements are not \\nprioritized, and business objectives are not targeted. For all these reasons it is \\nadvisable to separate requirements gathering from data analysis and prototyping. \\nBIBLIOGRAPHY AND ADDITIONAL READING'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 156}, page_content='Adelman, Sid, and Larissa Terpeluk Moss. Data Warehouse Project Management. \\nBoston, MA: Addison-Wesley, 2000. \\nCockburn, Alistair. Writing Effective Use Cases. Boston, MA: Addison-Wesley, \\n2000. \\nDyché, Jill. e-Data: Turning Data into Information with Data Warehousing. Bos- \\nton, MA: Addison-Wesley, 2000. \\nEnglish, Larry P. Improving Data Warehouse and Business Information Quality: \\nMethods for Reducing Costs and Increasing Profits. New York: John Wiley & Sons, \\n1999.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 156}, page_content='1999. \\nHoberman, Steve. Data Modeler’s Workbench: Tools and Techniques for Analysis \\nand Design. New York: John Wiley & Sons, 2001. \\nImhoff, Claudia, Lisa Loftis, and Jonathan G. Geiger. Building the Customer-Centric \\nEnterprise: Data Warehousing Techniques for Supporting Customer Relationship \\nManagement. New York: John Wiley & Sons, 2001. \\nInmon, William H., Claudia Imhoff, and Ryan Sousa. Corporate Information Fac- \\ntory. New York: John Wiley & Sons, 1997.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 156}, page_content='Jackson, Michael. Software Requirements and Specifications: A Lexicon of Practice, \\nPrinciples, and Prejudices. Reading, MA: Addison-Wesley, 1995. \\nJarke, Matthias, Maurizio Lenzerini, Yannis Vassiliou, and Panos Vassiliadis. Fun- \\ndamentals of Data Warehouses. New York: Springer, 2000. \\nKimball, Ralph, Laura Reeves, Margy Ross, and Warren Thornthwaite. The Data \\nWarehouse Lifecycle Toolkit: Expert Methods for Designing, Developing, and'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 156}, page_content='Deploying Data Warehouses. New York: John Wiley & Sons, 1998. \\nKovitz, Benjamin L. Practical Software Requirements: A Manual of Content and \\nStyle. Greenwich, CT: Manning Publications Company, 1998.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 157}, page_content='124 Step 4: Project Requirements Definition \\nMoeller, R. A. Distributed Data Warehousing Using Web Technology: How to Build \\na More Cost-Effective and Flexible Warehouse. New York: AMACOM American \\nManagement Association, 2001. \\nRoss, Ronald G. The Business Rule Concepts. Houston, TX: Business Rule Solu- \\ntions; Ine 1998. \\nVon Halle, Barbara. Business Rules Applied: Building Better Systems Using the Busi- \\nness Rules Approach. New York: John Wiley & Sons, 2001.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 157}, page_content='Wiegers, Karl E. Software Requirements. Redmond, WA: Microsoft Press, 1999. \\nWood, Jane, and Denise Silver. Joint Application Development. New York: John \\nWiley & Sons, 1995. \\nYourdon, Edward. Death March. Upper Saddle River, NJ: Prentice Hall, 1997.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 158}, page_content='ion aes CHAPTER FIVE \\nStep 5: Data Analysis Bs Eom wry : ye \\nPlanning \\nCHAPTER OVERVIEW \\nBusiness Analysis This chapter covers the following topics: \\nm@ Things to consider when analyzing source data for BI appli- \\ncations \\n> i The difference between the systems analysis phase of a \\ng Meta D traditional methodology and the business-focused data \\nanalysis performed during this step \\n@ Top-down logical data modeling, including project-specific'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 158}, page_content='logical data models, integrated enterprise logical data \\nmodels, and data-specific business meta data components \\ngathered during the logical data modeling process \\nm@ Bottom-up source data analysis, including how to apply \\nthree sets of transformation rules to the source data: tech- \\nnical data conversion rules, business data domain rules, \\nand business data integrity rules \\n@ The responsibilities for data archeology, data cleansing,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 158}, page_content='and data quality enforcement, plus the need to triage (pri- \\noritize) data-cleansing activities \\n@ Brief descriptions of the activities involved in data analysis, \\nthe deliverables resulting from those activities, and the \\nroles involved \\n@ The risks of not performing Step 5 \\n125'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 159}, page_content='126 Step 5: Data Analysis \\nTHINGS TO CONSIDER \\nSource Data \\nY Do we know where the source data resides? In what systems? In what files? In \\nwhat databases? \\nV Are there multiple potential sources for the same data? \\nVv Has the requested source data already been modeled? \\nY How current is the business meta data on those models? \\nV Have the data owners ratified the business meta data? \\nY Do we know who the data owners are? Who has authority over the source \\ndata?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 159}, page_content='data? \\nVv Is there any other type of documentation available for the requested source \\ndata? Is it current and complete? \\nVv Where is that documentation? In a meta data repository? In programs? In \\nmanuals? \\nData Quality \\n¥Y Do we know how clean the source data is? \\nV How clean does the data have to be according to our business representative? \\n¥ Will that be clean enough for other knowledge workers, business analysts, \\nand business managers who will use the same data?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 159}, page_content='Y Do we know who they are? \\nVv Where do we get the business rules for the data? From the data owners? \\nFrom the business representative on the project? \\nData Cleansing \\nV Have data errors already been documented by other project teams? If so, \\nwhere is that documentation? \\n¥ Who would know what the known data errors are? \\nVv Are codes being translated inside operational programs? If so, in which \\nprograms? \\nV Does a code translation book exist for encoded fields?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 159}, page_content='¥ Do we already know which data is critical, which is important, and which is \\ninsignificant (for data-cleansing triage purposes)?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 160}, page_content='Business-Focused Data Analysis 127 \\nOperational systems are developed as stovepipe automation solutions for \\nindividual business units and not as support for the executive decision-making \\nprocess. Therefore, operational systems are not designed to integrate or reconcile \\nwith each other in order to provide a consistent cross-organizational view. BI \\napplications, on the other hand, are designed to do just that—provide integrated \\nand reconciled business data to the business community.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 160}, page_content='BUSINESS-FOCUSED DATA ANALYSIS \\nFor many organizations, the BI decision-support initiative is the first attempt to \\nbring business data together from multiple sources in order to make it available \\nacross different departments. Organizations that use a traditional systems devel- \\nopment methodology on their BI projects usually run into severe source data \\nproblems when they try to implement their extract/transform/load (ETL) pro-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 160}, page_content='cesses because traditional development methodologies do not have steps for ana- \\nlyzing data domains early in the development process. They have, at best, a \\nsystems analysis phase for the application functions but no business-focused data \\nanalysis phase for the underlying data. \\nThe business-focused data analysis step is the most critical cross-organiza- \\ntional step described in Business Intelligence Roadmap. \\nStep 5, Data Analysis, is different from a systems analysis phase in a tradi-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 160}, page_content='tional methodology. The activities traditionally performed during systems analy- \\nsis are geared toward producing a design decision for the system to be built. The \\nactivities performed during data analysis are geared toward understanding and \\ncorrecting the existing discrepancies in the business data, irrespective of any sys- \\ntem design or implementation method. Data analysis is therefore a business- \\nfocused activity, not a system-focused activity.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 160}, page_content='Figure 5.1 points out that two complementary methods are required to per- \\nform rigorous data analysis: \\n1. Top-down logical data modeling for integration and consistency \\n2. Bottom-up source data analysis for standardization and quality'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 161}, page_content='128 Step 5: Data Analysis \\n| RR oS SE RE EA IE RNS EEE EEE \\nTop-Down \\nLogical Data \\nModeling \\nBottom-Up \\nSource Data \\nAnalysis \\nFigure 5.1: Complementary Data Analysis Techniques \\nTOP-DOWN LOGICAL DATA MODELING \\nThe most effective technique for discovering and documenting the single cross- \\norganizationally integrated and reconciled view of business data is entity- \\nrelationship (E-R) modeling, also known as logical data modeling. A popular'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 161}, page_content='approach to E-R modeling in the early 1980s was to model all the data for the \\nentire organization all at once. While this approach was a worthwhile architec- \\ntural endeavor, it did not yield better systems because the process was not inte- \\ngrated with the systems development lifecycle. A more effective approach is to \\nincorporate E-R modeling into every project and then merge the project-specific \\nlogical data models into one consolidated enterprise data model over time.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 161}, page_content='Project-Specific Logical Data Model \\nE-R modeling is based on normalization rules, which are applied during top- \\ndown data modeling as well as during bottom-up source data analysis. Using \\nnormalization rules along with other data administration principles assures that \\neach data element within the scope of the BI project is uniquely identified, cor- \\nrectly named, and properly defined and that its domain is validated for all busi-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 161}, page_content='ness people who will be accessing the data. Thus, the normalized project-specific \\nlogical data model yields a formal representation of the data exactly as it exists in \\nthe real world, without redundancy and without ambiguity. \\nThis formal representation of data follows another normalization rule: pro- \\ncess independence. Therefore, by definition, a logical data model, which is based \\non normalization rules, is also process independent. Process independence'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 161}, page_content='means that the structure and content of the logical data model are not influenced'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 162}, page_content='Top-Down Logical Data Modeling 129 \\nAccess Path \\nIndependent \\nDesign \\nIndependent \\nDatabase \\nIndependent \\nE-R Model: \\nBusiness View \\nProgram \\nIndependent \\nHardware \\nIndependent \\nTool \\nIndependent \\nFigure 5.2: Process Independence of Logical Data Models \\nby any type of database, access path, design, program, tool, or hardware, as \\nshown by the X markings in Figure 5.2. \\nBecause of its process independence, a logical data model is a business view,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 162}, page_content='not a database view and not an application view. Therefore, a unique piece of \\ndata, which exists only once in the real business world, also exists only once in a \\nlogical data model even though it may be physically stored in multiple source files \\nor multiple BI target databases. \\nEnterprise Logical Data Model \\nIt is the responsibility of an enterprise architecture group, or of data administra- \\ntion if the organization does not have an enterprise architecture group, to merge'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 162}, page_content='the project-specific logical data models into an integrated and standardized \\nenterprise logical data model, as illustrated in Figure 5.3.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 163}, page_content='130 Step 5: Data Analysis \\nProject A Project B Project C \\n“= Enterprise Logical Data Model \\nFigure 5.3: Creating an Enterprise Logical Data Model \\nThis enterprise logical data model, also known as the enterprise information \\narchitecture, is not constructed all at once, nor is it a prerequisite for BI projects to \\nhave a completed one. Instead, the enterprise logical data model evolves over time \\nand may never be completed. It does not need to be completed because the objec-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 163}, page_content='tive of this process is not to produce a finished model but to discover and resolve \\ndata discrepancies among different views and implementations of the same data. \\nThese data discrepancies exist en masse among stovepipe operational systems \\nand are the root causes of an organization’s inability to provide integrated and \\nconsistent cross-organizational information to its business people. The discovery \\nof these discrepancies should be embraced and celebrated by the BI project team,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 163}, page_content='and especially by the business people, because poor-quality data is finally being \\naddressed and resolved. Gaining control over the existing data chaos is, after all, \\none major function of any BI decision-support initiative. \\nPaw If organizations would follow business analysis best practices by developing \\nlogical data models for all their operational applications and merging them \\n(over time) into an enterprise logical data model, the BI decision-support'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 163}, page_content='development effort could be significantly reduced. This would enable Bl \\nproject teams to increase the speed of delivering reliable decision-support \\ninformation to the business people. In other words, the BI project teams could \\ndeliver the “quick hits” that everyone wants—and deliver them with quality.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 164}, page_content='Top-Down Logical Data Modeling 131 \\nLogical Data Modeling Participants \\nLogical data modeling sessions are typically facilitated and led by a data adminis- \\ntrator who has a solid business background. If the data administrator does not \\nhave a good understanding of the business, a subject matter expert must assist \\nhim or her in this task. \\nThe business representative and the subject matter expert assigned to the BI'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 164}, page_content='project are active participants during the modeling sessions. If the data is being \\nextracted from several different operational systems, multiple data owners may \\nhave to participate on the BI project because each operational system may be \\nunder the governance of a different owner. Data owners are those business indi- \\nviduals who have authority to establish business rules and set business policies \\nfor those pieces of data originated by their departments. When data discrepancies'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 164}, page_content='are discovered, it is the data owners’ responsibility to sort out the various busi- \\nness views and to approve the legitimate usage of their data. This data reconcilia- \\ntion process is and should be a business function, not an information technology \\n(IT) function, although the data administrators, who usually work for IT, facili- \\ntate the discovery process. \\nSystems analysts, developers, and database administrators should also be'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 164}, page_content='available to participate in some of the modeling sessions on an as-needed basis. \\nThese IT technicians maintain the organization’s applications and data structures, \\nand they often know more than anyone else about the data—how and where it is \\nstored, how it is processed, and ultimately how it is used by the business people. \\nIn addition, these technicians often have in-depth knowledge of the accuracy of \\nthe data, how it relates to other data, the history of its use, and how the content'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 164}, page_content='and meaning of the data have changed over time. It is important to obtain a com- \\nmitment to the BI project from these IT resources since they are often busy \\n“fighting fires” and working on enhancements to the operational systems. \\nStandardized Business Meta Data \\nA logical data model, representing a single cross-organizational business view of \\nthe data, is composed of an E-R diagram and supporting business meta data.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 164}, page_content='Business meta data includes information about business data objects, their data \\nelements, and the relationships among them. Business meta data as well as tech- \\nnical meta data, which is added during the design and construction stages, ensure \\ndata consistency and enhance the understanding and interpretation of the data in \\nthe BI decision-support environment. A common subset of business meta data \\ncomponents as they apply to data (as opposed to processes) appears in Figure 5.4,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 165}, page_content='132 Step 5: Data Analysis \\nData \\nOwnership \\nData \\nPolicy \\nData \\nContent \\nData \\nLength \\nData \\nRelationship \\nData \\nIdentifer \\nData \\nDefinition \\nFigure 5.4: Data-Specific Business Meta Data Components \\n- A data name, an official label developed from a formal data-naming taxon- \\nomy, should be composed of a prime word, a class word, and qualifiers. Each \\ndata name uniquely identifies one piece of data within the logical data model. \\nNo synonyms and no homonyms should exist.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 165}, page_content='- A data definition is a one- or two-sentence description of a data object or a \\ndata element, similar to a definition in a language dictionary. If a data object \\nhas many subtypes, each subtype should have its own unique data definition. \\nA data definition explains the meaning of the data object or data element. It \\ndoes not include who created the object, when it was last updated, what sys- \\ntem originates it, what values it contains, and so on. That information is'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 165}, page_content='stored in other meta data components (e.g., data ownership, data content). \\n- A data relationship is a business association among data occurrences in a \\nbusiness activity. Every data relationship is based on business rules and busi- \\nness policies for the associated data occurrences under each business activity. \\nA data identifier uniquely identifies an occurrence of a data object. A data \\nidentifier should be known to the business people. It should also be “minimal,”'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 165}, page_content='which means it should be as short as possible (composed of just enough data \\nelements to make it unique). In addition, a data identifier should be nonintelli- \\ngent, with no embedded logic. For example, account numbers 0765587654'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 166}, page_content='Bottom-Up Source Data Analysis 133 \\nand 0765563927, where 0765 is an embedded branch number, would be poor \\ndata identifiers. \\nPaw A logical data identifier is not the same thing as a primary key in a database. \\nAlthough a data identifier can be used as a primary key, it is often replaced by \\na surrogate (‘made-up’) key during database design. \\nData type describes the structure of a data element, categorizing the type of \\nvalues (character, number, decimal, date) allowed to be stored in it.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 166}, page_content='Data length specifies the size of a data element for its particular data type. \\nFor example, a decimal data element can be an amount field with two digits \\nafter the decimal point or a rate field with three digits after the decimal point. \\nData content (domain) identifies the actual allowable values for a data ele- \\nment specific to its data type and data length. A domain may be expressed as \\na range of values, a list of allowable values, a generic business rule, or a'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 166}, page_content='dependency rule between two or more data elements. \\nA data rule is a constraint on a data object or a data element. A data constraint \\ncan also apply to a data relationship. A data constraint can be in the form of a \\nbusiness rule or a dependency rule between data objects or data elements, for \\nexample, “The ceiling interest rate must be higher than the floor interest rate.” \\nData policy governs the content and behavior of a data object or a data ele-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 166}, page_content='ment. It is usually expressed as an organizational policy or a government reg- \\nulation. For example, “Patients on Medicare must be at least 65 years old.” \\nData ownership identifies the persons who have the authority to establish \\nand approve the business meta data for the data objects and data elements \\nunder their control. \\nAlthough logical data models are extremely stable, some of these business \\nmeta data components (such as data content, data rules, data policy, data owner-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 166}, page_content='ship) occasionally change for legitimate reasons. It is important to track these \\nchanges in the meta data repository. \\nBOTTOM-UP SOURCE DATA ANALYSIS \\nData analysis cannot stop after top-down logical data modeling because the \\nsource data often does not follow the business rules and policies captured during \\nthe modeling sessions. If bottom-up source data analysis were not performed, the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 167}, page_content='134 Step 5: Data Analysis \\ndata problems and business rule violations would not be discovered until the ETL \\nprocess was being implemented. Some data quality problems would not be dis- \\ncovered at all until after implementation, and then only if somebody complained \\nabout them. As Figure 5.5 shows, source data mapping must adhere not only to \\nthe usual technical data conversion rules but also to the business data domain \\nrules and to the business data integrity rules. \\nTechnical'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 167}, page_content='Technical \\nData Conversion | <— _ Always Performed \\nBusiness \\nData Integrity \\nRules \\nOa \\nData Domain \\noo tk \\nOften Neglected \\nFigure 5.5: Source Data-Mapping Rules \\nTechnical Data Conversion Rules \\nAny time data is mapped from one system to another, whether for traditional sys- \\ntems conversion or for source-to-target mapping in BI applications, the following \\ntechnical rules must be observed. \\n1. The data types of the source data elements must match the data types of the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 167}, page_content='target data elements. \\n2. The data lengths must be adequate to allow the source data elements to be \\nmoved, expanded, or truncated into the target data elements. \\n3. The logic of the programs manipulating the source data elements must be \\ncompatible with and applicable to the content of the source data elements. \\nOtherwise the results will be unpredictable. \\nBusiness Data Domain Rules \\nA much larger effort of source data analysis revolves around business data'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 167}, page_content='domain rules. These rules are more important to the business people than the \\ntechnical data conversion rules. A source data element can meet all three techni- \\ncal data conversion rules but still have incorrect values. Business data domain'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 168}, page_content='Bottom-Up Source Data Analysis 135 \\nrules are rules about the semantics (meaning and interpretation) of data content. \\nThey are used to identify and correct data violations like those listed in Table 5.1. \\nBusiness Data Integrity Rules \\nSimilar to business data domain rules, business data integrity rules are much \\nmore important to improving information quality than are the technical data \\nconversion rules. The business data integrity rules govern the semantic content'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 168}, page_content='among dependent or related data elements, as well as constraints imposed by \\nbusiness rules and business policy. Table 5.2 lists examples of violations to busi- \\nness data integrity rules. \\nTable 5.1: Data Domain Violations \\n1. Missing data values (a big issue on BI projects) \\n2. Default values; for example, “0”, “999”, “FF”, blank \\n3. Intelligent ‘dummy’ values, which are specific default (or dummy) values that actually'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 168}, page_content='have a meaning; for example, using a value of “888-88-8888’ for the social security \\nnumber to indicate that the person is a nonresident alien \\n4. Logic embedded in a data value, such as an implied business rule; for example, using \\nlower-valued ZIP codes (postal codes) to indicate a state on the east coast, such as \\n07456 in New Jersey, and higher-valued ZIP codes to indicate a state on the west \\ncoast, such as 91024 in California'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 168}, page_content='5. Cryptic and overused data content; for example, using the values “A, B, C, D’ of a data \\nelement to define type of customer, while the values “E, F, G, H” of the same data \\nelement define type of promotion, and the values “I, J, K, L’ define type of location \\n6. Multipurpose data elements, that is, programmatically and purposely redefined data \\ncontent; for example, the redefines Clause in COBOL statements \\n7. Multiple data elements embedded in, concatenated across, or wrapped around free-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 168}, page_content='form text fields; for example, Address lines 1 through 5 containing name and address \\ndata elements: \\nAddress line 1: Brokovicz, Meyers, and Co \\nAddress line 2: hen, Attorneys at Law \\nAddress line 3: 200 E. Washington Bouleva \\nAddress line 4: rd, \\nAddress line 5: Huntsville OR 97589'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 169}, page_content='136 Step 5: Data Analysis \\nRA TAY ET TOE ICL SE SLL OED AEE ELIE DESDE DEES EEF III DIED IEEE EEL EEDA EE, \\nTable 5.2: Data Integrity Violations \\n1. Contradicting data content between two or more data elements; for example, \\n“Boston, CA’ (instead of MA) \\n2. Business rule violation; for example, for the same person, “Date of Birth = 05/02/1985’ \\nand “Date of Death = 11/09/1971” \\n3. Reused primary key (same key value used for multiple object instances); for example,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 169}, page_content='two employees with the same employee number (when one employee left the \\ncompany, his or her employee number was reassigned to a new employee) \\n4.No unique primary key (multiple key values for the same object instance); for \\nexample, one customer with multiple customer numbers \\n5. Objects without their dependent parent object; for example, job assignment points to \\nemployee 3321, but the employee database contains no employee 3321'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 169}, page_content='6. A real-world relationship between two data objects, or between two occurrences of \\nthe same data object, that cannot be built because it is not tracked by the operational \\nsystems; for example, a customer refinances a mortgage loan but the operational \\nsystem does not track the relationship between the old paid-off loan and the new \\nrefinanced loan \\nEvery critical and important data element must be examined for these \\ndefects, and a decision must be made whether and how to correct them. The'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 169}, page_content='information consumers (business people who will be using those data elements \\nto make business decisions) and data owners should make that decision after dis- \\ncussing the impact of the cleansing effort with the business sponsor, the project \\nmanager, and the core team. \\nDATA CLEANSING \\nOne of the goals stated most frequently for BI applications is to deliver clean, \\nintegrated, and reconciled data to the business community. Unless all three sets'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 169}, page_content='of data-mapping rules are addressed, this goal cannot be achieved. Many organi- \\nzations will find a much higher percentage of dirty data in their source systems \\nthan they expected, and their challenge will be to decide how much of it to \\ncleanse.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 170}, page_content='Data Cleansing 137 \\nData Quality Responsibility \\nData archeology (the process of finding bad data), data cleansing (the process of \\ncorrecting bad data), and data quality enforcement (the process of preventing \\ndata defects at the source) are all business responsibilities—not IT responsibili- \\nties. That means that business people (information consumers as well as data \\nowners) must be involved with the data analysis activities and be familiar with \\nthe source data-mapping rules.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 170}, page_content='Since data owners originate the data and establish business rules and policies \\nover the data, they are directly responsible to the downstream information con- \\nsumers (knowledge workers, business analysts, business managers) who need to \\nuse that data. If downstream information consumers base their business deci- \\nsions on poor-quality data and suffer financial losses because of it, the data own- \\ners must be held accountable. In the past, this accountability has been absent'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 170}, page_content='from stovepipe systems. Data quality accountability is neither temporary nor BI- \\nspecific, and the business people must make the commitment to accept these \\nresponsibilities permanently. This is part of the required culture change, discus- \\nsion of which is outside the scope of this book. \\nThe challenge for IT and for the business sponsor on a BI project is to enforce \\nthe inescapable tasks of data archeology and data cleansing to meet the quality'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 170}, page_content='goals of the BI decision-support environment. \\nPaw Step 5, Data Analysis, may be time intensive since many battles may rage \\namong the business people as to the valid meaning and domain of data. \\nAlthough data-cleansing tools can assist in the data archeology process, \\ndeveloping data-cleansing specifications is mainly a manual process. IT manag- \\ners, business managers, and data owners who have never been through a data'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 170}, page_content='quality assessment and data-cleansing initiative often underestimate the time and \\neffort required of their staff by a factor of four or more. \\nSource Data Selection Process \\nPoor-quality data is such an overwhelming problem that most organizations will \\nnot be able to correct all the discrepancies. When selecting the data for the BI \\napplication, consider the five general steps shown in Figure 5.6.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 171}, page_content='138 Step 5: Data Analysis \\nit i i) \\nIndentity | Analyze Select || Prepare data- | Select j \\n| requireddata © datacontent ==—S dataforBl =—cleansingspecs tools \\nFigure 5.6: Source Data Selection Process \\nLe Identify the required data. \\nIdentify the data of interest and the significance of this data. Data cleansing is \\na collaborative effort between business analysts who are familiar with the seman- \\ntics of the data and data quality analysts who know the program-specific'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 171}, page_content='meanings of the data (e.g., the use and meaning of a “flag” value or redefined \\nrecord layouts). \\n. Analyze the data content. \\nAnalyze the data for content, meaning, and importance. Many organizations \\nhave accumulated massive amounts of data in files and databases. This data \\nconstitutes a prospective gold mine of valuable business knowledge and is \\npotentially a good source for data mining. However, the quality of the data'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 171}, page_content='content must be assessed first, since mining dirty data is of little value. \\n. Select the data for BI. \\nDetermine which data to include in the BI application. Select only the data \\nthat will meet core business requirements. Even with automated tools, the \\ncost of assuring data quality for an all-inclusive BI decision-support environ- \\nment becomes prohibitive for most organizations. Some questions to con- \\nsider when selecting data appear below.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 171}, page_content='— Is this data clean enough for decision-support usage? \\n— If not, can this data be cleansed, at least partially? Do we know how? \\n— Is the dirty data the reason for building this BI application? Is cleansing this \\ndata therefore mandatory? \\n— How much effort will it take to figure out how to cleanse the data? \\n— How much will the data-cleansing effort cost? \\n— What is the benefit of cleansing the data as opposed to moving it into the \\nBI application at the current level of dirtiness?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 171}, page_content='— What are the data quality expectations from the information consumers \\nand from business management in general?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 172}, page_content='Data Cleansing 139 \\n4. Prepare the data-cleansing specifications. \\nThe IT staff, working with the business representative, will get to know the \\nbusiness rules needed to write the data-cleansing specifications. In essence, \\nthis is a source data reengineering process. \\n5. Select the tools. \\nSelect the ETL and cleansing tools. Determine whether it is appropriate and \\ncost-effective to acquire an ETL tool, a cleansing tool, or both. Examine the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 172}, page_content='suitability and effectiveness of those tools. Some data-cleansing specifications \\ncan be very complicated. Be sure the tools are capable of handling them. \\nPaw Automated tools do not eliminate the manual labor of source data analysis; \\nthey only reduce it. \\nKey Points of Data Selection \\nWhen identifying and selecting the operational data to be used to populate the BI \\ntarget databases, some key points should be considered. Applying the source data'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 172}, page_content='selection criteria shown in Figure 5.7 minimizes the need for and effort of data \\ncleansing. \\n* Data integrity \\n* Data precision \\nv4 * Data accuracy \\nSN + Data reliability \\nES: * Data format \\nFigure 5.7: Source Data Selection Criteria \\n- Data integrity: How internally consistent is the data? This is the most impor- \\ntant criterion. \\n— The greater the proportion of manually entered data (data keyed in with \\nfew or no data controls, edits, and validations), the lower the integrity.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 172}, page_content='— Programming errors also contaminate great masses of data—and do so \\nautomatically. \\n— The lower the integrity, the greater the cleansing requirement.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 173}, page_content='140 Step 5: Data Analysis \\n- Data precision: How precise is the data? This is the next important criterion. \\n— How is the data represented internally? \\n— For numeric data, what is the scale and precision of the data? \\n— For date data, how is it formatted? \\n+ Data accuracy: How correct is the data? \\n— Are there edit checks in the data entry program? \\n— Are dependent values cross-checked? For example, does the data entry pro- \\ngram forbid an expiration date to precede an effective date?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 173}, page_content='— Is there an operational process in place for correcting data? \\n— Are calculated values stored? What, if any, mechanisms are in place to keep \\nthese values accurate? \\n* Data reliability: How old is the data? \\n— What generation is the data (month-end, weekly, daily)? \\n— Was the data obtained from direct sources or from downloads? \\n— Is the source of the data known? \\n— Is the data a duplicate of data in another data store? If so, is the data current?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 173}, page_content='* Data format: The closer the data is to the destination data format, the fewer \\nthe conversion requirements will be. From highest to lowest, the format pri- \\norities are: \\n— Data from a relational database (e.g., DB2, Oracle) \\n— Data from a nonrelational database (e.g., IMS, CA- IDMS) \\n— Flat files (e.g., VSAM, ISAM) \\nPaw Source data quality will be only as good as the enforcement of quality pro- \\ncesses in the operational systems. Mandatory quality processes should'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 173}, page_content='include data entry rules and edit checks in programs. If those processes are \\nnot enforced or do not exist, data usually gets. corrupted, regardless of \\nwhether the data is in a relational database or in an old VSAM file. \\nTo Cleanse or Not to Cleanse \\nMany organizations struggle with this question. Data-cleansing research indicates \\nthat some organizations downplay data cleansing to achieve short-term goals. \\nThe consequences of not addressing poor-quality data usually hit home when their'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 173}, page_content='business ventures fail or encounter adverse effects because of inaccurate data. \\nIt is important to recognize that data cleansing is a labor-intensive, time- \\nconsuming, and expensive process. Cleansing all the data is usually neither cost- \\njustified nor practical, but cleansing none of the data is equally unacceptable. It is'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 174}, page_content='Data Analysis Activities 141 \\ntherefore important to analyze the source data carefully and to classify the data \\nelements as critical, important, or insignificant to the business. Concentrate on \\ncleansing all the critical data elements, keeping in mind that not all data is equally \\ncritical to all business people. Then, cleanse as many of the important data ele- \\nments as time allows, and move the insignificant data elements into the BI target'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 174}, page_content='databases without cleansing them. In other words, you do not need to cleanse all \\nthe data, and you do not need to do it all at once. \\nCleansing Operational Systems \\nWhen the selected data is cleansed, standardized, and moved into the BI target \\ndatabases, a question to consider is whether the source files and source databases \\nshould also be cleansed. Management may ask, why not spend a little extra \\nmoney and time to cleanse the source files and databases so that the data is con-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 174}, page_content='sistent in the source as well as in the target? This is a valid question, and this \\noption should definitely be pursued if the corrective action on the source system \\nis as simple as adding an edit check to the data entry program. \\nIf the corrective action requires changing the file structure, which means \\nmodifying (if not rewriting) most of the programs that access that file, the cost \\nfor such an invasive corrective action on the operational system is probably not'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 174}, page_content='justifiable—especially if the bad data is not interfering with the operational needs \\nof that system. Remember that many companies did not even want to make such \\ndrastic changes for the now infamous Y2K problem; they made those changes \\nonly when it was clear that their survival was at stake. Certainly, a misused code \\nfield does not put an organization’s survival at stake. Hence, the chances that \\noperational systems will be fixed are bleak. \\nDATA ANALYSIS ACTIVITIES'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 174}, page_content='The activities for data analysis do not need to be performed linearly. Figure 5.8 \\nindicates which activities can be performed concurrently. The list below briefly \\ndescribes the activities associated with Step 5, Data Analysis. \\n1. Analyze the external data sources. \\nIn addition to requiring internal operational source data, many BI applications \\nneed data from external sources. Merging external data with internal data'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 174}, page_content='presents its own set of challenges. External data is often dirty and incomplete,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 175}, page_content='142 Step 5: Data Analysis \\nSSS ES SS PS AE EE EE ES OE A SE LE OE SE IE SSSI SI \\nExpand enterprise \\nlogical data model \\nRefine logical \\ndata model \\nWrite data-cleansing \\nspecifications \\nAnalyze external \\ndata sources \\nResolve data \\ndiscrepancies \\nAnalyze source \\ndata quality \\nFigure 5.8: Data Analysis Activities \\nand it usually does not follow the same format or key structure as internal \\ndata. Identify and resolve these differences during this step. \\n2. Refine the logical data model.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 175}, page_content='A high-level, project-specific logical data model should have been created \\nduring one of the previous steps. In addition, some or all of the internal and \\nexternal data may have been modeled on other projects and may already be \\npart of the enterprise logical data model. In that case, extract the representa- \\ntive portion of the enterprise logical data model and expand it with the new \\ndata objects, new data relationships, and new data elements. If the required'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 175}, page_content='data has not been previously modeled, create a new logical data model for the \\nscope of this BI project. It should include all internal as well as external data \\nelements. \\n3. Analyze the source data quality. \\nAt the same time that the logical data model is created or expanded, the qual- \\nity of the internal and external source files and source databases must be ana- \\nlyzed in detail. It is quite common that existing operational data does not'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 175}, page_content='conform to the stated business rules and business policies. Many data ele- \\nments are used for multiple purposes or are simply left blank. Identify all \\nthese discrepancies and incorporate them into the logical data model. \\n4, Expand the enterprise logical data model. \\nOnce the project-specific logical data model is relatively stable, merge it back \\ninto the enterprise logical data model. During this merge process additional'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 175}, page_content='data discrepancies or inconsistencies may be identified. Those will be sent \\nback to the BI project for resolution.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 176}, page_content='Deliverables Resulting from These Activities 143 \\n5. Resolve data discrepancies. \\nOccasionally data discrepancies discovered during data analysis involve other \\nbusiness representatives from other projects. In that case, summon the other \\nbusiness representatives as well as the data owners to work out their differ- \\nences. Either they will discover a new legitimate subtype of a data object or a \\nnew data element, which must be modeled as such, or they will have to'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 176}, page_content='resolve and standardize the inconsistencies. \\n6. Write the data-cleansing specifications. \\nOnce all data problems are identified and modeled, write the specifications \\nfor how to cleanse the data. These specifications should be in plain English so \\nthey can be validated by the data owner and by business people who will use \\nthe data. \\nDELIVERABLES RESULTING FROM THESE ACTIVITIES \\n1. Normalized and fully attributed logical data model'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 176}, page_content='This project-specific logical data model is a fully normalized entity-relationship \\ndiagram showing kernel entities, associative entities, characteristic entities, \\ncardinality, optionality, unique identifiers, and all attributes. \\n2. Business meta data \\nThe business entities and attributes from the logical data model must be \\ndescribed with meta data. Data-specific business meta data components \\ninclude data names, data definitions, data relationships, unique identifiers,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 176}, page_content='data types, data lengths, domains, business rules, policies, and data owner- \\nship. These are usually captured in the tool repository of the computer-aided \\nsoftware engineering (CASE) tool. \\n3. Data-cleansing specifications \\nThis document describes the cleansing logic that must be applied to the \\nsource data in order to bring it into compliance with the technical data con- \\nversion rules, the business data domain rules, and the business data integrity'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 176}, page_content='rules. This document will be used to create the transformation specifications \\non the source-to-target mapping document in Step 9, ETL Design. \\n4, Expanded enterprise logical data model \\nThis deliverable is produced behind the scenes by data administration or the \\nenterprise architecture group when it merges the project-specific logical data \\nmodel into the enterprise logical data model. Any rejected entities or'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 177}, page_content='144 Step 5: Data Analysis \\nSa \\nattributes and any discrepancies between the models will be presented to the \\nBI project team for resolution. \\nROLES INVOLVED IN THESE ACTIVITIES \\n® Business representative \\nThe business representative assigned to the BI project is a major contributor \\nduring the top-down logical data modeling activities as well as the bottom-up \\nsource data analysis activities. He or she provides the business meta data to the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 177}, page_content='data administrator and assists the data quality analyst in analyzing the source \\nfiles. \\n@ Data administrator \\nThe data administrator is trained in logical data modeling, business meta \\ndata, normalization techniques, business data domain rules, business data \\nintegrity rules, and standardization methods. The job description of a data \\nadministrator matches the activities of the Data Analysis step. The data \\nadministrator will be the lead person during this step and will facilitate all of'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 177}, page_content='the data modeling sessions. He or she also has the responsibility of document- \\ning the logical data model and the supporting business meta data in the CASE \\ntool. \\n@ Data quality analyst \\nThe data quality analyst is a systems analyst, trained in using the technical data \\nconversion rules, in reading as well as writing programs, and in extracting \\ndata from all types of source files and source databases. Finding the data viola-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 177}, page_content='tions in the source files and source databases is the prime responsibility of the \\ndata quality analyst. He or she works closely with the data administrator to \\nmodel data anomalies and to correct the data violations with help from the \\nbusiness representative and the data owners. \\n@ ETL lead developer \\nThe ETL lead developer must be involved in the modeling reviews and must \\nbe aware of the magnitude of data quality problems found in the source files'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 177}, page_content='and source databases. He or she needs to understand the complexity of cleans- \\ning the data because the cleansing algorithms must be incorporated into the \\nETL process. In some cases, the ETL tool will not be able to support some \\ncleansing algorithms, and custom code may have to be written.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 178}, page_content='Risks of Not Performing Step 5 145 \\n® Meta data administrator \\nAs the custodian of meta data and the administrator of the meta data reposi- \\ntory, the meta data administrator needs to know what business meta data \\ncomponents are being collected and how. Some meta data components may \\nbe entered into a CASE tool, while other components may be captured in \\nword processing documents or in spreadsheets. The meta data administrator'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 178}, page_content='will have to extract the meta data components from the various files and tools \\nand merge them into the meta data repository. \\n® Stakeholders (including data owners) \\nThe business people using the BI applications are usually downstream infor- \\nmation consumers and not the data owners. During this step, both informa- \\ntion consumers and data owners have the responsibility to standardize the \\nbusiness data and to set rules and policies for the data. Continuing disagree-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 178}, page_content='ments over data between data owners and information consumers must be \\npushed up to business executives for resolution. \\n@ Subject matter expert \\nThe subject matter expert assists the data administrator and data quality analyst \\nby interpreting the business data, explaining the business rules and policies for \\nthe data, and determining the domain (valid values) of the data. In addition, \\nthe subject matter expert is responsible for finding data problems in the source'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 178}, page_content='data files and source databases and for suggesting how to correct them. \\nRISKS OF NOT PERFORMING STEP 5 \\nBusiness managers, IT managers, and IT technicians often do not want to take \\nthe time to perform rigorous data analysis, which involves logical data modeling, \\nsource data archeology, and data cleansing. They see those activities as a waste of \\ntime. They judge the success of a BI project by the speed with which it gets deliv-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 178}, page_content='ered, rather than by the quality of its deliverable. As a result, organizations often \\ncreate stovepipe data marts and populate them “suck and plunk” style with the \\nsame data they have on the source files and source databases, thereby copying all \\nthe existing data impairments to the new BI decision-support environment. \\nInstead of eliminating their existing data problems, they just compounded \\nthem—now there are additional redundant and inconsistent BI target databases'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 178}, page_content='and applications to maintain.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 179}, page_content='146 Step 5: Data Analysis \\nOf all the 16 steps presented in Business Intelligence Roadmap, Step 5, Data \\nAnalysis, is the most critical cross-organizational step. This step is a major differen- \\ntiator between a traditional systems development approach and a cross-organizational \\ndevelopment approach. The activities of business-focused data analysis force the \\ninformation consumers and the data owners to reconstruct a cross-organizational'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 179}, page_content='view and to clean up their expensive data chaos, not only in the BI decision-support \\nenvironment but in their operational systems as well. These are all prerequisites \\nfor improving the business executives’ abilities to make decisions. Without this \\nstep, you are just building another traditional stovepipe decision-support system, \\nnot a BI solution. \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nAdelman, Sid, and Larissa Terpeluk Moss. Data Warehouse Project Management.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 179}, page_content='Boston, MA: Addison-Wesley, 2000. \\nAiken, Peter H. Data Reverse Engineering: Slaying the Legacy Dragon. New York: \\nMcGraw-Hill, 1995. \\nAtre, Shaku. Data Base: Structured Techniques for Design, Performance, and Man- \\nagement, Second Edition. New York: John Wiley & Sons, 1988. \\nBischoff, Joyce, and Ted Alexander. Data Warehouse: Practical Advice from the \\nExperts. Upper Saddle River, NJ: Prentice Hall, 1997. \\nBrackett, Michael H. Data Resource Quality: Turning Bad Habits into Good Prac-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 179}, page_content='tices. Boston, MA: Addison-Wesley, 2000. \\n. The Data Warehouse Challenge: Taming Data Chaos. New York: John \\nWiley & Sons, 1996. \\nDownes, P. M. Practical Data Analysis. Pinner, Middlesex, UK: Blenheim Online \\nPublications, 1989. \\nEnglish, Larry P. Improving Data Warehouse and Business Information Quality: \\nMethods for Reducing Costs and Increasing Profits. New York: John Wiley & Sons, \\n1999) \\nHoberman, Steve. Data Modeler’s Workbench: Tools and Techniques for Analysis'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 179}, page_content='and Design. New York: John Wiley & Sons, 2001. \\nInmon, William H., John A. Zachman, and Jonathon G. Geiger. Data Stores, Data \\nWarehousing and the Zachman Framework: Managing Enterprise Knowledge. New \\nYork: McGraw-Hill, 1997.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 180}, page_content='Bibliography and Additional Reading 147 \\nJarke, Matthias, Maurizio Lenzerini, Yannis Vassiliou, and Panos Vassiliadis. Fun- \\ndamentals of Data Warehouses. New York: Springer, 2000. \\nKuan-Tsae, Huang, Yang W. Lee, and Richard Y. Wang. Quality Information and \\nKnowledge Management. Upper Saddle River, NJ: Prentice Hall, 1998. \\nReingruber, Michael C., and William W. Gregory. The Data Modeling Handbook: \\nA Best-Practice Approach to Building Quality Data Models. New York: John Wiley & \\nSons, 1994.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 180}, page_content='Sons, 1994. \\nRoss, Ronald G. The Business Rule Concepts. Houston, TX: Business Rule Solu- \\ntions, Inc., 1998. \\nSimsion, Graeme. Data Modeling Essentials: Analysis, Design, and Innovation. \\nBoston, MA: International Thomson Computer Press, 1994. \\nVon Halle, Barbara. Business Rules Applied: Building Better Systems Using the Busi- \\nness Rules Approach. New York: John Wiley & Sons, 2001. \\nZachman, John. The Zachman Framework: A Primer for Enterprise Engineering'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 180}, page_content='and Manufacturing. La Canada, CA: Zachman International, 2002. \\nInformation Impact International, Inc.: http://www. infoimpact.com \\nZachman Institute for Framework Advancement: http://www.zifa.com'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 181}, page_content='eM tinted core! bos omilen Paina’ dee \\n— QagePhab. |) Ste ie cigy ? ERR agape? clan wre \\nAGATA EO) eres relent hh Geet GAT 5 \\ndee peo Real canes Ta Web hatte , \\nyee Set Sy Os Ve isle \\n. Soc omar pei ce: tals ) Sth edve Oomgetish Me a \\n7 \\n: \\n: \\nFae, ‘ a, 1 (> \\n- season ST tid i gaia.) 20h seas ia ae : \\n7 won aes 281, : \\na Pe giant! angie, olameereS Gell on 3 \\n400) gor iajeqme) nord? tk \\net age ion aid eri grohiggiects ity. 4st ean \\neel, Wee fea Weg aaa 8 | is yee'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 181}, page_content=\"Hediigh ya ees soe ih mary, fame Rata) ae face ie wen ue \\nVatiane dias tee \\nua Atee the a7 rh eA Sere IN | 20! dana cee \\n: ee ee andes eae \\nPan DIRE. Ore “Vs Aaaer bleu Ce > Paes an eae \\nMagied, \\\\ stad 665m fi wpe, (4) Fence 140 all’: Cry \\nPeper, Mica Vi Das Kesoate “Aiibe~ fh on an ot Gd i Fee, hater, MAAculcr--00 a, 3,0 \\npee, [Og Uicay 4 a04 sats ealloage ie Dae Chak? Stew Verte Je \\nWide @ Sai, 1 \\nWiese, I At fre imas [4G tna gen, O24 nein aiieiais us Pine \\nPiles 2's arid, | dpey\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 181}, page_content='pagar Kayrry 0 igen itey Tie WR inigs die) ft wiipen biaiiienié \\n(OMS & Geviadins [> 97 908 lnprmpian Pais ‘New Vereen dew hel \\nt \\n= fo \\nore \\ner iien, <aiy <cow Cheb Werhhneet Tiadt wil oe \\ntr [ogtee—feee YL Adin eG DP de. Sy, \\nbe, ‘AGL eet), ii A oA ism 6SC \\nVe reap aml oh * eee Freeeediied) \\nich: NOG iveeealy, |'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 182}, page_content='Justification \\nPlanning \\n4} Application | Meta Dat \\n/\\\\ Prototyping /, & tory \\nCHAPTER SIX \\nStep 6: Application \\nPrototyping \\nCHAPTER OVERVIEW \\nThis chapter covers the following topics: \\n@ Things to consider about prototyping \\n@ How prototyping can provide an effective way to validate \\napplication requirements \\n@ The concept of “time-boxing’ prototyping activities \\n@ Best practices for prototyping \\n@ Prototyping considerations such as proper team structure,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 182}, page_content='deadline management, scope and deliverables, and busi- \\nness participation \\nm@ The purposes and implications of the six different types of \\nprototypes: show-and-tell, mock-up, proof-of-concept, \\nvisual-design, demo, and operational \\n@ Guidelines for prototyping \\nm@ An example of a skill survey used to determine the skill \\nsets of the business people who will participate in the pro- \\ntotype and will later use the BI application \\n@ Brief descriptions of the activities involved in application'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 182}, page_content='prototyping, the deliverables resulting from those activities, \\nand the roles involved \\n@ The risks of not performing Step 6 \\n149'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 183}, page_content='150 Step 6: Application Prototyping \\nTHINGS TO CONSIDER \\nObjectives \\nVY Are the objectives for this prototype clear? \\nY Do we know what kind of prototype we want to build? \\nV Have we developed a prototype in the past? \\n/ If we have, what was our experience? What lessons did we learn? \\nY How will the business people benefit from prototyping this BI application? \\nY How will the organization benefit? \\nScope and Schedule \\n¥ What is the scope of the prototype? \\nY How will we manage scope changes?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 183}, page_content='Y How much time do we have for this prototype? \\n/Y How many versions (iterations) of the prototype are we planning to create \\nbefore starting real development work? \\nVY How will we time-box prototype activities? By version? By activity? By \\ndeliverable? \\nDeliverables \\nVv Are the requirements clear about the prototype deliverables? \\n¥V What reports do the business people expect from the BI application? Will we \\nprototype all of those reports? If not, which ones?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 183}, page_content='¥ What queries will the business analysts write against the BI target databases? \\nWhich of these queries should we prototype? \\nVY Are any business analysts currently using spreadsheets to satisfy their query \\nneeds? Will the prototype include reports to replace all those spreadsheets? \\n¥ What data do we need for the prototype database? \\n¥ Will a BI application interface be required? If so, are we prototyping it? For \\nhow many business people? What do they have now?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 183}, page_content='Vv Are we going to include a Web front end in the prototype? \\nBusiness Participation \\n¥Y Who will use the BI application? How many of those business people will be \\ninvolved with the prototype? \\n¥ Where are the business people located? How will they connect to the BI \\napplication? By local area network (LAN)? By wide area network (WAN)? \\nThrough the intranet?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 184}, page_content='Purposes of Prototyping 151 \\nVv Have we worked with these business people in the past? \\n¥ What types of technical skills do they have? What technical skills are needed \\nto participate in the prototype? \\n¥Y How much will they participate in this prototype? Hands-on, full-time \\ninvolvement? Occasional demo reviews only? \\nTools and Methods \\nv What tools will we use to develop the prototype? \\n¥ Will we use the same tools to develop the final BI application?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 184}, page_content='Y How will lessons learned be communicated to the extract/transform/load \\n(ETL) team? \\nThere is nothing business people like more than to see their requirements \\nturn into a tangible deliverable they can “touch and feel” very quickly. A proto- \\ntype accomplishes that goal. \\nPURPOSES OF PROTOTYPING \\nPrototyping can be an effective method for validating the project requirements \\nand finding missing pieces and discrepancies in the requirements. Business peo-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 184}, page_content='ple seldom think of all the details when they state their requirements. They often \\nforget to include dependent processes or related data. A prototype can also help \\nthem focus on their access path requirements because they will see the capabilities \\nof the BI technology and the access and analysis portion of their BI application. \\nIf time and budget permit, building a prototype for the original requirements \\nallows the business community to test, extend, or change those requirements at'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 184}, page_content='an early stage when the impact on the project schedule is not yet high. The costs \\nof experimenting with different database designs, different visualization meth- \\nods, different development tools, or different application programming tech- \\nniques are much less during prototyping than during development because they \\ndo not affect a full-scale application. \\nAnother purpose for prototyping is to verify that the design as well as the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 184}, page_content='selected tools, database management system (DBMS), and other technology com- \\nponents will be appropriate for the BI decision-support environment. If the func- \\ntions of all technology components perform as expected during the prototype'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 185}, page_content='152 Step 6: Application Prototyping \\ndevelopment, then the chances of having a successful BI implementation are \\nincreased. Therefore, testing the technology features is a valuable benefit of pro- \\ntotyping, regardless of whether you are using existing technology components or \\nbuying new ones. \\nTesting the technology for performance, however, is usually not a valid pur- \\npose for a prototype. A prototype is not a stress-test environment. It is usually'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 185}, page_content='loaded with only small sets of data, and its main purpose is to try out visual \\ninterfaces and functionality. \\nTime-Boxing \\nEveryone likes prototyping. It is fun and creative, dynamic and exciting—and it is \\nmeant to be short. Thus, a word of caution: It is tempting to endlessly expand the \\nscope of the prototype. Prolonging the prototyping effort beyond its original \\npurpose reduces the cost-effectiveness of the prototype and produces diminish-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 185}, page_content='ing returns, as shown in Figure 6.1. It also reduces control over the project as the \\nprototype starts to feel like a runaway train. \\nEach prototype iteration should be limited in duration to just a few weeks, \\nand the activities within each prototype iteration should be time-boxed for every \\nweek, as illustrated in Figure 6.2. Prototyping activities are carefully planned and \\nmonitored. Each participant must know which tasks to perform and which task'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 185}, page_content='deliverables to produce by the end of every week. \\nAs unexpected discoveries arise (one main reason for prototyping is to find \\nout what does not work), the plan should be revised for every team member who \\nis affected by that discovery. The plan and schedule for the prototype can be \\nextended or shortened. A plan does not dictate what must be done; it is only a \\nproposal for activities that make the most sense at the time. If something does \\nnot make sense anymore, change it. \\nCalendar'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 185}, page_content='Calendar \\n1/12 [ ano! | Rigen Ween | \\n| RT eee \\nDiminishing Returns \\nFigure 6.1: Uncontrolled Prototyping Activity \\nPrototype \\nDeliverable \\nCost-Effective'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 186}, page_content='Best Practices for Prototyping 153 \\nCalendar \\n1/26 2/9 2/16 \\nFigure 6.2: Controlled (Time-Boxed) Prototyping Activity \\nBEST PRACTICES FOR PROTOTYPING \\nA few lessons learned regarding prototyping appear below. \\nLimit the scope: Limit the functional scope as well as the data scope of each \\nprototype iteration to a specific subset of the application. This helps to focus \\nthe business people on one small piece of their overall requirements. They'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 186}, page_content='can learn about the capabilities and limitations of the new environment with- \\nout getting bogged down with the complexities of the whole development \\neffort. It is also a good general training indoctrination in how to use the new \\ntechnology and the new application. \\nUnderstand database requirements early: The prototype will help the data- \\nbase administrator understand the access path requirements to the BI target \\ndatabases, the reporting dimensions needed for application development'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 186}, page_content='with online analytical processing (OLAP) tools, the levels of aggregation and \\nsummarization needed, and what type of data is usually accessed together. \\nThe database administrator will be able to start making some database design \\ndecisions, such as how to cluster tables and where to place the data sets. The \\ndatabase administrator will also get a sense of the performance expectations \\nand the anticipated size of the databases.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 186}, page_content='Choose the right data: Carefully select sample data for the prototype. The \\nsample data set should be a meaningful representation of the source data so \\nthat all functions and features of the prototype can be tested. Keep the sample \\ndata set small so as not to spend too much time on loading and testing. Try to \\nselect clean data for the prototype. You do not want to have your prototype \\nresults tarnished because of dirty data. You also do not want to take the time'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 186}, page_content='to cleanse data while creating the prototype unless the purpose of the proto- \\ntype is to test your transformation logic or the transformation functionality \\nof an ETL tool or a data-cleansing tool.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 187}, page_content='154 Step 6: Application Prototyping \\n- Test tool usability: Test the usability of the access and analysis tools. Make \\nsure the query tools are easy to use and do not intimidate the business people \\nwho need to use them. Test the features of the report writer on one of the \\nmore complicated reports. Give the business people hands-on experience \\nwith the OLAP tool. Although multidimensional analysis is relatively intui-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 187}, page_content='tive for most business people, the capability of dynamically drilling down and \\nrolling up with a tool is still a new experience for many. \\nInvolve the business people: Test the prototype with more than one business \\nperson. Try it with a single business person first, then add more business peo- \\nple from different business units or departments. Be sure to measure the per- \\nformance of the prototype as you add more people. Observe the business'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 187}, page_content='people while they use the prototype. You will be able to see how they react to \\nthe prototype when you test it with them. Address any difficulties or misgiv- \\nings immediately so that the problems do not become roadblocks during \\napplication development. \\nConsiderations for Prototyping \\nTo build a successful prototype and to produce the optimal physical database \\ndesign, the prototyping team must first understand how the business people will'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 187}, page_content='retrieve the data and what they will do with it. The team members should ask \\nsuch questions as the following: \\n- Are there frequently asked business questions? \\n+ What dimensions of the data are prevalent on reports? \\n- Are there reporting patterns among departments? \\nPrototyping is a useful technique to ensure that the business people and the \\nprototyping team understand and agree on the functional business requirements.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 187}, page_content='A prototype could also ensure that everyone agrees on what is expected from the \\nfinal BI application. Important considerations about developing a prototype are \\nbriefly described below. \\n* Prototyping team: The prototyping team should be small. One of the many \\nreasons why some software companies have become successful is that their \\nproject teams are very small. They do not staff their projects with more than \\nseven or eight people.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 188}, page_content='Best Practices for Prototyping 155 \\nDeadline management: When project teams routinely miss deadlines, shrink \\nthe size of the team. This is exactly the opposite of what many organizations \\ndo. Most organizations put more people on the team, which usually backfires \\nbecause more people require more time for communication, and that slows \\ndown the project even more. By shrinking the size of the team, the people \\nremaining on the team may have more work to do, but they will get things'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 188}, page_content='done faster. \\nScope: Try to build “slimware,” that is, deliverables with the barest number of \\nfeatures possible to satisfy the purpose of the prototype. This can head off \\n“code bloat” down the road when the application code needs to be written. \\nDeliverables: Each prototype should have a well-defined deliverable. Plan to \\nuse an iterative process for prototyping, and try to control the activities on \\neach prototype iteration in weekly increments with weekly deliverables.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 188}, page_content='Delivery methods: Test the graphical user interfaces (GUIs), Web-enabled \\ninterfaces, and other delivery methods. \\nData integration: Try to have only a few data integration requirements in \\nyour prototype scope. Prototyping should not be used to address all project \\nrequirements but only to get a basic understanding of the major deliverables. \\nBusiness participation: The prototype should include at the most five to \\neight business people. Consider the politics involved in selecting the right'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 188}, page_content='blend of business people for the prototyping activities. \\nSuccess criteria: Encourage business participation in the prototyping process \\nfrom the beginning, especially during the activities of needs assessment and \\nGUI construction. Be sure to include the business representative and the \\nbusiness sponsor when establishing the success criteria for the prototype. \\nRemember, their definition of success or failure is the one that counts. You'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 188}, page_content='may also consider building a coalition comprised of the business representa- \\ntive and the business sponsor, IT managers, and other senior business man- \\nagers who will support the BI project beyond the prototype. \\nBefore starting the prototype, review the Things to Consider section at the \\nbeginning of this chapter to determine the overall scope of the prototype, the \\nprototype’s purpose, how many business people will participate, and the level of'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 188}, page_content='complexity. Use this information to carve out and focus on one or two essential \\nfunctions that have the highest payback.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 189}, page_content='156 Step 6: Application Prototyping \\nTYPES OF PROTOTYPES \\nPrototyping is a visual communication technique used to help the BI project \\nteam understand and refine the scope of the project requirements. There are dif- \\nferent types of prototypes, each with a different purpose and life expectancy. \\nThese prototypes are discussed below in the order of least to most functionality, \\nsophistication, and reusability. \\nShow-and-Tell Prototype'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 189}, page_content='A show-and-tell prototype serves as a demo for management and business peo- \\nple, as described in Table 6.1. It could also be used to obtain budget approval or \\nto get a business sponsor for the BI application during Step 1, Business Case \\nAssessment. \\nTable 6.1: Show-and-Tell Prototype \\nPurposes Implications \\n* Avoid costly coding by only * Business people may mistake the \\ndemonstrating “look and feel.’ prototype for a functioning system. Be'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 189}, page_content='¢ Gain buy-in from business people. sure to explain that there is no \\n* Gain business support for the BI functionality at all—it is only for visual \\napplication. communication. \\n¢ Secure funding for the BI application. * Concentrate on displaying the most \\nimportant screens to get business buy-in. \\nMock-Up Prototype \\nThe purpose of a mock-up prototype is to understand the access and analysis \\nrequirements and the business activities behind them. Therefore, mock-up pro-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 189}, page_content='totypes are completed in a very short time, as mentioned in Table 6.2. Since the \\nmock-up prototype is just a front for a BI application, it is usually a throwaway.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 190}, page_content='Types of Prototypes 157 \\nIB ESSE PR I ST SS SE I IE \\nTable 6.2: Mock-Up Prototype \\nPurposes Implications \\n¢ Understand the application * Pay attention to interfaces: building \\nrequirements. interfaces gives the impression of \\n* Understand the business activities. working code. \\n* Initiate system functions. * Use a less sophisticated programming \\n* Speed is of the essence. language to build the prototype faster. \\nFor example, you may want to use Visual'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 190}, page_content='Basic for the prototype and write the final \\naccess and analysis application in C++. \\nProof-of-Concept Prototype \\nThe purpose of a proof-of-concept prototype is to explore implementation \\nuncertainties. This method allows the identification of risks and unknowns, \\nthereby enabling the decision whether or not to proceed with the project, as indi- \\ncated in Table 6.3. \\nTable 6.3: Proof-of-Concept Prototype \\nPurpose Implications \\n¢ Explore implementation risks and * Stay narrow in scope.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 190}, page_content='unknowns to decide whether or not to * Do not build any application interfaces. \\nproceed. * Build only enough functionality to make \\na go/no-go decision. \\nVisual-Design Prototype \\nA visual-design prototype is a step up from a mock-up. It is ideal for developing \\ninterface specifications for the access and analysis portion of the BI application. \\nGood interface specifications are mandatory, as listed in Table 6.4. Visually, it is'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 190}, page_content='important for business people to have as much information as possible on the \\nsame screen to avoid toggling between screens. Once the code is generated, this \\ntype of prototype may survive and be incorporated into the final BI application.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 191}, page_content='158 Step 6: Application Prototyping \\nTherefore, unless you are certain that this prototype is a throwaway, stay away \\nfrom “quick and dirty” code. There is no such thing as a one-time-use-only program. \\nOnce a program works, even if it does not work well, it is liable to be used forever. \\nTable 6.4: Visual-Design Prototype \\nPurposes Implications \\n¢ Understand the design of visual * If the intent is to use the prototype like a \\ninterfaces. mock-up only, write it in a language'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 191}, page_content='* Develop specifications for visual different from the delivery language so \\ninterfaces and displays. you can complete it faster. \\n¢ If the intent is to potentially use the \\nprototype for the final BI application, \\nwrite it in the delivery language from the \\nstart so you can reuse it for the real BI \\napplication. Allocate additional time for \\nwriting quality code. \\nDemo Prototype \\nA demo prototype is used to convey vision and partial functionality to business'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 191}, page_content='people, business managers, potential customers, or other external groups, as indicated \\nin Table 6.5. It is not fully functioning, but it is more sophisticated than code stubs. \\nTable 6.5: Demo Prototype \\nPurposes Implications \\n* Convey the vision of the BI application to —* On the initial screen, graphically convey \\nthe business people or to external groups. what percentage of the application is \\n* Test the market for the viability of a full- represented by the prototype so you set'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 191}, page_content='scale BI application. realistic expectations. Otherwise, the \\n* Test or demonstrate the usability of the business people may mistake this \\nproposed access and analysis portion of prototype for a functioning application. \\nthe BI application. \\nSS RS SSS SSE TR ED RA TTR OR SS SSS EEE'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 192}, page_content='Building Successful Prototypes 159 \\nOperational Prototype \\nAn operational prototype is the most involved, most extensive, and most time- \\nconsuming of all prototypes. As a result, it is also the most expensive, most com- \\nplete, most functional, and most likely to survive and evolve into the real access \\nand analysis portion of the BI application. The purpose of this prototype is to \\nobtain feedback from the business people who participate in the prototyping'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 192}, page_content='activities through the actual use of the application’s functionality. This is accom- \\nplished by designing the entire access and analysis application up front but using \\nonly a basic part of the code to generate the prototype. It can be considered a bare- \\nbones application, with just enough functionality to evoke feedback, as men- \\ntioned in Table 6.6. This type of prototype is also excellent for hands-on training. \\nTable 6.6: Operational Prototype \\nPurposes Implications'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 192}, page_content='* Create an almost fully functioning pilot * On the initial screen, graphically convey \\nfor alpha or beta use of the access and what percentage of the application is \\nanalysis portion of the BI application. represented by the prototype so you can \\n¢ Obtain feedback through real hands-on set realistic expectations. \\ntrials of the bare-bones application. * This prototype has a high potential for \\nevolving into the final access and \\nanalysis portion of the BI application.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 192}, page_content='¢ Write the prototype in the delivery \\nlanguage. Allocate additional time for \\nwriting quality code. \\nBUILDING SUCCESSFUL PROTOTYPES \\nBuilding a successful prototype starts with defining its purpose and setting its \\nscope. The purpose and scope of a prototype can never be the implementation of \\na full-scale BI application, which is comprised of an ETL process, an access and \\nanalysis application, and a meta data repository. There are two main reasons why'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 192}, page_content='a prototype can never produce a complete BI application. \\n1. While portions of the ETL process and some functionality of the ETL tool \\ncan be tested in a prototype, the entire ETL process is too complicated and \\nwould take too long to be an appropriate scope for prototyping.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 193}, page_content='160 Step 6: Application Prototyping \\n2. Similarly, the design and some functionality of the meta data repository can \\nbe tested in prototyping, but developing a robust, production-worthy, enter- \\nprise-wide meta data repository is outside the scope of prototyping. \\nTherefore, the most appropriate and the most common purpose and scope \\nfor prototyping is to demonstrate the overall usefulness of the access and analysis'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 193}, page_content='portion of a BI application by using a small subset of functionality and data. \\nConsequently, prototyping is the best way for the project team members of the \\nApplication track to perform “systems analysis,” which is systems-focused analy- \\nsis of functional requirements that leads to application design. To take it a step \\nfurther, if the BI project team chooses to build an operational prototype, it is \\nconceivable that after several prototyping iterations the operational prototype'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 193}, page_content='can evolve into the final access and analysis application. \\nOnce the prototyping activities are in progress, it is quite common to make \\nnew discoveries that lead to new requirements, which can affect not only the scope \\nof the prototype but also the scope of the source data analysis activity, the ETL \\nprocess, and the meta data repository. Be sure to review and renegotiate the project \\nconstraints when the scope changes, and be sure to communicate daily with the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 193}, page_content='project team members of the ETL track and the Meta Data Repository track. \\nPrototype Charter \\nPrepare a prototype charter, which is similar to a project charter but much smaller \\nand less formal. A prototype charter is an agreement between the business sponsor \\nand the IT staff for developing a prototype. It should include the following sections: \\n- The primary purpose of the prototype, for example, whether the focus is on'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 193}, page_content='testing queries for marketing analysis, demonstrating executive information, \\nrunning a financial analysis report, or fulfilling another specific purpose. \\n- The prototype objectives, including a statement of what type of prototype \\nwill be built. Each type of prototype takes a different amount of effort and \\nproduces different results. It must be clear to the business people what the \\nlimitations of the prototype will be. \\n: A list of business people who will:'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 193}, page_content='— Participate in building the prototype \\n— Sign off on the prototype \\n— Use (test) the prototype \\n* The data, including information on the type of data, the amount of data, and \\nthe consolidation level of data that will initially be brought into the prototype'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 194}, page_content='Building Successful Prototypes 161 \\n> The hardware and software platforms on which the prototype will be con- \\nstructed and the language in which it will be written. \\n- The measures of success should be itemized for the prototype. How will you \\nknow whether it was worthwhile to prototype portions of your BI application? \\n* An application interface agreement is also important to cover the following: \\n— Compliance with standards (or development of standards if none exist)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 194}, page_content='— Necessary level of understanding and skills required \\n— Ease of use (“user-friendliness” ) \\nRegardless of how much we use the term “user-friendly system,” it is still an \\noxymoron, like a “simple programming change.” In most cases, we seem to be \\nlooking for “system-friendly users” instead of developing “user-friendly systems.” \\nExpress the goals for ease of use in terms of quantifiable criteria for: \\n+ The minimum time it takes to learn the new application.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 194}, page_content='* The speed of task accomplishment (e.g., time to analyze a market condition). \\n* The retention rate of queries over a period of time. \\n* Subjective satisfaction; business people like applications that are intuitive and \\nforgiving. \\n* The effectiveness of the help function (if included in the prototype). Is the \\nhelp function really helping people resolve problems? Are the business people \\nmaking use of the help function frequently? What is their feedback about the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 194}, page_content='content of the help function? \\nGuidelines for Prototyping \\nCreate prototyping guidelines and communicate them to all prototype partici- \\npants. Table 6.7 lists some sample guidelines. \\nAdditional considerations appear below. \\n* With each prototype iteration, plan to expand the number of data types, and \\nplan to increase the functionality and the volume of data. \\n* Keep the type and placement of GUI components consistent among proto-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 194}, page_content='types. If you are choosing a pull-down menu for certain types of displays, do \\nnot switch to radio buttons on another prototype. The business people may \\nneed to reach consensus on some basic standardization for the BI decision- \\nsupport environment.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 195}, page_content='162 Step 6: Application Prototyping \\nTable 6.7: Prototyping Guidelines \\n. Do not deviate from the basic purpose for which the prototype is being developed. \\n. Develop a working prototype quickly; therefore, keep the scope small. \\n. Acknowledge that the first iteration will have problems. \\n. Frequently demonstrate the prototype to stakeholders. \\n. Solicit and document top-down as well as bottom-up feedback on the prototype. \\n. Ask for ongoing validation of the prototype results.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 195}, page_content='SI 6) Ol SB WN: = . Continue to cycle between demonstrating and revising the prototype until its \\nfunctionality is satisfactory to all parties. \\njee) . Review your prototyping approach and modify it if necessary before proceeding with \\nthe next prototype iteration. \\nSkills Survey \\nThe business people who will participate in the prototype and will later use the BI \\napplication should be evaluated to determine their skill sets. What level of busi-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 195}, page_content='ness knowledge do they have about the business functions addressed by the BI \\napplication? Are they experts in using computers but do not know much about \\nthe business functions? Or are they experts in the business functions but have not \\nused a computer extensively before? . \\nYou may want to use a skills matrix, similar to Table 6.8, to assess the skill sets \\nof the business people in order to determine how simple or how sophisticated the \\nprototype and the final BI application need to be.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 195}, page_content='If the survey shows an overwhelming number of people with XX skill sets \\n(expert in computer skills and expert in application knowledge), build as many \\nshortcuts as possible. If the survey shows an overwhelming number of people \\nTable 6.8: Skills Matrix \\nComputer Skill \\nBusiness Functions Knowledge Beginning (B) Advanced (A) Expert (X) \\nBeginning (B) BB BA BX \\nAdvanced (A) AB AA AX \\nExpert (X) XB XA XX SS FE ES SE SLE TS I SE TIE'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 196}, page_content='Application Prototyping Activities 163 \\nwith BB skill sets (beginner in computer skills and beginner in application \\nknowledge), provide as much guidance and help functionality as possible. If the \\nsurvey shows an overwhelming number of people with any other skill set combi- \\nnation, you need to take a hard look at your proposed solution and decide \\nwhether only one solution will be sufficient. If the BI application is designed for'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 196}, page_content='only one level of skills but has to satisfy everybody using the application, either it \\nwill be perfect for beginners but the experts will be bored and frustrated, or it will \\nbe perfect for experts but the beginners will be lost and frustrated. \\nAPPLICATION PROTOTYPING ACTIVITIES \\nThe activities for application prototyping do not need to be performed linearly. \\nFigure 6.3 indicates which activities can be performed concurrently. The list below'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 196}, page_content='briefly describes the activities associated with Step 6, Application Prototyping. \\n1 \\nAnalyze access \\nrequirements \\nYj. <Y7 SS \\nDesign reports \\nand queries \\n2 \\nDetermine scope \\nof prototype \\nPrepare \\nprototype charter \\nDemonstrate \\nprototype \\nBuild \\nprototype Select tools \\nfor prototype \\nFigure 6.3: Application Prototyping Activities \\n1. Analyze the access requirements. \\nBased on the business needs, determine the access requirements for reports'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 196}, page_content='and queries. Most access requirements will probably be multidimensional, \\nwhich makes them perfect candidates for prototyping. Also, assess the skill \\nsets of the business people participating in the prototype activities. \\n2. Determine the scope of the prototype. \\nThe business representative and the project manager should determine the \\nscope of the prototype. The scope should be small enough that the prototype \\ncan be built and tested in a matter of days or weeks. It should contain only a'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 197}, page_content='Step 6: Application Prototyping \\nsubset of data, just enough to support the functionality chosen for the proto- \\ntype. Prototyping by definition is iterative, which allows functionality and \\ndata to be added with each prototype iteration. \\n. Select tools for the prototype. \\nYou may want to evaluate the existing suite of tools at your organization \\navailable for building the prototype. People are already trained on those tools'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 197}, page_content='and feel comfortable using them. The comfort factor is a big enabler. If you \\ndecide to select new tools, determine how much training is required, and \\nschedule the training sessions as soon as possible. \\n. Prepare the prototype charter. \\nPut together a short and informal prototype charter that outlines the main \\npurpose for the prototype, the scope of the prototype, what platform it will \\nbe built on, how many iterations you are planning, the time frame for com-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 197}, page_content='pleting the prototype, and who will participate. \\n. Design the reports and queries. \\nBased on the access requirements, design the prototype database and the \\nreports and queries. If a Web front end is part of the prototype, design the Web \\npages as well. Select the relevant data for the prototype, and map the data from \\nthe source files and source databases to the prototype database. Be sure to consult \\nwith the data quality analyst to learn about source data problems. It is best to'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 197}, page_content='leave out poor-quality data rather than contaminate the prototype with it. \\n. Build the prototype. \\nBuild the prototype based on the initial database design, report and query \\ndesigns, and Web page designs. Expect that the design will change several \\ntimes. Use this opportunity to test various database and application tuning \\ntechniques. The database structures as well as the reports and queries devel- \\noped during the prototype could be used as a yardstick to validate the time'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 197}, page_content='and cost estimates for the final BI application. \\n. Demonstrate the prototype. \\nPrepare demonstrations with as much functionality as the type of prototype \\nyou have chosen allows. A show-and-tell prototype will have much less func- \\ntionality than an operational prototype. Run the demonstrations for a short \\ntime and solicit approval for the BI project and additional support for the BI \\ninitiative as a whole. The demonstrations should be considered a BI market-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 197}, page_content='ing activity in addition to being a vehicle for validating the requirements and \\nfunctionality of the BI application. \\nRepeat the process outlined above for additional prototype iterations.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 198}, page_content='Roles Involved in These Activities 165 \\nDELIVERABLES RESULTING FROM THESE ACTIVITIES \\n1. Prototype charter \\nThis document is similar to a project charter because it represents an agree- \\nment between the business sponsor and the IT staff regarding the prototyp- \\ning activities for the BI project. It contains the following sections: \\n— Primary purpose for the prototype \\n— Prototype objectives \\n— Prototype participants \\n— Data to be used for the prototype'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 198}, page_content='— Hardware and software platforms to be used \\n— Measures of success \\n— Application interface agreement \\n2. Completed prototype \\nThe main deliverable from this step is a completed prototype. This can be a \\ndemo, a few mocked-up screens, or a partially functioning BI application. \\n3. Revised application requirements document \\nDuring prototyping, you may discover new requirements or decide to change \\nor drop some of the original ones. Reflect these changes in the application'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 198}, page_content='requirements document. \\n4. Skills survey matrix \\nThis matrix indicates the skill sets of the business people. It should state whether \\na business person has beginning, advanced, or expert skills in computer usage as \\nwell as knowledge about the business functions pertaining to the BI application. \\n5. Issues log \\nDocument any issues that came up during prototyping (whether they were \\nresolved or not) in an issues log, indicating status or final resolution, impact'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 198}, page_content='on the real BI application, action items to pursue, and to whom the action \\nitems were assigned. \\nROLES INVOLVED IN THESE ACTIVITIES \\n@ Application lead developer \\nThe application lead developer should review the application requirements \\ndocument with the business representative, and together they should prepare \\na short and informal prototype charter. The application lead developer should \\nalso review the existing or mock-up report and query layouts, which will form'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 199}, page_content='166 Step 6: Application Prototyping \\nthe basis for the prototype design. He or she also has to make plans for sched- \\nuling the prototype demonstrations. \\n® Business representative \\nThe primary responsibility of a business representative is to use the prototype \\nto learn about the feasibility and the look and feel of the BI application. The \\nbusiness representative should assist the application lead developer in creating'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 199}, page_content='the prototype charter. The business representative also needs to review the \\noverall BI project requirements and revise them if necessary. This can be \\naccomplished only if the business representative participates in the design and \\nthe review of the prototype and is actively involved in the demonstrations. \\n@ Database administrator \\nThe database administrator is responsible for designing and loading the pro- \\ntotype database with sample source data or sample test data. He or she should also'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 199}, page_content='review all database access calls (Structured Query Language [SQL] statements). \\n@ Stakeholders \\nThe stakeholders do not directly participate in the BI project activities, but \\nthey have a vested interest in the project. They should take part in the proto- \\ntype demonstrations and provide input regarding any additional common \\naccess requirements for reports, queries, and ad hoc usage. \\n@ Subject matter expert \\nThe subject matter expert has to analyze and discuss the access and analysis'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 199}, page_content='requirements for reports and queries with the prototyping team. He or she \\nshould work with the business representative and project manager to deter- \\nmine the purpose, goals, and primary use of the prototype. \\n@ Web master \\nThe Web master has to review the existing tools slated for use with Web access \\nto the BI application. The Web master also has to evaluate the usability of the \\nprototype design with regard to Web access and has to determine the neces- \\nsary interfaces.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 199}, page_content='sary interfaces. \\nRISKS OF NOT PERFORMING STEP 6 \\nThe main purpose of prototyping is to make sure that the design of the database, \\nthe design of the access and analysis application, and the BI technologies selected \\nwill be able to meet the business requirements when the BI application is imple- \\nmented as intended. By building a successful prototype, you can also validate the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 200}, page_content='Bibliography and Additional Reading 167 \\naccuracy of your cost and time estimates for the full-scale final BI application. \\nThe risk of not performing this step is that you may build a BI solution that will \\ncost much more and take much longer than you expected—and that you will not \\nrealize it until it is too late. \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nBajaj, Chandrajit. Trends in Software: Data Visualization Techniques. New York: \\nJohn Wiley & Sons, 1999.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 200}, page_content='Beck, Kent. Extreme Programming Explained: Embrace Change. Boston, MA: \\nAddison-Wesley, 2000. \\nCockburn, Alistair. Agile Software Development. Boston, MA: Addison-Wesley, \\n2002. \\nDevlin, Barry. Data Warehouse: From Architecture to Implementation. Reading, MA: \\nAddison-Wesley, 1997. \\nHumphrey, Watts S. Winning with Software: An Executive Strategy. Boston, MA: \\nAddison-Wesley, 2002. \\nKimball, Ralph, Laura Reeves, Margy Ross, and Warren Thornthwaite. The Data'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 200}, page_content='Warehouse Lifecycle Toolkit: Expert Methods for Designing, Developing, and \\nDeploying Data Warehouses. New York: John Wiley & Sons, 1998. \\nShneiderman, Ben. Designing the User Interface: Strategies for Effective Human- \\nComputer Interaction. Boston, MA: Addison-Wesley, 1998. \\nTurkle, Sherry. Life on the Screen: Identity in the Age of the Interface. New York: \\nSimon & Schuster, 1997.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 201}, page_content='- wy \\nsnellotges Ni 1 aiiieun aete jtrieli.® Ont Mine Sa ey ee \\nHewebAle SA, ea TE TE tele Perd o que. eit anierotaey weit y aire \\nVion Tibeeaging ooh rhb meriabs px ery ey 1079 capi thayert oat hasan \\nTheyre? veep walt lie ud) Seine a yreanaaeel ochineg \\niti Wns ‘Gated ther tah lve che bid oh fnel of (ie tht opel \\n| [apalennes so yprotaenr Sagan ieethd ¢ co) hes prom aly ‘¢ohdes \\n7 ible nly iq. foarte), TH ta) een a muses :'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 201}, page_content=\"- 0! i i teres end. 7 what 40 aulginia® yqpine: y win! m2 scanty, easy 6 if i <eel™, ie a! f Si \\na A Le Ayer ane sctivily areved it] ned ; \\naH gpd, sw, nel Sonunian' renner es coat a \\n: The bie Ghali 4 eronnuble dip eign en — \\nteed Sopa lplads, 2A Mbpaccarnet!] wAttere aly ath cael k ois, \\ngreiowm ol! ijateeie 40094 A le treet | wipe) lang re: ‘Lye r \\nsold cyilD crib ongimaesvesbaen enue, as say (pie? wa aa Wve] x \\n; Thap piekghodorny ilar’ 60) 44 pela eal? an 4D, uy aa\"),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 201}, page_content='(Al iahod ay rant, mira i linke gree thon danibhie g . \\n: bye AC rasaiel te ioey anal fiiie ila siege i carl te Ss af ; \\nmx ie ST NEG ME ar Brin ai apr re Lapse ig ca \\nWis hig Glare eaters 6G tLetri reqh tetedh aan AT \\nibe _ PET OORT ramon eal ds cat elt liga wad { anani agehin i. \\nwa HH Mihi ant SAGA he) HN WEEE Nie - \\n=e BN pote’ iets eile Ate Tiel \\nsped whvtvanl Wi te\" yr Ah! Line rae GAL ree 5 igi \" cold @ \\n> a WOW pita PAP i) & eke ore “ram datey / 7 oo'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 201}, page_content='ig> “WW A $ptetacst thi, \"le NOL OueiT™ areola 4 ets ly ar Shp - \\nPIR ITY Gig + Griese’ STIVOG 4 iil ian Wh dots 7 ae \\nee 46 ae = \\nwe \\ni \\nx 5 \\n6 \\nSiren ir PCa? Pe ejeneye; See A : \\niwi i ne oe LO ie ee GRO? eG hed \\ni) cer + ie i “eT onl PY \\\\% app aiiiu;, pm \\npel! Gig Alsee (yi eg eld tes alsa ~ ap pat, Nag R \\nemaAles’) O46 Nk Wile ti. “pall “uw @Vre i tips vy apn Me \\nreece'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 202}, page_content='<r Step 7: Meta Data \\nPlanning | Repository Analysis \\nCHAPTER OVERVIEW \\nThis chapter covers the following topics: \\n@ Things to consider when analyzing whether to license (buy) \\nor build a meta data repository \\nmg Why it is important to deliver meta data with every BI \\nproject Meta Data \\nRepository \\nAnalysis \\nm@ The differences between the two categories of meta data: \\nbusiness meta data and technical meta data \\n@ How a meta data repository can help business people find'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 202}, page_content='and use their business data after the data has been stan- \\ndardized for the BI decision-support environment \\nm@ The four groupings of meta data components: ownership, \\ndescriptive characteristics, rules and policies, and physical \\ncharacteristics \\n@ How to prioritize meta data for implementation purposes i ie, B Be ap @ \\nwONS TUK \\na= m Five common difficulties encountered with meta data \\n\\\\ [Meta Data | repository initiatives: technical, staffing, budget, usability,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 202}, page_content='\\\\ “hy and political challenges \\nyy @ The entity-relationship (E-R) meta model used to document \\nthe meta data requirements /\\\\ SS \\n@ A definition and examples of meta-meta data \\nDeployment DENG @ Brief descriptions of the activities involved in meta data \\n( : repository analysis, the deliverables resulting from those \\nactivities, and the roles involved \\n@ The risks of not performing Step 7 \\n169'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 203}, page_content='170 Step 7: Meta Data Repository Analysis \\nTHINGS TO CONSIDER \\nMeta Data Repository Usage \\n¥Y Who will be using the meta data in the meta data repository? \\nY What standards do we have in place for its use? What standards do we need \\nto develop? \\nY Do we already have a meta data repository? If not, will we license (buy) one \\nor build one? \\nY Will this meta data repository support only the BI decision-support envi- \\nronment, or will it be used for all systems throughout the organization?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 203}, page_content='Y How will we know if we are using the meta data repository effectively? \\nMeta Model Requirements \\n/Y Do we need to create a meta model for the meta data repository, or do we \\nalready have one? \\nV If we have one, what meta data objects do we need to add to it? \\n¥ Which meta data repository products support our meta model? \\nV Are these meta data repository products extendable? \\nMeta Data Repository Security \\n¥ What type of security will we need for the meta data repository?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 203}, page_content='¥ Who will be authorized to enter and maintain the meta data? \\nV Will everyone be authorized to access any meta data at any time? \\nMeta Data Capture \\n¥ What types of business meta data do we need to capture? \\nV Will we be using a computer-aided software engineering (CASE) tool to \\ncapture the business meta data? \\nv What type of technical meta data do we need to capture? \\nVv Will we be capturing technical meta data in the extract/transform/load'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 203}, page_content='(ETL), online analytical processing (OLAP), and other access and analysis \\ntools? \\nV How will we extract the meta data from these tools and migrate it to the \\nmeta data repository? Who is responsible for migrating it? \\nY Who will connect the business meta data from the CASE tool to the techni- \\ncal meta data from the ETL, OLAP, and other tools? |'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 204}, page_content='171 \\nMeta Data Delivery \\n¥Y How will meta data be displayed? How will it be accessed? Will we have a \\nWeb interface to the meta data repository? \\nVv Will we need to produce meta data reports? What types of reports? \\n¥ How will these reports be distributed? \\n¥ Will there be a help function (online tutorial)? Will the help function be \\ncontext sensitive? \\nStaffing \\n¥ Do we already have a meta data administrator? If not, do we have a data'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 204}, page_content='administrator with technical skills who can perform the functions of a meta \\ndata administrator? \\nV Will we have to hire more meta data administrators? \\nV How will meta data responsibilities be divided among data administrators \\nand meta data administrators? \\nA meta data repository is a database. But unlike ordinary databases, a meta \\ndata repository is not designed to store business data for a business application.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 204}, page_content='Instead, it is designed to store contextual information about the business data. \\nExamples of contextual information about business data include the following: \\n* Meaning and content of the business data \\n* Policies that govern the business data \\n* Technical attributes of the business data \\n- Specifications that transform the business data \\n* Programs that manipulate the business data \\nContextual information about business data inherently exists in every organi-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 204}, page_content='zation, whether it is documented or not. When contextual information is docu- \\nmented, it is known as meta data. When the information is not documented, it is \\nusually not known to everyone in the organization. As a result, business people \\noften invent their own business rules and create their own redundant data along \\nwith redundant processes, not realizing (or sometimes not caring) that what they \\nneed may already exist. Forty years of such practices have now brought most'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 204}, page_content='organizations to the brink of drowning in data and dehydrating from lack of \\ninformation.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 205}, page_content='172 Step 7: Meta Data Repository Analysis \\nTHE IMPORTANCE OF META DATA \\nMeta data describes an organization in terms of its business activities and the busi- \\nness objects on which the business activities are performed. Consider, for example, \\na sale of a product to a customer by an employee. The sale is a business activity and the \\nproduct, customer, and employee are the business objects on which the sale activity is'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 205}, page_content='performed. Business activities and business objects, whether manual or automated, \\nbehave according to a set of relationships and rules, which are defined by the busi- \\nness. These activities and objects, and the relationships and rules that govern them, \\nprovide the context in which the business people use the business data every day. \\nMeta data is so important for the BI decision-support environment because it \\nhelps metamorphose business data into information. The difference between'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 205}, page_content='data and information is that information is raw data within a business context. \\nMeta data provides that business context; that is, meta data ensures the correct \\ninterpretation (based on activities, objects, relationships, and rules) of what the \\nbusiness data actually means. \\nFor example, what is profit? Is it the amount of money remaining after a \\nproduct has been sold and everybody who was involved in that product has been'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 205}, page_content='paid? Or is it a more complicated calculation, such as “total annual revenue \\nminus sum of average base cost per product minus actual staff overhead minus \\naccumulated annual production bonuses minus wholesale discounts minus cou- \\npons divided by twelve?” Does every business person have the same understand- \\ning of profit? Is there one and only one calculation for profit? If there are different \\ninterpretations of profit, are all interpretations legitimate? If there are multiple'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 205}, page_content='legitimate versions for profit calculations, then multiple data elements must be \\ncreated, each with its own unique name, definition, content, rules, relationships, \\nand so on. All of this contextual information about profit is meta data. \\nSince meta data provides the business context in which business data is used, \\nmeta data can be viewed as a semantic (interpretive) layer of the BI decision-sup- \\nport environment. This semantic layer helps the business people navigate'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 205}, page_content='through the BI target databases, where the business data resides. It also helps the \\ntechnicians manage the BI target databases as well as the BI applications. \\nSome important characteristics of meta data and meta data repositories are \\nlisted below. \\n* A meta data repository is populated with meta data from many different \\ntools, such as CASE tools, ETL tools, OLAP tools, and data mining tools.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 206}, page_content='The Importance of Meta Data 173 \\n* Meta data documents the transformation and cleansing of source data and \\nprovides an audit trail of the periodic data loads. \\n* Meta data helps track BI security requirements, data quality measures, and \\ngrowth metrics (for data volume, hardware, and so on). \\n* Meta data provides an inventory of all the source data that populates the BI \\napplications. \\n* Meta data can be centrally managed, or it can be distributed. Either way, each'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 206}, page_content='instance of a meta data component should be unique, regardless of its physi- \\ncal location. \\nMeta Data Categories \\nThere are two categories of meta data: business meta data and technical meta data. \\n1. Business meta data provides business people with a roadmap for accessing \\nthe business data in the BI decision-support environment. Since many busi- \\nness people are relatively nontechnical, they should have access to meta data,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 206}, page_content='which defines the BI decision-support environment in business terms they \\nunderstand. \\n2. Technical meta data supports the technicians and “power users” by provid- \\ning them with information about their applications and databases, which \\nthey need in order to maintain the BI applications. \\nTable 7.1 highlights some differences between business meta data and techni- \\ncal meta data. \\nTable 7.1: Business Meta Data versus Technical Meta Data \\nBusiness Meta Data Technical Meta Data'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 206}, page_content='* Provided by business people * Provided by technicians or tools \\n¢ Documented in business terms on data ¢ Documented in technical terms in \\nmodels and in data dictionaries databases, files, programs, and tools \\n* Used by business people ¢ Used by technicians, “power users,” data- \\nbases, programs, and tools (e.g., ETL, OLAP) \\n* Names fully spelled out in business ¢ Abbreviated names with special charac- \\nlanguage ters, such as “_” (underscore) or “—’ (dash),'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 206}, page_content='used in databases, files, and programs \\nRS EE SE ET TL SL II I AT IAL DE AE IT EE IOI TE'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 207}, page_content='174 Step 7: Meta Data Repository Analysis \\nMETA DATA REPOSITORY AS NAVIGATION TOOL \\nMeta data is not new; it has always been part of operational systems. It can be \\nfound in systems documentation, record layouts, database catalogs, and data dec- \\nlaration sections in programs. The role of meta data in an operational environ- \\nment was always viewed as systems documentation, which was mainly used by the \\ntechnicians who maintained the operational systems. When some of the systems'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 207}, page_content='documentation (meta data) became outdated, the technical staff had enough \\nskills to read through the actual programming code to extract the information \\nthey were looking for, such as the meaning and content of a data element. Thus, \\nmore often than not, meta data was treated as an afterthought. \\nIn a BI decision-support environment, meta data takes on a new level of \\nimportance. A new audience has to be serviced, namely, the business people.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 207}, page_content='Meta data helps them locate, manage, understand, and use the data in the BI tar- \\nget databases. Meta data has a new role: navigation, not just documentation. \\nBusiness people ordinarily do not have the technical skills, nor the time or desire, \\nto decipher programming code. They also do not want to stay dependent on the \\nIT department to interpret the meaning and content of the data after it has been \\nmanipulated by the programs. Rather than calling a programmer, a business per-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 207}, page_content='son should be able to access the meta data, which would then help him or her \\neffectively navigate through the BI decision-support environment and interpret \\nthe BI data. As illustrated in Figure 7.1, meta data describes what data is available \\nMeta Data \\nRepository \\nWhere is the \\ninformation \\nWe * What data do we have? \\n* Where is it located? \\n* What format is it stored in? \\n+ Who is responsible for the content? \\n+ When was the source data last updated?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 207}, page_content='+ Which tools should be used for retrieval? \\n+ Has someone prepared the query or report | need? \\n“..¢ How do | initiate it? \\nvipa \\nFigure 7.1: Using a Meta Data Repository as a Navigation Tool'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 208}, page_content='Meta Data Repository as Navigation Tool 175 \\nin which BI target database, where the data came from, how to access it, how to \\ndrill down to the detailed data for closer examination, and how to use it. \\nData Standardization \\nIf business data had been stored and used in a consistent, approved manner all \\nalong, the data redundancy and inconsistency problems that currently plague \\nmany operational systems would not exist to the extent they do today. Unfortu-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 208}, page_content='nately, bad habits die hard. Developers and business people still explicitly or \\nimplicitly reuse the business data in operational systems for different purposes. \\nFor example, developers still explicitly redefine data elements in their programs, \\nand business people still implicitly redefine (invent new codes for) existing data \\nelements to capture unrelated information. Documentation of these redefinitions \\nalso remains poor or nonexistent. If any documentation exists, it is rarely distrib-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 208}, page_content='uted to everyone in the organization who needs it, and it is very seldom kept up- \\nto-date. Therefore, business people continue to invent their own business rules \\nand create their own redundant data along with redundant processes. \\nEvery BI project team must address this existing data chaos and must make \\nevery attempt to promote the standardization of data. While standardizing the \\nbusiness data for the BI decision-support environment, the BI project team'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 208}, page_content='should document all changes made to the data so that everyone can be aware of them. \\nThis documentation takes the form of meta data in the meta data repository. For \\nexample, a source data element could be renamed to conform to new naming \\nstandards, or data values could be filtered, added, or transformed to enforce a \\nbusiness rule. In both cases, the BI data in the BI target database would no longer \\nmatch the source data in the source file or source database. The meta data would'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 208}, page_content='provide the navigation between the two. \\nUsing BI applications without knowing that the business data was changed \\nand how it was changed can be a frustrating experience that can eventually end \\nwith the business people no longer wanting to use the BI applications at all. That \\nwould be devastating since one of the most important aspects of a BI decision- \\nsupport initiative is to provide an easy-to-use, intuitive way for the business people'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 208}, page_content='to access and query the data. An easy-to-use application means the business people: \\n* Have no need to be relational technology experts \\n- Have no need to know Structured Query Language (SQL) \\n* Have no need to know the physical structure of the databases \\n* Have no need to know the location of their data'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 209}, page_content='176 Step 7: Meta Data Repository Analysis \\n- Have no need to guess the meaning of the data \\n* Have no need to search for the required information \\nMETA DATA CLASSIFICATIONS \\nSince BI projects can generate a great number of meta data components, it is useful \\nto classify these components and to prioritize them for incremental implementation. \\nGroupings of Meta Data Components \\nMeta data components can be sorted into four meta data groupings or classifica-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 209}, page_content='tions: ownership, descriptive characteristics, rules and policies, and physical \\ncharacteristics (Figure 7.2). The meta data repository should be able to store the \\nmeta data components of all four classifications, as listed below. \\n2 \\nDescriptive \\nCharacteristics \\n« Business data \\n« Business processes \\n* Data owner \\n3 + Application owner \\n¢ Business rules Rules and \\n¢ Business policies Policies \\n4 \\nPhysical \\nCharacteristics \\n* Technical data features \\n* Application features'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 209}, page_content='Figure 7.2: Meta Data Classifications \\nOwnership \\n* Data owner: Data is owned by the organization. However, since the organiza- \\ntion is a legal entity and not a person, someone in the organization must take \\non the authority and responsibility to set policy, determine rules, and estab- \\nlish standards for the organizational data. This authority and responsibility \\ncan be distributed among line-of-business managers or assigned to a data'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 209}, page_content='ownership committee (whose members will most likely be some or all of the \\nline-of-business managers). An example of distributed data ownership is a'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 210}, page_content='Meta Data Classifications 177 \\nmanager of the human resource department who has the authority and \\nresponsibility to establish policies, rules, and standards for payroll data but \\nnot for product data. With data ownership by committee, the committee \\nestablishes policies, rules, and standards for all data by consensus, by delega- \\ntion to a committee member, or by some other committee rule. \\nApplication owner: Traditionally, ownership has been assigned to a system as'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 210}, page_content='a whole. Since a system is usually composed of an application and its data, \\n“system ownership” implies that the same person has authority to set policy, \\ndetermine rules, and establish standards for both data and functionality (the \\napplication). That may be a valid condition for operational systems where \\ndata is originated, but it is not valid for BI applications because most business \\npeople using the BI applications are not the same individuals who originate'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 210}, page_content='the operational data. Therefore, BI information consumers may own the BI \\napplication, but most of them will not own the data. \\nDescriptive Characteristics \\nName: Every data object, data element, and business process should have a \\nunique name. \\nDefinition: Every data object, data element, and business process should have \\na brief definition explaining what it is. \\nType and length: Every data element should have an official type and length'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 210}, page_content='declared for it, even if the data elements in the source systems or the columns \\nor cells on the target databases may deviate from it. That deviation would \\nalso be defined as meta data under the data element, the column, or the cell \\nwhere it occurred. \\nDomain: Every data element should have a declared set of allowable values, \\neven if the set is all-inclusive, such as “any character, number, or sign.” \\nNotes: Additional facts of interest about data or processes should be included.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 210}, page_content='This is a catchall for free-form comments, such as “Dispute between engi- \\nneering and marketing regarding the meaning of Product Subcomponent \\nType Code was turned over to the BI steering committee for resolution.” \\nRules and Policies \\nRelationships: Data objects are related to each other through business activi- \\nties. The meta data repository should be able to store information about \\nthese relationships.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 211}, page_content='178 Step 7: Meta Data Repository Analysis \\n- Business rules and business policies: These components can apply to data as \\nwell as to processes. They can be technical data conversion rules, business \\ndata domain rules, business data integrity rules, or processing rules. \\nSecurity: Requirements for security can apply to data, meta data, processes, \\ndatabases, applications (programs and screens), tools, and Web sites. \\nCleanliness: Metrics about the ETL reconciliation totals and about the qual-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 211}, page_content='ity of the BI data should be stored. The metrics can be expressed as reliability \\npercentages of a data load (e.g., 89 percent of the customer type code is valid) \\nor as record counts stating the number of records filtered (rejected) and the \\nnumber of records passed through during the ETL process. \\nApplicability: Data does not live forever. Occasionally, new data is invented \\nand captured, and old data is retired and no longer used. Since the BI target'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 211}, page_content='databases store many years of history, some columns or cells will not have \\nvalues for all time periods because the data was not applicable or did not exist \\nduring certain time periods. If spikes appear on trend analysis graphs, the \\nmeta data repository should be consulted to determine the applicability of \\nthat particular piece of data. \\n- Timeliness: Business people will want to know when the source data was last \\nupdated and which of the versions of the operational systems were used for'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 211}, page_content='the update. Not all operational systems run daily or on the same day of the \\nmonth. One operational system may run on the last calendar day of the \\nmonth while another may run on the last business day of the month. Some \\noperational systems do not “close out the month” until they complete an \\nadjustment run four to ten days after the last calendar day of the month. \\nPhysical Characteristics \\n* Origin (source): Since BI target databases only store existing operational data'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 211}, page_content='(internally generated and externally purchased), the origin or source for each \\ndata element should be documented. One column in the BI target database \\ncan be populated with data elements from multiple sources. For example, the \\ncolumn Account Balance in the Account table could be populated from the \\ndata element Demand Deposit Account Balance in the Checking Account \\nsource database and from the data element Time Deposit Account Daily Balance'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 211}, page_content='in the Savings Account Transaction file. Conversely, one source data element \\ncan feed multiple columns in the BI target database. For example, the data \\nelement Type Code may be used for two purposes in the operational system.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 212}, page_content='Meta Data Classifications 179 \\nThe data values “A”, “B”, and “C” of Type Code may be used to populate the \\ncolumn Customer Type Code in the Customer table, and the data values “N”, \\n“O”, and “P” of the same Type Code may be used to populate the column \\nProduct Type Code in the Product table. \\nPhysical location: Several meta data components (e.g., tables, columns, \\ndataset names) should describe where the data resides in the BI decision-sup- \\nport environment.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 212}, page_content='port environment. \\nTransformation: Very few data elements can be moved from source to target \\nwithout any type of transformation. At a minimum, the data type and length \\nmay have to change, or single-character codes may have to be translated into \\nmulti-character mnemonics. In the worst case, lengthy business rules may \\nrequire more complicated transformations involving editing, filtering, com- \\nbining, separating, or translating data values.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 212}, page_content='Derivation: This component stores the calculation for derived columns. \\nWhile derived columns are customarily not stored in operational systems, it \\nis the norm to store them in BI target databases. \\nAggregation and summarization: Similar to derivation, aggregation and \\nsummarization rules should be stored as meta data. \\nVolume and growth: The size and growth of BI target databases are often \\nenormous. Therefore, projected as well as actual volumes should be docu-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 212}, page_content='mented as meta data in terms of the number of rows and the percentage of \\nexpected growth. \\nBusiness people most frequently access the meta data components in the \\ndescriptive characteristics classification as well as the rules and policies classifica- \\ntion (Figure 7.3). Technicians typically access the meta data components in the \\nphysical characteristics classification (Figure 7.4). \\nPrioritization of Meta Data Components'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 212}, page_content='Capturing all meta data components may not be necessary or practical for all BI \\nprojects. However, capturing none is unacceptable. As a rule, meta data should be \\na deliverable with every BI project. It will serve the business people to recognize \\ntheir old data, trace what happened to it (transformation), locate it in the new BI \\ntarget databases, and determine how to use it properly. In other words, the busi-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 212}, page_content='ness people will greatly benefit from having meta data available to help them nav- \\nigate through the BI decision-support environment.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 213}, page_content='180 Step 7: Meta Data Repository Analysis \\nContent \\nBusiness rules \\nTransformation Business policies 5 baa : l 5 quality \\nDerivation Valid values °%s° Metrics Aggregation \\nC=A+B \\niy \\nBusiness names \\nDefinitions Timeliness \\nApplicability \\nOrigin ot \\n(Source) Security (Ownership) \\nFigure 7.3: Meta Data Usage by Business People \\nContent \\nValid values \\nTransformation Ranges \\nDerivation Business rules \\nAggregation \\nC=A+B \\nTechnical names \\nSize and length \\nPhysical Location \\nTable name \\nColumns'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 213}, page_content='Columns \\nIndices \\nTechnician \\nSecurity \\n(Implementation) \\nFigure 7.4: Meta Data Usage by Technicians'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 214}, page_content='Meta Data Classifications 181 \\nNot all meta data components have the same value to all business people or \\nall BI applications. It might be useful to prioritize the meta data components into \\nthree groups: mandatory, important (beneficial but not mandatory), and \\noptional. Table 7.2 shows a recommended prioritization scheme for capturing \\nmeta data components in a meta data repository. \\nTable 7.2: Prioritization of Meta Data Components \\nMeta Data Mandatory Important Optional \\nOwner A'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 214}, page_content='Owner A \\nBusiness data name / \\nTechnical data name f \\nDefinition of \\nType and length oY \\nContent (domain) Wa \\nRelationships Y \\nBusiness rules and policies f \\nSecurity f \\nCleanliness Ue \\nApplicability f \\nTimeliness Sf \\nOrigin (source) o \\nPhysical location (BI databases) f \\nTransformation Y \\nDerivation f \\nAggregation oY \\nSummarization S) \\nVolume and growth \\nNotes v \\na I I IE I EE I SE I TT'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 215}, page_content='182 Step 7: Meta Data Repository Analysis \\nPaw All mandatory meta data components, and as many important meta data com- \\nponents as possible, should be captured and stored in the meta data reposi- \\ntory. Optional meta data components could be postponed to future Bl \\napplication releases. \\nMETA DATA REPOSITORY CHALLENGES \\nGood ideas are often hard to implement. Providing a meta data repository is a \\ngood idea but also quite a challenging one, regardless of whether the decision is'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 215}, page_content='made to license (buy) a commercially available product or to build a repository \\nfrom scratch. This section briefly describes the challenges faced when imple- \\nmenting a meta data repository (Figure 7.5). \\nBudget \\nStaffing e @ \\n® Usability \\nlee @ Political \\nChallenges \\nFigure 7.5: Meta Data Repository Challenges \\nTechnical Challenges \\nBuilding a meta data repository is not a trivial task. It is a project in itself, with its'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 215}, page_content='own project plan, its own development steps, and its own staff. All the technology \\nchallenges that apply to databases and applications can surface on meta data \\nrepository projects. \\nLicensing a meta data repository product is an alternative to building one, but \\nthe “plain vanilla” versions of commercially available meta data repository prod- \\nucts often do not meet all the meta data requirements of a BI decision-support'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 215}, page_content='environment. Therefore, licensing a meta data repository product still necessi- \\ntates extensive analysis of the requirements in order to select the right product, as \\nwell as a considerable implementation effort to enhance it.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 216}, page_content='Meta Data Repository Challenges 183 \\nEnhancing licensed software comes with its own challenges. The source code \\nfor the product may not be available. The vendor may insist on incorporating the \\nrequested enhancements for a price and at his or her own speed. The time and \\neffort required for product maintenance increase because the enhancements \\nmust be reapplied to the new releases and versions of the licensed meta data \\nrepository product. \\nStaffing Challenges'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 216}, page_content='Meta data should be “living” documentation stored in a database, that is, in the \\nmeta data repository. Storing meta data as paper documents is guaranteed to \\nturn it into “shelfware” within months, if not weeks. This means that, at a mini- \\nmum, one meta data administrator must be dedicated full-time to managing the \\nmeta data repository content and the software. If a meta data repository is being \\nbuilt as part of the BI project, a staff of one person will not be enough. The meta'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 216}, page_content='data repository effort will require an analyst, a data modeler, a database designer, \\nand one or more developers. \\nBudget Challenges \\nAlthough many BI experts think of meta data as the “glue” of the BI decision- \\nsupport environment, most organizations allocate little or no money for creating \\nand maintaining a meta data repository. They still regard meta data as systems \\ndocumentation for technicians, rather than a navigation tool for business people.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 216}, page_content='The pain of access frustration and data confusion must often reach an intolerable \\nlevel before organizations include meta data as a mandatory and standard deliv- \\nerable of their BI projects. \\nPaw Lack of meta data has frequently been cited as one of the reasons for BI appli- \\ncation failure. \\nUsability Challenges \\nUsing a meta data repository should be completely intuitive. Business people \\nshould be able to click on an icon and immediately get the requested information'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 216}, page_content='about a table or column, a chart or report, or even a business query. More com- \\nplex inquiries against the meta data repository should be handled with built-in or \\ncustomized macros. However, the most polished way to present meta data is to \\ninclude it in BI queries, as shown in Figure 7.6.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 217}, page_content='184 Step 7: Meta Data Repository Analysis \\nMonthy Sales Report \\nUS Sales ($) | Canada Sales ($) Total Sales ($) \\nJanuary Apples \\nBananas \\nCoconuts ; \\nFebruary Apples 22,500 8,500 \\nBananas 10,000 \\nCoconuts \\nMarch Apples \\nBananas 9,900 \\nCoconuts 2,400 =k \\nData Quality Load Statistics: \\n51% of $ values not loaded \\n10% of source records not loaded \\nMeta Data ———»> \\nFigure 7.6: Example of Meta Data in a BI Query \\nUnfortunately, many meta data repository products are still designed by tech-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 217}, page_content='nicians for technicians rather than for business people. Some of these products \\nstill have a cryptic meta data language, lack sophisticated reporting capabilities, \\nare not context sensitive, and require an understanding of the meta model that \\ndescribes the meta data objects and their relationships. \\nPolitical Challenges \\nBuilding an enterprise-wide meta data solution is difficult because departmental \\ndifferences must be reconciled and cross-departmental politics must be resolved.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 217}, page_content='These disputes, although totally predictable, are rarely taken into account when \\nthe project plan is created. As a result, projects are delayed while these issues are \\naddressed or pushed up to business executives and steering committees. This \\ngives the impression that BI projects are difficult, controversial, tiresome, drain- \\ning, slow, and generally undesirable work. \\nDespite all these challenges, a meta data repository is a mandatory compo- \\nnent of every BI decision-support environment.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 217}, page_content='THE LOGICAL META MODEL \\nRegardless of whether the meta data repository is licensed or built, and regardless of \\nthe implementation method (centralized, decentralized, or distributed, as discussed'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 218}, page_content='The Logical Meta Model 185 \\nin Step 10, Meta Data Repository Design), the meta data repository should sup- \\nport a logical meta model, which reflects the meta data requirements. As with \\nbusiness data, each component of meta data is unique by nature. It is important \\nto define these unique meta data objects, their contents, their interrelationships, \\nand their interdependencies, independent of how they will be stored or accessed.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 218}, page_content='The technique for this activity is logical data modeling, only in this case it will \\nproduce a logical meta model. \\nA logical meta model is a data model that indicates objects, the relationships \\nbetween the objects, and the cardinality and optionality of the relationships. The \\ndifference between a logical meta model for a meta data repository and a logical \\ndata model for a business application lies in the nature of the objects. Objects in a'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 218}, page_content='logical meta model represent meta data, such as entity, attribute, definition, \\ndomain, table, column, and index. Objects in a logical data model represent busi- \\nness data, such as customer, product, employee, account, and location. \\nThe Entity-Relationship Meta Model \\nA logical meta model is created during the first meta data initiative and is \\nexpanded with each subsequent initiative. The logical representation of meta data'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 218}, page_content='objects should be captured as an E-R diagram because of its explicit definitions of \\nthe meta data objects, the relationships among them, and the contents of the \\nobjects. Figure 7.7 shows an example of an E-R meta model. \\nAn E-R meta model primarily helps people understand, communicate, and \\nvalidate the meta data requirements. Therefore, an E-R meta model should be \\nviewed as a requirements model to be used for evaluating meta data repository'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 218}, page_content='Figure 7.7: Entity-Relationship Meta Model. (Short vertical lines indicate “one,” and the \\ncrow’s feet indicate “many.”)'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 219}, page_content='186 Step 7: Meta Data Repository Analysis \\nproducts and for setting a baseline when designing a customized meta data \\nrepository, even if its physical meta model (database design) ends up being \\nobject-oriented (OO). \\nMeta-Meta Data \\nSince meta data is the contextual information about business data, meta-meta \\ndata is the contextual information about meta data. Many components of meta- \\nmeta data are similar to those of meta data. For example, every meta data object'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 219}, page_content='should have components that cover name, definition, size and length, content, \\nownership, relationship, business rules, security, cleanliness, physical location, \\napplicability, timeliness, volume, and notes. The meta-meta data for a meta data \\nobject might look like this: \\n* Name: Entity \\n* Relationship: related to one or many tables \\n* Security: read by all, updated by the data administrator \\n* Ownership: the data administrator \\n* Origin: ERWIN CASE tool \\n* Physical location: MDRSYSENT table'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 219}, page_content='* Cleanliness: 2 percent missing data \\n* Timeliness: last updated on November 1, 2002 \\n* Volume and growth: 2,391 rows, growth rate 1 percent annually \\nMETA DATA REPOSITORY ANALYSIS ACTIVITIES \\nThe activities for meta data repository analysis do not need to be performed lin- \\nearly. Figure 7.8 indicates which activities can be performed concurrently. The list \\nbelow briefly describes the activities associated with Step 7, Meta Data Repository \\nAnalysis.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 220}, page_content='Meta Data Repository Analysis Activities 187 \\nAnalyze meta data \\nrepository requirements \\nia Ce \\n5 \\nAUS hy cua ical Creat requirements for g ay meta model meta-meta data meta data repository \\n\"3 Analyze meta data \\nrepository access and \\nreporting requirements \\n~~ \\nFigure 7.8: Meta Data Repository Analysis Activities \\n1. Analyze the meta data repository requirements. \\nWork with the business representative to determine and prioritize the meta'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 220}, page_content='data requirements for your specific BI project. Indicate which of the meta \\ndata components are mandatory, important, and optional. If a meta data \\nrepository already exists, determine which meta data components need to be \\nadded, if any. Update the latest version of the application requirements docu- \\nment (revised during or after prototyping). \\n2. Analyze the interface requirements for the meta data repository. \\nWhether a meta data repository is licensed or built, it must accept meta data'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 220}, page_content='from different sources. Business meta data will have to be extracted from \\nCASE tools, word processing documents, or spreadsheets. Technical meta \\ndata will have to be extracted and merged from database management system \\n(DBMS) dictionaries, ETL tools, data-cleansing tools, OLAP tools, report \\nwriters, and data mining tools. \\n3. Analyze the meta data repository access and reporting requirements. \\nPopulating a database is meaningless unless the content can be accessed, que-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 220}, page_content='ried, and reported. This is as true for meta data as it is for business data. Iden- \\ntify the meta data access requirements, security requirements, and help \\nfunction requirements. Evaluate alternative display modes, such as Portable \\nDocument Format (PDF), Hypertext Markup Language (HTML), SQL,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 221}, page_content='188 Step 7: Meta Data Repository Analysis \\ncanned queries, or proprietary meta data repository reporting software. A \\ncontext-sensitive help tutorial would be a beneficial feature to include. \\n4. Create the logical meta model. \\nDraw the logical meta model as an E-R model to explicitly show the relation- \\nships between meta data objects, even if you plan to implement the meta data \\nrepository as an OO database. In other words, the logical meta model should'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 221}, page_content='always be an E-R model, while the physical meta model (the meta data repos- \\nitory database design created in Step 10, Meta Data Repository Design) can \\nbe either an E-R model or an OO model. \\n5. Create the meta-meta data. \\nWhile the logical meta model shows the meta data repository requirements at \\na glance, the meta-meta data describes the required meta data components in \\ndetail. \\nDELIVERABLES RESULTING FROM THESE ACTIVITIES \\n1. Logical meta model'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 221}, page_content='This data model is a fully normalized E-R diagram showing kernel entities, \\nassociative entities, characteristic entities, relationships, cardinality, optional- \\nity, unique identifiers, and all attributes for meta data repository objects. \\n2. Meta-meta data \\nThe meta data entities and attributes from the logical meta model must be \\ndescribed with meta data. Meta data—specific meta data components (meta- \\nmeta data) are meta data names, meta data definitions, meta data relation-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 221}, page_content='ships, unique identifiers, types, lengths, domains, business rules, policies, and \\nmeta data ownership. \\nROLES INVOLVED IN THESE ACTIVITIES \\n® Data administrator \\nThe data administrator gathers the business meta data in a CASE tool during \\nthe logical data modeling activities. This meta data will be one of the sources \\nfor the meta data repository. The data administrator, in collaboration with the \\nmeta data administrator, writes and publishes the data standards. He or she'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 221}, page_content='may also assist with creating the meta model and the meta-meta data.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 222}, page_content='Risks of Not Performing Step 7 189 \\n® Meta data administrator \\nThe meta data administrator has primary responsibilities for storing and pro- \\nviding access to the meta data and for maintaining the meta data repository. \\nHe or she must analyze the meta data requirements, identify the meta data \\ncomponents, and produce or enhance the logical meta model and the meta- \\nmeta data. \\n® Subject matter expert \\nThe subject matter expert participates in this step by representing the business'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 222}, page_content='people and their meta data requirements. The subject matter expert identifies \\nsecurity requirements and data ownership and works with the data adminis- \\ntrator, the meta data administrator, the data owners, and other business peo- \\nple to standardize names, definitions, content, and business rules. \\nRISKS OF NOT PERFORMING STEP 7 \\nSince one of the BI decision-support objectives is to eliminate inconsistencies, the'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 222}, page_content='source data must be standardized. Standardization invariably results in changing \\nmuch of the source data. Changes may include renaming the data, splitting one \\nsource data element into multiple target columns, or populating one target col- \\numn from multiple source data elements. It can also mean translating codes into \\nmnemonics, standardizing (changing) data values, and filtering out inappropri- \\nate or invalid data. In the end, business people will not be able to reconcile their'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 222}, page_content='operational source data to the BI target data unless they have a trace of these \\nchanges. This trace is called meta data, and business people need it to navigate \\neffectively through the BI decision-support environment. \\nWithout meta data, the business people would have a difficult time under- \\nstanding and using the transformed data in the BI target databases. It would be as \\nfrustrating as aimlessly driving a car for weeks or months without a map, guess-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 222}, page_content='ing your way to your destination. Once the business people perceive the BI appli- \\ncation as difficult to use or they think the BI data is unreliable because it no \\nlonger matches the source data in the operational systems, they could label the BI \\ndecision-support initiative a failure.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 223}, page_content='190 Step 7: Meta Data Repository Analysis \\nBIBLIOGRAPHY AND ADDITIONAL READING \\nAdelman, Sid, and Larissa Terpeluk Moss. Data Warehouse Project Management. \\nBoston, MA: Addison-Wesley, 2000. \\nBrackett, Michael H. Data Resource Quality: Turning Bad Habits into Good Prac- \\ntices. Boston, MA: Addison-Wesley, 2000. \\n. The Data Warehouse Challenge: Taming Data Chaos. New York: John \\nWiley & Sons, 1996. \\nDevlin, Barry. Data Warehouse: From Architecture to Implementation. Reading,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 223}, page_content='MA: Addison-Wesley, 1997. \\nHackney, Douglas. Understanding and Implementing Successful Data Marts. Read- \\ning, MA: Addison-Wesley, 1997. \\nInmon, William H., J. D. Welch, and Katherine L. Glassey. Managing the Data \\nWarehouse: Practical Techniques for Monitoring Operations and Performance, \\nAdministering Data and Tools and Managing Change and Growth. New York: John \\nWiley & Sons, 1996. \\nMarco, David. Building and Managing the Meta Data Repository: A Full Lifecycle'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 223}, page_content='Guide. New York: John Wiley & Sons, 2000. \\nReingruber, Michael C., and William W. Gregory. The Data Modeling Handbook: \\nA Best-Practice Approach to Building Quality Data Models. New York: John Wiley & \\nSons, 1994, \\nRoss, Ronald G. The Business Rule Concepts. Houston, TX: Business Rule Solutions, \\nInc., 1998. \\nSimsion, Graeme. Data Modeling Essentials: Analysis, Design, and Innovation. \\nBoston, MA: International Thomson Computer Press, 1994.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 223}, page_content='Sperley, Eric. The Enterprise Data Warehouse: Planning, Building, and Implemen- \\ntation. Upper Saddle River, NJ: Prentice Hall, 1999. \\nTannenbaum, Adrienne. Metadata Solutions: Using Metamodels, Repositories, \\nXML, and Enterprise Portals to Generate Information on Demand. Boston, MA: \\nAddison-Wesley, 2002. \\nData Management Association (DAMA): http://www.dama.org \\nDM Review magazine: http://www.dmreview.com \\nEnterprise Warehousing Solutions, Inc.: http://www.EWSolutions.com'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 224}, page_content='Justification CHAPTER EIGHT \\nStep 8: Database Design \\nPlanning \\nCHAPTER OVERVIEW \\nThis chapter covers the following topics: \\nm@ Things to consider about database design \\n@ The differences in database design philosophies and in \\nbest design practices for operational databases and for Bl \\ntarget databases \\n@ The multidimensional design premise of aggregation and \\nsummarization \\n_ @ Basic explanations of a star schema and a snowflake \\nDatabase Mata Data schema \\nDesign } , |'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 224}, page_content='Design } , | \\n. @ Aspects of physical database design, including implemen- \\ntation options (such as free space and buffer space), physi- \\ncal dataset placement, partitioning, clustering, indexing, \\nreorganizations, backup and recovery, and parallel query \\nexecution \\nie \\nConstruction \\\\ / | o @ Brief descriptions of the activities involved in database \\n4 : : ro a design, the deliverables resulting from those activities, and \\nthe roles involved \\n@ The risks of not performing Step 8 \\n191'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 225}, page_content='192 Step 8: Database Design \\nTHINGS TO CONSIDER \\nReports and Queries \\n/¥ What common reporting patterns exist across departments? \\nY What level of detailed data will the business people require for drill-down \\nqueries? \\nY How much ad hoc querying against detail data do we project will occur? \\n/ How many reporting dimensions should we consider? What are they? \\n/ How many new dimensions may have to be added in the future? \\nDesign Considerations \\nV Should we store aggregated and summarized data?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 225}, page_content='Y How much concurrent usage of the data should we expect? \\nV How big will the BI target databases be? What are the projected data volumes \\nand growth factors? \\n¥Y How much historical data will we keep? \\n¥ What will be the frequency of loads? \\nV Will the databases need to be distributed? \\n¥ What are the availability requirements? \\nPerformance Considerations \\n¥ What are the performance requirements? \\nV How will we cluster the tables? By the date column or by other columns?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 225}, page_content='V What tables should be co-located? \\nVY How will we partition the tables? Will we partition by date? \\n¥ What types of indexing algorithms should we use (B-tree, hash, inverted file, \\nsparse, binary)? \\n¥Y Can we run multiple operations (queries, loads) in parallel? \\nSelection of Database Management System \\n¥ Which database management system (DBMS) are we using for our existing \\napplications? Will we use the same DBMS for the BI target databases?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 225}, page_content='Y Will our current DBMS scale to the expected size? \\nVv Are we satisfied with the current DBMS? If not, what are we doing about it? \\n¥ Will we need to license (buy) another DBMS?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 226}, page_content='Differences in Database Design Philosophies 193 \\nStaffing \\n¥ What skills do we have available to design the BI target databases? \\nV Do we have enough database administrators? \\nY Can one database administrator be dedicated to this project full-time? \\nY Does he or she have multidimensional design skills? If not, how soon can he \\nor she receive training? \\n¥ Will we need to hire a consultant to mentor the database administrator and \\nthe team?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 226}, page_content='the team? \\nBI decision-support requirements for aggregated and summarized data have \\nintroduced a new type of database design and a new way of storing data. This new \\nmultidimensional database design schema, coupled with new BI technology, sup- \\nports the ability to “slice and dice” information in myriad ways for reporting and \\nanalysis purposes. In order to implement the capabilities of slicing and dicing, \\ndatabase administrators and developers must learn new design techniques and'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 226}, page_content='must acquire a new way of working with the databases. They must begin by under- \\nstanding the ways in which the data will be accessed. Data can be accessed either \\nin a conventional way (usually detailed records retrieved with Structured Query \\nLanguage [SQL] queries) or in a multidimensional way (usually summarized \\nrecords retrieved with an online analytical processing [OLAP] tool). Multidimen- \\nsional data storage and data access techniques, which support slicing and dicing,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 226}, page_content='allow information to be viewed from a variety of perspectives, such as Products \\nby Factory by Market Segment and Market Segments by Product by Factory. \\nDIFFERENCES IN DATABASE DESIGN PHILOSOPHIES \\nThere is a completely different design philosophy behind BI target databases as \\ncompared with operational databases. Table 8.1 summarizes the differences \\nbetween these two types of databases. \\nOperational Databases \\nThe intent of operational database design is to prevent the storage of the same'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 226}, page_content='data attributes in multiple places and thus to avoid the update anomalies caused \\nby redundancy. In other words, from an operational perspective you want to'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 227}, page_content='194 Step 8: Database Design \\nTable 8.1: Operational Databases versus BI Target Databases \\nOperational Databases BI Target Databases \\n* Geared toward eliminating redundancy, = * Geared toward supporting a wide range \\ncoordinating updates, and repeating the of queries and reports. Queries and \\nsame types of operations many times a reports may vary from one business \\nday, every day (for example, airline analyst to another or from one'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 227}, page_content='reservations, deposits and withdrawals department to another. All of the queries \\nfrom bank accounts, hotel room and reports may not run on the same \\nreservations). day and may not run every day (for \\nexample, quarterly trend analysis reports \\non regional sales, monthly order \\nfulfillment report). \\n* Most of the transactional systems require Although response time is important, \\nsubsecond response time. subseconds cannot be expected. Typical \\nresponse times are seconds, minutes, or \\nhours.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 227}, page_content='hours. \\n* Highly normalized to support consistent Highly denormalized to provide quick \\nupdates and maintenance of referential retrieval of a wide range and a large \\nintegrity. amount of data. Data that belongs \\ntogether from an analytical reporting \\nperspective is usually stored together. \\n+ Store very little derived data. Data is Store large amounts of derived data. This \\nusually derived dynamically when saves time for the queries and reports. \\nneeded.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 227}, page_content='needed. \\n* Do not store historical data. Historical Store large amounts of historical data, \\nrecords are archived. often at some level of summarization, \\nbut just as often at a detailed level. \\n¢ Lightly summarized, mostly for reporting + Many levels of precalculated, \\npurposes. summarized data, from lightly \\nsummarized to highly summarized. \\navoid storing the same data in multiple columns in multiple tables so they do not'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 227}, page_content='get out of synch. Designing normalized database structures is key for developing \\nrelational databases in support of that intent. Normalization ensures that the data \\nis created, stored, and modified in a consistent, nonredundant way.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 228}, page_content='Differences in Database Design Philosophies 195 \\nMost operational systems are designed with a data-in philosophy (data \\nentry), not a data-out philosophy (reporting and querying). The objective of a \\ndata-in philosophy is to make data entry as efficient as possible, running hun- \\ndreds of thousands of transactions per day, while eliminating or minimizing \\nredundancies in the data. Data redundancy leads to inconsistencies, and incon-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 228}, page_content='sistencies are often the reason for poor-quality data. Therefore, in trying to solve \\nthe enormous data quality and data redundancy problems in operational sys- \\ntems, the goal is to avoid redundancy (except for key redundancy, which is \\nunavoidable). This goal is achieved through normalization. \\nWhile normalization works well for operational systems, the requirements \\nfor reporting are different from the requirements for data entry. Reporting uses'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 228}, page_content='data that has already been created, which means update anomalies cannot occur. \\nWhile it is of great benefit that the data is consistent and nonredundant as a result \\nof a normalized database design, that same design makes reporting difficult. For \\nexample, to create strategic trend analysis reports, many tables have to be \\naccessed, and every row in those tables has to be read. This is not only complex \\nbut also extremely inefficient when run against a normalized database design'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 228}, page_content='because it requires scanning tables and performing large multi-table JOINs. For \\nthat reason, most BI target databases are based on a multidimensional design, in \\nwhich the data for the strategic trend analysis reports is stored in a precalculated \\nand presummarized way. \\nFigure 8.1 illustrates the general difference between an operational normal- \\nized design and a BI multidimensional design. \\nInventory \\nItem \\nMonthly Regional \\nSummary Summary'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 228}, page_content='Summary Summary \\nOperational—Normalized Design Bl—Multidimensional Design \\nFigure 8.1: Operational normalized versus BI Multidimensional Designs'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 229}, page_content='196 Step 8: Database Design \\nIn this example, the operational database design shows an Order database \\nwhere customers are associated with orders, and each order is composed of many \\nline items. With each placed order, the line items have to be subtracted from a \\nseparate Inventory database. The BI target database design shows a database with \\nsummaries that are used to identify trends over time. In this design, the same \\ndata about orders, line items, and inventory may exist in multiple tables'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 229}, page_content='(Monthly Summary, Regional Summary, Product Summary), albeit summarized \\nby different dimensions. While operational databases generally store granular \\n(atomic) data, BI target databases, for the most part, store summarized data. \\nBI Target Databases \\nContrary to the data-in philosophy (data entry) of operational systems, the data- \\nout philosophy (reporting and querying) of BI applications includes the follow- \\ning design considerations.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 229}, page_content='- BI target databases are designed for simplified, high-performance data \\nretrieval, not for efficiency of data storage and maintenance (which are \\nimportant design considerations for operational databases). \\nEliminating or minimizing data redundancy is not a goal in designing BI tar- \\nget databases. If a choice must be made, data redundancy is favored over \\ncomplexity, but the redundancy must be controlled. Redundant data must be \\nconsistent and reconcilable.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 229}, page_content='Basic assumptions for designing BI target databases are listed below. \\n— Data is stored in such a manner that it is readily accessible in ways that are \\nof interest to the business people. \\n— The design is driven by access and usage. \\n— A normalized design is not necessarily intuitive for a business person and \\ncould therefore become quite complex. \\n— No BI data can be invented! All data in the BI target databases must exist in'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 229}, page_content='or be derivable from current internal or external operational data sources. \\nA key decision for all BI applications is whether or not, and at what level, to \\nstore summarized data in the BI target databases. The database administrator and \\nthe lead developer may decide to store both detailed data and summarized data, \\neither together in the same BI target database or in different BI target databases. \\nThis database design decision must be based on access and usage requirements.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 230}, page_content='Logical Database Design 197 \\nLOGICAL DATABASE DESIGN \\nBecause of the differences in intent and purpose between operational systems and \\nBI applications, different database design techniques have been devised for BI \\ntarget databases. These highly denormalized designs store aggregated and sum- \\nmarized data in a multidimensional fashion. Logical database designs are docu- \\nmented as physical data models with technical meta data.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 230}, page_content='Aggregation and summarization are probably the most significant contribu- \\ntors to good BI application performance. If most business analysts need to see \\ntheir data summarized, these totals should be precalculated and stored for quick \\nretrieval. It is important to discuss the level of granularity with the business rep- \\nresentative, as well as with other business analysts who will be using the BI target \\ndatabases, since they will expect the database design to allow them to drill down'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 230}, page_content='to a certain level of detail. \\nMultidimensional database designs support the quick retrieval of a wide \\nrange of data. Two popular multidimensional design techniques are the star \\nschema and the snowflake schema, both described below. \\nThe Star Schema \\nIn a star schema, data is represented as an array of precalculated values, called \\nfacts, around which analysis is performed. These precalculated facts represent \\natomic operational data values that have been presummarized by certain dimen-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 230}, page_content='sions, such as customer, product, and time. A dimension in a star schema is simi- \\nlar to an entity in a logical data model: it is a business object about which data is \\ncollected for business purposes. \\nThe star schema mirrors the view of a business query. As the name implies, \\nthe star schema has a single object in the middle, called the fact table, which is \\nconnected in a radial fashion to a number of objects, called dimension tables. Fig- \\nure 8.2 presents an example of a star schema.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 230}, page_content='A star schema has two, and only two, levels: the fact table and a series of sin- \\ngle-level dimension tables. Fact tables have the following characteristics: \\n- A fact table represents a critical business event (a business activity or transac- \\ntion, such as a sale or a claim). \\n- The facts are the quantifiable aspects of the business event; that is, they are \\ncolumns in the fact table.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 231}, page_content='Step 8: Database Design \\nPR ST SE TI EES LE ATE TELE \\nTIME PRODUCT \\nTime ID \\nDay of Week \\nWeek of Month \\nMonth \\nYear \\nCentury \\nSeason Name \\nTime ID \\nStore ID \\nProduct ID \\nCustomer ID \\nDollar Sales \\nUnit Sales \\nPayment Type Store ID \\nStore Address \\nSquare Feet \\nDistrict Name \\nDistrict Location \\nRegion Code \\nRegion Manager \\nFigure 8.2: Star Schema \\nProduct ID \\nProduct Name \\nProduct Category \\nProduct Price \\nProduct Size \\nProduct Color \\nCUSTOMER \\nCustomer ID \\nCustomer Name \\nCustomer Phone'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 231}, page_content='Customer Phone \\nCustomer Income \\nCustomer Age \\nCustomer Gender \\n: A fact table links to its related dimension tables (business objects, such as cus- \\ntomer or product). \\nA fact table has a long composite key comprised of the primary keys of the \\nrelated dimension tables (which are foreign keys in the fact table). \\nA number of highly redundant fact tables may exist for a given subject area. \\nEach fact table could contain a different aggregation level of the same data. \\nFor example:'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 231}, page_content='For example: \\n— Sales facts by store by region by date \\n— Sales facts by product by store by date \\n— Sales facts by customer by region by date \\nFact tables are long and narrow: the tables have an immense number of rows \\n(long), but there are relatively few columns in the tables (narrow). \\nDimension tables have very different characteristics. \\nDimension tables are business objects, which represent the different perspec- \\ntives from which the facts in a fact table can be viewed and analyzed.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 231}, page_content='from a specific business perspec \\ntogether into one table. This pro \\nacceptable in this design schema. \\nDimension tables usually have a one-attribute primary key. \\nDimension tables are denormalized, which means that data belonging together \\ntive, such as a roll-up hierarchy, is grouped \\nduces some redundant data values, which is'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 232}, page_content='Logical Database Design 199 \\nDimension tables are short and wide: the tables have relatively few rows \\n(short), but there are many columns in the tables (wide). \\nWhenever possible, dimension tables should be shared by the fact tables \\n(conformed dimensions). \\nOne dimension is always a time dimension with attributes describing the \\ntimestamp, such as calendar year, quarter, season, fiscal period, or accounting \\nperiod. Some other examples of common dimension tables are customer,'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 232}, page_content='product, policy, sales representative, region, and store. \\nMost multidimensional DBMSs effectively deal with the optimization of large \\nmulti-table JOINs. One method for determining whether the DBMS is resolving \\nthe query efficiently is to look at the optimized plan for the query. For example: \\nIf the fact table is the last table JOINed, this is an indicator of optimization. If \\nthe fact table appears to be somewhere in the middle, or even somewhere'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 232}, page_content='toward the beginning, the DBMS may not be resolving the JOIN optimally, \\nunless it uses more sophisticated JOIN algorithms. \\nIf the DBMS does not use Cartesian product JOINs, the DBMS may take the \\nqualifying row keys and apply them against a composite fact table index, or it \\nmay apply them via an index intersection against multiple fact table single- \\ncolumn indices. \\nIn either case, verify that your DBMS is executing multidimensional queries in'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 232}, page_content='the most efficient manner since your performance depends on it. \\nThe star schema is the most popular database design schema for BI applica- \\ntions for a variety of reasons. \\nIt yields the best performance for trend analysis queries and reports that \\ninclude years of historical data. \\nIt provides maximum flexibility for multidimensional data analysis. \\nIt is supported by most of the relational DBMS vendors with modifications to \\ntheir DBMS optimizer.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 232}, page_content='Its simplicity makes complex data analysis much less difficult than with a stan- \\ndard normalized design. It is much easier to ask questions such as the following: \\n— Which insurance broker is giving us the most or the least lucrative business? \\n— What are the most frequently occurring types of claims from this insurance \\nbroker? \\n— When are these claims occurring?'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 233}, page_content='200 Step 8: Database Design \\nThe preceding questions are typical drill-down questions (asking for more \\ndetailed data) and typical roll-up questions (asking for more summarized data). \\nThe Snowflake Schema \\nA snowflake schema is a variation of a star schema, except in a snowflake the \\npoints of the star radiate into more points, as shown in Figure 8.3. \\nIn snowflake schemas, the levels of the hierarchies in the dimension tables are'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 233}, page_content='normalized, thereby increasing the number of tables. Table 8.2 lists the advan- \\ntages and disadvantages of snowflake schemas. \\nTIME \\nTime ID \\nDistrict ID \\nREGION District Name \\nDistrict Location \\nRegion ID \\nDistrict ID \\nRegion ID \\nRegion Code \\nRegion Manager \\nFigure 8.3: Snowflake Schema \\nTable 8.2: Advantages and Disadvantages of Snowflake Schemas \\nAdvantages Disadvantages \\nPRODUCT \\nProduct ID \\nDay of Week Product Name \\nWeek of Month Product Category \\nMonth Product Price'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 233}, page_content='Year FACT Product Size \\nCentury Time ID Product Color \\nSeason Name Store ID \\nProduct ID \\nCustomer ID \\nSTORE poate. CUSTOMER Unit Sales \\nStore ID Payment Type Customer ID \\nDISTRICT Store Address Customer Name \\nSquare Feet Customer Phone \\nCustomer Income \\nCustomer Age \\nCustomer Gender \\n* The size of the dimension tables is \\nreduced and data value redundancy is \\navoided because parent-child hierarchies \\nare no longer collapsed. JOINS. \\n* The increased number of tables may'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 233}, page_content='adversely affect query performance \\nbecause of the necessary additional \\n* Application flexibility is increased. ¢ Database maintenance effort is increased \\nbecause there are more tables to maintain.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 234}, page_content='Physical Database Design 201 \\nPHYSICAL DATABASE DESIGN \\nBecause BI applications usually require operational detailed data as well as sum- \\nmarized data, and because they often need to store some or all of that data redun- \\ndantly, the size of some BI target databases can be enormous. Databases approaching \\nor exceeding one terabyte of data are called very large databases (VLDBs). Design- \\ning VLDBs is a big challenge, and the day-to-day chores of maintaining these'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 234}, page_content='VLDBs are demanding. Many difficult physical design decisions need to be made, \\nand some highly effective performance enhancements need to be used. The fol- \\nlowing sections present some suggested guidelines. \\nImplementation Options \\nAlmost every DBMS lets the database administrator choose from a number of \\nimplementation options. Give considerable attention to selecting the right \\noptions when implementing a BI target database. It takes experience to know'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 234}, page_content='which combination of options will meet the desired performance level. Imple- \\nmentation decisions include the following: \\n* How much free space to choose \\n* How much buffer space to declare \\n* How large to set the blocksize \\n* Whether to use any compaction technique \\nPhysical Dataset Placement \\nAnother basic issue that affects performance is the placement of the datasets. \\nMethods for achieving fast response include combinations of: \\n* Storing frequently referenced data on fast devices.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 234}, page_content='* Storing different aggregation levels on different platforms. For performance \\nreasons, it may be necessary to store aggregate data on distributed midrange \\nservers while keeping detail data on the mainframe. \\n* Striping disks in an interleaved fashion to optimize input/output (I/O) con- \\ntroller usage. Using lots of small disks instead of a few large disks, separating \\nthose disks onto separate controllers, and writing the data across devices \\nincreases I/O throughput.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 234}, page_content='- Placing datasets in a way that lengthy seeks are avoided when possible.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 235}, page_content='202 Step 8: Database Design \\n- Selecting address and search schemes that require few seeks, preferably only \\none per retrieval. \\n* Running multiple operations in parallel. \\nAlso consider whether to separate indices from data and put them on separate disks. \\nPartitioning \\nEnsure that tables are partitioned effectively across multiple disks. This is partic- \\nularly important for VLDBs where fact tables can reach several hundred'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 235}, page_content='gigabytes. Partitioning allows the data of one “logical” table to be spread across \\nmultiple physical datasets. The physical data distribution is based on a partition- \\ning column, which is most commonly date. Since a partitioning column must be \\npart of the table’s primary key, the partitioning column cannot be a derived col- \\numn, and it cannot contain NULL values. Partitioning enables you to back up \\nand restore a portion of a table without impacting the availability of other por-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 235}, page_content='tions of the same table that are not being backed up or restored. \\nClustering \\nDefine cluster table requirements, and physically co-locate related tables on the \\ndisk drive. Clustering is a very useful technique for sequential access of large \\namounts of data. Clustering is accomplished through clustering indices that \\ndetermine in which sequential order the rows in the tables are physically stored in \\nthe datasets. Ideally, you want to cluster the primary key of each table to avoid'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 235}, page_content='page splits, that is, to make sure that new rows inserted into the tables will be \\nstored sequentially on the disk according to the columns in their clustering index. \\nUsing this technique can dramatically improve performance because sequential \\naccess of data is the norm in BI applications. When the rows of a table are no \\nlonger stored in the same order as its clustering index (data fragmentation), per- \\nformance will suffer and the table has to be reorganized. \\nIndexing'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 235}, page_content='Indexing \\nThere are two extreme indexing strategies, neither of which is advisable: one \\nstrategy is to index everything, and the other is to index nothing. Instead of veer- \\ning to these extremes, index those columns that are frequently searched and that \\nhave a high distribution in values, such as Account Open Date. Do not index col- \\numns that have a low distribution in values, such as Gender Code.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 236}, page_content='Physical Database Design 203 \\nOnce you have decided which columns to index, determine the index strategy \\nto use. Most DBMSs provide several access methods to choose from, either \\nsequential access or direct access using any of the following well-known indexing \\nalgorithms: \\n* B-tree \\n* Hash \\n* Inverted file \\n* Sparse \\n* Binary \\nConsult with your DBMS vendor to choose the most optimum access \\nmethod (indexing algorithm) for the DBMS product you are using. \\nReorganizations'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 236}, page_content='Reorganizations \\nOccasionally you will need to reorganize the databases because incremental loads \\nwill fragment the datasets over time, and inserted rows will no longer be stored in \\na logical sequence. This fragmentation may result in long data retrieval chains, \\nand performance can drop off significantly. Most DBMSs provide reorganization \\nroutines to rearrange the fragmented database in order to reclaim space occupied'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 236}, page_content='by deleted data or to move records from overflow areas into free space in prime \\ndata areas. \\nThe basic activities involved in reorganizing a database are to copy the old \\ndatabase onto another device, reblock the rows, and reload them. This is not a \\ntrivial effort for BI target databases. The good news is that all DBMSs can per- \\nform a partial reorganization routine on database partitions, which is another \\nreason for the database administrator to partition the BI target databases.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 236}, page_content='Backup and Recovery \\nSince software and hardware may fail, it is necessary to establish backup and \\nrecovery procedures. DBMSs provide utilities to take full backups as well as incre- \\nmental backups. Many organizations are under the misguided impression that \\nthe BI target databases can always be recreated from the original source data. \\nThey neglect to realize that it may take a very long time to recreate the BI target'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 236}, page_content='databases if they have to rerun all the initial and historical extract/transform/load \\n(ETL) programs—assuming the original source files are still available.'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 237}, page_content='204 Step 8: Database Design \\nDisaster recovery is also an issue for BI applications. If the backup tapes or \\ncartridges are destroyed during a disaster, it could be difficult to recreate your BI \\ntarget databases, and it could take a very long time (if recovery is possible at all). \\nFor this reason, many companies choose to store their database backups in \\nremote locations. \\nParallel Query Execution \\nTo improve the performance of a query, break down a single query into compo-'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 237}, page_content='nents to be run concurrently. Some DBMS products offer transparent parallel \\nexecution, which means you do not need to know how to break down a query \\ninto components because the DBMS does it for you. Performance is greatly \\nincreased when multiple portions of one query run in parallel on multiple pro- \\ncessors. Other applications of parallel query execution are loading tablespace par- \\ntitions, building indices, and scanning or sorting tables. Parallel processing is a'),\n",
       " Document(metadata={'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf', 'page': 237}, page_content='very important concept for BI applications and should be considered whenever \\npossible. \\nDATABASE DESIGN ACTIVITIES \\nThe activities for database design do not need to be performed linearly. Figure 8.4 \\nindicates which activities can be performed concurrently. The list below briefly \\ndescribes the activities associated with Step 8, Database Design. \\n1. Review the data access requirements. \\nThe database administrator must review the data access and analysis require-'),\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd4d9694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78ea0671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the Embeddings from Hugging Face\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fbb5891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anil Kumar\\AppData\\Local\\Temp\\ipykernel_11908\\1196424635.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51958971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab6971ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03447727859020233,\n",
       " 0.031023195013403893,\n",
       " 0.0067350007593631744,\n",
       " 0.02610897831618786,\n",
       " -0.03936203941702843,\n",
       " -0.16030246019363403,\n",
       " 0.06692393869161606,\n",
       " -0.006441489793360233,\n",
       " -0.04745043069124222,\n",
       " 0.014758850447833538,\n",
       " 0.07087530940771103,\n",
       " 0.05552756413817406,\n",
       " 0.019193332642316818,\n",
       " -0.026251299306750298,\n",
       " -0.010109570808708668,\n",
       " -0.026940522715449333,\n",
       " 0.022307388484477997,\n",
       " -0.022226659581065178,\n",
       " -0.1496925801038742,\n",
       " -0.017493056133389473,\n",
       " 0.00767620699480176,\n",
       " 0.05435231328010559,\n",
       " 0.003254441311582923,\n",
       " 0.03172589838504791,\n",
       " -0.08462132513523102,\n",
       " -0.02940601296722889,\n",
       " 0.0515955425798893,\n",
       " 0.048124007880687714,\n",
       " -0.003314810572192073,\n",
       " -0.05827917903661728,\n",
       " 0.04196931794285774,\n",
       " 0.022210605442523956,\n",
       " 0.12818878889083862,\n",
       " -0.022338947281241417,\n",
       " -0.011656264774501324,\n",
       " 0.06292837113142014,\n",
       " -0.03287631645798683,\n",
       " -0.09122605621814728,\n",
       " -0.031175334006547928,\n",
       " 0.052699584513902664,\n",
       " 0.04703482240438461,\n",
       " -0.0842030793428421,\n",
       " -0.030056186020374298,\n",
       " -0.020744839683175087,\n",
       " 0.009517842903733253,\n",
       " -0.0037218458019196987,\n",
       " 0.007343307137489319,\n",
       " 0.03932436555624008,\n",
       " 0.0932740718126297,\n",
       " -0.0037886016070842743,\n",
       " -0.052742063999176025,\n",
       " -0.058058205991983414,\n",
       " -0.0068643661215901375,\n",
       " 0.005283276084810495,\n",
       " 0.0828929916024208,\n",
       " 0.01936279982328415,\n",
       " 0.00628449534997344,\n",
       " -0.01033071894198656,\n",
       " 0.009032391011714935,\n",
       " -0.037683695554733276,\n",
       " -0.04520602896809578,\n",
       " 0.024016322568058968,\n",
       " -0.006944161839783192,\n",
       " 0.01349164079874754,\n",
       " 0.10005493462085724,\n",
       " -0.07168395817279816,\n",
       " -0.02169514261186123,\n",
       " 0.031618449836969376,\n",
       " -0.05163465440273285,\n",
       " -0.08224768936634064,\n",
       " -0.06569328159093857,\n",
       " -0.009895364753901958,\n",
       " 0.0058164168149232864,\n",
       " 0.07355453819036484,\n",
       " -0.034050315618515015,\n",
       " 0.02488609403371811,\n",
       " 0.014488139189779758,\n",
       " 0.026457395404577255,\n",
       " 0.00965672917664051,\n",
       " 0.03021724708378315,\n",
       " 0.052803948521614075,\n",
       " -0.07535989582538605,\n",
       " 0.009897196665406227,\n",
       " 0.029836809262633324,\n",
       " 0.01755565032362938,\n",
       " 0.023091943934559822,\n",
       " 0.0019338717684149742,\n",
       " 0.0014001894742250443,\n",
       " -0.04717593267560005,\n",
       " -0.011194330640137196,\n",
       " -0.11420140415430069,\n",
       " -0.019811946898698807,\n",
       " 0.0402662418782711,\n",
       " 0.002192963380366564,\n",
       " -0.07979224622249603,\n",
       " -0.025382302701473236,\n",
       " 0.09448298811912537,\n",
       " -0.028981076553463936,\n",
       " -0.1450026035308838,\n",
       " 0.23097744584083557,\n",
       " 0.027731148526072502,\n",
       " 0.032111503183841705,\n",
       " 0.031065041199326515,\n",
       " 0.042832810431718826,\n",
       " 0.06423773616552353,\n",
       " 0.03216316178441048,\n",
       " -0.004876782186329365,\n",
       " 0.05569944158196449,\n",
       " -0.03753238543868065,\n",
       " -0.02150549180805683,\n",
       " -0.02834264002740383,\n",
       " -0.028846895322203636,\n",
       " 0.03835306689143181,\n",
       " -0.017468618229031563,\n",
       " 0.052485328167676926,\n",
       " -0.07487602531909943,\n",
       " -0.031259745359420776,\n",
       " 0.021841585636138916,\n",
       " -0.03989573195576668,\n",
       " -0.008587098680436611,\n",
       " 0.026956548914313316,\n",
       " -0.04849553108215332,\n",
       " 0.011469858698546886,\n",
       " 0.02961823344230652,\n",
       " -0.020572161301970482,\n",
       " 0.013103851117193699,\n",
       " 0.02883346751332283,\n",
       " -3.194199819506188e-33,\n",
       " 0.06478208303451538,\n",
       " -0.018130233511328697,\n",
       " 0.05178995802998543,\n",
       " 0.12198270857334137,\n",
       " 0.028780125081539154,\n",
       " 0.008721953257918358,\n",
       " -0.07052117586135864,\n",
       " -0.016907276585698128,\n",
       " 0.040739696472883224,\n",
       " 0.0421161912381649,\n",
       " 0.025447219610214233,\n",
       " 0.03574623540043831,\n",
       " -0.04914480820298195,\n",
       " 0.002129069995135069,\n",
       " -0.015546540729701519,\n",
       " 0.05073061212897301,\n",
       " -0.0481853149831295,\n",
       " 0.03588062524795532,\n",
       " -0.004067050293087959,\n",
       " 0.10172471404075623,\n",
       " -0.055970001965761185,\n",
       " -0.010681054554879665,\n",
       " 0.011235776357352734,\n",
       " 0.09068655967712402,\n",
       " 0.004234483931213617,\n",
       " 0.03513865917921066,\n",
       " -0.009702853858470917,\n",
       " -0.09386517852544785,\n",
       " 0.0928555428981781,\n",
       " 0.008004956878721714,\n",
       " -0.007705432828515768,\n",
       " -0.05208674445748329,\n",
       " -0.01258798222988844,\n",
       " 0.003266932675614953,\n",
       " 0.006013541016727686,\n",
       " 0.007581572514027357,\n",
       " 0.010517138056457043,\n",
       " -0.08634554594755173,\n",
       " -0.06987877190113068,\n",
       " -0.002533965278416872,\n",
       " -0.09097656607627869,\n",
       " 0.04688730463385582,\n",
       " 0.052076514810323715,\n",
       " 0.007193834520876408,\n",
       " 0.010903686285018921,\n",
       " -0.005229517351835966,\n",
       " 0.013937318697571754,\n",
       " 0.021968355402350426,\n",
       " 0.03420857712626457,\n",
       " 0.060224682092666626,\n",
       " 0.00011670673848129809,\n",
       " 0.0147319957613945,\n",
       " -0.07008929550647736,\n",
       " 0.02849906124174595,\n",
       " -0.02760162204504013,\n",
       " 0.010768426582217216,\n",
       " 0.034830935299396515,\n",
       " -0.02248784527182579,\n",
       " 0.00976906530559063,\n",
       " 0.07722777873277664,\n",
       " 0.02158840000629425,\n",
       " 0.11495620757341385,\n",
       " -0.0680011659860611,\n",
       " 0.023761052638292313,\n",
       " -0.0159839428961277,\n",
       " -0.017826968804001808,\n",
       " 0.06439490616321564,\n",
       " 0.03202574700117111,\n",
       " 0.050270289182662964,\n",
       " -0.00591370090842247,\n",
       " -0.033708006143569946,\n",
       " 0.01784026436507702,\n",
       " 0.016573334112763405,\n",
       " 0.06329652667045593,\n",
       " 0.03467720374464989,\n",
       " 0.04647340252995491,\n",
       " 0.09790612757205963,\n",
       " -0.006635523401200771,\n",
       " 0.025207122787833214,\n",
       " -0.07798831164836884,\n",
       " 0.01692642644047737,\n",
       " -0.0009458051645196974,\n",
       " 0.022471899166703224,\n",
       " -0.03825320675969124,\n",
       " 0.09570478647947311,\n",
       " -0.005350811406970024,\n",
       " 0.010469130240380764,\n",
       " -0.11524051427841187,\n",
       " -0.013262511231005192,\n",
       " -0.01070948876440525,\n",
       " -0.0831172838807106,\n",
       " 0.07327359169721603,\n",
       " 0.04939224198460579,\n",
       " -0.00899436790496111,\n",
       " -0.09584558010101318,\n",
       " 3.3661496637765335e-33,\n",
       " 0.12493180483579636,\n",
       " 0.019349727779626846,\n",
       " -0.05822576582431793,\n",
       " -0.0359882190823555,\n",
       " -0.050746794790029526,\n",
       " -0.04566240310668945,\n",
       " -0.0826033279299736,\n",
       " 0.1481948345899582,\n",
       " -0.08842115849256516,\n",
       " 0.0602744035422802,\n",
       " 0.051030147820711136,\n",
       " 0.010303161107003689,\n",
       " 0.14121423661708832,\n",
       " 0.03081386908888817,\n",
       " 0.061033107340335846,\n",
       " -0.052851222455501556,\n",
       " 0.13664893805980682,\n",
       " 0.009189913049340248,\n",
       " -0.01732524298131466,\n",
       " -0.012848681770265102,\n",
       " -0.007995298132300377,\n",
       " -0.050980038940906525,\n",
       " -0.05235063657164574,\n",
       " 0.007593035697937012,\n",
       " -0.015166332013905048,\n",
       " 0.01696031540632248,\n",
       " 0.021270543336868286,\n",
       " 0.02055801823735237,\n",
       " -0.12002810835838318,\n",
       " 0.01446179486811161,\n",
       " 0.02675991877913475,\n",
       " 0.02533069998025894,\n",
       " -0.042754653841257095,\n",
       " 0.006768454797565937,\n",
       " -0.014458565041422844,\n",
       " 0.04526202380657196,\n",
       " -0.09147650003433228,\n",
       " -0.019439103081822395,\n",
       " -0.017833510413765907,\n",
       " -0.05491011589765549,\n",
       " -0.05264107510447502,\n",
       " -0.01045909058302641,\n",
       " -0.05201606824994087,\n",
       " 0.020891984924674034,\n",
       " -0.07997031509876251,\n",
       " -0.012111318297684193,\n",
       " -0.05773138627409935,\n",
       " 0.023178258910775185,\n",
       " -0.008031727746129036,\n",
       " -0.025989310815930367,\n",
       " -0.07995673269033432,\n",
       " -0.020728876814246178,\n",
       " 0.048817701637744904,\n",
       " -0.02038918063044548,\n",
       " -0.04917660728096962,\n",
       " 0.014159666374325752,\n",
       " -0.06362208724021912,\n",
       " -0.007807414513081312,\n",
       " 0.016431523486971855,\n",
       " -0.02568252757191658,\n",
       " 0.01338119339197874,\n",
       " 0.026248816400766373,\n",
       " 0.00997838657349348,\n",
       " 0.06322891265153885,\n",
       " 0.0026721819303929806,\n",
       " -0.006582723930478096,\n",
       " 0.016631903126835823,\n",
       " 0.03236641362309456,\n",
       " 0.03794247284531593,\n",
       " -0.03637607395648956,\n",
       " -0.006910870783030987,\n",
       " 0.00015973052359186113,\n",
       " -0.0016335236141458154,\n",
       " -0.027278190478682518,\n",
       " -0.028038104996085167,\n",
       " 0.04968145489692688,\n",
       " -0.028867211192846298,\n",
       " -0.0024179802276194096,\n",
       " 0.014774898067116737,\n",
       " 0.00976458378136158,\n",
       " 0.005797632969915867,\n",
       " 0.013486168347299099,\n",
       " 0.0055678836070001125,\n",
       " 0.0372270792722702,\n",
       " 0.0072325291112065315,\n",
       " 0.040156178176403046,\n",
       " 0.08150330930948257,\n",
       " 0.07199162989854813,\n",
       " -0.013056146912276745,\n",
       " -0.04288206994533539,\n",
       " -0.011011242866516113,\n",
       " 0.004897794686257839,\n",
       " -0.009229745715856552,\n",
       " 0.035191502422094345,\n",
       " -0.05103505030274391,\n",
       " -1.571437557856825e-08,\n",
       " -0.08862437307834625,\n",
       " 0.023909324780106544,\n",
       " -0.016238702461123466,\n",
       " 0.03170046955347061,\n",
       " 0.027284231036901474,\n",
       " 0.05246885493397713,\n",
       " -0.047070953994989395,\n",
       " -0.05884741619229317,\n",
       " -0.0632082000374794,\n",
       " 0.040888555347919464,\n",
       " 0.049828026443719864,\n",
       " 0.10655169188976288,\n",
       " -0.0745023563504219,\n",
       " -0.012495414353907108,\n",
       " 0.01837071031332016,\n",
       " 0.03947410359978676,\n",
       " -0.02479788102209568,\n",
       " 0.01451626792550087,\n",
       " -0.03706921637058258,\n",
       " 0.020015697926282883,\n",
       " -4.857365638599731e-05,\n",
       " 0.009866541251540184,\n",
       " 0.02483879029750824,\n",
       " -0.05245817080140114,\n",
       " 0.029314158484339714,\n",
       " -0.08719190210103989,\n",
       " -0.014499804005026817,\n",
       " 0.026019113138318062,\n",
       " -0.01874629780650139,\n",
       " -0.07620517164468765,\n",
       " 0.03504331782460213,\n",
       " 0.10363949090242386,\n",
       " -0.028050526976585388,\n",
       " 0.012718189507722855,\n",
       " -0.07632551342248917,\n",
       " -0.018652359023690224,\n",
       " 0.024976713582873344,\n",
       " 0.08144530653953552,\n",
       " 0.06875885277986526,\n",
       " -0.0640566349029541,\n",
       " -0.08389381319284439,\n",
       " 0.06136239692568779,\n",
       " -0.033545564860105515,\n",
       " -0.10615334659814835,\n",
       " -0.040080562233924866,\n",
       " 0.03253018856048584,\n",
       " 0.07662485539913177,\n",
       " -0.07301626354455948,\n",
       " 0.0003375968663021922,\n",
       " -0.040871623903512955,\n",
       " -0.0757884755730629,\n",
       " 0.027527621015906334,\n",
       " 0.07462543994188309,\n",
       " 0.01771729066967964,\n",
       " 0.0912184864282608,\n",
       " 0.11022017151117325,\n",
       " 0.0005698121385648847,\n",
       " 0.05146332457661629,\n",
       " -0.014551322907209396,\n",
       " 0.033232010900974274,\n",
       " 0.023792298510670662,\n",
       " -0.02288983389735222,\n",
       " 0.038937509059906006,\n",
       " 0.030206825584173203]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8836df24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01a4ec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=os.environ.get('pcsk_6w34RU_SJY478JxddiVhBaPxwB4yGb5D2MFpD7cZ8YRWB4XPGc18dAMCrnqSQngGWythU3')\n",
    "GOOGLE_API_KEY= os.environ.get('AIzaSyCblvDS5Z6QNzzAAFGxulWiRsqy1Bor3Mw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0104da03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to index: scholar-ai\n"
     ]
    }
   ],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone \n",
    "index_name = \"scholar-ai\"\n",
    "index = pc.Index(index_name)\n",
    "print(f\"Successfully connected to index: {index_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "79da4885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"pcsk_6w34RU_SJY478JxddiVhBaPxwB4yGb5D2MFpD7cZ8YRWB4XPGc18dAMCrnqSQngGWythU3\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCblvDS5Z6QNzzAAFGxulWiRsqy1Bor3Mw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f61ffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "73f05af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Existing index \n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8ed33d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x1d712240a10>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e402311",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3e1bc28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"business intelligence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d28751a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 2.0, 'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf'}, page_content='Business Intelligence Roadmap'),\n",
       " Document(metadata={'page': 579.0, 'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf'}, page_content='r e/Data Warehousing \\nBusiness Intelligence Roadmap \\nMoss ¢ Atre \\n“If you are looking for a complete treatment of business intelligence, then go no further than this book. Larissa \\nT. Moss and Shaku Atre have covered all the bases in a cohesive and logical order, making it easy for the reader \\nto follow their line of thought. From early design to ETL to physical database design, the book ties together all \\nthe components of business intelligence.” \\n—Bill Inmon, Inmon Enterprises'),\n",
       " Document(metadata={'page': 7.0, 'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf'}, page_content='The idea of a book was conceived owing to the demand by students and instructor fraternities alike, for \\na book which includes a comprehensive coverage of business intelligence, data warehousing, analytics \\nand its business applications. \\nSalient Features of the Book\\nThe following are few salient features of the book:\\n • The book promises to be a single source of introductory knowledge on business intelligence'),\n",
       " Document(metadata={'page': 410.0, 'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf'}, page_content='businesses set out to achieve such as increase in customer base, increased market share, increase in pro-\\nductivity, increase in profitability, retention of employees, etc.\\nBusiness Intelligence (BI): Business Intelligence is about making available the right information in the \\nright format at the right time to the right decision makers. It supports fact-based decision making. It \\nfocuses on ensuring “single version of truth”. BI helps provide 360 degree perspective on the business.'),\n",
       " Document(metadata={'page': 20.0, 'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf'}, page_content='their “roadmap”; as the subtitle of their book promises, they have provided a \\ncomplete project lifecycle for the development of such systems. Because BI and \\ndecision-support systems ultimately rely on a rich treasure trove of data, there is a \\nsignificant emphasis in Business Intelligence Roadmap on various technical \\naspects of data: meta data, data mining, data warehousing, multidimensional \\ndata analysis (online analytical processing [OLAP]), data security, and so on. But'),\n",
       " Document(metadata={'page': 579.0, 'source': 'D:\\\\scholar-aI\\\\Data\\\\Business Intelligence Roadmap - The Complete Project -- Larissa T. Moss; Shaku Atre; Edward Yourdon -- ( WeLib.org ).pdf'}, page_content='Business Intelligence Roadmap is a clear and comprehensive guide to negotiating the complexities inherent in \\nthe development of valuable business intelligence decision-support applications. \\nShaku Atre \\nPresident, Atre Group, Inc. \\nhttp://www.atre.com \\nLarissa T. Moss \\nPresident, Method Focus, Inc. \\nhttp://www.methodfocus.com \\nhttp://www.awprofessional.com \\nCover photograph by Digital Vision \\n€ Text printed on recycled paper \\nvv Addison-Wesley \\nPearson Education'),\n",
       " Document(metadata={'page': 111.0, 'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf'}, page_content='What’s in store\\nYou are now familiar with the big picture of a business enterprise and the role of IT in an enterprise. You \\ncan also now distinguish between OLTP and OLAP systems. Let’s get to the heart of the subject matter \\nof this book, viz., analytics that support business decisions. This is also referred to as Business Intelligence.\\nIn this chapter we will familiarize you with the definition of Business Intelligence and the associated'),\n",
       " Document(metadata={'page': 147.0, 'source': 'D:\\\\scholar-aI\\\\Data\\\\Fundamentals of Business Analytics, 2ed -- R N Prasad, Seema Acharya -- ( WeLib.org ).pdf'}, page_content='or intelligence from data assets like data warehouses/data marts. Using BI tools, we can generate strategic, \\nfinancial, customer, or risk intelligence. This information can be obtained through various BI applica-\\ntions, such as DSS (decision support system), EIS (executive information system), OLAP (on-line \\nanalytical processing), data mining and discovery, etc.\\nFew of the BI applications are discussed in the section “Business Intelligence Applications” later in \\nthis chapter.')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "168453ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# Using 'gemini-2.5-flash' model for its speed and capability in RAG tasks.\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3e0665c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dff7fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "927e311c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business Intelligence involves decision-support applications that help companies react faster to changing market conditions. This is achieved by integrating BI into operational processes. The field also encompasses data warehousing and analytics.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"what is businees intelligence\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8a6d5b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Justification Stage is the first stage in the engineering project. Within this stage, the primary step identified is \"Step 1: Business Case Assessment.\" This step involves defining the business problem or opportunity and proposing a BI solution, ensuring it is cost-justified and clearly defines benefits.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What are the differnt stage inJustification Stage ?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scholar-aI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
